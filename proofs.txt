===============================
Question: <p>I have read a few proofs that $\sqrt{2}$ is irrational.</p>

<p>I have never, however, been able to really grasp what they were talking about.</p>

<p>Is there a simplified proof that $\sqrt{2}$ is irrational?</p>

 
Answer: <p>You use a proof by contradiction. Basically, you suppose that $\sqrt{2}$ can be written as $p/q$. Then you know that $2q^2 = p^2$. However, both $q^2$ and $p^2$ have an even number of factors of two, so $2q^2$ has an odd number of factors of 2, which means it can't be equal to $p^2$.</p>

==============================
===============================
Question: <p>I'm told by <em>smart people</em> that
$$0.999999999\dots=1$$
and I believe them, but is there a proof that explains why this is?</p>

 
Answer: <p>What does it mean when you refer to $.99999\ldots$?  Symbols don't mean anything in particular until you've <em>defined what you mean by them</em>.</p>

<p>In this case the definition is that you're taking the limit of $.9$, $.99$, $.999$, $.9999$, etc.  What does it mean to say that limit is $1$?  Well, it means that no matter how small a number $x$ you pick, I can show you a point in that sequence such that all further numbers in the sequence are within distance $x$ of $1$.  But certainly whatever number you chose your number is bigger than $10^{-k}$ for some $k$.  So I can just pick my point to be the $k$th spot in the sequence.</p>

<p>A more intuitive way of explaining the above argument is that the reason $.99999\ldots = 1$ is that their difference is zero.  So let's subtract $1.0000\ldots -.99999\ldots = .00000\ldots = 0$.  That is, </p>

<p>$1.0 -.9 = .1$</p>

<p>$1.00-.99 = .01$</p>

<p>$1.000-.999=.001$, </p>

<p>$\ldots$</p>

<p>$1.000\ldots -.99999\ldots = .000\ldots = 0$</p>

==============================
===============================
Question: <p>I've come across statements in the past along the lines of "function $f(x)$ has no closed form integral", which I assume means that there is no combination of the operations:</p>

<ul>
<li>addition/subtraction</li>
<li>multiplication/division</li>
<li>raising to powers and roots</li>
<li>trigonometric functions</li>
<li>exponential functions</li>
<li>logarithmic functions</li>
</ul>

<p>which when differentiated gives the function $f(x)$. I've heard this said about the function $f(x) = x^x$, for example.</p>

<p>What sort of techniques are used to prove statements like this? What is this branch of mathematics called?</p>

<hr>

<p>Merged with "<a href="https://math.stackexchange.com/questions/2328/">How to prove that some functions don't have a primitive</a>" by <a href="https://math.stackexchange.com/users/918/ismael">Ismael</a>:  </p>

<p>Sometimes we are told that some functions like $\sin(x)/x$ don't have a indefinite integral, or that it can't be expressed in term of other simple functions.</p>

<p>I wonder how we can prove that kind of assertion?</p>

 
Answer: <p>It is a theorem of Liouville, reproven later with purely algebraic methods, that for rational functions $f$ and $g$, $g$ nonconstant, the antiderivative</p>

<p>$$\int [f(x)\exp(g(x))] \, \mathrm dx$$</p>

<p>can be expressed in terms of elementary functions if and only if there exists some rational function $h$ such that it is a solution to the differential equation:</p>

<p>$$f = h' + hg$$</p>

<p>$\int e^{x^2} dx$ is another classic example of such a function with no elementary antiderivative.</p>

<p>I don't know how much math you've had, but some of this paper might be comprehensible in its broad strokes: <a href="http://www.sci.ccny.cuny.edu/~ksda/PostedPapers/liouv06.pdf" rel="noreferrer">http://www.sci.ccny.cuny.edu/~ksda/PostedPapers/liouv06.pdf</a></p>

<p>Liouville's original paper:</p>

<blockquote>
  <p>Liouville, J. <a href="http://sites.mathdoc.fr/JMPA/PDF/JMPA_1837_1_2_A7_0.pdf" rel="noreferrer">"<em>Suite du Mémoire sur la classification des Transcendantes, et sur l'impossibilité d'exprimer les racines de certaines équations en fonction finie explicite des coefficients</em>."</a> J. Math. Pure Appl. 3, 523-546, 1838. </p>
</blockquote>

<p>Michael Spivak's book on Calculus also has a section with a discussion of this.</p>

==============================
===============================
Question: <p>Prime numbers are numbers with no factors other than one and itself.</p>

<p>Factors of a number are always lower or equal to than a given number; so, the larger the number is, the larger the pool of "possible factors" that number might have.</p>

<p>So the larger the number, it seems like the less likely the number is to be a prime.</p>

<p>Surely there must be a number where, simply, every number above it has some other factors.  A "critical point" where every number larger than it simply will always have some factors other than one and itself.</p>

<p>Has there been any research as to finding this critical point, or has it been proven not to exist?  That for any $n$ there is always guaranteed to be a number higher than $n$ that has no factors other than one and itself?</p>

 
Answer: <p>Euclid's famous proof is as follows: Suppose there is a finite number of primes.  Let $x$ be the product of all of these primes.  Then look at $x+1$.  It is clear that $x$ is coprime to $x+1$.  Therefore, no nontrivial factor of $x$ is a factor of $x+1$, but every prime is a factor of $x$.  By the fundamental theorem of arithmetic, $x+1$ admits a prime factorization, and by the above remark, none of these prime factors can be a factor of $x$, but $x$ is the product of all primes.  This is a contradiction.</p>

==============================
===============================
Question: <p>I remember hearing several times the advice that, we should avoid using a proof by contradiction, if it is simple to convert to a direct proof or a proof by contrapositive.  Could you explain the reason?  Do logicians think that proofs by contradiction are somewhat weaker than direct proofs?</p>

<p>Edit: To clarify the question.  I am wondering, if there is any reason that one would still continue looking for a direct proof of some theorem, although a proof by contradiction has already been found.  I don't mean improvements in terms of elegance or exposition, I am asking about logical reasons.  For example, in the case of axiom of choice, there is obviously reason to look for a proof that does not use the axiom of choice.  Is there a similar case for proofs by contradiction?</p>

 
Answer: <p>Over at <a href="https://mathoverflow.net/questions/12342/reductio-ad-absurdum-or-the-contrapositive/12400#12400">this MathOverflow question</a>, I posted the following answer to a similar question (and there are several other interesting answers there):</p>

<ul>
<li><em>With good reason</em>, we mathematicians prefer a direct proof of an implication over a proof by contradiction, when such a proof is available. (all else being equal)</li>
</ul>

<p>What is the reason? The reason is the <em>fecundity</em> of the proof, meaning our ability to use the proof to make further mathematical conclusions. When we prove an implication (p implies q) directly, we assume p, and then make some intermediary conclusions r<sub>1</sub>, r<sub>2</sub>, before finally deducing q. Thus, our proof not only establishes that p implies q, but also, that p implies r<sub>1</sub> and r<sub>2</sub> and so on. Our proof has provided us with additional knowledge about the context of p, about what else must hold in any mathematical world where p holds. So we come to a fuller understanding of what is going on in the p worlds.</p>

<p>Similarly, when we prove the contrapositive (&not;q implies &not;p) directly, we assume &not;q, make intermediary conclusions  r<sub>1</sub>, r<sub>2</sub>, and then finally conclude &not;p. Thus, we have also established not only that &not;q implies &not;p, but also, that it implies r<sub>1</sub> and r<sub>2</sub> and so on. Thus, the proof tells us about what else must be true in worlds where q fails. Equivalently, since these additional implications can be stated as (&not;r<sub>1</sub> implies q), we learn about many different hypotheses that all imply q. </p>

<p>These kind of conclusions can increase the value of the proof, since we learn not only that (p implies q), but also we learn an entire context about what it is like in a mathematial situation where p holds (or where q fails, or about diverse situations leading to q). </p>

<p>With reductio, in contrast, a proof of (p implies q) by contradiction seems to carry little of this extra value. We assume p and &not;q, and argue  r<sub>1</sub>, r<sub>2</sub>, and so on, before arriving at a contradiction. The statements r<sub>1</sub> and r<sub>2</sub> are all deduced under the contradictory hypothesis that p and &not;q, which ultimately does not hold in any mathematical situation. The proof has provided extra knowledge about a nonexistant, contradictory land. (Useless!) So these intermediary statements do not seem to provide us with any greater knowledge about the p worlds or the q worlds, beyond the brute statement that (p implies q) alone.</p>

<p>I believe that this is the reason that sometimes, when a mathematician completes a proof by contradiction, things can still seem unsettled beyond the brute implication, with less context and knowledge about what is going on than would be the case with a direct proof.</p>

<p>For an example of a proof where we are led to false expectations in a proof by contradiction, consider Euclid's theorem that there are infinitely many primes. In a common proof by contradiction, one assumes that p<sub>1</sub>, ..., p<sub>n</sub> are <em>all</em> the primes. It follows that since none of them divide the product-plus-one p<sub>1</sub>...p<sub>n</sub>+1, that this product-plus-one is also prime. This contradicts that the list was exhaustive. Now, many beginner's falsely expect after this argument that whenever p<sub>1</sub>, ..., p<sub>n</sub> are prime, then the product-plus-one is also prime. But of course, this isn't true, and this would be a misplaced instance of attempting to extract greater information from the proof, misplaced because this is a proof by contradiction, and that conclusion relied on the assumption that p<sub>1</sub>, ..., p<sub>n</sub> were <em>all</em> the primes. If one organizes the proof, however, as a direct argument showing that whenever p<sub>1</sub>, ..., p<sub>n</sub> are prime, then there is yet another prime not on the list, then one is led to the true conclusion, that p<sub>1</sub>...p<sub>n</sub>+1 has merely a prime divisor not on the original list. (And Michael Hardy mentions that indeed Euclid had made the direct argument.)</p>

==============================
===============================
Question: <p>Can someone give a simple explanation as to why the <a href="http://en.wikipedia.org/wiki/Harmonic_series_(mathematics)"><em>harmonic series</em></a> </p>

<blockquote>
  <p>$$\sum_{n=1}^\infty\frac1n=\frac 1 1 + \frac 12 + \frac 13 + \cdots $$</p>
</blockquote>

<p>doesn't converge, on the other hand it grows very slowly? </p>

<p>I'd prefer an easily comprehensible explanation rather than a rigorous proof regularly found in undergraduate textbooks.</p>

 
Answer: <p>Let's group the terms as follows:</p>

<p>Group $1$ : $\displaystyle\frac11\qquad$           ($1$ term)</p>

<p>Group $2$ : $\displaystyle\frac12+\frac13\qquad$($2$ terms)</p>

<p>Group $3$ : $\displaystyle\frac14+\frac15+\frac16+\frac17\qquad$($4$ terms)</p>

<p>Group $4$ : $\displaystyle\frac18+\frac19+\cdots+\frac1{15}\qquad$   ($8$ terms)</p>

<p>$\quad\vdots$</p>

<p>In general, group $n$ contains $2^{n-1}$ terms.  But also, notice that the smallest element in group $n$ is larger than $\dfrac1{2^n}$.  For example all elements in group $2$ are larger than $\dfrac1{2^2}$.  So the sum of the terms in each group is larger than $2^{n-1} \cdot \dfrac1{2^n} =  \dfrac1{2}$.  Since there are infinitely many groups, and the sum in each group is larger than $\dfrac1{2}$, it follows that the total sum is infinite.  </p>

<p>This proof is often attributed to Nicole Oresme.</p>

==============================
===============================
Question: <p>Below is a visual proof (!) that $32.5 = 31.5$. How could that be?</p>

<p><img src="https://farm1.static.flickr.com/48/152036443_ca28c8d2a1_o.png" alt="alt text"></p>

 
Answer: <p>It's an optical illusion - neither the first nor second set of blocks actually describes a triangle. The diagonal edge of the first is slightly concave and that of the second is slightly convex.</p>

<p>To see clearly, look at the gradients of the hypotenuses of the red and blue triangles - they're not 'similar'.</p>

<p>gradient of blue triangle hypotenuse = 2/5<br>
gradient of red triangle hypotenuse = 3/8  </p>

<p>Since these gradients are different, combining them in the ways shown in the diagram does not produce an overall straight (diagonal) line.</p>

==============================
===============================
Question: <p>I know that the harmonic series $1 + \frac12 + \frac13 + \frac14 + \cdots$ diverges. I also know that the sum of the inverse of prime numbers $\frac12 + \frac13 + \frac15 + \frac17 + \frac1{11} + \cdots$ diverges too, even if really slowly since it's $O(\log \log n)$.</p>

<p>But I think I read that if we consider the numbers whose decimal representation does not have a certain digit (say, 7) and sum the inverse of these numbers, the sum is finite (usually between 19 and 20, it depends from the missing digit). Does anybody know the result, and some way to prove that the sum is finite?</p>

 
Answer: <p>EDIT: <a href="http://mathworld.wolfram.com/KempnerSeries.html">This</a> might be what you're looking for. Found it from looking at the source below. They're called Kempner series.</p>

<p>An article <a href="http://www.jstor.org/stable/2974352">here</a> (and cited below) says that one Dr. Kempner proved in 1914 that the series 1+ 1/2 + 1/3 + ..., with any term that has a 9 in the denominator removed, is convergent (though he doesn't say what it converges to in the introductory paragraph). The article goes on to generalize the result.  </p>

<p>A Curious Convergent Series
Frank Irwin
The American Mathematical Monthly, Vol. 23, No. 5 (May, 1916), pp. 149-152
Published by: Mathematical Association of America
Stable URL: <a href="http://www.jstor.org/stable/2974352">http://www.jstor.org/stable/2974352</a></p>

==============================
===============================
Question: <p>I'm currently trying to understand the concepts and theory behind some of the common proof verifiers out there, but am not quite sure on the exact nature and construction of the sort of systems/proof calculi they use. Are they essentially based on higher-order logics that use Henkin semantics, or is there something more to it? As I understand, extending Henkin semantics to higher-order logic does not render the formal system any less sound, though I am not too clear on that.</p>

<p>Though I'm mainly looking for a general answer with useful examples, here are a few specific questions:</p>

<ul>
<li>What exactly is the role of type theory in creating higher-order logics? Same goes with category theory/model theory, which I believe is an alternative.</li>
<li>Is extending a) natural deduction, b) sequent calculus, or c) some other formal system the best way to go for creating higher order logics?</li>
<li>Where does typed lambda calculus come into proof verification?</li>
<li>Are there any other approaches than higher order logic to proof verification?</li>
<li>What are the limitations/shortcomings of existing proof verification systems (see below)?</li>
</ul>

<p>The Wikipedia pages on proof verification programs such as <a href="http://en.wikipedia.org/wiki/HOL_Light">HOL Light</a> <a href="http://en.wikipedia.org/wiki/Calculus_of_constructions">Coq</a>, and <a href="http://us.metamath.org/">Metamath</a> give some idea, but these pages contain limited/unclear information, and there are rather few specific high-level resources elsewhere. There are so many variations on formal logics/systems used in proof theory that I'm not sure quite what the base ideas of these systems are - what is required or optimal and what is open to experimentation.</p>

<p>Perhaps a good way of answering this, certainly one I would appreciate, would be a brief guide (albeit with some technical detail/specifics) on how one might go about generating a complete proof calculus (proof verification system) from scratch? Any other information in the form of explanations and examples would be great too, however.</p>

 
Answer: <p>I'll answer just part of your question: I think the other parts will become clearer based on this.</p>

<p>A proof verifier is essentially a program that takes one argument, a proof representation, and checks that this is properly constructed, and says OK if it is, and either fails silently otherwise, or highlights what is invalid otherwise.</p>

<p>In principle, the proof representation could just be a sequence of formulae in a Hilbert system: all logics (at least, first-orderisable logics) can be represented in such a way.  You don't even need to say which rule is specified at each step, since it is decidable whether any formula follows by a rule application from earlier formulae.</p>

<p>In practice, though, the proof representations are more complex.  Metamath is rather close to Hilbert systems, but has a rich set of rules.  Coq and LF use (different) typed lambda calculi with definitions to represent the steps, which are computationally quite expensive to check (IIRC, both are PSPACE hard).  And the proof verifier can do much more: Coq allows ML programs to be extracted from proofs.</p>

==============================
===============================
Question: <p>I just came back from my Number Theory course, and during the lecture there was mention of the Collatz Conjecture.</p>

<p>I'm sure that everyone here is familiar with it; it describes an operation on a natural number -- n/2 if it is even, 3n+1 if it is odd.</p>

<p>The conjecture states that if this operation is repeated, all numbers will eventually wind up at 1 (or rather, in an infinite loop of 1-4-2-1-4-2-1).</p>

<p>I fired up Python and ran a quick test on this for all numbers up to 5.76 × 10^18 (using the powers of cloud computing and dynamic programming magic).  Which is millions of millions of millions.  And all of them eventually ended up at 1.</p>

<p>Surely I am close to testing every natural number?  How many natural numbers could there be?  Surely not much more than millions of millions of millions. (I kid)</p>

<p>I explained this to my friend, who told me, "Why would numbers suddenly get different at a certain point?  Wouldn't they all be expected to behave the same?"</p>

<p>To which I said, "No, you are wrong!  In fact I am sure there are many conjectures which have been disproved by counterexamples that are extremely large!"</p>

<p>And he said, "It is my conjecture that there are none! (and if any, they are rare)"</p>

<p>Please help me, smart math people.  Can you provide a counterexample to his conjecture?  Perhaps, more convincingly, several?  I've only managed to find one! (Polya's)  One, out of the many thousands (I presume) of conjectures.  It's also one that is hard to explain the finer points to the layman.  Are there any more famous or accessible examples?</p>

 
Answer: <p>Another example: <a href="http://en.wikipedia.org/wiki/Euler%27s_sum_of_powers_conjecture">Euler's sum of powers conjecture</a>, a generalization of Fermat's Last Theorem. It states:<br>
If the equation $\sum_{i=1}^kx_i^n=z^n$ has a solution in positive integers, then n ≤ k (unless k=1). Fermat's Last Theorem is the k=2 case of this conjecture.</p>

<p>A counterexample for n&nbsp;=&nbsp;5 was found in 1966: it's<br>
$$
61917364224=27^5+84^5+110^5+133^5=144^5
$$
The smallest counterexample for n&nbsp;=&nbsp;4 was found in 1988:<br>
$$
31858749840007945920321 = 95800^4+217519^4+414560^4=422481^4
$$
This example used to be even more useful in the days before FLT was proved, as an answer to the question "Why do we need to prove FLT if it has been verified for thousands of numbers?" :-)</p>

==============================
===============================
Question: <p>Let $A$ be a commutative ring. Suppose $P \subset A$ is a minimal prime ideal. Then it is a theorem that $P$ consists of zero-divisors.</p>

<p>This can be proved using localization, when $A$ is noetherian: $A_P$ is local artinian, so every element of $PA_P$ is nilpotent.  Hence every element of $P$ is a zero-divisor. (As Matt E has observed, when $A$ is nonnoetherian, one can still use a similar argument: $PA_P$ is the only prime in $A_P$, hence is the radical of $A_P$ by elementary commutative algebra.)</p>

<p>Can this be proved without using localization?</p>

 
Answer: <p>Denote set complements in $\rm A $ by $\rm\,\bar T = A - T.\, $ Consider the monoid $\rm\,S\,$ generated by $\rm\,\bar P\,$ and $\rm\,\bar Z,\ $ for $\rm\,Z = $ all zero-divisors in $\rm A $ (including $0).\,$ Note $\rm\,0\not\in S\ $ (else $\rm\, 0 = a\,b,$ $\rm\ a\in \bar P,$ $\rm\ b\in \bar Z\ $ $\rm \Rightarrow b\in Z)$ so we can enlarge $\,0\,$ to an ideal $\rm\,Q\,$ maximally disjoint from $\rm\,S.\, $ Since $\rm\,S\,$ is a monoid, $\rm\,Q\,$ is prime.  $\rm\, S\,\supset\, \bar P \cup \bar Z\ \Rightarrow\ Q \subset \bar S \subset P\cap Z,\, $ so by minimality of $\rm\,P\,$ we infer $\rm\, P = Q \subset Z.\quad$ <strong>QED</strong></p>

==============================
===============================
Question: <p>The group:</p>

<p>$$
G = \left\langle x, y \;  \left| \;  x^2 = y^3 = (xy)^7 = 1\right. \right\rangle
$$</p>

<p>is infinite, or so I've been told. How would I go about proving this? (To prove finiteness of a finitely presented group, I could do a coset enumeration, but I don't see how this helps if I want to prove that it's infinite.)</p>

 
Answer: <p>$\langle x,y \; | \; x^2=y^3=1 \rangle \cong \operatorname{PSL}_2(\mathbb Z)$ and this isomorphism identifies G with $\operatorname{PSL}_2/T^7=1$ (where $T:z\mapsto z+1$). Result is the symmetry group of <a href="http://en.wikipedia.org/wiki/(2,3,7)_triangle_group" rel="nofollow">the tiling</a> of the hyperbolic plane. From this description one can see that G is infinite (e.g. because there are infinitely many triangles in the tiling and G acts on them transitively).</p>

==============================
===============================
Question: <p>Why are the only (associative) division algebras over the real numbers the real numbers, the complex numbers, and the quaternions?</p>

<p>Here a division algebra is an associative algebra where every nonzero number is invertible (like a field, but without assuming commutativity of multiplication).</p>

<p>This is an old result proved by Frobenius, but I can't remember how the argument goes.  Anyone have a quick proof?</p>

 
Answer: <p>Essentially one first proves that any real division algebra $D$ is a Clifford algebra (i.e. it's generated by elements of some inner product vector space I subject to relations $v^2=\langle v, v\rangle$): first one splits $D$ as $\mathbb R\oplus D_0$ where $D_0$ is the space of elements with $Tr=0$ and then one observes that minimal polynomial of a traceless element has the form $x^2-a=0$ (it's quadratic because it's irreducible and the coefficient of $x$ is zero because it is the trace). Now it remains to find out which Clifford algebras are division algebras which is pretty straightforward (well, and it follows from the classification of Clifford algebras).</p>

<p>This proof <a href="http://en.wikipedia.org/wiki/Frobenius_theorem_(real_division_algebras)">is written</a> in Wikipedia.</p>

==============================
===============================
Question: <p>The volume of a cone with height $h$ and radius $r$ is $\frac{1}{3} \pi r^2 h$, which is exactly one third the volume of the smallest cylinder that it fits inside.</p>

<p>This can be proved easily by considering a cone as a <a href="http://en.wikipedia.org/wiki/Solid_of_revolution" rel="noreferrer">solid of revolution</a>, but I would like to know if it can be proved or at least visual demonstrated without using calculus.</p>

<p><a href="https://i.stack.imgur.com/CMqwh.gif" rel="noreferrer"><img src="https://i.stack.imgur.com/CMqwh.gif" alt=""></a></p>

 
Answer: <p><a href="http://www.mathematische-basteleien.de/wuerfel16.gif" rel="noreferrer">alt text http://www.mathematische-basteleien.de/wuerfel16.gif</a><br>
A visual demonstration for the case of a pyramid with a square base. As <a href="https://math.stackexchange.com/questions/623/why-is-the-volume-of-a-cone-one-third-of-the-volume-of-a-cylinder/635#635">Grigory states</a>, <a href="http://en.wikipedia.org/wiki/Cavalieris_principle" rel="noreferrer">Cavalieri's principle</a> can be used to get the formula for the volume of a cone. We just need the base of the square pyramid to have side length $ r\sqrt\pi$. Such a pyramid has volume $\frac13 \cdot h \cdot \pi \cdot r^2. $<br>
<a href="http://www.csrjjsmp.com/images/offsite/cone.png" rel="noreferrer">alt text http://www.csrjjsmp.com/images/offsite/cone.png</a><br>
Then the area of the base is clearly the same. The cross-sectional area at distance a from the peak is a simple matter of similar triangles: The radius of the cone's cross section will be $a/h \times r$. The side length of the square pyramid's cross section will be $\frac ah \cdot   r\sqrt\pi.$<br>
Once again, we see that the areas must be equal. So by Cavalieri's principle, the cone and square pyramid must have the same volume:$ \frac13\cdot h \cdot \pi \cdot r^2$</p>

==============================
===============================
Question: <p>I just got out from my Math and Logic class with my friend.  During the lecture, a well-known math/logic puzzle was presented:</p>

<blockquote>
  <p>The King has $1000$ wines, $1$ of which is poisoned.  He needs to identify the poisoned wine as soon as possible, and with the least resources, so he hires the protagonist, a Mathematician.  The king offers you his expendable servants to help you test which wine is poisoned.</p>
  
  <p>The poisoned wine is very potent, so much that one molecule of the wine will cause anyone who drinks it to die.  However, it is slow-acting.  The nature of the slow-acting poison means that there is only time to test one "drink" per servant. (A drink may be a mixture of any number of wines)  (Assume that the King needs to know within an hour, and that any poison in the drink takes an hour to show any symptoms)</p>
  
  <p>What is the minimum amount of servants you would need to identify the poisoned wine?</p>
</blockquote>

<p>With enough time and reasoning, one can eventually see that this requires at most <strong>ten</strong> ($10$) servants (in fact, you could test 24 more wines on top of that 1000 before requiring an eleventh servant).  The proof/procedure is left to the reader.</p>

<p>My friend and I, however, was not content with resting upon this answer.  My friend added the question:</p>

<blockquote>
  <p>What would be different if there were $2$ wines that were poisoned out of the 1000?  What is the new minimum then?</p>
</blockquote>

<p>We eventually generalized the problem to this:</p>

<blockquote>
  <p>Given $N$ bottles of wine ($N \gt 1$) and, of those, $k$ poisoned wines  ($0 \lt k \lt N$), what is the optimum method to identify the all of the poisoned wines, and how many servants are required ($s(N,k)$)?</p>
</blockquote>

<p>After some mathsing, my friend and I managed to find some (possibly unhelpful) lower and upper bounds:</p>

<p>$ log_2 {N \choose k} \le s(N,k) \le N-1 $</p>

<p>This is because $log_2 {N \choose k}$ is the minimum number of servants to uniquely identify the $N \choose k$ possible configurations of $k$ poisoned wines in $N$ total wines.</p>

<p>Can anyone help us find an optimum strategy?  Besides the trivial one requiring $N-1$ servants.  How about a possible approach to start?</p>

<p>Would this problem be any different if you were only required to find a strategy that would for sure find a wine that is <strong>not</strong> poisoned, instead of identifying all poisoned wines? (other than the slightly trivial solution of $k$ servants)</p>

 
Answer: <p>I asked this question <a href="https://mathoverflow.net/questions/59939/identifying-poisoned-wines/60312#60312">on MathOverflow</a> and got a great answer there.</p>

<hr>

<p>For $k = 2$ I can do it with ${\lceil \log_2 N \rceil + 2 \choose 2} - 1$ servants.  In particular for $N = 1000$ I can do it with $65$ servants.  The proof is somewhat long, so I don't want to post it until I've thought about the problem more.</p>

<hr>

<p>I haven't been able to improve on the above result.  Here's how it works.  Let $n = \lceil \log_2 N \rceil$.  Let me go through the algorithm for $k = 1$ so we're all on the same page.  Number the wines and assign each of them the binary expansion of their number, which consists of $n$ bits.  Find $n$ servants, and have servant $i$ drink all the wines whose $i^{th}$ bit is $1$.  Then the set of servants that die tells you the binary expansion of the poisoned wine.</p>

<p>For $k = 2$ we need to find $n$ butlers, $n$ maids, and ${n \choose 2}$ cooks.  The cooks will be named $(i, j)$ for some positive integers $1 \le i &lt; j \le n$.  Have butler $i$ drink all the wines whose $i^{th}$ bit is $1$, have maid $i$ drink all the wines whose $i^{th}$ bit is $0$, and have cook $(i, j)$ drink all the wines such that the sum of the $i^{th}$ bit through the $j^{th}$ bit, inclusive, mod 2, is $1$.  This is how the casework breaks down for butlers and maids.</p>

<ul>
<li>If both butler $i$ and maid $i$ die, then one of the poisoned wines has $i^{th}$ bit $0$ and the other has $i^{th}$ bit $1$.</li>
<li>If only butler $i$ dies, then both of the poisoned wines have $i^{th}$ bit $1$.</li>
<li>If only maid $i$ dies, then both of the poisoned wines have $i^{th}$ bit $0$.</li>
</ul>

<p>The second two cases are great.  The problem with case 1 is that if it occurs more than once, there's still ambiguity about which wine has which bit.  (The worst scenario is if all the butlers and maids die.)  To fix the issue with case 1, we use the cooks.  </p>

<p>Let $i_1 &lt; ... &lt; i_m$ be the set of bits where case 1 occurs.  We'll say that the poisoned wine whose $(i_1)^{th}$ bit is $1$ is wine A, and the other one is wine B.  Notice that the sum of the $(i_1)^{th}$ through $(i_2)^{th}$ bits of wine A mod 2 is the same as the sum of the $(i_1)^{th}$ through $(i_2)^{th}$ bits of wine B mod 2, and we can determine what this sum is by looking at whether cook $(i_1, i_2)$ died.  The value of this sum determines whether the $(i_2)^{th}$ bit of wine A is 1 or 0 (and the same for wine B).  Similarly, looking at whether cook $(i_j, i_{j+1})$ died tells us the remaining bits of wine A, hence of wine B.</p>

<hr>

<p>One last comment for now.  The lower bound is not best possible when $k$ is large compared to $N$; for example, when $k = N-1$ it takes $N-1$ servants.  The reason is that any servant who drinks more than one wine automatically dies, hence gives you no information. </p>

==============================
===============================
Question: <p>Can someone point me to a proof that the set of irrational numbers is uncountable? I know how to show that the set $\mathbb{Q}$ of rational numbers is countable, but how would you show that the irrationals are uncountable?</p>

 
Answer: <p>Given that the reals are uncountable (which can be shown via <a href="http://en.wikipedia.org/wiki/Cantor_diagonalization">Cantor diagonalization</a>) and the rationals are countable, the irrationals are the reals with the rationals removed, which is uncountable. (Or, since the reals are the union of the rationals and the irrationals, if the irrationals were countable, the reals would be the union of two countable sets and would have to be countable, so the irrationals must be uncountable.)</p>

==============================
===============================
Question: <p>Pick's theorem says that given a square grid consisting of all points in the plane with integer coordinates, and a polygon without holes and non selt-intersecting whose vertices are grid points, its area is given by: </p>

<p>$$i + \frac{b}{2} - 1$$</p>

<p>where $i$ is the number of interior lattice points and $b$ is the number of points on its boundary. Theorem and proof may be found on <a href="http://en.wikipedia.org/wiki/Pick%27s_theorem" rel="nofollow">Wikipedia</a>.</p>

<p>Let us suppose that the grid is not square but triangular (or hexagonal). Does a similar theorem hold?</p>

 
Answer: <p>The short answer is that, no, there can be no formula for polygons with vertices in the hexagonal lattice in terms of just boundary and interior points. This is based on the fact that primitive triangles on this lattice--ones with no lattice points on their boundary (besides the vertices) or in the interior--can have different areas, whereas for the square lattice all primitive triangles have area $\frac{1}{2}$.</p>

<p>However, as Casebash has partly gotten at in his answer, you can approximate things well if you compute what, in the below paper, is called the "boundary characteristic" of the polygon, a number that is somewhat complicated to think to compute, but which gives a decent proxy for how many of each type of primitive triangle the polygon contains.</p>

<p>Kolodziejczyk has been the main one doing work on hexagonal lattice results of this type that I know; he's worth looking up for similar results. Ding Ren is another, and the older work of Grunbaum, etc., still bears on the problem.</p>

<p><a href="http://www.jstor.org/pss/2323889" rel="nofollow">"A Fast Pick-Type Approximation for the Area of H-Polygons,"</a> Ren, Kolodziejczyk, et al., American Mathematical Monthly, 1993.</p>

==============================
===============================
Question: <p>I know this is very basic and old hat to many, but I love this question and I am interested in seeing whether there are any proofs beyond the two I already know.</p>

 
Answer: <p>The most elementary proof I can think of, without explicitly mentioning any number theory: out of the three consecutive numbers $p – 1$, $p$, $p + 1$, one of them must be divisible by $3$; also, since the neighbours of <em>p</em> are consecutive even numbers, one of them must be divisible by $2$ and the other by $4$, so their product is divisible by $3 &#183; 2 &#183; 4 = 24$ — and of course, we can throw $p$ out since it's prime, and those factors cannot come from it.</p>

==============================
===============================
Question: <p>Let $S$ be a set of size $n$.  There is an easy way to count the number of subsets with an even number of elements.  Algebraically, it comes from the fact that</p>

<p>$\displaystyle \sum_{k=0}^{n} {n \choose k} = (1 + 1)^n$</p>

<p>while</p>

<p>$\displaystyle \sum_{k=0}^{n} (-1)^k {n \choose k} = (1 - 1)^n$.</p>

<p>It follows that </p>

<p>$\displaystyle \sum_{k=0}^{n/2} {n \choose 2k} = 2^{n-1}$.  </p>

<p>A direct combinatorial proof is as follows: fix an element $s \in S$.  If a given subset has $s$ in it, add it in; otherwise, take it out.  This defines a bijection between the number of subsets with an even number of elements and the number of subsets with an odd number of elements.</p>

<p>The analogous formulas for the subsets with a number of elements divisible by $3$ or $4$ are more complicated, and divide into cases depending on the residue of $n \bmod 6$ and $n \bmod 8$, respectively.  The algebraic derivations of these formulas are as follows (with $\omega$ a primitive third root of unity):  observe that</p>

<p>$\displaystyle \sum_{k=0}^{n} \omega^k {n \choose k} = (1 + \omega)^n = (-\omega^2)^n$</p>

<p>while</p>

<p>$\displaystyle \sum_{k=0}^{n} \omega^{2k} {n \choose k} = (1 + \omega^2)^n = (-\omega)^n$</p>

<p>and that $1 + \omega^k + \omega^{2k} = 0$ if $k$ is not divisible by $3$ and equals $3$ otherwise.  (This is a special case of the discrete Fourier transform.)  It follows that</p>

<p>$\displaystyle \sum_{k=0}^{n/3} {n \choose 3k} = \frac{2^n + (-\omega)^n + (-\omega)^{2n}}{3}.$</p>

<p>$-\omega$ and $-\omega^2$ are sixth roots of unity, so this formula splits into six cases (or maybe three).  Similar observations about fourth roots of unity show that</p>

<p>$\displaystyle \sum_{k=0}^{n/4} {n \choose 4k} = \frac{2^n + (1+i)^n + (1-i)^n}{4}$</p>

<p>where $1+i = \sqrt{2} e^{ \frac{\pi i}{4} }$ is a scalar multiple of an eighth root of unity, so this formula splits into eight cases (or maybe four).  </p>

<p><strong>Question:</strong>  Does anyone know a direct combinatorial proof of these identities? </p>

 
Answer: <p>Fix two elements s<sub>1</sub>,s<sub>2</sub>&isin;S and divide subsets of S into two parts (subsets of S containing only s<sub>2</sub>)&cup;(subsets of S which contains s<sub>1</sub> if they contain s<sub>2</sub>). The second part contains equal number of sets for all reminders mod 3 (because Z/3 acts there adding s<sub>1</sub>, then s<sub>2</sub>, then removing both of them) -- namely, 2<sup>n-2</sup>. And for the first part we have a bijection with subsets <em>(edit: with 2 mod 3 elements)</em> of a set with (n-2) elements.</p>

<p>So we get a recurrence relation that gives an answer 2<sup>n-2</sup>+2<sup>n-4</sup>+... -- i.e. (2<sup>n</sup>-1):3 for even and (2<sup>n</sup>-2):3 for odd n.</p>

<hr>

<p><strong>Errata.</strong> For n=0,1,5 mod 6 one should add "+1" to the answer from the previous paragraph (e.g. for n=6 the correct answer is 1+20+1=22 and not 21).</p>

<p>Let me try to rephrase the solution to make it obvious. For n=2k divide S on k pairs and consider an action of a group Z/3Z on each pair described in a first paragraph. We get an action of (Z/3Z)<sup>k</sup> on subsets of S, and after removal of it's only fixed point (k-element set consisting of second points from each pair) we get a bijection between subsets which have 0, 1 or 2 elements mod 3. So there are (2<sup>n</sup>-1):3 sets with i mod 3 elements excluding the fixed point <em>and</em> to count that point one should add "+1" for i=k mod 3.</p>

<p>And for n=2k+1 there are 2 fixed points&nbsp;&mdash; including or not (2k+1)-th element of S&nbsp;&mdash; with k+1 and k elements respectively.</p>

==============================
===============================
Question: <blockquote>
  <p>Let $A$ and $B$ be two matrices which can be multiplied. Then $$\operatorname{rank}(AB) \leq \operatorname{min}(\operatorname{rank}(A), \operatorname{rank}(B)).$$</p>
</blockquote>

<p>I proved $\operatorname{rank}(AB) \leq \operatorname{rank}(B)$ interpreting $AB$ as a composition of linear maps, observing that $\operatorname{ker}(B) \subseteq \operatorname{ker}(AB)$ and using the kernel-image dimension formula. This also provides, in my opinion, a nice interpretation: if non stable, under subsequent compositions the kernel can only get bigger, and the image can only get smaller, in a sort of <em>loss of information</em>.</p>

<p>How to manage $\operatorname{rank}(AB) \leq \operatorname{rank}(A)$? Is there a nice interpretation like the previous one?</p>

 
Answer: <p>Yes. If you think of A and B as linear maps, then the domain of A is certainly at least as big as the image of B. Thus when we apply A to either of these things, we should get "more stuff" in the former case, as the former is bigger than the latter.</p>

==============================
===============================
Question: <p>Let $f$ and $g$ be two periodic functions over $\Bbb{R}$ with the following property: If $T$ is a period of $f$, and $S$ is a period of $g$, then $T/S$ is irrational. </p>

<p><strong>Conjecture</strong>: $f+g$ is <em>not</em> periodic.</p>

<p>Could you give a proof or a counter example?  It is easier if we assume continuity.  But is it true for arbitrary real valued functions?</p>

 
Answer: <p>Here is a counterexample.  Let $a, b, c \in \mathbb{R}$ be linearly independent over $\mathbb{Q}$.  Let $\text{span}(x, y, z, ...)$ be the $\mathbb{Q}$-vector space in $\mathbb{R}$ spanned by $x, y, z, ...$.  Let $AB = \text{span}(a, b), BC = \text{span}(b, c), AC = \text{span}(a, c)$.  And for a subset $S$ of $\mathbb{R}$, let $\chi_S$ denote the characteristic function of $S$.  Now define</p>

<p>$\displaystyle f(x) = \chi_{AB} - 2 \chi_{BC}$</p>

<p>and</p>

<p>$\displaystyle g(x) = 3 \chi_{AC} + 2 \chi_{BC}.$</p>

<p>Then $f$ has period set $\text{span}(b)$, $g$ has period set $\text{span}(c)$, and $f + g$ has period set $\text{span}(a)$.  (I am not sure if the coefficients are necessary; they're just precautions.)</p>

<p>Are you still interested in the continuous case?</p>

<hr>

<p>(Old answer below.  I slightly misunderstood the question when I wrote this.)</p>

<p>Here is a simpler example.  I claim that the function $h(x) = \sin x + \sin \pi x$ cannot possibly be periodic.  Why?  Suppose an equation of the form</p>

<p>$\sin x + \sin \pi x = \sin (x+T) + \sin \pi (x+T)$</p>

<p>held for all $x$ and some $T > 0$.  Take the second derivative of both sides with respect to $x$ to get</p>

<p>$\sin x + \pi^2 \sin \pi x = \sin (x+T) + \pi^2 \sin \pi(x+T).$</p>

<p>This implies that $\sin x = \sin (x+T)$ and that $\sin \pi x = \sin \pi(x+T)$, which is impossible.</p>

<p>(Or is the question whether the sum <em>can</em> be periodic?)</p>

==============================
===============================
Question: <p>The "<a href="http://en.wikipedia.org/wiki/Angle_addition_formula#Angle_sum_and_difference_identities">sum and difference</a>" formulas often come in handy, but it's not immediately obvious that they would be true.</p>

<p>\begin{align}
\sin(\alpha \pm \beta) &amp;= \sin \alpha \cos \beta \pm \cos \alpha \sin \beta \\
\cos(\alpha \pm \beta) &amp;= \cos \alpha \cos \beta \mp \sin \alpha \sin \beta
\end{align}</p>

<p>So what I want to know is, </p>

<ol>
<li>How can I prove that these formulas are correct?</li>
<li>More importantly, how can I understand these formulas intuitively?</li>
</ol>

<p>Ideally, I'm looking for answers that make no reference to Calculus, or to <a href="http://en.wikipedia.org/wiki/Euler%27s_formula">Euler's formula</a>, although such answers are still encouraged, for completeness.</p>

 
Answer: <p>The key fact here is that rotation is a linear transformation, e.g. the rotation of $u + v$ is the rotation of $u$ plus the rotation of $v$.  You should draw a diagram that shows this carefully if you don't believe it.  That means a rotation is determined by what it does to $(1, 0)$ and to $(0, 1)$.</p>

<p>But $(1, 0)$ rotated by $\theta$ degrees counterclockwise is just $(\cos \theta, \sin \theta)$, whereas $(0, 1)$ rotated by $\theta$ degrees counterclockwise is just $(-\sin \theta, \cos \theta)$.  (Again, draw a diagram.)  That means a rotation by $\theta$ is given by a $2 \times 2$ matrix with those entries.  (Matrices don't work here yet.)</p>

<p>So take a rotation by $\theta$ and another one by $\theta'$, and multiply the corresponding matrices.  What you get is the sine and cosine angle addition formulas.  (The connection to complex numbers is that one can represent complex numbers as $2 \times 2$ real matrices.)</p>

<p>Also, if you believe that $a \cdot b = |a| |b| \cos \theta$, this implies the cosine angle difference formula when $a$ and $b$ are unit vectors.  Ditto for the cross product and the sine angle difference formula.</p>

==============================
===============================
Question: <p>The identity</p>

<p>$\displaystyle (n+1) \text{lcm} \left( {n \choose 0}, {n \choose 1}, ... {n \choose n} \right) = \text{lcm}(1, 2, ... n+1)$</p>

<p>is probably not well-known.  The only way I know how to prove it is by using <a href="http://planetmath.org/kummerstheorem" rel="nofollow noreferrer">Kummer's theorem</a> that the power of $p$ dividing ${a+b \choose a}$ is the number of carries needed to add $a$ and $b$ in base $p$.  Is there a more direct proof, e.g., by showing that each side divides the other?</p>

 
Answer: <p>Consider <em><a href="http://en.wikipedia.org/wiki/Leibniz_harmonic_triangle">Leibniz harmonic triangle</a></em> — a table that is like &laquo;Pascal triangle reversed&raquo;: on it's sides lie numbers $\frac{1}{n}$ and each number is the sum of two beneath it (see the <a href="http://upload.wikimedia.org/math/5/8/1/581098eb5e9213bf6c66e932ed218e08.png">picture</a>).</p>

<p>One can easily proove by induction that m-th number in n-th row of Leibniz triangle is $\frac{1}{(n+1)\binom{n}{m}}$. So LHS of our identity is just lcd of fractions in n-th row of the triangle.</p>

<p>But it's not hard to see that any such number is an integer linear combination of fractions on triangle's sides (i.e. $1/1,1/2,\dots,1/n$) — and vice versa. So LHS is equal to $lcd(1/1,\dots,1/n)$ — and that is exactly RHS.</p>

==============================
===============================
Question: <p>The following integral,</p>

<p>$$ \int_0^1 \frac{x^4(1-x)^4}{x^2 + 1} \mathrm{d}x = \frac{22}{7} - \pi $$</p>

<p>is clearly positive, which proves that $\pi &lt; 22/7$.</p>

<p>Is there a similar integral which proves $\pi > 333/106$?</p>

 
Answer: <blockquote>
  <p>This integral would do the job:</p>
</blockquote>

<p>$$\int_0^1 \frac{x^5(1-x)^6(197+462x^2)}{530(1+x^2)}\:dx= \pi -\frac{333}{106}$$</p>

<blockquote>
  <ul>
  <li><p>Also you can refer to S.K. Lucas <em>Integral proofs that</em> $355/113 &gt; \pi$, Gazette, Aust. Math. Soc.  32 (2005), 263-266.</p></li>
  <li><p><a href="http://educ.jmu.edu/~lucassk/Papers/more%20on%20pi.pdf" rel="noreferrer">This</a> is the link. (Thanks to lhf for pointing out.)</p></li>
  </ul>
</blockquote>

==============================
===============================
Question: <p>I have a partition of a positive integer $(p)$. How can I prove that the factorial of $p$ can always be divided by the product of the factorials of the parts?</p>

<p>As a quick example $\frac{9!}{(2!3!4!)} = 1260$ (no remainder), where $9=2+3+4$.</p>

<p>I can <em>nearly</em> see it by looking at factors, but I can't see a way to guarantee it.</p>

 
Answer: <p>The key observation is that the product of $n$ consecutive integers is divisible by $n!$. This can be proved by induction.</p>

==============================
===============================
Question: <p>The Hilbert Cube $H$ is defined to be $[0,1]^{\mathbb{N}}$, i.e., a countable product of unit intervals, topologized with the product topology.</p>

<p>Now, I've read that the Hilbert Cube is homogeneous.  That is, given two points $p, q\in H$, there is a homeomorphism $f:H\rightarrow H$ with $f(p)=q$.</p>

<p>What's confusing to me is that it seems like there seems to be a stratification of points.  That is, there are</p>

<ol>
<li><p>Points contained in $(0,1)^{\mathbb{N}}$</p></li>
<li><p>Points which have precisely $n$ coordinate a $0$ or $1$ for n a fixed natural number.</p></li>
<li><p>Point which have countably many coordinates equaling $0$ or $1$ and countably many not and</p></li>
<li><p>Points which have n many coordinates NOT equal to $0$ or $1$.</p></li>
</ol>

<p>Now, for fixed $p$ and $q$ both in class $1$ or $3$ (or fix an n and use class $2$ or $4$), it's clear to me that there is a homeomorphism taking $p$ to $q$, simply by swapping around factors and using the fact that $(0,1)$ is clearly homogeneous.</p>

<p>But what are the homeomorphisms which mix the classes?  In particular, what homemorphism takes $(0,0,0,\ldots )$ to $(1/2, 1/2,1/2,\ldots )$?</p>

<p>Said another way, for any natural number $n&gt;1$, $[0,1]^n$ is NOT homogeneous, precisely because of these boundary points.  What allows you to deal with the boundary points in the infinite product case?</p>

<p>As always, feel free to retag, and thanks in advance!</p>

<p><strong>Edit</strong>  In the off chance that someone stumbles across this question, I just wanted to provide a rough idea of the answer, as garnered from the link Pete provided in his answer.</p>

<p>If one has a point of the form $(1,p)$ in $[0,1] \times [0,1]$, then there is a self homeomorphism of $[0,1]\times[0,1]$ taking $(1,p)$ to $(q,1)$ with $q\neq 0, 1$.  For example, one can use a "square rotation".  From here, the idea is simple:  given a point in $H$ of the form $(1, p_2, p_3, p_4,\ldots )$, apply the square rotation on the first two factors to get a new point of the form $(q_1, 1, p_2, p_3,\ldots )$.  Now, apply the square rotation on the second two factors to get a new point of the form $(q_1, q_2, 1, p_3,\ldots )$.  The point is that after $k$ iterations, the first $k$ coordinates are all in the interior.</p>

<p>Now one proves a techinical lemma that states that the infinite composition of these homeomorphisms is a well defined homeomorphism.  The infinite composition maps the point $(1, p_2, \ldots )$ to a point of the form $(q_1, q_2,\ldots )$ which lies on the "interior" of $H$.  Finally, using the fact that $(0,1)$ is clearly homogeneous, one can easily map $(q_1, q_2,\ldots )$ to $(1/2,1/2,\ldots )$.</p>

 
Answer: <p>When I first saw the question, I intended to post the following link as an answer, but then I saw that Qiaochu had come first with an essentially equivalent answer.  I still don't see anything lacking in his answer (I was the first to upvote it), but if someone is looking for a different reference, here is one:</p>

<p><a href="http://www.narcis.info/publication/RecordID/oai:cwi.nl:7603">http://www.narcis.info/publication/RecordID/oai:cwi.nl:7603</a></p>

==============================
===============================
Question: <p>Apparently $1+2+3+4+\ldots+n = \dfrac{n\times(n+1)}2$.</p>

<p>How? What's the proof? Or maybe it is self apparent just looking at the above? </p>

<p>PS: This problem is know as "The sum of the first $n$ positive integers".</p>

 
Answer: <p>Let $$S = 1 + 2 + ... + (n-1) + n.$$ Write it backwards: $S = n + (n-1) + ... + 2 + 1.$
Add the two equations, term by term; each term is $n+1,$ so
$$2S = (n+1) + (n+1) + ... + (n+1) = n(n+1).$$
Divide by 2: $$S = \frac{n(n+1)}{2}$$.</p>

==============================
===============================
Question: <p>I am auditing a Linear Algebra class, and today we were taught about the rank of a matrix. The definition was given from the row point of view: </p>

<blockquote>
  <p>"The rank of a matrix A is the number
  of non-zero rows in the reduced
  row-echelon form of A".</p>
</blockquote>

<p>The lecturer then explained that if the matrix $A$ has size $m * n$, then $rank(A) \leq m$ and $rank(A) \leq n$. </p>

<p>The way I had been taught about rank was that it was the smallest of </p>

<ul>
<li>the number of rows bringing new information</li>
<li>the number of columns bringing new information. </li>
</ul>

<p>I don't see how that would change if we transposed the matrix, so I said in the lecture:</p>

<p>"then the rank of a matrix is the same of its transpose, right?" </p>

<p>And the lecturer said: </p>

<p>"oh, not so fast! Hang on, I have to think about it". </p>

<p>As the class has about 100 students and the lecturer was just substituting for the "normal" lecturer, he was probably a bit nervous, so he just went on with the lecture.</p>

<p>I have tested "my theory" with one matrix and it works, but even if I tried with 100 matrices and it worked, I wouldn't have proven that it always works because there might be a case where it doesn't.</p>

<p>So my question is first whether I am right, that is, whether the rank of a matrix is the same as the rank of its transpose, and second, if that is true, how can I prove it?</p>

<p>Thanks  :)</p>

 
Answer: <p>The answer is yes.  This statement often goes under the name "row rank equals column rank".  Knowing that, it is easy to search the internet for proofs, e.g.</p>

<p><a href="http://homepage.mac.com/ehgoins/ma265/lecture_28.pdf">http://homepage.mac.com/ehgoins/ma265/lecture_28.pdf</a></p>

<p>Also any reputable linear algebra text should prove this: it is indeed a rather important result.</p>

<p>Finally, since you said that you had only a substitute lecturer, I won't castigate him, but this would be a distressing lacuna of knowledge for someone who is a regular linear algebra lecturer.  </p>

==============================
===============================
Question: <p>How can you prove that:</p>

<p>$$\sum_{k=1}^{n-1}\tan^{2}\frac{k \pi}{2n} = \frac{(n-1)(2n-1)}{3}$$</p>

<p>for every integer $n\geq 1$.</p>

<p>PS: no, it's not a homework... :-)</p>

 
Answer: <p>By a well know formula we have
$$
\left(\cos{\frac{k\pi}{2n}} + i\sin{\frac{k\pi}{2n}}\right)^{2n}=(-1)^{k}
$$
Hence by <a href="http://en.wikipedia.org/wiki/Binomial_formula">Binomial theorem</a> we have ($[x]$ is not an integer part, brackets are added for clarity)
$$
\sum_{t=0}^{2n}\binom{2n}{t}\left[\cos{\frac{k\pi}{2n}}\right]^t \cdot \left[i\sin{\frac{k\pi}{2n}}\right]^{2n-t}=(-1)^{k}
$$
Now we consider only imaginary part of this:
$$
\sum_{r=0}^{n-1}\binom{2n}{2r+1}\left[\cos{\frac{k\pi}{2n}}\right]^{2r+1} \cdot \left[i\sin{\frac{k\pi}{2n}}\right]^{2n-2r-1}=0
$$
Divide it by $[\cos{\frac{k\pi}{2n}}]^{2n}$:
$$
\sum_{r=0}^{n-1}\binom{2n}{2r+1}\left[i\tan{\frac{k\pi}{2n}}\right]^{2n-2r-1}=0
$$
Now multiply by $i\tan{\frac{k\pi}{2n}}$:
$$
\sum_{r=0}^{n-1}\binom{2n}{2r+1}\left[i\tan{\frac{k\pi}{2n}}\right]^{2n-2r}=0
$$
So $[\tan{\frac{k\pi}{2n}}]^2$ are roots of the following polynomial:
$$
\sum_{r=0}^{n-1}\binom{2n}{2r+1}\left[-x\right]^{n-r}=0
$$
Hence by <a href="http://en.wikipedia.org/wiki/Vieta%27s_formulas">Vieta's_formulas</a> sum of it roots is equal to
$$
\frac{\binom{2n}{3}}{\binom{2n}{1}} =\frac{(2n-1)(n-1)}{3}
$$</p>

==============================
===============================
Question: <p>The number of elements of order 2 in a group is fairly restricted: 0, odd, or infinity.  All such possibilities occur already in the trivial group and in dihedral groups.</p>

<p>The number of elements of order 3 in a group can be shown to be similarly restricted: 0, 2 mod 6, or infinity.  However, something strange happens: not all possibilities can be realized.</p>

<p>Even worse, there is a fairly small number that I cannot decide whether it is or is not the number of elements of order 3 in a finite group:</p>

<blockquote>
  <p>Is there a group with exactly 92 elements of order 3?</p>
</blockquote>

<p>More boldly, I would like to know (but feel free to answer only the first question):</p>

<blockquote>
  <p>Exactly which numbers occur as the number of elements of order 3 in a group?</p>
</blockquote>

<p><strong>Background</strong>: Such questions were studied a bit by Sylow and more heavily by Frobenius.  The theorem that the number of elements of order p is equal to −1 mod p is contained in one of Frobenius's 1903 papers.  Since elements of order 3 come in pairs, this doubles to give 2 mod 6 for p=3.</p>

<p>However, Frobenius's results were improved some 30 years later by P. Hall who showed that if the Sylow p-subgroups are not cyclic, then the number of elements of order p is −1 mod p<sup>2</sup>.</p>

<p>If the Sylows are cyclic of order p<sup>n</sup>, then the number of subgroups of order p is congruent to 1 mod p<sup>n</sup> by the standard counting method.  If the Sylow itself is order p, then the subgroup generated by the elements of order p acts faithfully and transitively on the Sylow subgroups, so for small enough numbers, the subgroup can just be looked up.</p>

<p>In all cases, we can assume the group is finite since the subgroup generated by the elements of a fixed order is finite (assuming there are only finitely many elements of that fixed order).</p>

<p><strong>Easier example</strong>: For instance there is no group with exactly 68 elements of order 3, since such a group would have cyclic Sylow 3-subgroups by Hall, order 3 Sylows by the counting, but then would have 34 Sylow 3-subgroups, and so (the subgroup generated by the elements of order 3 would) be a primitive group of degree 34.  One checks the list of primitive groups of degree 34 (that is, A<sub>34</sub> and S<sub>34</sub>, both with ginormous Sylow 3-subgroups) to see no such group exists.</p>

<p>One could also try 140, but the action need not be primitive so the table lookup is harder.  Such a group has Sylows of order 3, but is not solvable, so is somewhat restricted.</p>

 
Answer: <p>Let $p,p' \equiv 2\pmod{3}$ be prime.</p>

<p>Suppose that $G$ is a group with the following properties:</p>

<p>(i)  The $3$-Sylow subgroup of $G$ is cyclic;</p>

<p>(ii) The number of elements of order $3$ in $G$ is $2 p p'$.</p>

<p>Claim: There exists a group which <em>in addition</em> satisfies either:</p>

<p>(iiia) $G$ is simple; <em>or</em></p>

<p>(iiib) $3\,||\, \#G$, and $G$ surjects onto $\mathbb{Z}/3\mathbb{Z}$.</p>

<p>Remark: Suppose that $G$ is a group with cyclic $3$-Sylow subgroups. Since all $3$-Sylow subgroups are conjugate, this implies that every subgroup of
order $3$ in $G$ is also conjugate.</p>

<p>Proof: We may assume that $G$ is not simple, and hence admits a proper normal
subgroup $H$.</p>

<p>Suppose that $H$ is a normal subgroup of $G$. If $3$ divides $\# H$, then
$H$ contains a subgroup of $G$ of order $3$. All such subgroups are
conjugate in $G$, and since $H$ is normal, they all lie in $H$. Thus
$G$ and $H$ have the same number of elements of order $3$.
Moreover, the $3$-Sylow subgroup of $H$ is clearly cyclic, and so we may
replace $G$ by $H$.</p>

<p>Suppose that $(\# H,3) = 1$. Then $G/H$ still has a cyclic $3$-Sylow subgroup, and hence every element of order $3$ in $G/H$ is conjugate. This implies that every element of order $3$ in $G/H$ lifts to an element of order $3$ in $G$. Thus $G/H$ has at most $2 p p'$ elements of order three. Yet by a theorem of Frobenius, the number $N$ of $g\in G$ of order exactly $3$ is divisible by $\phi(3) = 2$, and the number $N + 1$ of elements of order dividing $3$ is divisible by $3$. Hence $N\equiv 2\pmod{6}$. Thus the
number of elements of $G/H$ of order $3$ is either $2$ or $2pp'$. In the latter case, we replace $G$ by $G/H$. </p>

<p>We may now assume that $G/H$ has exactly $2$ elements of order $3$.
Clearly $G/H$ has a unique subgroup of order $3$, which must be normal.
Thus $G/H$ and $G$ have a quotient of order $\frac{1}{3}\#(G/H)$, and thus $G$ contains
a normal subgroup $F$ of order $3\#H$. As above, we may replace $G$ by $F$.
Note, however, that $3$ exactly divides $\#F$, and 
$F$ surjects onto $\mathbb{Z}/3\mathbb{Z}$, and thus, by Schur-Zassenhaus
(overkill in this case, of course), $F$ is a semi-direct product.</p>

<hr>

<p>My understanding of Jack's argument:</p>

<p>Suppose that $p' = 2$, so $G$ has $4p$ elements of order $3$. We still assume that the $3$-Sylow of $G$ is cyclic. $G$ acts by conjugation on the $2p$ subgroups of order $p$, giving a map $G\to S_{2p}$. Let $Q$ be one of these subgroups, and let $M$ be the normalizer of $Q$. Let $P$ be a $3$-Sylow containing $Q$. Certainly $[G:M] = 2p$, by the orbit-stabilizer formula.</p>

<p>If $X\subset G$ contains $M$, then $[G:X] = 1,2,p, \text{ or } 2p$. Let $N$ be the normalizer of $P$. Clearly $M\supset N$. Thus $P\subset M$, and thus $P$ is a $3$-Sylow of $M$. Similarly, $P$ is also a $3$-Sylow subgroup of $X$. The Sylow theorems applied to $M$ and $X$ thus imply that $[X:N], [M:N] \equiv 1\pmod{3}$, and thus $[X:M]\equiv 1\pmod{3}$. Hence, since $[X:M] = 1,2,p\text{ or }2p$, and, since $p \equiv 2\pmod{3}$, either $X = M$ or $X = G$. Thus $M$ is a maximal subgroup of $G$, and hence the action of $G$ is primitive. </p>

<p>Now we suppose:</p>

<p>Assumption (*): The only primitive subgroups of $S_{2p}$ are $A_{2p}$ and $S_{2p}$.</p>

<p>Then, we deduce that some quotient of $G$ is either $A_{2p}$ or $S_{2p}$. If $G$ is simple, we deduce that $G = A_{2p}$, which doesn't have cyclic
$3$-Sylows if $2p &gt; 5$. If $G$ is a semi-direct product of $\mathbb{Z}/3\mathbb{Z}$ with a group of order coprime to $3$, then $G$ cannot surject onto $A_{2p}$ or $S_{2p}$ if $p &gt; 2$. It seems to follow that:</p>

<p>If $p \equiv 5,8 \pmod{9}$ and Assumption (*) holds, then $G$ cannot have $4p$ elements of order $3$. (The congruence conditions on $p$ ensure that the $3$-Sylow of $G$ is cyclic).</p>

==============================
===============================
Question: <p>This is a pet idea of mine which I thought I'd share.  Fix a prime $q$ congruent to $1 \bmod 4$ and define a sequence $F_n$ by $F_0 = 0, F_1 = 1$, and</p>

<p>$\displaystyle F_{n+2} = F_{n+1} + \frac{q-1}{4} F_n.$</p>

<p>Then $F_n = \frac{\alpha^n - \beta^n}{\alpha - \beta}$ where $\alpha, \beta$ are the two roots of $f(x) = x^2 - x - \frac{q-1}{4}$.  When $q = 5$ we recover the ordinary Fibonacci numbers.  The discriminant of $f(x)$ is $q$, so it splits $\bmod p$ if and only if $q$ is a quadratic residue $\bmod p$.  </p>

<p>If $\left( \frac{q}{p} \right) = -1$, then the Frobenius morphism $x \mapsto x^p$ swaps $\alpha$ and $\beta$ (working over $\mathbb{F}_p$), hence $F_p \equiv -1 \bmod p$.  And if $\left( \frac{q}{p} \right) = 1$, then the Frobenius morphism fixes $\alpha$ and $\beta$, hence $F_p \equiv 1 \bmod p$.  In other words,</p>

<p>$\displaystyle F_p \equiv \left( \frac{q}{p} \right) \bmod p.$</p>

<p>Quadratic reciprocity in this case is equivalent to the statement that</p>

<p>$\displaystyle F_p \equiv \left( \frac{p}{q} \right) \bmod p.$</p>

<p><strong>Question:</strong>  Does anyone have any ideas about how to prove this directly, thereby proving quadratic reciprocity in the case that $q \equiv 1 \bmod 4$?</p>

<p>My pet approach is to think of $F_p$ as counting the number of ways to tile a row of length $p-1$ by tiles of size $1$ and $2$, where there is one type of tile of size $1$ and $\frac{q-1}{4}$ types of tiles of size $2$.  The problem is that I don't see, say, an obvious action of the cyclic group $\mathbb{Z}/p\mathbb{Z}$ on this set.  Any ideas?</p>

 
Answer: <p>The following paper seems to answer your question: P. T. Young, <em>"Quadratic reciprocity via Lucas sequences"</em>, Fibonacci Quart. <strong>33</strong> (1995), no. 1, 78–81.</p>

<p>Here's its <a href="http://www.ams.org/mathscinet-getitem?mr=1316286">MathSciNet Review</a> by A. Grytczuk:</p>

<blockquote>
  <p>Let $\{\gamma_n\}^\infty_{n=0}$ be a given Lucas sequence defined by $\gamma_0=0$, $\gamma_1=1$, $\gamma_{n+1}=\lambda \gamma_n+\mu \gamma_{n-1}$, $n\geq 1$, $\lambda, \mu\in{\bf Z}$, and let $q$ be an odd prime such that $D=(\frac{-1}q)q=\lambda^2+4\mu$. Then the author proves that there is a unique formal power series $\Phi$ with integer coefficients and constant term zero such that (1) $\sum^\infty_{n=1}\gamma_n\Phi^n(t)/n=\sum^\infty_{n=1}(\frac nq)t^n/n$ holds, where $(\frac nq)$ is the Legendre symbol.<br>
     From this result follows the Gauss law of quadratic reciprocity in the following form: (2) $(\frac pq)=(\frac Dp)$, where $p$, $q$ are distinct odd primes and $D=(\frac{-1}q) q=\lambda^2+4\mu$.</p>
</blockquote>

<p>Here's the <a href="http://www.mathstat.dal.ca/FQ/Scanned/33-1/young.pdf">direct link</a> to the paper.</p>

==============================
===============================
Question: <p>I have been fascinated by this problem since I first heard about it in high school.  From the Wikipedia article <a href="http://en.wikipedia.org/wiki/Collatz_problem">http://en.wikipedia.org/wiki/Collatz_problem</a>:</p>

<blockquote>
  <p>Take any natural number $n$. If $n$ is even, divide it by $2$ to get $n / 2$, if $n$ is odd multiply it by $3$ and add $1$ to obtain $3n + 1$. Repeat the process indefinitely. The conjecture is that no matter what number you start with, you will always eventually reach $1$. [...]</p>
  
  <p>Paul Erdős said about the Collatz conjecture: "Mathematics is not yet ready for such problems." He offered $500 USD for its solution.</p>
</blockquote>

<p>My question is: how important do you consider the answer to this question, and why?</p>

<p>And would you speculate on what might have possessed Paul Erdős to make such an offer?</p>

<p>EDIT: Is there any reason to think that a proof of the Collatz Conjecture would be
complex (like FLT) rather than simple (like PRIMES is in P)?  And can this
characterization of FLT vs. PRIMES is in P be made more specific than a bit-length comparison?</p>

 
Answer: <p>Most of the answers so far have been along the general lines of 'Why hard problems are important', rather than 'Why the Collatz conjecture is important'; I will try to address the latter.</p>

<p>I think the basic question being touched on is:</p>

<blockquote>
  <p>In what ways does the prime factorization of $a$ affect the prime factorization of $a+1$?</p>
</blockquote>

<p>Of course, one can always multiply out the prime factorization, add one, and then factor again, but this throws away the information of the prime factorization of $a$.  Note that this question is also meaningful in other UFDs, like $\mathbb{C}[x]$.</p>

<p>It seems very hard to come up with answers to this question that don't fall under the heading of 'immediate', such as distinct primes in each factorization.  This seems to be in part because a small change in the prime factorization for $a$ (multiplication by a prime, say) can have a huge change in the prime factorization for $a+1$ (totally distinct prime support perhaps).  Therefore, it is tempting to regard the act of adding 1 as an essentially-random shuffling of the prime factorization.</p>

<p>The most striking thing about the Collatz conjecture is that it seems to be making a deep statement about a subtle relation between the prime factorizations of $a$ and $a+1$.  Note that the Collatz iteration consists of three steps; two of which are 'small' in terms of the prime factorization, and the other of which is adding one:</p>

<ul>
<li>multiplying by 3 has a small effect on the factorization.</li>
<li>adding 1 has a (possibly) huge effect on the factorization.</li>
<li>factoring out a power of 2 has a small effect on the factorization (in that it doesn't change the other prime powers in the factorization).</li>
</ul>

<p>So, the Collatz conjecture seems to say that there is some sort of abstract quantity like 'energy' which is cannot be arbitrarily increased by adding 1.  That is, no matter where you start, and no matter where this weird prime-shuffling action of adding 1 takes you, eventually the act of pulling out 2s takes enough energy out of the system that you reach 1.  I think it is for reasons like this that mathematicians suspect that a solution of the Collatz conjecture will open new horizons and develop new and important techniques in number theory.</p>

==============================
===============================
Question: <p>If $n&gt;1$ is an integer, then $\sum \limits_{k=1}^n \frac1k$ is not an integer.</p>

<p>If you know <a href="http://en.wikipedia.org/wiki/Bertrand%27s_postulate">Bertrand's Postulate</a>, then you know there must be a prime $p$ between $n/2$ and $n$, so $\frac 1p$ appears in the sum, but $\frac{1}{2p}$ does not. Aside from $\frac 1p$, every other term $\frac 1k$ has $k$ divisible only by primes smaller than $p$. We can combine all those terms to get $\sum_{k=1}^n\frac 1k = \frac 1p + \frac ab$, where $b$ is not divisible by $p$. If this were an integer, then (multiplying by $b$) $\frac bp +a$ would also be an integer, which it isn't since $b$ isn't divisible by $p$.</p>

<p>Does anybody know an elementary proof of this which doesn't rely on Bertrand's Postulate? For a while, I was convinced I'd seen one, but now I'm starting to suspect whatever argument I saw was wrong.</p>

 
Answer: <p><strong>Hint</strong> $\ $ Since there is a unique denominator $\rm\:\color{#C00} {2^K}\:$ having maximal power of $2,\,$ upon multiplying all terms through by $\rm\:2^{K-1}$ one deduces the contradiction that $\rm\ 1/2\, =\, c/d \;$ with $\rm\: d \:$ odd, $ $ e.g.</p>

<p>$$\begin{eqnarray} &amp; &amp;\rm\ \ \ \  \color{green}{m}  &amp;=&amp;\ \  1 &amp;+&amp; \frac{1}{2} &amp;+&amp; \frac{1}{3} &amp;+&amp;\, \color{#C00}{\frac{1}{4}} &amp;+&amp; \frac{1}{5} &amp;+&amp; \frac{1}{6} &amp;+&amp; \frac{1}{7} \\
&amp;\Rightarrow\ &amp;\rm\ \ \color{green}{2m} &amp;=&amp;\ \ 2 &amp;+&amp;\ 1 &amp;+&amp; \frac{2}{3} &amp;+&amp;\, \color{#C00}{\frac{1}{2}} &amp;+&amp; \frac{2}{5} &amp;+&amp; \frac{1}{3} &amp;+&amp; \frac{2}{7}^\phantom{M^M}\\
&amp;\Rightarrow\ &amp; -\color{#C00}{\frac{1}{2}}\ \ &amp;=&amp;\ \ 2 &amp;+&amp;\ 1 &amp;+&amp; \frac{2}{3} &amp;-&amp;\rm \color{green}{2m}  &amp;+&amp; \frac{2}{5} &amp;+&amp; \frac{1}{3} &amp;+&amp; \frac{2}{7}^\phantom{M^M}
\end{eqnarray}$$</p>

<p>The prior sum has all odd denominators so reduces to a fraction with odd denominator $\rm\,d\, |\, 3\cdot 5\cdot 7$.</p>

<p><strong>Note</strong> $\ $ I purposely avoided any use of valuation theory because Anton requested an "elementary" solution. The above proof can easily be made comprehensible to a high-school student.</p>

==============================
===============================
Question: <p>This is a final exam question in my algorithms class:</p>

<p>$k$ is a taxicab number if $k = a^3+b^3=c^3+d^3$, and $a,b,c,d$ are distinct positive integers. Find all taxicab numbers $k$ such that $a,b,c,d &lt; n$ in $O(n)$ time.</p>

<p>I don't know if the problem had a typo or not, because $O(n^3)$ seems more reasonable. The best I can come up with is $O(n^2 \log n)$, and that's the best anyone I know can come up with. </p>

<p>The $O(n^2 \log n)$ algorithm: </p>

<ol>
<li><p>Try all possible $a^3+b^3=k$ pairs, for each $k$, store $(k,1)$ into a binary tree(indexed by $k$) if $(k,i)$ doesn't exist, if $(k,i)$ exists, replace $(k,i)$ with $(k,i+1)$</p></li>
<li><p>Transverse the binary tree, output all $(k,i)$ where $i\geq 2$</p></li>
</ol>

<p>Are there any faster methods? This should be the best possible method without using any number theoretical result because the program might output $O(n^2)$ taxicab numbers. </p>

<p>Is $O(n)$ even possible? One have to prove there are only $O(n)$ taxicab numbers lesser than $2n^3$ in order to prove there exist a $O(n)$ algorithm.</p>

<p><strong>Edit</strong>: The professor admit it was a typo, it should have been $O(n^3)$. I'm happy he made the typo, since the answer Tomer Vromen suggested is amazing.</p>

 
Answer: <p>I don't know about $O(n)$, but I can do it in $O(n^2)$. The main idea is to use <a href="http://eli.thegreenplace.net/2008/08/23/initializing-an-array-in-constant-time/">initialization of an array in $O(1)$</a> (this is the best reference that I've found, which is weird since this seems like a very important concept). Then you iterate through all the possible $(a,\ b)$ pairs and do the same as step 1 in your proposed algorithm. Since $a^3+b^3 \leq 2n^3$, the array needs to be of size $2n^3$, but it's still initialized in $O(1)$. Accessing an array element is $O(1)$ like in a regular array.</p>

==============================
===============================
Question: <p>Consider the sequence defined as</p>

<p>$x_1 = 1$</p>

<p>$x_{n+1} = \sin x_n$</p>

<p>I think I was able to show that the sequence $\sqrt{n} x_{n}$ converges to $\sqrt{3}$ by a tedious elementary method which I wasn't too happy about.</p>

<p>(I think I did this by showing that $\sqrt{\frac{3}{n+1}} &lt; x_{n} &lt; \sqrt{\frac{3}{n}}$, don't remember exactly)</p>

<p>This looks like it should be a standard problem. </p>

<p>Does anyone know a simple (and preferably elementary) proof for the fact that the sequence $\sqrt{n}x_{n}$ converges to $\sqrt{3}$?</p>

 
Answer: <p>Before getting into the details, let me say: The ideas I'm talking about, including this exact example, can be found in chapter 8 of <i>Asymptotic Methods in Analysis</i> (second edition), by N. G. de Bruijn. This is a really superb book, and I recommend it to anyone who wants to learn how to approximate quantities in "calculus-like" settings. (If you want to do approximation in combinatorial settings, I recommend Chapter 9 of <i>Concrete Mathematics</i>.) </p>

<p>Also, this isn't just about $\sin$. Let $f$ be a function with $f(0)=0$ and $0 \leq f(u) &lt; u$ for $u$ in $(0,c]$ then the sequence $x_n:=f(f(f(\cdots f(c)\cdots)$ approaches $0$. If $f(u)=u-a u^{k+1} + O(u^{k+2})$ (with $a&gt;0$) then $x_n \approx \alpha n^{-1/k}$ and you can prove that by the same methods here.</p>

<p>Having said that, the answer to your question. On $[0,1]$, we have
$$\sin x=x-x^3/6+O(x^5).$$
Setting $y_n=1/x_n^2$, we have
$$1/x_{n+1}^2 = x_n^{-2} \left(1-x_n^2/6+O(x_n^4) \right)^{-2} =  1/x_n^2 + 1/3 + O(x_n^2)$$
so
$$y_{n+1} = y_n + 1/3 + O(y_n^{-1}).$$</p>

<p>We see that
$$y_n = \frac{n}{3} + O\left( \sum_{k=1}^n y_k^{-1} \right)$$
and
$$\frac{1}{n}y_n = \frac{1}{3} + \frac{1}{n} O\left( \sum_{k=1}^n y_k^{-1} \right)$$
Since we already know that $x_n \to 0$, we know that $y_n^{-1} \to 0$, so the average goes to zero and we get $\lim_{n \to \infty} y_n/n=1/3$. Transforming back to $\sqrt{n} x_n$ now follows by the continuity of $1/\sqrt{t}$.  </p>

==============================
===============================
Question: <p>Some years ago I was interested in the following Markov chain
whose state space is the positive integers. The chain begins at state "1", 
and from state "n" the chain next jumps to a state uniformly
selected from {n+1,n+2,...,2n}.</p>

<p>As time goes on, this chain goes to infinity, with occasional
large jumps. In any case, the chain is quite unlikely to hit any
particular large n.</p>

<p>If you define p(n) to be the probability that this chain
visits state "n", then p(n) goes to zero like c/n for some 
constant c. In fact, </p>

<p>$$    np(n) \to c = {1\over 2\log(2)-1} = 2.588699. \tag1$$</p>

<p>In order to prove this convergence, I recast it as an analytic 
problem. Using the Markov property, you can see that the sequence
satisfies: </p>

<p>$$   p(1)=1\quad\mbox{ and }\quad p(n)=\sum_{\lceil n/2\rceil}^{n-1} {p(j)\over j}\mbox{ for }n&gt;1.  \tag2$$</p>

<p>For some weeks, using generating functions etc. I tried and failed to find
an analytic proof of the convergence in (1). Finally, at a conference
in 2003 Tom Mountford showed me a (non-trivial) probabilistic proof.</p>

<p>So the result is true, but since then I've
continued to wonder if I missed something obvious. Perhaps there is
a standard technique for showing that (2) implies (1).</p>

<p><strong>Question:</strong> Is there a direct (short?, analytic?) proof of (1)? </p>

<p>Perhaps someone who understands sequences better than I do could take a shot at this.</p>

<p><strong>Update:</strong> I'm digging through my old notes on this. I now remember that I had a proof (using generating functions) that <em>if</em> $\ np(n)$ converges, then the limit is $1\over{2\log (2)-1}$. It was the convergence that eluded me.</p>

<p>I also found some curiosities like: $\sum_{n=1}^\infty {p(n)\over n(2n+1)}={1\over 2}.$ </p>

<p><strong>Another update</strong>: Here is the conditional result mentioned above. </p>

<p>As in Qiaochu's answer, define $Q$ to be the generating function of $p(n)/n$, that is,
 $Q(t)=\sum_{n=1}^\infty {p(n)\over n} t^n$ for $0\leq t&lt;1$.
 Differentiating gives
 $$Q^\prime(t)=1+{Q(t)-Q(t^2)\over 1-t}.$$
 This is slightly different from Qiaochu's expression because
 $p(n)\neq \sum_{j=\lceil n/2\rceil}^{n-1} {p(j)\over j}$ when $n=1$,
 so that $p(1)$ has to be treated  separately.</p>

<p>Differentiating again and multiplying by $1-t$, we get
 $$(1-t)Q^{\prime\prime}(t)=-1+2\left[Q^\prime(t)-t Q^\prime(t^2)\right],$$
 that is,
 $$(1-t)\sum_{j=0}^\infty (j+1) p(j+2) t^j =  -1+2\left[\sum_{j=1}^\infty (jp(j)) {t^j-t^{2j}\over j}\right].$$</p>

<p>Assume that $\lim_n np(n)=c$ exists. Letting $t\to 1$ above the left hand side gives $c$,
 while the right hand side is $-1+2c\log(2)$ and hence $c={1\over 2\log(2)-1}$.</p>

<p>Note: $\sum_{j=1}^\infty {t^j-t^{2j}\over j}=\log(1+t).$ </p>

<p><strong>New update: (Sept. 2)</strong> </p>

<p>Here's an alternative proof of the conditional result that my colleague Terry Gannon
 showed me in 2003.</p>

<p>Start with the sum $\sum_{n=2}^{2N}\ p(n)$, substitute the formula in the title,
 exchange the variables $j$ and $n$, and rearrange to establish the identity:</p>

<p>$${1\over 2}=\sum_{j=N+1}^{2N} {j-N\over j}\ {p(j)}.$$</p>

<p>If $jp(j)\to c$, then
$1/2=\lim_{N\to\infty} \sum_{j=N+1}^{2N} {j-N\over j^2}\  c=(\log(2)-1/2)\  c,$ so that
$c={1\over 2\log(2)-1}$.</p>

<p><strong>New update: (Sept. 8)</strong> Despite the nice answers and interesting discussion below, I am still holding out for an (nice?, short?) analytic proof of convergence. Basic Tauberian theory is allowed :) </p>

<p><strong>New update: (Sept 13)</strong> I have posted a sketch of the probabilistic proof of convergence under "A fun and frustrating recurrence sequence" in the "Publications" section of my homepage.</p>

<p><strong>Final Update:</strong> (Sept 15th) The deadline is approaching, so I have decided to award the bounty to T.. 
Modulo the details(!), it seems that the probabilistic approach is the most likely to lead to a proof.</p>

<p>My sincere thanks to everyone who worked on the problem, including those who tried it but 
didn't post anything. </p>

<p>In a sense, I <em>did</em> get an answer to my question: there doesn't seem to be an easy, or standard
proof to handle this particular sequence.  </p>

 
Answer: <p>Update: the following probabilistic argument I had posted earlier shows only that $p(1) + p(2) + \dots + p(n) = (c + o(1)) \log(n)$ and not, as originally claimed, the convergence $np(n) \to c$.  Until a complete proof is available [edit: George has provided one in another answer] it is not clear whether $np(n)$ converges or has some oscillation, and at the moment there is evidence in both directions.  Log-periodic or other slow oscillation is known to occur in some problems where the recursion accesses many previous terms.  Actually, everything I can calculate about $np(n)$ is consistent with, and in some ways suggestive of, log-periodic fluctuations, with convergence being the special case where the bounds could somehow be strengthened and the fluctuation scale thus squeezed down to zero.</p>

<hr>

<p>$p(n) \sim c/n$ is [edit: only in average] equivalent to $p(1) + p(2) + \dots + p(n)$ being asymptotic to $c \log(n)$.  The sum up to $p(n)$ is the expected time the walk spends in the interval [1,n].  For this quantity there is a simple probabilistic argument that explains (and can rigorously demonstrate) the asymptotics.</p>

<p>This Markov chain is a discrete approximation to a log-normal random walk.  If $X$ is the position of the particle, $\log X$ behaves like a simple random walk with steps $\mu \pm \sigma$ where $\mu = 2 \log 2 - 1 = 1/c$ and $\sigma^2 = (1- \mu)^2/2$.  This is true because <em>the Markov chain is bounded between two easily analyzed random walks with continuous steps</em>.</p>

<p>(Let X be the position of the particle and $n$ the number of steps; the walk starts at X=1, n=1.)</p>

<p>Lower bound walk $L$: at each step, multiply X by a uniform random number in [1,2] and replace n by (n+1).   $\log L$ increases, on average, by $\int_1^2 log(t) dt = 2 \log(2) - 1$ at each step.</p>

<p>Upper bound walk $U$: at each step, jump from X to uniform random number in [X+1,2X+1] and replace n by (n+1).  </p>

<p>$L$ and $U$ have means and variances that are the same within $O(1/n)$, where the $O()$ constants can be made explicit.  Steps of $L$ are i.i.d and steps of $U$ are independent, asymptotically identical-distributed.  Thus, the Central Limit theorem shows that $\log X$ after $n$ steps is approximately a Gaussian with mean $n\mu + O(\log n)$ and variance $n\sigma^2 + O(\log n)$.  </p>

<p>The number of steps for the particle to escape the interval $[1,t]$ is therefore $({\log t})/\mu$ with fluctuations of size $A \sqrt{\log t}$ having probability that decays rapidly in A  (bounded by $|A|^p \exp(-qA^2)$ for suitable constants).   Thus, the sum p(1) + p(2) + ... p(n) is asymptotically equivalent to $(\log n)/(2\log (2)-1)$.</p>

<p>Maybe this is equivalent to the 2003 argument from the conference.  If the goal is to get a proof from the generating function, it suggests that dividing by $(1-x)$ may be useful for smoothing the p(n)'s.</p>

==============================
===============================
Question: <p>In <a href="http://terrytao.wordpress.com/2010/01/02/254a-notes-0a-stirlings-formula/" rel="noreferrer">these notes by Terence Tao</a> is a proof of Stirling's formula.  I really like most of it, but at a crucial step he uses the integral identity</p>

<p>$$n! = \int_{0}^{\infty} t^n e^{-t}  dt$$</p>

<p>coming from the Gamma function.  I have a mathematical confession to make: I have never "grokked" this identity.  Why should I expect the integral on the right to give me the number of elements in the symmetric group on $n$ letters?  </p>

<p>(It's not that I don't know how to prove it.  It's quite fun to prove; my favorite proof observes that it is equivalent to the integral identity $\int_{0}^{\infty} e^{(x-1)t}  dt = \frac{1}{1 - x}$.  But if someone were to ask me, "yes, but why, <em>really</em>?" I would have no idea what to say.)</p>

<p>So what are more intuitive ways of thinking about this identity?  Is there a probabilistic interpretation?  What kind of random variable has probability density function $\frac{t^n}{n!} e^{-t}$?  (What does this all have to do with Tate's thesis?)</p>

<p>As a rough measure of what I'm looking for, your answer should make it obvious that $t^n e^{-t}$ attains its maximum at $t = n$.</p>

<p>Edit:  The kind of explanation I'm looking for, as I described in the comments, is similar to <a href="https://math.stackexchange.com/questions/3528/beta-function-derivation/3540#3540">this explanation</a> of the beta integral.</p>

 
Answer: <p>I haven't quite got this straight yet, but I think one way to go is to think about choosing points at random from the positive reals. This answer is going to be rather longer than it really needs to be, because I'm thinking about this in a few (closely related) ways, which probably aren't all necessary, and you can decide to reject the uninteresting parts and keep anything of value. Very roughly, the idea is that if you "randomly" choose points from the positive reals and arrange them in increasing order, then the probability that the $(n+1)^\text{th}$ point is in a small interval $(t,t+dt)$ is a product of probabilities of independent events, $n$ factors of $t$ for choosing $n$ points in the interval $[0,t]$, one factor of $e^{-t}$ as all the other points are in $[t,\infty)$, one factor of $dt$ for choosing the point in $(t,t+dt)$, and a denominator of $n!$ coming from the reordering. At least, as an exercise in making a simple problem much harder, here it goes...</p>

<p>I'll start with a bit of theory before trying to describe intuitively why the probability density $\dfrac{t^n}{n!}e^{-t}$ pops out.</p>

<p>We can look at the <a href="http://en.wikipedia.org/wiki/Poisson_process" rel="nofollow noreferrer">homogeneous Poisson process</a> (with rate parameter $1$). One way to think of this is to take a sequence on independent exponentially distributed random variables with rate parameter $1$, $S_1,S_2,\ldots$, and set $T_n=S_1+\cdots+S_n$. As has been commented on already, $T_{n+1}$ has the probability density function $\dfrac{t^n}{n!}e^{-t}$. I'm going to avoid proving this immediately though, as it would just reduce to manipulating some integrals. Then, the Poisson process $X(t)$ counts the number of times $T_i$ lying in the interval $[0,t]$.</p>

<p>We can also look at Poisson point processes (aka, <a href="http://en.wikipedia.org/wiki/Poisson_random_measure" rel="nofollow noreferrer">Poisson random measures</a>, but that Wikipedia page is very poor). This is just makes rigorous the idea of randomly choosing unordered sets of points from a sigma-finite measure space $(E,\mathcal{E},\mu)$. Technically, it can be defined as a set of nonnegative integer-valued random variables $\{N(A)\colon A\in\mathcal{E}\}$ counting the number of points chosen from each subset A, such that $N(A)$ has the Poisson distribution of rate $\mu(A)$ and $N(A_1),N(A_2),\ldots$ are independent for pairwise disjoint sets $A_1,A_2,\ldots$. By definition, this satisfies
$$
\begin{array}{}\mathbb{P}(N(A)=n)=\dfrac{\mu(A)^n}{n!}e^{-\mu(A)}.&amp;&amp;(1)\end{array}
$$
The points $T_1,T_2,\ldots$ above defining the homogeneous Poisson process also define a Poisson random measure with respect to the Lebesgue measure $(\mathbb{R}\_+,{\cal B},\lambda)$. Once you forget about the order in which they were defined and just regard them as a random set that is, which I think is the source of the $n!$. If you think about the probability of $T_{n+1}$ being in a small interval $(t,t+\delta t)$ then this is just the same as having $N([0,t])=n$ and $N((t,t+\delta t))=1$, which has probability $\dfrac{t^n}{n!}e^{-t}\delta t$.</p>

<p>So, how can we choose points at random so that each small set $\delta A$ has probability $\mu(\delta A)$ of containing a point, and why does $(1)$ pop out? I'm imagining a hopeless darts player randomly throwing darts about and, purely by luck, hitting the board with some of them. Consider throwing a very large number $N\gg1$ of darts, independently, so that each one only has probability $\mu(A)/N$ of hitting the set, and is distributed according to the probability distribution $\mu/\mu(A)$. This is consistent, at least, if you think about the probability of hitting a subset $B\subseteq A$. The probability of missing with all of them is $(1-\mu(A)/N)^N=e^{-\mu(A)}$. This is a multiplicative function due to independence of the number hitting disjoint sets. To get the probability of one dart hitting the set, multiply by $\mu(A)$ (one factor of $\mu(A)/N$ for each individual dart, multiplied by $N$ because there are $N$ of them). For $n$ darts, we multiply by $\mu(A)$ $n$ times, for picking $n$ darts to hit, then divide by $n!$ because we have over-counted the subsets of size $n$ by this factor (due to counting all $n!$ ways of ordering them). This gives $(1)$. I think this argument can probably be cleaned up a bit.</p>

<p>Getting back to choosing points randomly on the positive reals, this gives a probability of $\dfrac{t^n}{n!}e^{-t}dt$ of picking $n$ in the interval $[0,t]$ and one in $(t,t+dt)$. If we sort them in order as $T_1\lt T_2\lt\cdots$ then $\mathbb{P}(T_1\gt t)=e^{-t}$, so it is exponentially distributed. Conditional on this, $T_2,T_3,\ldots$ are chosen randomly from $[T_1,\infty)$, so we see that the differences $T_{i+1}-T_{i}$ are independent and identically distributed.</p>

<p>Why is $\dfrac{t^n}{n!}e^{-t}$ maximized at $t=n$? I'm not sure why the mode should be a simple property of a distribution. It doesn't even exist except for unimodal distributions. As $T_{n+1}$ is the sum of $n+1$ IID random variables of mean one, the law of large numbers suggests that it should be peaked approximately around $n$. The central limit theorem goes further, and gives $\dfrac{t^n}{n!}e^{-t}\approx\dfrac{1}{\sqrt{2\pi n}}e^{-(t-n)^2/{2n}}$. Stirling's formula is just this evaluated at $t=n$.</p>

<p>What's this to do with Tate's thesis? I don't know, and I haven't read it (but intend to), but have a vague idea of what it's about. If there is anything to do with it, maybe it is something to do with the fact that we are relating the sums of independent random variables $S_1+\cdots+S_n$ distributed with respect to the Haar measure on the multiplicative group $\mathbb{R}_+$ (edit: oops, that's not true, the multiplicative Haar measure has cumulative distribution given by $\log$, not $\exp$) with randomly chosen sets according to the Haar measure on the additive group $\mathbb{R}$.</p>

==============================
===============================
Question: <p>At the beginning of <a href="http://math.ucr.edu/home/baez/week300.html">Week 300 of John Baez's blog</a>,
Baez gives a proof that the "number" of finite sets (more specifically, the cardinality of the groupoid of all finite sets, where an object in the groupoid counts as $1/n!$ if it has $n!$ symmetries) equals $e$.</p>

<p>He then says that this leads to a purely combinatorial proof that $e^x$ is its own derivative.</p>

<p>Can anyone explain the purely combinatorial proof?</p>

 
Answer: <p>I am not quite sure how to translate this into groupoid cardinality language, but here is the standard proof.  Suppose $A(x) = \sum_{n \ge 0} a_n \frac{x^n}{n!}$ is an exponential generating function.  Then we should interpret $a_n$ as being the number of ways to put a certain structure on a set of size $n$.  For example, when $a_n = 1$ this is the structure of "being a set."  When $a_n = n!$ this is the structure of "being a totally ordered set."  And so forth.  We will call this an $A$-structure.</p>

<p>Then $A'(x) = \sum_{n \ge 0} a_{n+1} \frac{x^n}{n!}$ can be interpreted as having coefficients $b_n = a_{n+1}$ which count the number of ways to add an element to a set of size $n$, then put an $A$-structure on the resulting set of size $n+1$.  This is a purely combinatorial definition of differentiation.</p>

<p>With this definition, the proof is quite obvious: there is exactly one way for a set to be a set, and there is also exactly one way to add an element to a set and then make the result a set.  So $\frac{d}{dx} e^x = e^x$.</p>

<p>This proof might seem contentless.  Try to see how it generalizes to show that $\frac{d}{dx} e^{ax} = ae^{ax}$ for any positive integer $a$, and if you're up for a challenge see if you can generalize it all the way to <a href="http://qchu.wordpress.com/2009/06/24/gila-vi-the-cycle-index-polynomials-of-the-symmetric-groups/">this identity</a>.</p>

<p>Vaguely the proof in groupoid cardinality language goes like this.  For a finite set $X$ the groupoid of finite sets equipped with a function to $X$ has cardinality $e^{|X|}$.  (The morphisms between two objects $A \to X, B \to X$ in this category are isomorphisms $A \simeq B$ such that the obvious triangle commutes.)  One way to think about this groupoid is as the groupoid of "colored" sets, where $X$ is the set of colors and an isomorphism must respect color.  Then it is easy to see that an isomorphism class of colored sets where there are $|X|$ colors is the same thing as a disjoint union of isomorphism classes of $|X|$ sets, one for each color.  One gets a direct interpretation of the terms in the expansion $\left( \sum_{n \ge 0}^{\infty} \frac{1}{n!} \right)^{|X|}$ this way.</p>

<p>Differentiation replaces $|X|^n$ with $n|X|^{n-1}$, which means that we replace functions from an $n$-element set $S$ to $X$ with functions from $S - \{ s \}$ to $X$ where $s$ ranges over all elements of $S$.  The resulting groupoid is still the groupoid of finite sets equipped with a function to $X$; in particular, it has the same cardinality.  (Note that $X$ does not really have to be a finite set of a particular size for this argument to work; it can be a "formal" set in the same way that $x$ is a formal variable and the resulting groupoid cardinality is a generating function instead of a number.  I think this is what the formal theory of "stuff types" is for, but I am not familiar with it.)</p>

==============================
===============================
Question: <p>Could you provide a proof of Euler's formula: $e^{i\varphi}=\cos(\varphi) +i\sin(\varphi)$?</p>

 
Answer: <p>Assuming you mean $e^{ix}=\cos x+i\sin x$, one way is to use the MacLaurin series for sine and cosine, which are known to converge for all real $x$ in a first-year calculus context, and the MacLaurin series for $e^z$, trusting that it converges for pure-imaginary $z$ since this result requires complex analysis.</p>

<p>The MacLaurin series:
\begin{align}
\sin x&amp;=\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n+1)!}x^{2n+1}=x-\frac{x^3}{3!}+\frac{x^5}{5!}-\cdots
\\\\
\cos x&amp;=\sum_{n=0}^{\infty}\frac{(-1)^n}{(2n)!}x^{2n}=1-\frac{x^2}{2!}+\frac{x^4}{4!}-\cdots
\\\\
e^z&amp;=\sum_{n=0}^{\infty}\frac{z^n}{n!}=1+z+\frac{z^2}{2!}+\frac{z^3}{3!}+\cdots
\end{align}</p>

<p>Substitute $z=ix$ in the last series:
\begin{align}
e^{ix}&amp;=\sum_{n=0}^{\infty}\frac{(ix)^n}{n!}=1+ix+\frac{(ix)^2}{2!}+\frac{(ix)^3}{3!}+\cdots
\\\\
&amp;=1+ix-\frac{x^2}{2!}-i\frac{x^3}{3!}+\frac{x^4}{4!}+i\frac{x^5}{5!}-\cdots
\\\\
&amp;=1-\frac{x^2}{2!}+\frac{x^4}{4!}+\cdots +i\left(x-\frac{x^3}{3!}+\frac{x^5}{5!}-\cdots\right)
\\\\
&amp;=\cos x+i\sin x
\end{align}</p>

==============================
===============================
Question: <p>If memory serves, ten years ago to the week (or so), I taught first semester freshman calculus for the first time.  As many calculus instructors do, I decided I should ask some extra credit questions to get students to think more deeply about the material.  The first one I asked was this:</p>

<p>1) Recall that a function $f: \mathbb{R} \rightarrow \mathbb{R}$ is said to have a <strong>removable discontinuity</strong> at a point $x_0 \in \mathbb{R}$ if $\lim_{x \rightarrow x_0} f(x)$ exists but not does not equal $f(x_0)$.  Does there exist a function $f$ which has a removable discontinuity at $x_0$ <em>for every</em> $x_0 \in \mathbb{R}$?</p>

<p>Commentary: if so, we could define a new function $\tilde{f}(x_0) = \lim_{x \rightarrow x_0} f(x)$ and it seems at least that $\tilde{f}$ has a fighting chance to be continuous on $\mathbb{R}$.  Thus we have successfully "removed the discontinuities" of $f$, but in so doing we have changed the value at every point!  </p>

<p>Remark: Lest you think this is too silly to even seriously contemplate, consider the function $f: \mathbb{Q} \rightarrow \mathbb{Q}$ given by $f(0) = 1$ and for a nonzero 
rational number $\frac{p}{q}$, $f(\frac{p}{q}) = \frac{1}{q}$.  It is easy to see that this function has limit $0$ at every (rational) point!</p>

<p>So I mentioned this problem to my students.  A week later, the only person who asked me about it at all was my Teaching Assistant, who was an older undergraduate, not even a math major, I think.  (I hasten to add that this was not in any sense an honors calculus class, i.e., I was pretty clueless back then.)  Thinking about it a bit, I asked him if he knew about uncountable sets, and he said that he didn't.  At that point I realized that I didn't have a solution in mind that he would understand (so still less so for the freshman calculus students) and I advised him to forget all about it.</p>

<blockquote>
  <p>So <strong>my actual question is</strong>: can you solve this problem using only the concepts in a non-honors freshman calculus textbook?  (In particular, without using notions of un/countability?)</p>
  
  <p>[<b>Addendum</b>: Let me say explicitly that I would welcome an answer that proceeds directly in terms of the least upper bound axiom.  Most freshman calculus books <em>do</em> include this, albeit somewhere hidden from view of the casual readers, i.e., actual freshman calculus students.]</p>
</blockquote>

<p>If you can't figure out how to answer the question at all, I think the following related question helps.</p>

<p>2) Define a function $f: \mathbb{R} \rightarrow \mathbb{R}$ to be <strong>precontinuous</strong> if the limit exists at every point.  For such a function, we can define $\tilde{f}$ as above.  Prove/disprove that, as suggested above, $\tilde{f}$ is indeed continuous.  [Then think about $f - \tilde{f}$.]</p>

<p>Now that I think about it, there is an entire little area here that I don't know anything about, e.g.</p>

<p>3) The set of discontinuities of an arbitrary function is known -- any $F_{\sigma}$ set inside $\mathbb{R}$ can serve.  What can we say about the set of discontinuities of a "precontinuous function"?  [Edit: from the link provided in Chandru1's answer, we see that it is countable.  What <em>else</em> can we say?  Note that taking the above example and extending by $0$ to the irrationals, we see that the set of points of discontinuity of a precontinuous function can be dense.]</p>

 
Answer: <p>I think the following works:</p>

<p>Here is a sketch, I will fill in the details later if required.</p>

<p>Let $g(x) = \lim_{t\rightarrow x} f(t)$. Then we can show that $g(x)$ is continuous.</p>

<p>Let $h(x) = f(x) - g(x)$. Then $\lim_{t \rightarrow x} h(t)$ exists and is $0$ everywhere.</p>

<p>We will now show that $h(c) = 0$ for some $c$. </p>

<p>This will imply that $f(x)$ is continuous at $c$ as then we will have $f(c) = g(c) = \lim_{t->c} f(t)$.</p>

<p>Consider any point $x_0$.</p>

<p>By limit of $h$ at $x_0$ being $0$, there is a closed interval $I_0$ (of length > 0) such that $|h(x)| &lt; 1$ for all $x \in I_0$.</p>

<p>This is because, given an $\epsilon > 0$ there is a $\delta > 0$ such that $|h(x)| &lt; \epsilon$ for all $x$ such that $0 &lt; |x - x_{0}| &lt; \delta$. Pick $\epsilon = 1$ and pick $I_{0}$ to be any closed interval of non-zero length in $(x_{0}, x_{0} + \delta)$.</p>

<p>Now pick any point $x_1$ in $I_0$.</p>

<p>By limit of $h$ at $x_1$ being $0$, there is a closed interval $I_1 \subset I_0$ (of length > 0) such that $|h(x)| &lt; 1/2$ for all $x \in I_1$, by argument similar to above.</p>

<p>Continuing this way, we get a sequence of closed intervals $I_n$ such that</p>

<p>$|h(x)| &lt; \frac{1}{n+1}$ for all $x \in I_n$. We also have that $I_{n+1} \subset I_n$ for each $n$, and that length $I_n$ > 0. We could also arrange so that length $I_n \rightarrow 0$.</p>

<p>Now there is a point $c$ (by completeness of $\mathbb{R}$) such that $c \in \bigcap_{n=0}^{\infty}I_{n}$.</p>

<p>Thus we have that $|h(c)| &lt; \frac{1}{n+1}$ for all $n$ and so $h(c) = 0$ and $f(c) = g(c)$.</p>

==============================
===============================
Question: <p>I really like mathematics, but I am not good at learning it.  I find it takes me a long time to absorb new material by reading on my own and I haven't found a formula that works for me.  I am hoping a few people out there will tell me how they go about learning math so I can try out their systems.</p>

<p>I need to know basic things.  </p>

<ul>
<li><p>Should I use one book at a time or should I be reading many books on the same topic at once? </p></li>
<li><p>Do you stop reading when you hit on a fact that you don't understand or do you keep reading?</p></li>
<li><p>Do you read all in one go or do you do a little bit and for how long (1 hr, 2 hr or more?)</p></li>
<li><p>Do you read all the chapters or do you do all the exercises before moving on from a chapter?</p></li>
<li><p>Do you adjust your technique in Calculus (calculation heavy) vs. Analysis (proof heavy)? If so, how?</p></li>
<li><p>When you make notes, what do you make notes about? Do you make notes while you read or after?</p></li>
<li><p>If you think these decisions all depend, can you say what they depend on?</p></li>
</ul>

<p>I am really lost here.  I would appreciate any input.</p>

 
Answer: <p>Of course everybody has their own learning style.  Here are some general suggestions.</p>

<p>Find a <strong>teacher</strong>.  It is <em>hard</em> to learn mathematics on your own until you have reached a certain level of mathematical sophistication; nobody is there to tell you what is important and what is unimportant.  Take courses at a university; as Agusti Roig mentioned, video lectures on MIT's <a href="http://ocw.mit.edu/index.htm">OpenCourseWare</a> are a good cheap alternative.  </p>

<p><strong>Read</strong> as much mathematics as you possibly can, from as many sources as you possibly can.  This is not limited to textbooks but extends to popular math books, blogs, expository papers, MO, math.SE... doing this will get you used to not understanding things, which is important.  It will also expose you to many fascinating ideas that will fire up your curiosity enough for you to look at the material more seriously.  As <a href="http://math.stanford.edu/~vakil/potentialstudents.html">Ravi Vakil</a> says:</p>

<blockquote>...mathematics is so rich and infinite that it is impossible to learn it systematically, and if you wait to master one topic before moving on to the next, you'll never get anywhere. Instead, you'll have tendrils of knowledge extending far from your comfort zone. Then you can later backfill from these tendrils, and extend your comfort zone; this is much easier to do than learning "forwards". </blockquote>

<p>A specific way in learning backwards is easier than learning forwards is that instead of reading the proof of a theorem in a book, you might hear about a theorem without proof, but remember that someone on a blog said something vague about a crucial step, then gradually learn enough material that suddenly you can work out the proof independently.  I have done this a handful of times, and it is quite satisfying. For example, the theorem I proved in <a href="http://qchu.wordpress.com/2010/04/27/the-mckay-correspondence-i/">this blog post</a> is classical and extremely well-known, but I had never seen a proof of it.  I juggled around some ideas for about half a year until I figured out how to prove Lemma 6 (which I saw in a paper somewhere, again without proof), and I wrote down a proof.  Later I read a proof in an actual book, and although the second half of the proof was similar, it did not use Lemma 6.  I have yet to see a proof of Lemma 6 in print, although I am sure it is also well-known.  </p>

<p>This might sound like more work.  But guess how well I <em>remember</em> this theorem and its proof now!</p>

<p><strong>Do</strong> as much mathematics as you possibly can.  This is not limited to textbook exercises but includes competition problems, finding alternate proofs of theorems, working out concrete examples of abstract theorems, etc.  I try to do this as much as I can on <a href="http://qchu.wordpress.com/">my blog</a>; it keeps me sharp and is also, at least for me, much more fun than reading a textbook, which I can't do for long periods of time.  This is also why I post here so often.</p>

<p><strong>Question</strong> everything.  There are a few aspects to this.  If something is unclear or unmotivated to you, ask yourself exactly where it becomes unclear or unmotivated.  Find someone to explain it to you (for example, on math.SE!).  Read a blog post about it.  <em>Write</em> a blog post about it!  Ask yourself how things generalize and how they connect to other things you know.  (Again, math.SE is good for this.)  The worst thing you can do is to accept what a textbook tells you as the Word of God.</p>

<p>Finally, <strong>teach</strong> as much mathematics as you possibly can.  This is the other purpose of my blog, and is an amazing test of how well you understand something.  You would be surprised how much you can learn about something by teaching it.  </p>

==============================
===============================
Question: <p>There is a theorem that states that if $f$ is analytic in a domain $D$, and the closed disc {$  z:|z-\alpha|\leq r$} contained in $D$, and $C$ denotes the disc's boundary followed in the positive direction, then for every $z$ in the disc we can write:
$$f(z)=\frac{1}{2\pi i}\int\frac{f(\zeta)}{\zeta-z}d\zeta$$</p>

<p>My question is:
<strong>What is the intuitive explanation of this formula?</strong> (For example, but not necessary, geometrically.)</p>

<p>(Just to clarify - I know the proof of this theorem, I'm just trying to understand where does this exact formula come from.)</p>

 
Answer: <p>Irene, if you are looking for intution then let us <em>assume</em> that we can expand $f(\zeta)$ into a power series around $z$: $f(\zeta) = \sum_{n \geq 0} c_n(\zeta - z)^n$. Note $c_0 = f(z)$.
If you plug this into the integral and interchange the order of integration 
and summation then that integral on the right side of the formula 
becomes $\sum_{n \geq 0} \int c_n(\zeta - z)^{n-1}d\zeta$.  Let us also assume that an integral along a contour doesn't change if we deform the contour continuously through a region where the function is "nice". So let us take as our path of integration a circle going once around the point $z$ (counterclockwise). Then you are basically reduced to 
showing that $\int (\zeta - z)^{m}d\zeta$ is 0 for $m \geq 0$ and is $2\pi i$ for $m = -1$.
These can be done by direct calculations using polar coordinates with $\zeta = z + e^{it}$.  Now divide by $2\pi i$ and you have the formula.  Of course this is a hand-wavy argument in places, but the question was not asking for a rigorous proof.  Personally, this is how I first came to terms with understanding how Cauchy's integral formula could be guessed.</p>

==============================
===============================
Question: <p>In the comments to the question: <a href="https://math.stackexchange.com/questions/3978/if-ann-mid-bnn-for-all-n-then-a-b">If $(a^{n}+n ) \mid (b^{n}+n)$ for all $n$, then $ a=b$</a>, there was a claim that $5^n+n$ is never prime (for integer $n&gt;0$).</p>

<p>It does not look obvious to prove, nor have I found a counterexample.</p>

<p>Is this really true?</p>

<p><strong>Update</strong>: $5^{7954} + 7954$ has been found to be prime by a computer: <a href="http://www.mersenneforum.org/showpost.php?p=233370&amp;postcount=46" rel="nofollow noreferrer">http://www.mersenneforum.org/showpost.php?p=233370&amp;postcount=46</a></p>

<p>Thanks to Douglas (and lavalamp)!</p>

 
Answer: <p>A general rule-of-thumb for "is there a prime of the form f(n)?" questions is, unless there exists a set of small divisors D, called a <em>covering set,</em> that divide every number of the form f(n), then there will eventually be a prime.  See, e.g. <a href="http://en.wikipedia.org/wiki/Sierpinski_number">Sierpinski numbers</a>.</p>

<p>Running WinPFGW (it should be available from the primeform yahoo group <a href="http://tech.groups.yahoo.com/group/primeform/">http://tech.groups.yahoo.com/group/primeform/</a>), it found that $5^n+n$ is <a href="http://en.wikipedia.org/wiki/Probable_prime">3-probable prime</a> when n=7954.  Moreover, for every n less than 7954, we have $5^n+n$ is composite.</p>

<p>To actually certify that $5^{7954}+7954$ is a prime, you could use Primo (available from <a href="http://www.ellipsa.eu/public/misc/downloads.html">http://www.ellipsa.eu/public/misc/downloads.html</a>).  I've begun running it (so it's passed a few more pseudo-primality tests), but I doubt I will continue until it's completed -- it could take a long time (e.g. a few months).</p>

<p>EDIT: $5^{7954}+7954$ is officially prime.  A proof certificate was given by lavalamp at <a href="http://www.mersenneforum.org/showpost.php?p=233370&amp;postcount=46">mersenneforum.org</a>.</p>

==============================
===============================
Question: <p>I got this interesting question in my mind:</p>

<blockquote>
  <p>How do we prove that if $a \in  \mathbb N$, then $\sqrt a$ is an integer or an irrational number?</p>
</blockquote>

<p>Can we extend this result? That is, can it be shown that if $a,b \in \mathbb N$, then $a^{1/b}$ is an integer or an irrational number?</p>

 
Answer: <p>These (standard) results are discussed in detail in </p>

<p><a href="http://math.uga.edu/~pete/4400irrationals.pdf">http://math.uga.edu/~pete/4400irrationals.pdf</a></p>

<p>This is the second handout for a first course in number theory at the advanced undergraduate level.  Three different proofs are discussed:</p>

<p>1) A generalization of the proof of irrationality of $\sqrt{2}$, using the decomposition of any positive integer into a perfect $k$th power times a $k$th power-free integer, followed by Euclid's Lemma.  (For some reason, I don't give all the details of this proof.  Maybe I should...)</p>

<p>2) A proof using the functions $\operatorname{ord}_p$, very much along the lines of the one Carl Mummert mentions in his answer.</p>

<p>3) A proof by establishing that the ring of integers is integrally closed.  This is done directly from unique factorization, but afterwards I mention that it is a special case of the Rational Roots Theorem.</p>

<p>Let me also remark that every proof I have ever seen of this fact uses the Fundamental Theorem of Arithmetic (existence and uniqueness of prime factorizations) in some form.  [<b>Edit</b>: I have now seen Robin Chapman's answer to the question, so this is no longer quite true.]  However, if you want to prove any particular case of the result, you can use a brute force case-by-case analysis that avoids FTA.  </p>

==============================
===============================
Question: <p>We know that the sine function takes it values between $[-1,1]$. So is the set $$A = \{ \sin{n} \ : \ n \in \mathbb{N}\}$$ dense in $[-1,1]$. Generally, for showing the set is dense, one proceeds, by finding out what is $\overline{A}$ of this given set. And if $\overline{A} = [-1,1]$, we are through with the proof, but i having trouble here!</p>

<p>Similarly can one do this with cosine function also, that is proving $B= \{ \cos{n} \ : \ n \in \mathbb{N}\}$ being dense in $[-1,1]$</p>

 
Answer: <p>The hard part is to show that for any $x$ such that $0 \le x \le 2\pi$, and any $\epsilon>0$ there exists a real number $y$ and two integers $m$ and $n$ such that $|y-x|&lt;\epsilon$ and $n=2\pi m+y$. Hint: break up $[0,2\pi]$ into small subintervals, remember that $\pi$ is irrational and apply the pigeonhole principle.</p>

==============================
===============================
Question: <p>My question was inspired by <a href="https://math.stackexchange.com/questions/5035/1-1-2-1-3-1-n">this</a> stackexchange question. For the last 90 minutes I have been trying to prove this formula due to <a href="http://en.wikipedia.org/wiki/Euler-Mascheroni_constant" rel="nofollow noreferrer">Gregorio Fontana</a>:</p>

<p>$$H_n = \gamma + \log n + {1 \over 2n} - \sum_{k=2}^\infty { (k-1)! C_k \over n(n+1)\ldots(n+k-1)},
\qquad \textrm{ for } n=1,2,3,\ldots,$$</p>

<p>where $H_n = \sum_{k=1}^n 1/k$ and the coefficients $C_k$ are the Gregory coefficients given by
$${ z \over \log(1-z)} = \sum_{n=0}^\infty C_k z^k \qquad \textrm{ for } |z|&lt;1.$$</p>

<p>It's a bit frustrating as it's something I recall proving as a student many years ago. I have a vague recollection that I began with something like:</p>

<p>$$H_n = \int_0^1 {1-(1-x)^n \over x } \textrm{d}x,$$</p>

<p>but my attempts to follow on from there have failed. Can you help?</p>

 
Answer: <p>Let's rewrite the formula, using $C_1=1/2$ as
$$S_n=\gamma+\log n-H_{n-1}$$
where
$$S_n=\sum_{k=1}^\infty\frac{(k-1)!C_k}{n(n+1)\cdots(n+k-1)}.$$
Use the formula
$$\frac{(k-1)!}{n(n+1)\cdots(n+k-1)}=\int_0^1 x^{n-1}(1-x)^{k-1}dx$$
which is a special case of the beta integral.
Therefore
$$S_n=\int_0^1x^{n-1}\sum_{k=1}^\infty C_k(1-x)^k
dx=\int_0^1\left(\frac{1}{1-x}+\frac{1}{\log x}\right)x^{n-1}dx.$$
When $n=1$ we get
$$S_1=\int_0^1\left(\frac{1}{1-x}+\frac{1}{\log x}\right)dx=\gamma$$
by a well-known <a href="http://en.wikipedia.org/wiki/Euler-Mascheroni_constant" rel="nofollow">formula</a> which can be derived from the aymptotic
$$\int_t^\infty\frac{e^{-x}}{x}dx=-\log t-\gamma+O(t)$$
as $t\to0$, for the exponential integral.</p>

<p>By induction it suffices to consider the difference
$$S_n-S_{n+1}=\int_0^1\left(x^{n-1}+\frac{x^{n-1}-x^n}{\log x}\right)dx
=\frac1n-\int_0^\infty\frac{e^{-ny}-e^{-(n+1)y}}{y}dy.$$
Using the identity
$$\int_0^\infty\frac{e^{-ay}-e^{-by}}{y}dy=\log\frac ba$$
for $0 &lt; a &lt; b$ 
which follows by integrating $e^{-xy}$ over the region $[a,b]\times[0,\infty)$
we get
$$S_n-S_{n+1}=\frac1n-\log\frac{n+1}{n}.$$
The desired formula for $S_n$ now follows by induction.</p>

==============================
===============================
Question: <p>A famous exercise which one encounters while doing Complex Analysis (Residue theory) is to prove that the given integral:
$$\int_0^\infty \frac{\sin x} x \,\mathrm dx = \frac \pi 2.$$</p>

<p>Well, can anyone prove this without using Residue theory. I actually thought of doing this:
$$\int_0^\infty \frac{\sin x} x \,\mathrm  dx = \lim_{t \to \infty} \int_0^t \frac{1}{t} \left( t - \frac{t^3}{3!} + \frac{t^5}{5!} + \cdots \right) \,\mathrm  dt,$$
but I don't see how $\pi$ comes here, since we need the answer to be equal to $\frac{\pi}{2}$.</p>

 
Answer: <p>Here's another way of finishing off Derek's argument. He proves
$$\int_0^{\pi/2}\frac{\sin(2n+1)x}{\sin x}dx=\frac\pi2.$$
Let
$$I_n=\int_0^{\pi/2}\frac{\sin(2n+1)x}{x}dx=
\int_0^{(2n+1)\pi/2}\frac{\sin x}{x}dx.$$
Let
$$D_n=\frac\pi2-I_n=\int_0^{\pi/2}f(x)\sin(2n+1)x\ dx$$
where
$$f(x)=\frac1{\sin x}-\frac1x.$$
We need the fact that if we define $f(0)=0$ then $f$ has a continuous
derivative on the interval $[0,\pi/2]$. Integration by parts yields
$$D_n=\frac1{2n+1}\int_0^{\pi/2}f'(x)\cos(2n+1)x\ dx=O(1/n).$$
Hence $I_n\to\pi/2$ and we conclude that
$$\int_0^\infty\frac{\sin x}{x}dx=\lim_{n\to\infty}I_n=\frac\pi2.$$</p>

==============================
===============================
Question: <p>While working on a proof showing that all functions limited to the domain of real numbers can be expressed as a sum of their odd and even components, I stumbled into a troublesome roadblock; namely, I had no clue how one divides the function into these even and odd parts.</p>

<p>Looking up a solution for the proof, I found these general formulas for the even and odd parts of a function $f(n)$:</p>

<p>$$\begin{align*}
f_e(n)&amp;\overset{\Delta}{=}\frac{f(n)+f(-n)}{2}\\
f_o(n)&amp;\overset{\Delta}{=}\frac{f(n)-f(-n)}{2}
\end{align*}$$</p>

<p>While I understand that in an even function $f(n) = f(-n)$ and that in an odd function $f(-n) = -f(n)$, I still don't get how these general formulas for the even and odd parts were obtained. Can someone guide me through the logic?</p>

 
Answer: <p>Suppose you could write a function $f(x)$ as the sum of an even and an odd function; call them $E(x)$ and $O(x)$. </p>

<p>In particular, you would have
\[f(x) = E(x)+O(x)\]
and you would also have
\[f(-x) = E(-x) + O(-x) = E(x) - O(x)\]
with the latter equation because we are assuming $E$ is even and $O$ is odd, so $E(x)=E(-x)$ and $O(-x) = -O(x)$.</p>

<p>Adding both equations you get $f(x)+f(-x) = 2E(x)$. Subtracting the second equation from the first gives you $f(x)-f(-x)=2O(x)$. Now solve for $E(x)$ and $O(x)$, and you get the formulas you see in the solution. Then you check that the answer does indeed work (that is, you check that the formulas you found do give you an even and an odd function in all cases).</p>

<p>In other words: pretend you already know the answer, and try to deduce conditions that the answer must satisfy (these will be <em>necessary</em> conditions); if things go well, you'll get enough information about what they <em>must</em> be like to figure out <em>what</em> they are.</p>

==============================
===============================
Question: <p>I am reading a Set Theory book by Kunen. He presents first-order logic and claims that if a set of sentences in inconsistent, then it proves every possible sentence. Since he does not explicitly specify the inference rules, I became curious as to how fundamental this property of inconsistent systems is.</p>

<p>So my question is what is the simplest proof, with the least use of assumptions, of the vague claim that "inconsistent systems can prove anything" - in particular I'm interested in the assumptions about the system needed to prove this - is it true only for first order logic? Only for first order logic with the "standard" rules of inference (Modus ponens and GEN)? Or is it such a basic truth that it can be proved for every "reasonable" proof system (and what is "reasonable")?</p>

 
Answer: <p>It doesn't have to: logics which don't are called paraconsistent.</p>

<p>The most important paraconsistent logic is relevance logic, which repudiates the K axiom:
$$\alpha \rightarrow \beta \rightarrow \alpha$$
and replaces it by axioms that do not allow there to be unused assumptions.  This is equivalent to saying weakening, the principle that if $\Gamma \vdash \alpha$ then $\Gamma'\vdash \alpha$ for $\Gamma\subset\Gamma'$.  This blocks derivations such as Weltschmertz's, which appeals to the K axiom once, Asaf's which uses it twice; Francesco appeals to monotonicity in his proof, which is another name for weakening.</p>

<p>It's not difficult to see that this also blocks proofs of everything from a contradictory pair of propositions in a logic satisfying compactness, since one can prove inductively about such proof systems that if $\alpha\rightarrow\beta$, then all positive atoms in $\beta$ must occur either negatively in $\beta$ or positively in $\alpha$.  So if our contradictory pair (over an assumption) takes the form $\alpha\rightarrow\beta$ and $\alpha\rightarrow\neg\beta$, we need to prove for any $\gamma$ that $\alpha\rightarrow\gamma$.  But if we choose $\gamma$ to be any positive atom not occuring in $\alpha$, our inductive proof tells us this cannot be done.  We need compactness here, to be ensure that the basis for all contradictory pairs can be expressed by a finitary formula.</p>

==============================
===============================
Question: <p>The web is littered with any number of pages (<a href="http://planetmath.org/proofofthueslemma">example</a>) giving an existence and uniqueness proof that a pair of squares can be found summing to primes congruent to 1 mod 4 (and also that there are no such pairs for primes congruent to 3 mod 4).</p>

<p>However, none of the stuff I've read on the topic offers any help with actually efficiently finding (ie other than a straight search up to sqrt(p)) the concrete values of such squares.</p>

<p>What's the best way to actually find them ?</p>

 
Answer: <p>In practice this comes to the same algorithm as Moron's, but I'll give
my two penn'orth anyway. There are two stages: (i) find $z$ with $z^2\equiv -1$
(mod $p$), and (ii) use $z$ to find $x$ and $y$.</p>

<p>Stage (i). If $a$ is a quadratic nonresidue modulo $p$ then $a^{(p-1)/2}
\equiv-1$ (mod $p$) so we can take $z\equiv a^{(p-1)/4}$ (mod $p$)
(and that is easily computed by <a href="http://en.wikipedia.org/wiki/Modular_exponentiation">modular exponentiation</a>).
How does one find quadratic nonresidues? Well just over half of all
numbers $a$ such that $1 &lt; a &lt; p-1$ 
are quadratic nonresidues, so taking $a$ at random
will need at most two goes on average.</p>

<p>Stage (ii). Compute the greatest common divisor of $p$ and $z+i$ using the
Euclidean algorithm for the <a href="http://en.wikipedia.org/wiki/Gaussian_integer">Gaussian integers</a>. The answer will
be $x+yi$ where $x^2+y^2=p$.</p>

<p>If $p\equiv 1$ (mod $2^k$) where $k\ge3$ one can speed up stage (i) a bit
on average. Compute $w=a^{(p-1)/2^k}$ modulo $p$. If $w\equiv\pm1$ we lose
but otherwise keep squaring $w$. Then we eventually get to $-1$ and before
that we have the required $z$. This sometimes wins even if $a$ is a quadratic
residue.</p>

<p>In effect the Gaussian gcd above and Moron's Hermite-Serret algorithm amount
to the same thing.</p>

<p>Below is some rough-and-ready Python code to compute $a$ and $b$ such that
$p=a^2+b^2$. The function that does this is 2sq. It will behave erratically
if fed p not a prime congruent to 1 modulo 4.</p>

<hr>

<pre><code>def mods(a, n):
    if n &lt;= 0:
        return "negative modulus"
    a = a % n
    if (2 * a &gt; n):
        a -= n
    return a

def powmods(a, r, n):
    out = 1
    while r &gt; 0:
        if (r % 2) == 1:
            r -= 1
            out = mods(out * a, n)
        r /= 2
        a = mods(a * a, n)
    return out

def quos(a, n):
    if n &lt;= 0:
        return "negative modulus"
    return (a - mods(a, n))/n

def grem(w, z):
    # remainder in Gaussian integers when dividing w by z
    (w0, w1) = w
    (z0, z1) = z
    n = z0 * z0 + z1 * z1
    if n == 0:
        return "division by zero"
    u0 = quos(w0 * z0 + w1 * z1, n)
    u1 = quos(w1 * z0 - w0 * z1, n)
    return(w0 - z0 * u0 + z1 * u1,
           w1 - z0 * u1 - z1 * u0)

def ggcd(w, z):
    while z != (0,0):
        w, z = z, grem(w, z)
    return w

def root4(p):
    # 4th root of 1 modulo p
    if p &lt;= 1:
        return "too small"
    if (p % 4) != 1:
        return "not congruent to 1"
    k = p/4
    j = 2
    while True:
        a = powmods(j, k, p)
        b = mods(a * a, p)
        if b == -1:
            return a
        if b != 1:
            return "not prime"
        j += 1

def sq2(p):
    a = root4(p)
    return ggcd((p,0),(a,1))
</code></pre>

==============================
===============================
Question: <p>It would seem that one way of proving this would be to show the existence of non-algebraic numbers. Is there a simpler way to show this?</p>

 
Answer: <p>As Steve D. noted, a finite dimensional vector space over a countable field is necessarily countable: if $v_1,\ldots,v_n$ is a basis, then every vector in $V$ can be written uniquely as $\alpha_1 v_1+\cdots+\alpha_n v_n$ for some scalars $\alpha_1,\ldots,\alpha_n\in F$, so the cardinality of the set of all vectors is exactly $|F|^n$. If $F$ is countable, then this is countable. Since $\mathbb{R}$ is uncountable and $\mathbb{Q}$ is countable, $\mathbb{R}$ cannot be finite dimensional over $\mathbb{Q}$. (Whether it has a basis or not depends on your set theory).</p>

<p>Your further question in the comments, whether a vector space over $\mathbb{Q}$ is finite dimensional <em>if and only if</em> the set of vectors is countable, has a negative answer. If the vector space is finite dimensional, then it is a countable set; but there are infinite-dimensional vector spaces over $\mathbb{Q}$ that are countable as sets. The simplest example is $\mathbb{Q}[x]$, the vector space of all polynomials with coefficients in $\mathbb{Q}$, which is a countable set, and has dimension $\aleph_0$, with basis $\{1,x,x^2,\ldots,x^n,\ldots\}$. </p>

<p><strong>Added:</strong> Of course, if $V$ is a vector space over $\mathbb{Q}$, then it has <em>countable dimension</em> (finite or denumerable infinite) if and only if $V$ is countable as a set. So the counting argument in fact shows that not only is $\mathbb{R}$ infinite dimensional over $\mathbb{Q}$, but that (if you are working in an appropriate set theory) it is <em>uncountably</em>-dimensional over $\mathbb{Q}$. </p>

==============================
===============================
Question: <p>I've come across a paper that mentions the fact that matrices commute if and only if they share a common basis of eigenvectors. Where can I find a proof of this statement?</p>

 
Answer: <p>Suppose that $A$ and $B$ are $n\times n$ matrices, with complex entries say, that commute.<br>
Then we decompose $\mathbb C^n$ as a direct sum of eigenspaces of $A$, say
$\mathbb C^n = E_{\lambda_1} \oplus \cdots \oplus E_{\lambda_m}$, where $\lambda_1,\ldots, \lambda_m$ are the eigenvalues of $A$, and $E_{\lambda_i}$ is the eigenspace for $\lambda_i$.
(Here $m \leq n$, but some eigenspaces could be of dimension bigger than one, so we need not have $m = n$.)</p>

<p>Now one sees that since $B$ commutes with $A$, $B$ preserves each of the $E_{\lambda_i}$:
If $A v = \lambda_i v, $ then $A (B v) = (AB)v = (BA)v = B(Av) = B(\lambda_i v) = \lambda_i Bv.$  </p>

<p>Now we consider $B$ restricted to each $E_{\lambda_i}$ separately, and decompose
each $E_{\lambda_i}$ into a sum of eigenspaces for $B$.   Putting all these decompositions together, we get a decomposition of $\mathbb C^n$ into a direct sum of spaces, each of which is a simultaneous eigenspace for $A$ and $B$.</p>

<p>NB: I am cheating here, in that $A$ and $B$ may not be diagonalizable (and then the statement of your question is not literally true), but in this case, if you replace "eigenspace" by "generalized eigenspace", the above argument goes through just as well.</p>

==============================
===============================
Question: <p>Any number less than 1 can be expressed in base g as $\sum _{k=1}^\infty {\frac {D_k}{g^k}}$, where $D_k$ is the value of the $k^{th}$ digit. If we were interested in only the non-zero digits of this number, we could equivalently express it as $\sum _{k=1}^\infty {\frac {C_k}{g^{Z(k)}}}$, where $Z(k)$ is the position of the $k^{th}$ non-zero digit base $g$ and $C_k$ is the value of that digit (i.e. $C_k = D_{Z(k)}$).</p>

<p>Now, consider all the numbers of this form $(\sum _{k=1}^\infty {\frac {C_k}{g^{Z(k)}}})$ where the function $Z(k)$ eventually dominates any polynomial. Is there a proof that any number of this form is transcendental?</p>

<p>So far, I have found a paper demonstrating this result for the case $g=2$; it can be found <a href="http://www.escholarship.org/uc/item/44t5s388?display=all">here</a>.</p>

 
Answer: <p>The answer to your question is yes. All numbers of the form $x=\sum_{n\ge0}\frac{C_k}{g^{Z(k)}}$ for Z(k) eventually dominating any polynomial are indeed transcendental. As in the question, g and C<sub>k</sub> are integers with 1&nbsp;&le;&nbsp;C<sub>k</sub>&nbsp;&le;&nbsp;g-1. In fact, the methods used by the paper linked in the question generalize in a quite straightforward way to handle this situation. I don't know of this result appearing in any published paper, but note the following points.</p>

<ol>
<li><p>We can say straight-away that x is irrational. This follows from Z(n) eventually dominating any linear function of n, so its base-g expansion is not eventually periodic. </p></li>
<li><p>If Z(n+1)/Z(n) is unbounded then, as noted in the comments, x will be a <a href="http://en.wikipedia.org/wiki/Liouville_number" rel="nofollow noreferrer">Liouville number</a> so, by Liouville's theorem, it is transcendental. For any N&nbsp;&gt;&nbsp;0, Z(n+1)&nbsp;&ge;&nbsp;NZ(n) for infinitely many n. The fact that it is a Liouville number follows from taking $p=\sum_{k=1}^nC_kg^{Z(n)-Z(k)}$ and $q=g^{Z(n)}$, giving the rational approximation $|x-p/q|&lt; g^{1+Z(n)-Z(n+1)}\le gq^{-N}$.</p></li>
<li><p>By the <a href="http://en.wikipedia.org/w/index.php?title=Thue%E2%80%93Siegel%E2%80%93Roth_theorem&amp;oldid=385480595" rel="nofollow noreferrer">Thue–Siegel–Roth theorem</a>, if Z(n+1)/Z(n)&nbsp;&ge;&nbsp;2+&epsilon; infinitely often (any &epsilon;&nbsp;&gt;&nbsp;0) then x will be transcendental. The theorem says that an irrational algebraic number has only finitely many rational approximations $\vert x-p/q\vert\le cq^{-2-\epsilon}$ for any fixed c,&epsilon;&nbsp;&gt;&nbsp;0. That x has infinitely many such rational approximations follows in the same way as for point 2 above. Every Z(n+1)&nbsp;&ge;&nbsp;(2+&epsilon;)Z(n) gives a rational approximation $\vert x-p/q\vert&lt; gq^{-2-\epsilon}$, so x cannot be algebraic. This covers the case where Z(n) grows exponentially of rate a<sup>n</sup> for any a&nbsp;&gt;&nbsp;2, but is not strong enough to cover cases such as Z(n)&nbsp;=&nbsp;2<sup>n</sup>.</p></li>
<li><p>If Z(n+1)/Z(n)&nbsp;&gt;&nbsp;1+&epsilon; infinitely often (any &epsilon;&nbsp;&gt;&nbsp;0) then x will be transcendental. This is a consequence of the Roth-Ridout theorem, from the 1957 paper <a href="http://dx.doi.org/10.1112/S0025579300001182" rel="nofollow noreferrer"><em>Rational approximations to algebraic numbers</em></a> (not free access, but is also quoted in the freely available paper <a href="http://seminariomatematico.dm.unito.it/rendiconti/cartaceo/53-3.html" rel="nofollow noreferrer"><em>An explicit version of the theorem of Roth-Ridout</em></a>, Theorem 2). The Roth-Ridout theorem strengthens the Thue-Siegel-Roth theorem implying, in particular, for irrational and algebraic x, there are only finitely many rational approximations $\vert x-p/q\vert\le cq^{-1-\epsilon}$ when the prime factors of q all belong to some fixed finite set <em>P</em>. In our case, we can let <em>P</em> be the set of prime factors of g and the result follows in the same way as for point 3 above. This shows that x is transcendental if Z(n) grows exponentially. (thanks to Mike Bennett over at mathoverflow for pointing out the Roth-Ridout theorem).</p></li>
<li><p>A paper by Bugeaud, <a href="http://rendiconti.math.unipd.it/volumes/vol118.php?lan=english" rel="nofollow noreferrer"><em>On the b-ary expansion of an algebraic number</em></a> shows that, if x is irrational and algebraic then for large enough n, there are at least (log n)<sup>1+1/(&omega;+4)</sup> (loglog n)<sup>-1/4</sup> nonzero digits among the first n digits of the base g expansion. Here, &omega; is the the number of prime divisors of g. This shows that, if Z(n)&nbsp;&ge;&nbsp;exp(cn<sup>&alpha;</sup>) for large n and any fixed c&nbsp;&gt;&nbsp;0, &alpha;&nbsp;&gt;&nbsp;1/(1+1/(&omega;+4)) then x is transcendental.</p></li>
<li><p>After reading through the details of the paper linked in the original question, I note that they do generalize to the base g&nbsp;&ge;&nbsp;2 case. So x is transcendental as long as Z(n) eventually dominates any polynomial. I don't know of any published paper proving this, but posted my proof on <a href="https://mathoverflow.net/questions/41609/have-all-numbers-with-sufficiently-many-zeros-been-proven-transcendental/41760#41760">mathoverflow</a> where this question was also asked. I have re-read through this proof a few times to be sure, and am now confident that it is correct (modulo small typos, etc). Also, Bugeaud posted an answer to the question agreeing that the method generalizes. Using #(x,n) to denote the number of non-zero digits in the first n digits of the base g expansion of x, the precise statement is as follows.</p>

<blockquote>
  <p>If x is irrational and satisfies a rational polynomial of degree D then #(x,n)&nbsp;&ge;&nbsp;cn<sup>1/D</sup> for a positive constant c and all large enough n.</p>
</blockquote></li>
</ol>

<p>In fact, you can easily remove the "large enough" from this statement, although I find it convenient stated in this way. The proof I wrote out is a generalization of the methods used in the paper linked in the question. There is one change worth noting though. Whereas the paper made use of the Thue-Siegel-Roth theorem at one point (Theorem 3.1), I used <a href="http://en.wikipedia.org/wiki/Liouville_number" rel="nofollow noreferrer">Liouville's theorem</a>. This means that the constant c appearing in the statement above is not quite as good (if you go through the proof and work it out explicitly) although, in any case, the paper linked in the question could have obtained a better value by using the Roth-Ridout theorem instead. Using Liouville's theorem does have two advantages though. Firstly, it is elementary. A proof of Liouville's theorem is given in the linked Wikipedia article. Secondly, it is <em>effective</em>. That is, not only can the constant c be calculated but you can also work out exactly what "large enough" means for n in the statement above (which will depend on the polynomial satisfied by x). The strengthened versions of Liouville's theorem such as Thue-Siegel-Roth and Roth-Ridout are not effective.</p>

==============================
===============================
Question: <p>Is there a simple explanation of what the Laplace transformations do exactly and how they work?  Reading my math book has left me in a foggy haze of proofs that I don't completely understand. I'm looking for an explanation in layman's terms so that I understand what it is doing as I make these seemingly magical transformations.</p>

<p>I searched the site and closest to an answer was <a href="https://math.stackexchange.com/questions/954/inverse-of-laplace-transform">this</a>. However, it is too complicated for me.</p>

 
Answer: <p>There are beautiful video lessons at <a href="http://ocw.mit.edu/index.htm">MIT Opencourseware</a>. I'm particularly in love with <a href="http://ocw.mit.edu/courses/mathematics/18-03-differential-equations-spring-2010/video-lectures/lecture-19-introduction-to-the-laplace-transform/">this</a> presentation of the Laplace transform.</p>

==============================
===============================
Question: <p><strong>Note:</strong> <a href="https://stackoverflow.com/q/3924602/33686">This question has been posted on StackOverflow</a>. I have moved it here because:</p>

<ol>
<li>I am curious about the answer</li>
<li>The OP has not shown any interest in moving it himself</li>
</ol>

<hr>

<p>In the Communications of the ACM, <a href="http://delivery.acm.org/10.1145/1790000/1787260/p128-winkler.html?key1=1787260&amp;key2=3588796821&amp;coll=portal&amp;dl=ACM&amp;CFID=108548737&amp;CFTOKEN=59330921" rel="nofollow noreferrer">August 2008 "Puzzled" column</a>, Peter Winkler asked the following question:</p>

<blockquote>
  <p>On the table before us are 10 dots,
  and in our pocket are 10 $1 coins.
  Prove the coins can be placed on the
  table (no two overlapping) in such a
  way that all dots are covered. Figure
  2 shows a valid placement of the coins
  for this particular set of dots; they
  are transparent so we can see them.
  The three coins at the bottom are not
  needed.</p>
</blockquote>

<p>In the <a href="http://delivery.acm.org/10.1145/1820000/1810917/p110-winkler.html?key1=1810917&amp;key2=2298796821&amp;coll=portal&amp;dl=ACM&amp;CFID=108548737&amp;CFTOKEN=59330921" rel="nofollow noreferrer">following issue</a>, he presented his proof:</p>

<blockquote>
  <p>We had to show that any 10 dots on a
  table can be covered by
  non-overlapping &#36;1 coins, in a problem
  devised by Naoki Inaba and sent to me
  by his friend, Hirokazu Iwasawa, both
  puzzle mavens in Japan.</p>
  
  <p>The key is to note that packing disks
  arranged in a honeycomb pattern cover
  more than 90% of the plane. But how do
  we know they do? A disk of radius one
  fits inside a regular hexagon made up
  of six equilateral triangles of
  altitude one. Since each such triangle
  has area $\frac{\sqrt{3}}{3}$, the hexagon
  itself has area $2 \sqrt{3}$; since the
  hexagons tile the plane in a honeycomb
  pattern, the disks, each with area $\pi$,
  cover $\frac{\pi}{2\sqrt{3}}\approx .9069$ of the
  plane's surface.</p>
  
  <p>It follows that if the disks are
  placed randomly on the plane, the
  probability that any particular point
  is covered is .9069. Therefore, if we
  randomly place lots of &#36;1 coins
  (borrowed) on the table in a hexagonal
  pattern, on average, 9.069 of our 10
  points will be covered, meaning at
  least some of the time all 10 will be
  covered. (We need at most only 10
  coins so give back the rest.)</p>
  
  <p>What does it mean that the disks cover
  90.69% of the infinite plane? The easiest way to answer is to say,
  perhaps, that the percentage of any
  large square covered by the disks
  approaches this value as the square
  expands. What is "random" about the
  placement of the disks? One way to
  think it through is to fix any packing
  and any disk within it, then pick a
  point uniformly at random from the
  honeycomb hexagon containing the disk
  and move the disk so its center is at
  the chosen point.</p>
</blockquote>

<p>I don't understand. Doesn't the probabilistic nature of this proof simply mean that in the <strong>majority</strong> of configurations, all 10 dots can be covered. Can't we still come up with a configuration involving 10 (or less) dots where one of the dots can't be covered?</p>

 
Answer: <p>Nice! The above proof proves that <em>any</em> configuration of 10 dots can be covered. What you have here is an example of the <a href="http://en.wikipedia.org/wiki/Probabilistic_method">probabilistic method</a>, which uses probability but gives a certain (not a probabilistic) conclusion (an example of <a href="http://en.wikipedia.org/wiki/Probabilistic_proofs_of_non-probabilistic_theorems">probabilistic proofs of non-probabilistic theorems</a>). This proof also implicitly uses the linearity of expectation, a fact that seem counter-intuitive in some cases until you get used to it.</p>

<p>To clarify the proof: given <em>any</em> configuration of 10 dots, <strong>fix</strong> the configuration, and consider placing honeycomb-pattern disks randomly. Now, what is the expected number $X$ of dots covered? Let $X_i$ be 1 if dot $i$ is covered, and $0$ otherwise. We know that $E[X] = E[X_1] + \dots + E[X_{10}]$, and also that $E[X_i] = \Pr(X_i = 1) \approx 0.9069$ as explained above, for all $i$. So $E[X] = 9.069$. (Note that we have obtained this result using linearity of expectation, even though it would be hard to argue about the events of covering the dots being independent.)</p>

<p>Now, since the average over placements of the disks (for the fixed configuration of points!) is 9.069, not <em>all</em> placements can cover ≤9 dots — at least one placement must cover all 10 dots.</p>

==============================
===============================
Question: <p>How does one prove the following limit?
$$
  \lim_{n \to \infty}
  \sqrt{1 + 2 \sqrt{1 + 3 \sqrt{1 + \cdots \sqrt{1 + (n - 1) \sqrt{1 + n}}}}}
= 3.
$$</p>

 
Answer: <p>This is the special case $\rm\ x,\:n,\:a = 2,\:1,\:0\ $ in Ramanujan's second notebook, chapter XII, entry 4:</p>

<p>$$\rm x + n + a\ =\ \sqrt{ax + (n+a)^2 + x\sqrt{a(x+n) + (n+a)^2 + (x+n) \sqrt{\cdots}}} $$</p>

<p>Below is Ramanujan's solution of the given special case - which was submitted to a journal in April 1911. Note that his solution is incomplete (exercise: why?). For further discussion see this 1935 Monthly article, <a href="http://www.jstor.org/stable/2301294" rel="noreferrer">Herschfeld: On infinite radicals.</a>  It also appeared as Problem A6 on the 27th Putnam competition, 1966. Vijayaraghavan proved that a sufficient criterion for the convergence of the following sequence $\ \sqrt{a_1 + \sqrt{a_2 +\:\cdots\: +\sqrt{a_n}}}\ \ $ is that $\rm\displaystyle\ \ {\overline \lim}_{n\to\infty}\frac{\log{a_n}}{2^n}\ &lt; \infty\:.\ $</p>

<p><img src="https://i.stack.imgur.com/UBCbs.jpg" alt="alt text"> </p>

==============================
===============================
Question: <p>Assume you want to prove an identity such as</p>

<p>$$\sum_{k=m+1}^{n}A(k,m)-B(k,m)=S(m)+T(n,m)\qquad\text{for } n,m\in 
\mathbb{Z},n,m\geq 0.$$</p>

<p><em>Added</em>: I applied mathematical induction on $m,n$ to prove it. I am unsure because up to now I have seen it applied to properties depending on a single variable only. </p>

<p>Question: does application of two inductive arguments, one on $m$ and the
other on $n$, guarantee the validity of such a proof? </p>

 
Answer: <p>Here are some induction principles for two variables:</p>

<ul>
<li>$P(0,0)$</li>
<li>$\forall x,y. P(x,y) \Rightarrow P(x+1,y)$</li>
<li><p>$\forall x,y. P(x,y) \Rightarrow P(x,y+1)$</p>

<hr></li>
<li><p>$\forall x,y. P(x,y)$</p></li>
</ul>

<p>and</p>

<ul>
<li>$P(0,0)$</li>
<li>$\forall x,y. P(x,0) \Rightarrow P(x+1,0)$</li>
<li><p>$\forall x,y. P(x+1,y) \Rightarrow P(x,y+1)$</p>

<hr></li>
<li><p>$\forall x,y. P(x,y)$</p></li>
</ul>

==============================
===============================
Question: <p>I would like to find the apothem of a regular pentagon. It follows from </p>

<p>$$\cos \dfrac{2\pi }{5}=\dfrac{-1+\sqrt{5}}{4}.$$</p>

<p>But how can this be proved (geometrically or trigonometrically)? </p>

 
Answer: <p>Since $x := \cos \frac{2 \pi}{5} = \frac{z + z^{-1}}{2}$ where $z:=e^{\frac{2 i \pi}{5}}$, and $1+z+z^2+z^3+z^4=0$ (for $z^5=1$ and $z \neq 1$), $x^2+\frac{x}{2}-\frac{1}{4}=0$, and voilà.</p>

==============================
===============================
Question: <p>So, I don't like proofs.</p>

<p>To me building a proof feels like constructing a steel trap out of arguments to <strong>make true</strong> what you're trying to assert.</p>

<p>Oftentimes the proof in the book is something that I get if I study, but hard to come up with on my own.  In other words I can't make steel traps, but I feel fine buying them from others.</p>

<p>How does one acquire the ability to create steel traps with fluency and ease?  Are there any particular reference books that you found helped you really get how to construct a proof fluently?  Or is it just practice?</p>

 
Answer: <p>I'd like to second one part of Qiaochu Yuan's answer: the recommendation to read Polya's book.  Unlike many other books I've seen (albeit none of the others recommended above), it actually does contain guidance on how to construct a proof "out of nothing".</p>

<p>And that's one problem with the "practise, practise, practise" mantra.  Practise what?  Where are the lists of similar-but-not-quite-identical things to prove to practise on?  I can find lists of integrals to do and lists of matrices to solve, but it's hard coming up with lists of things to prove.</p>

<p>Of course, practise is correct.  But just as with anything else in mathematics, there's guidelines to help get you started.</p>

<p>The first thing to realise is that reading others proofs is not guaranteed to give you any insight as to how the proof was developed.  A proof is meant to convince someone of a result, so a proof points to the theorem (or whatever) and knowing how the proof was constructed does not (or at least, <em>should not</em>) lend any extra weight to our confidence in the theorem.  Proofs can be written in this way, and when teaching we should make sure to present some proofs in this way, but to do it every time would be tedious.</p>

<p>So, what are the guidelines for constructing a proof?  You'll probably get different answers from different mathematicians so these should be construed as being my opinion and not a(n attempt at a) definitive answer.</p>

<p>My recommendation is that you take the statement that you want to prove and apply the following steps to it as often as you can:</p>

<ol>
<li><strong>Expand out unfamiliar terms.</strong></li>
<li><strong>Replacing generic statements by statements about generic objects.</strong></li>
<li><strong>Including implicit information.</strong></li>
</ol>

<p>Once you've done all that, the hope is that the proof will be much clearer.</p>

<p>Here's an example.</p>

<ol>
<li><p>Original statement:</p>

<blockquote>
  <p>The composition of linear transformations is again linear.</p>
</blockquote></li>
<li><p>Replace generic statements:</p>

<blockquote>
  <p>If $S$ and $T$ are two composable linear transformations then their composition, $S T$, is again linear.</p>
</blockquote>

<p>It is important to be precise here.  The word "composable" could have been left out, as the statement only makes sense if $S$ and $T$ are composable, but until you are completely familiar with this kind of process, it is better to be overly precise than otherwise.  In this case, leaving in the word "composable" reminds us that there is a restriction on the domains and codomains which will be useful later.  (However, one has to draw the line somewhere: even the word "composable" is not quite enough since it leaves open the question as to whether it is $S T$ or $T S$!)</p></li>
<li><p>Include implicit information:</p>

<blockquote>
  <p>If $S \colon V \to W$ and $T \colon U \to V$ are linear transformations then $S T \colon U \to W$ is again linear.</p>
</blockquote>

<p>Here's where remembering that $S$ and $T$ are composable in the previous step helps keep things clear.  As $S$ and $T$ are composable, we only need $3$ vector spaces.  Then, since we explicitly have the vector spaces the fact that $S$ and $T$ are composable is plain, though some may prefer to keep that fact in the statement.  Also, some may like to have the fact that $U$, $V$, and $W$ are <strong>vector</strong> spaces explicitly stated.</p></li>
<li><p>Expand out definitions:</p>

<blockquote>
  <p>If $S \colon V \to W$ and $T \colon U \to V$ are such that $S(v_1 + \lambda v_2) = S(v_1) + \lambda S(v_2)$ and $T(u_1) + \mu T(u_2)$ for all $v_1, v_2 \in V$, $u_1, u_2 \in U$, and $\lambda, \mu \in \mathbb{R}$, then $S T(x_1 + \eta x_2) = S T(x_1) + \eta S T(x_2)$ for all $x_1, x_2 \in U$ and $\eta \in \mathbb{R}$.</p>
</blockquote>

<p>Note that I have been careful not to repeat myself with the newly introduced symbols.  It would be technically alright to reuse $u_1$ and $u_2$ in place of $x_1$ and $x_2$ since these are <em>local</em> declarations (restricted by the phrases "for all ...").  However, humans are not good at differentiating between local and global declarations so it is best not to reuse symbols unless the scope is very clear.</p></li>
<li><p>Replace generic statements:</p>

<blockquote>
  <p>If $S \colon V \to W$ and $T \colon U \to V$ are such that $S(v_1 + \lambda v_2) = S(v_1) + \lambda S(v_2)$ and $T(u_1) + \mu T(u_2)$ for all $v_1, v_2 \in V$, $u_1, u_2 \in U$, and $\lambda, \mu \in \mathbb{R}$, then whenever  $x_1, x_2 \in U$ and $\eta \in \mathbb{R}$,  $S T(x_1 + \eta x_2) = S T(x_1) + \eta S T(x_2)$.</p>
</blockquote>

<p>Up to now, the rephrasing has not taken into account the fact that there is a <em>conclusion</em> and a <em>hypothesis</em>.  This rephrasing modifies a part of the conclusion to turn it from a generic statement "$P(p)$ is true for all $p \in Q$" to a statement about a generic object "whenever $p \in Q$ then $P(p)$ is true".  We do not do this for the similar statements in the hypothesis.  This is because these two pieces are treated differently in the proof.</p></li>
<li><p>Replace generic statements, and reorganise to bring choices to the fore:</p>

<blockquote>
  <p>Let $S \colon V \to W$ and $T \colon U \to V$ be such that $S(v_1 + \lambda v_2) = S(v_1) + \lambda S(v_2)$ and $T(u_1) + \mu T(u_2)$ for all $v_1, v_2 \in V$, $u_1, u_2 \in U$, and $\lambda, \mu \in \mathbb{R}$.  Let  $x_1, x_2 \in U$ and $\eta \in \mathbb{R}$.  Then  $S T(x_1 + \eta x_2) = S T(x_1) + \eta S T(x_2)$.</p>
</blockquote>

<p>In this form, the distinction between <em>hypothesis</em> and <em>conclusion</em> is all the clearer.  Parts of the hypothesis use the word "Let", parts of the conclusion use the word "Then".</p></li>
</ol>

<p>With this formulation, the proof essentially writes itself.  With all it's gory details:</p>

Proof

<p>Let $S \colon V \to W$ and $T \colon U \to V$ be such that $S(v_1 + \lambda v_2) = S(v_1) + \lambda S(v_2)$ and $T(u_1) + \mu T(u_2)$ for all $v_1, v_2 \in V$, $u_1, u_2 \in U$, and $\lambda, \mu \in \mathbb{R}$.  Let  $x_1, x_2 \in U$ and $\eta \in \mathbb{R}$.[^quick]  Then:</p>

<p>$$
S T(x_1 + \eta x_2) = S \big( T(x_1) + \eta T(x_2)\big)
$$</p>

<p>using the hypothesis on $T$ as $x_1, x_2 \in U$ and $\eta \in \mathbb{R}$.  So:</p>

<p>$$
S T(x_1 + \eta x_2) = S T(x_1) + \eta S T(x_2)
$$</p>

<p>using the hypothesis on $S$ as $T(x_1), T(x_2) \in V$ and $\eta \in \mathbb{R}$.  Hence the conclusion is true.</p>

<p>Notes:
1. This could be condensed, but the important thing here is how to <em>find</em> it, not what the final form should be.
2. Notice that I wrote "as $x_1, x_2 \in U$" rather than "with $u_1 = x_1$ and $u_2 = x_2$".  This is partly style, and partly because in the statement of linearity, $u_1$ and $u_2$ are <em>placeholders</em> into which we put $x_1$ and $x_2$.   So saying $u_1 = x_1$ is semantically incorrect as it equates a virtual vector with an actual vector.  This is a very minor point, though.</p>

<hr>

<p>Finally, I would like to disagree with one part of Qiaochu's answer.  I actually like the imagery of a steel trap.  A proof is a bit like a trap: we want to capture the theorem in a trap so that it can't wriggle out.  We construct the proof so that there is no possibility of escape.  Eventually, yes, we want the proof to be beautiful but when it's first constructed we just want it to do the job.  Only once the theorem is caught can we spend a little time decorating the cage to make it look pretty and set it off to its best advantage.  So build the trap because theorems can be dangerous!  An escaped theorem can do untold damage, rampaging across the countryside, laying waste like an unchecked viking.</p>

<p>(Okay, not quite finally.  The step-by-step proof above was taking from a page I wrote for my students on the nature of proof.  The original can be found <a href="http://loopspace.mathforge.org/CountingOnMyFingers/NatureOfProof/" rel="nofollow noreferrer">here</a>.)</p>

==============================
===============================
Question: <p>Much effort has been expended on a famous unsolved problem about the <a href="https://math.stackexchange.com/questions/540">Riemann Zeta function $\zeta(s)$</a>.  Not surprisingly, it's called the Riemann hypothesis, which asserts:</p>

<p>$$ \zeta(s) = 0 \Rightarrow \operatorname{Re} s = \frac1 2 \text{ or } \operatorname{Im} s = 0 .$$</p>

<p>Now there are numerical methods for approximating $\zeta(s)$, but as I understand, no one knows any exact values except at even integers, which include the trivial zeroes for which $\operatorname{Im} s = 0 $.  So I've always wondered:  <em>For the rest, how does one prove $\operatorname{Re} s = 1/2$ <strong>exactly</em></strong>?</p>

<p>(All I know that seems vaguely useful is the argument principle, which I'm not sure helps here, but I'd be happy to learn about other techniques that aren't too far advanced.)</p>

<p><strong>Edit</strong>:  Looking over this again, I found out I missed the closed-form values at <a href="http://en.wikipedia.org/wiki/Riemann_zeta_function#Specific_values" rel="nofollow noreferrer">odd negative integers</a>.  This doesn't affect the question but seemed worth correcting.  Thanks to the people who contributed.</p>

 
Answer: <p>As long as there are no multiple zeros on the line up to height  $T$  you can determine, rigorously and using a finite amount of computation:</p>

<ul>
<li><p>the number of zeros (counted with multiplicity) off the critical line, i.e., the number of counterexamples to the Riemann hypothesis, of height less than $T$.   This is done by contour integrals of $d \log \zeta$ -- the "argument principle" in complex analysis.  For each zero one can locate it to any specified accuracy, and determine its multiplicity.</p></li>
<li><p>the number of zeros on the critical line, up to height $T$.  For each zero, its ordinate on the line can be calculated to any desired accuracy.  This is done by counting sign changes of real-analytic functions with a $\zeta (1/2 + it)$ factor, on the critical line.  As Matt E mentioned, the ability to write down a real-valued function capturing the behavior of a complex function on a line is a special phenomenon particular to zeta and L-functions, coming from the functional equation relating $\zeta(s)$ to $\zeta(1-s)$.</p></li>
</ul>

<p>If there is a multiple zero of order $n$ at some point on the line, all you can determine by computations of the above type is that a very small neighborhood of that point contains $n$ zeros (counted with multiplicity).  This could mean zeros on the line, counterexamples to the Riemann conjecture, or both.</p>

<p>It is part of the package of conjectures surrounding the Riemann hypothesis, that there are no multiple zeros, and that the zeros in fact "repel" each other in a quantifiable sense. There is a lot of numerical and theoretical support for the zero repulsion, especially from random matrix theory.  If the Riemann hypothesis is true but there are multiple zeros, that would be almost as surprising as finding a zero off the line.</p>

==============================
===============================
Question: <p>For some collection of sets $A$, let $\sigma(A)$ denote the $\sigma$-algebra generated by $A$.</p>

<p>Let $C$ be some collection of subsets of a set $Y$, and let $f$ be a function from some set $X$ to $Y$. I want to prove:</p>

<p>$$f^{-1}(\sigma(C))=\sigma(f^{-1}(C))$$</p>

<p>I could prove that 
$$\sigma(f^{-1}(C)) \subset f^{-1}(\sigma(C))$$ 
since complements and unions are 'preserved' by function inverse. But how do I go the other way? </p>

<p>EDIT: One way to go the other way would be to argue that any set in $\sigma(C)$ must be built by <em>repeatedly</em> applying the complement, union and intersection operations to elements of $C$ and all these operations are preserved when taking the inverse. The problem I am facing with the approach is formalizing the word "repeatedly".</p>

<p><em>[not-homework]</em></p>

 
Answer: <p>Yes, we <em>can</em> use transfinite induction to prove this (formalizing the word "repeatedly"). That would be the bottom-up approach. There is also a top-down approach, using the characterization of $\sigma(C)$ as the smallest $\sigma$-algebra containing $C$. </p>

<p>A key fact here is the the preimage operation commutes with all the set algebra operations: if $f \colon X \to Y$ then</p>

<ul>
<li>$f^{-1}(A \cup B) = f^{-1}(A) \cup f^{-1}(B)$ </li>
<li>$f^{-1}(A \cap B) = f^{-1}(A) \cap f^{-1}(B)$ </li>
<li>$f^{-1}(A - B) = f^{-1}(A) - f^{-1}(B)$. In particular $f^{-1}(Y - A) = X - f^{-1}(A)$. </li>
</ul>

<p>and so forth. So $f^{-1}\colon P(Y) \to P(X)$ is a lattice homomorphism on the powerset lattices, to use that terminology.  More importantly for us, the preimage operation even commutes with infinite unions and intersections. </p>

<p>To show that $f^{−1}(\sigma(C)) \subseteq \sigma(f^{−1}(C))$, you could follow this strategy:</p>

<ul>
<li>Show that $f^{-1}(C) \in \sigma(f^{-1}(C))$</li>
<li>Show that if $f^{-1}(A_i) \in \sigma(f^{-1}(C))$ for $i \in \omega$ then  $f^{-1}(\bigcup A_i) \in \sigma(f^{-1}(C))$</li>
<li>Show that if $f^{-1}(A) \in \sigma(f^{-1}(C))$ then $f^{-1}(Y - A) \in \sigma(f^{-1}(C))$</li>
</ul>

<p>The point here is that, if we let $D$ be the collection of sets $A$ such that $f^{-1}(A) \in \sigma(f^{-1}(C))$, then $D$ is itself a $\sigma$ algebra containing $C$, which means $\sigma(C) \subseteq D$. But by the definition of $D$ this means $f^{-1}(\sigma(C)) \subseteq \sigma(f^{-1}(C))$.</p>

<p>None of the three bullets will require taking forward images under $f$. For example, for the third one, let $A$ be as stated. This means $f^{-1}(A)$ is in $\sigma(f^{-1}(C))$, which means that $X - f^{-1}(A)$ is also in $\sigma(f^{-1}(C))$. But $f^{-1}(Y - A)$ is exactly $X - f^{-1}(A)$, so we see that $f^{-1}(Y - A)$ is indeed in $\sigma(f^{-1}(C))$. </p>

<p>The underlying point here is that the entire proof is algebraic and that a more general theorem is true: you can replace $f^{-1}$ with any other homomorphism of the powerset lattices that preserves countable unions. </p>

==============================
===============================
Question: <p>One observes that 
\begin{equation*}
4!+1 =25=5^{2},~5!+1=121=11^{2} 
\end{equation*}
is a perfect square. Similarly for $n=7$ also we see that $n!+1$ is a perfect square. So one can ask the truth of this question:</p>

<ul>
<li>Is $n!+1$ a perfect square for infinitely many $n$? If yes, then how to prove.</li>
</ul>

 
Answer: <p>This is Brocard's problem, and it is still open.</p>

<p><a href="http://en.wikipedia.org/wiki/Brocard%27s_problem">http://en.wikipedia.org/wiki/Brocard%27s_problem</a></p>

==============================
===============================
Question: <p>Let $\varphi(n)$ be Euler's totient function, the number of positive integers less than or equal to $n$ and relatively prime to $n$.  </p>

<p>Challenge: Prove</p>

<p>$$\sum_{k=1}^n \left\lfloor \frac{n}{k} \right\rfloor \varphi(k) = \frac{n(n+1)}{2}.$$</p>

<p>I have two proofs, one of which is partially combinatorial.  </p>

<p>I'm posing this problem partly because I think some folks on this site would be interested in working on it and partly because I would like to see a purely combinatorial proof.  (But please post any proofs; I would be interested in noncombinatorial ones, too.  I've learned a lot on this site by reading alternative proofs of results I already know.)</p>

<p>I'll wait a few days to give others a chance to respond before posting my proofs.</p>

<p>EDIT: The two proofs in full are now given among the answers.</p>

 
Answer: <p>One approach is to use the formula $\displaystyle \sum_{d \mid k} \varphi(d) = k$ </p>

<p>So we have that $\displaystyle \sum_{k=1}^{n} \sum_{d \mid k} \varphi(d) = n(n+1)/2$</p>

<p>Exchanging the order of summation we see that the $\displaystyle \varphi(d)$ term appears $\displaystyle \left\lfloor \frac{n}{d} \right\rfloor$ times</p>

<p>and thus</p>

<p>$\displaystyle \sum_{d=1}^{n} \left\lfloor \frac{n}{d} \right\rfloor \varphi(d) = n(n+1)/2$</p>

<p>Or in other words, if we have the $n \times n$ matrix $A$ such that</p>

<p>$\displaystyle A[i,j] = \varphi(j)$ if $j \mid i$ and $0$ otherwise.</p>

<p>The sum of elements in row $i$ is $i$.</p>

<p>The sum of elements in column $j$ is $\displaystyle \left\lfloor \frac{n}{j} \right\rfloor \varphi(j)$ and the identity just says the total sum by summing the rows is same as the total sum by summing the columns.</p>

==============================
===============================
Question: <p>As I have heard people did not trust Euler when he first discovered the formula (solution of the <a href="http://en.wikipedia.org/wiki/Basel_problem">Basel problem</a>)
$$\zeta(2)=\sum_{k=1}^\infty \frac{1}{k^2}=\frac{\pi^2}{6}.$$
However, Euler was Euler and he gave other proofs. </p>

<p>I believe many of you know some nice proofs of this, can you please share it with us?</p>

 
Answer: <p>OK, here's my favorite. I thought of this after reading a proof from the book "Proofs from the book" by Aigner &amp; Ziegler, but later I found more or less the same proof as mine in <a href="http://homepage.univie.ac.at/josef.hofbauer/02amm.pdf">a paper</a> published a few years earlier by Josef Hofbauer. On Robin's list, the proof most similar to this is number 9
(EDIT: ...which is actually the proof that I read in Aigner &amp; Ziegler).</p>

<p>When $0 &lt; x &lt; \pi/2$ we have $0&lt;\sin x &lt; x &lt; \tan x$ and thus
$$\frac{1}{\tan^2 x} &lt; \frac{1}{x^2} &lt; \frac{1}{\sin^2 x}.$$
Note that $1/\tan^2 x = 1/\sin^2 x - 1$.
Split the interval $(0,\pi/2)$ into $2^n$ equal parts, and sum
the inequality over the (inner) "gridpoints" $x_k=(\pi/2) \cdot (k/2^n)$:
$$\sum_{k=1}^{2^n-1} \frac{1}{\sin^2 x_k} - \sum_{k=1}^{2^n-1} 1 &lt; \sum_{k=1}^{2^n-1} \frac{1}{x_k^2} &lt; \sum_{k=1}^{2^n-1} \frac{1}{\sin^2 x_k}.$$
Denoting the sum on the right-hand side by $S_n$, we can write this as
$$S_n - (2^n - 1) &lt; \sum_{k=1}^{2^n-1} \left( \frac{2 \cdot 2^n}{\pi} \right)^2 \frac{1}{k^2} &lt; S_n.$$</p>

<p>Although $S_n$ looks like a complicated sum, it can actually be computed fairly easily. To begin with,
$$\frac{1}{\sin^2 x} + \frac{1}{\sin^2 (\frac{\pi}{2}-x)} = \frac{\cos^2 x + \sin^2 x}{\cos^2 x \cdot \sin^2 x} = \frac{4}{\sin^2 2x}.$$
Therefore, if we pair up the terms in the sum $S_n$ except the midpoint $\pi/4$ (take the point $x_k$ in the left half of the interval $(0,\pi/2)$ together with the point $\pi/2-x_k$ in the right half) we get 4 times a sum of the same form, but taking twice as big steps so that we only sum over every other gridpoint; that is, over those gridpoints that correspond to splitting the interval into $2^{n-1}$ parts. And the midpoint $\pi/4$ contributes with $1/\sin^2(\pi/4)=2$ to the sum. In short,
$$S_n = 4 S_{n-1} + 2.$$
Since $S_1=2$, the solution of this recurrence is
$$S_n = \frac{2(4^n-1)}{3}.$$
(For example like this: the particular (constant) solution $(S_p)_n = -2/3$ plus the general solution to the homogeneous equation $(S_h)_n = A \cdot 4^n$, with the constant $A$ determined by the initial condition $S_1=(S_p)_1+(S_h)_1=2$.)</p>

<p>We now have
$$ \frac{2(4^n-1)}{3} - (2^n-1) \leq  \frac{4^{n+1}}{\pi^2} \sum_{k=1}^{2^n-1} \frac{1}{k^2}  \leq \frac{2(4^n-1)}{3}.$$
Multiply by $\pi^2/4^{n+1}$ and let $n\to\infty$. This squeezes the partial sums between two sequences both tending to $\pi^2/6$. Voilà!</p>

==============================
===============================
Question: <p>Well, this is an exercise problem from <em>Herstein</em> which sounds difficult:</p>

<ul>
<li>How does one prove that if $|G|&gt;2$, then $G$ has non-trivial automorphism?</li>
</ul>

<p>The only thing I know which connects a group with its automorphism is the theorem, $$G/Z(G) \cong \mathcal{I}(G)$$ where $\mathcal{I}(G)$ denotes the <em>Inner- Automorphism</em> of $G$. So for a group with $Z(G)=(e)$, we can conclude that it has a non-trivial automorphism, but what about groups with center?</p>

 
Answer: <p>As you note in the question, the group of inner automorphisms Inn($G$) is isomorphic to $G/Z(G)$. In particular, it's trivial if and only if $Z(G)=G$.  So there is a non-trivial (inner) automorphism unless $G=Z(G)$.</p>

<p>Now, notice that, by definition, $Z(G)=G$ if and only if $G$ is abelian; so we have reduced to the abelian case.</p>

<p>If $G$ is abelian then $g\mapsto -g$ is an automorphism, and it is non-trivial unless $g=-g$ for all $g\in G$.  But $g=-g$ if and only if the order of $g$ divdes two.  So we have now reduced to the case in which $2g=0$ for all $g\in G$.</p>

<p>In this case, $G$ is a vector space over the field $\mathbb{Z}/2$.  As
$|G|$ is equal to 2 raised to the power of the $\mathbb{Z}/2$-dimension of $G$,
the hypothesis that $|G|&gt;2$ implies that $\mathrm{dim}_{\mathbb{Z/2}} G&gt;1$.  But now we can write down lots of linear automorphisms of $G$. For instance, you could fix any basis $g_1,g_2,\ldots$ and take the automorphism $g_1\mapsto g_2$, $g_2\mapsto g_1$ and $g_i\mapsto g_i$ for every $i&gt;2$.</p>

==============================
===============================
Question: <p>Many young, and not so young, mathematicians struggle with how to spend their time. Perhaps this is due to the 90%-10% rule for mathematical insight: 90 pages of work yield only 10 pages of useful ideas. A venerable mathematician once described his career to me as constantly stumbling around in the dark. Of course, this struggle is largely personal...perhaps it is an evolutionary struggle to find one's own way to find something relevant to contribute to mathematics as literature. Such an evolutionary struggle necessitates the artist's turmoil and requires an acknowledgement of "l'importance d'être seul". Even when I have successfully done some reasonable mathematics, it behooves me to look for a more efficient way to proceed. This sort of searching turns up various nuggets of advice on how to do mathematics, like the following (paraphrased) ones:</p>

<p><em>Read a paper of a master for a year, and you will get something</em>- advice given to young mathematicians by Israel Gelfand at Harvard during his 90th birthday conference on the unity of mathematics.</p>

<p><em>Try to imagine a proof, no matter how vague</em>-Gowers's online essay on the philosophy of mathematics and our relationship to formalism</p>

<p><em>I try to colorize it in my mind, to try to see what it's really getting at, rather than simply what it says</em>-Thurston's online response to Ashley Reiter on reading mathematics.</p>

<p>Also recall Grothendieck's images of a softening nut and the rising sea...online interviews/documents with suggestions of Atiyah, Singer, Connes, Gromov...</p>

<p>There are many other such nuggets, many of which can be found on posts on this site. These all provide very inspiring images, but I would like to be more blunt:</p>

<blockquote>
  <p>What is your method? How do you go
  about doing mathematics on a day to
  day basis?</p>
</blockquote>

 
Answer: <p>The method is "keep trying". Try reading the paper again, try reading a different paper, try stopping reading papers and just work it out yourself. Try talking to other people, try struggling on your own, then try talking to people again. Try a different problem, then try going back to the same problem. Try the same method again and again, then try different methods, then go back to the first method and try it one more time. Try just writing out some calculations even if you don't see them going anywhere, try a stupid example, try drawing some pictures. Finally try taking a break, and then also try not taking a break. Try everything once, then try it again!</p>

<p>But enough of that, here's some more practical advice from my own experience (I'm a postdoc by the way).</p>

<p>1) For a hard problem, work intensely on it for a few weeks or months, until you feel like you've completely hit a wall. During this period you want to be producing as many calculations, lemmas, pictures, examples, etc as possible. They don't all have to be super-relevant -- your goal is maximum output of material. Then when you finally feel like you're going insane, take a deep breath and move on to something else. After a break of a few weeks or months, which may be spent either on work of some other kind or even on vacation, come back to the problem and see if the fresh perspective helps. It may take multiple cycles like this for a really hard problem.</p>

<p>2) Look for a variation of your problem which is easier or which your methods can better handle. Even if the variation is not as strong of a result as what you are ultimately aiming for, it may still "count" and end up being a nicer paper than you realize at first. It's good for your morale to register progress in this way, and if you can get a publication it's good for your CV too. Here is where advisors and mentors can help a lot -- they can help you identify which variation is meaningful, doable, and "interesting".</p>

<p>3) Remember that almost nothing ever works. One of the worst feelings to me is when I find a mistake in something I thought I had figured out, and all of a sudden weeks or months of progress begin to unravel. This can be extremely depressing. Try not to take it too hard, and over time you can rebuild and recover. Try also to appreciate the progress you are making, even if it is much less than you wish it was.</p>

<p>Good luck!</p>

==============================
===============================
Question: <p>Here is a funny exercise 
$$\sin(x - y) \sin(x + y) = (\sin x - \sin y)(\sin x + \sin y).$$
(If you prove it don't publish it here please).
Do you have similar examples?</p>

 
Answer: <p>$$\int_0^1\frac{\mathrm{d}x}{x^x}=\sum_{k=1}^\infty \frac1{k^k}$$</p>

==============================
===============================
Question: <p>How to prove
 $$\int_{0}^{\infty} \mathrm{e}^{-x^2}\, dx = \frac{\sqrt \pi}{2}$$</p>

 
Answer: <p>This is an old favorite of mine.<br>
Define $$I=\int_{-\infty}^{+\infty} e^{-x^2} dx$$ 
Then $$I^2=\bigg(\int_{-\infty}^{+\infty} e^{-x^2} dx\bigg)\bigg(\int_{-\infty}^{+\infty} e^{-y^2} dy\bigg)$$  
$$I^2=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}e^{-(x^2+y^2)} dxdy$$  
Now change to polar coordinates<br>
$$I^2=\int_{0}^{+2 \pi}\int_{0}^{+\infty}e^{-r^2} rdrd\theta$$  
The $\theta$ integral just gives $2\pi$, while the $r$ integral succumbs to the substitution $u=r^2$  
$$I^2=2\pi\int_{0}^{+\infty}e^{-u}du/2=\pi$$ 
So $$I=\sqrt{\pi}$$ and your integral is half this by symmetry</p>

<p>I have always wondered if somebody found it this way, or did it first using complex variables and noticed this would work.</p>

==============================
===============================
Question: <p>This should be an easy exercise: Given a finite odd abelian group $G$, prove that $\prod_{g\in G}g=e$. Indeed, using Lagrange's theorem this is trivial: There is no element of order 2 (since the order must divide the order of $G$, but it is odd), and so every element except $e$ has a unique inverse which is different from it. Hence both the element and its inverse participate in the product and cancel each other.</p>

<p>My problem is simple - I need to solve this <strong>without</strong> Lagrange's theorem. So either there's a smart way to prove the nonexistance of an element of order 2 in an odd abelian group, or I'm missing something even more basic...</p>

 
Answer: <p>If doesn't exist an element of order 2 then you are done. Supose $g\in G$ such that $g^2=e$. Since $\{g_1,\ldots, g_n\}=\{gg_1,\ldots,gg_n\}$, then $\prod g_i = g^n \prod g_i$ and $g^n=e$. Putting $n=2k+1$, $e=g^{2k+1}=g^{2k}g=g$.</p>

==============================
===============================
Question: <p>As a result of <a href="https://math.stackexchange.com/questions/9532/link-between-a-dense-subset-and-a-continuous-mapping">this question</a>, I've been thinking about the following condition on a topological space $Y$:</p>

<blockquote>
  <p>For every topological space $X$, $E\subseteq X$, and continuous maps $f,g\colon X\to Y$, if $E$ is dense in $X$, and $f$ and $g$ agree on $E$ (that is, $f(e)=g(e)$ for all $e\in E$), then $f=g$.</p>
</blockquote>

<p>If $Y$ is Hausdorff, then $Y$ satisfies this condition. The question is whether the converse holds: if $Y$ satisfies the above condition, will it necessarily be Hausdorff? </p>

<p>If $Y$ is not at least $T_1$, then $Y$ does not have the property: if $u,v\in Y$ are such that $u\neq v$ and every open neighborhood of $u$ contains $v$, then let $X$ be the Sierpinski space, $X=\{a,b\}$, $a\neq b$, with topology $\tau=\{\emptyset,\{b\},X\}$, $E=\{b\}$, let $f,g\colon X\to Y$ be given by $f(a)=f(b)=v$, and $g(a)=u$, $g(b)=v$. Then both $f$ and $g$ are continuous, agree on the dense subset $E$, but are distinct.</p>

<p>My attempt at a proof of the converse assumes the Axiom of Choice and proceeded as follows: assume $Y$ is $T_1$ but not $T_2$; let $u$ and $v$ be witnesses to the fact that $Y$ is not $T_2$, let $\mathcal{U}\_s$ and $\mathcal{V}\_t$ be the collection of all open nbds of $s$ that do not contain $t$, and all open nbds of $t$ that do not contain $s$, respectively. Construct a net with index set $\mathcal{U}\_s\times\mathcal{V}\_t$ (ordered by $(U,V)\leq (U',V')$ if and only if $U'\subseteq U$ and $V'\subseteq V$) by letting $y_{(U,V)}$ be a point in $U\cap V$ (this is where AC comes in). Let $E=\{y_{(U,V)}\mid (U,V)\in\mathcal{U}\_s\times\mathcal{V}\_t\}$, and let $X=E\cup\{s\}$. Give $X$ the induced topology; let $f\colon X\to Y$ be the inclusion map, and let $g\colon X\to Y$ be the map that maps $E$ to itself identically, but maps $s$ to $t$. </p>

<p>The only problem is I cannot quite prove that $g$ is continuous; the difficulty arises if I take an open set $\mathcal{O}\in \mathcal{V}_t$; the inverse image under $g$ is equal to $((\mathcal{O}\cap X)-\{t\})\cup\{s\}$, and I have not been able to show that this is open in $X$. </p>

<p>So:</p>

<blockquote>
  <p>Does the condition above characterize Hausdorff spaces? </p>
</blockquote>

<p>If not, I would appreciate a counterexample. If it <em>does</em> characterize Hausdorff, then ideally I would like a way to finish off my proof, but if the proof is unsalvageable (or nobody else can figure out how to finish it off either) then any proof will do. </p>

<hr/>

<p><strong>Added:</strong> A little digging turned up  this question raised in the Problem Section of the <strong>American Mathematical Monthly</strong> back in 1964 by Alan Weinstein. The <a href="http://www.jstor.org/stable/2315068" rel="noreferrer">solution by Sim Lasher</a> gives a one paragraph proof that does not require one to consider $T_1$ and non-$T_1$ spaces separately. </p>

 
Answer: <p>[This answer moved from <a href="https://math.stackexchange.com/questions/9532/link-between-a-dense-subset-and-a-continuous-mapping">this question</a> on Arturo's advice]</p>

<p>I think the following goes a long way towards proving a converse:</p>

<p>Let $(Y, T)$ be any T1 topological space with at least two points and let $a$ and $b$ be distinct points in $Y$.</p>

<p>Let $X = Y\setminus\{b\}$.
Let $f: X \to Y$ be the inclusion of $X$ in $Y$.
Let $g: X \to Y$ agree with $f$ on $X\setminus\{a\}$ and $g(a) = b$.</p>

<p>Finally, define the topology on $X$ to be the coarsest topology that makes both $f$ and $g$ continuous.</p>

<p>With these assumptions it turns out that $X\setminus\{a\}$ is dense in $X$ if and only if $a$ and $b$ do not have disjoint neighbourhoods in $Y$.</p>

<p>To see that this is true, let us construct a base of the topology on $X$.
To make $f$ continuous we only need to take the subspace topology. Since
X is open in Y this is $S_1 = \{ G \in T \mid b \notin G \}$. To also make $g$ continuous we need to add the open neighbourhoods of $b$, with $b$ replaced by $a$. This gives $S_2 = \{ (H\setminus\{b\} \cup \{a\} \mid H \in T, b \in H \}$.
Now $S_1 \cup S_2$ is a subbase of the topology on $X$.
Since $S_1$ and $S_2$ are already closed under finite intersection, and each covers $X$, we can say that
$B = \{ G \cap H \mid G \in S_1, H \in S_2 \}$ is a base of the topology.</p>

<p>Then (remembering that finite sets are closed in Y) we find that the following are all equivalent:</p>

<ul>
<li>$X\setminus\{a\}$ is not dense in $X$</li>
<li>$\{a\}$ is open in $X$</li>
<li>$\{a\} \in B$</li>
<li>there are $G \in S_1, H \in S_2$ such that $G \cap H = \{a\}$</li>
<li>there are $G \in S_1, H \in S_2$ such that $a \in G$ and $G \cap (H\setminus\{a\}\cup\{b\}) = \oslash$</li>
<li>$a$ and $b$ have disjoint neighbourhoods in $(Y, T)$.</li>
</ul>

==============================
===============================
Question: <p>Someone recently asked me why a negative $\times$ a negative is positive, and why a negative $\times$ a positive is negative, etc.</p>

<p>I went ahead and gave them a proof by contradiction like so:</p>

<p>Assume $(-x) \cdot (-y) = -xy$</p>

<p>Then divide both sides by $(-x)$ and you get $(-y) = y$</p>

<p>Since we have a contradiction, then our first assumption must be incorrect.</p>

<p>I'm guessing I did something wrong here. Since the conclusion of $(-x) \cdot (-y) = (xy)$ is hard to derive from what I wrote.</p>

<p>Is there a better way to explain this?  Is my proof incorrect?  Also, what would be an intuitive way to explain the negation concept, if there is one?</p>

 
Answer: <p>Well if I were to explain this in an intuitive way to someone (or at least try), I would like to think of an analogy with walking over the real line, by agreeing that walking left will be walking in the negative direction and walking right in the positive direction.</p>

<p>Then I will try to convey the idea that if you are multiplying to numbers (let's suppose they are integers to make things easier to picture) then a product as $2*3$ would just mean that you have to walk right (in the positive direction) a distance of $2$ (say miles for instance) three times, that is, first you walk $2$ miles, then another $2$ miles and finally another $2$ miles to the right.</p>

<p>Now you picture where you're at? Well, you're at the right of the origin so you are in the positive section. But in the same way you can play this idea with a negative times a positive.</p>

<p>With the same example in mind, what would $-2*3$ mean? First, suppose that the $-2$ just specifies that you will have to walk left a distance of $2$ miles. Then how many times you will walk that distance? Just as before $3$ times and in the end you'll be $6$ miles to the left of the origin so you'll be in the negative section.</p>

<p>Finally you'll have to try to picture what could $(-2)*(-3)$ mean. Maybe you could think of the negative sign in the second factor just making you change direction, that is, it makes you turn around and start walking the specified distance. So in this case the $-2$ tells you to walk left a distance of $2$ miles but the $-3$ tells you to fist turn around and then walk $3$ times the $2$ miles in the other direction, so you'll end up walking right and end in the point that is $6$ miles to the right of the origin, so you'll be in the positive section, and $(-2)*(-3) = 6$.</p>

<p>I don't know if this will help but it's the only way I can think of this in some intuitive sense.</p>

==============================
===============================
Question: <p>In exercise 36 <em>Miscellaneous Taylor Coefficients using Bernoulli
numbers</em> on pages 88-89 of Louis Comtet's <em><a href="http://books.google.pt/books?id=C0HPgWhEssYC&amp;printsec=frontcover&amp;dq=Louis+Comtet+Advanced+Combinatorics&amp;source=bl&amp;ots=rEhBo3Xuv8&amp;sig=rTARizLlaQKIHQNZcHAlHKRUKUc&amp;hl=pt-PT&amp;ei=jaHdTJnVI5OKhQeWqpiJDQ&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CBkQ6AEwAA#v=onepage&amp;q&amp;f=false">Advanced Combinatorics</a></em>, 1974,
one is asked to obtain the following explicit formula for the Bernoulli numbers:</p>

<p>$$B_{2n}=(-1)^{n-1}\dfrac{1+\left[ \varphi _{n}\right] }{2(2^{2n}-1)},$$</p>

<p>where</p>

<p>$$\varphi _{n}=\dfrac{2(2^{2n}-1)(2n)!}{2^{2n-1}\pi ^{2n}}\displaystyle\sum_{k=1}^{3n}\dfrac{1}{k^{2n}}$$</p>

<p>(with $\displaystyle\sum_{n\geq 0}B_{n}\dfrac{t^{n}}{n!}=\dfrac{t}{e^{t}-1}$), and to prove, among other sums, that </p>

<p>$$\displaystyle\sum_{n=1}^{\infty }\dfrac{1}{\dbinom{2n}{n}}=\dfrac{1}{3}+\dfrac{2\pi\sqrt{3}}{27}.\qquad (\ast )$$</p>

<p>Alfred van der Poorten wrote <a href="http://www.springerlink.com/content/3866u5593p65l016/">here (section 10)</a>: <em>seeing that</em> </p>

<p>$$\displaystyle\sum_{n=1}^{\infty}\dfrac{x^{2n}}{n^{2}\dbinom{2n}{n}}=2\arcsin^{2}\left( \dfrac{x}{2}\right) \qquad (\ast \ast )$$</p>

<p>(...) <em>formula</em> [ $(\ast )$ ] <em>become</em>[s] <em>quite accessible to proof</em>."</p>

<p>I am not able to show formula $(\ast \ast )$ neither how it can be used to
prove $(\ast )$.</p>

<hr>

<p><strong>Question</strong>: Could you provide (a) more detailed hint(s) on how and/or
different ways in which formula $(\ast )$ can be derived?</p>

<hr>

<p>Added: For information the other sums are:</p>

<p>$$\displaystyle\sum_{n=1}^{\infty }\dfrac{1}{n\dbinom{2n}{n}}=\dfrac{\pi \sqrt{3}}{9},\quad\displaystyle\sum_{n=2}^{\infty }\dfrac{1}{n^{2}\dbinom{2n}{n}}=\dfrac{\pi ^{2}}{18},\quad\displaystyle\sum_{n=2}^{\infty }\dfrac{1}{n^{4}\dbinom{2n}{n}}=\dfrac{17\pi ^{4}}{3240}.$$</p>

 
Answer: <p>Another one, which has been mentioned multiple times on this site (search for Wallis' product) is the following:</p>

<p>$$\displaystyle \int_{0}^{\pi/2} \sin^{2n-1} x \ dx = \dfrac{2 \cdot 4 \cdot 6 \cdots (2n-2)}{1 \cdot 3 \cdot 5 \cdots (2n-1)} \ \ n \gt 1$$</p>

<p>Now $$\displaystyle \dfrac{2 \cdot 4 \cdot 6 \cdots (2n-2)}{1 \cdot 3 \cdot 5 \cdots (2n-1)} = \dfrac{2^{2n}}{2n{2n \choose n}} = \dfrac{2^{2n-1}}{n{2n \choose n}}$$</p>

<p>Thus</p>

<p>$$\displaystyle \int_{0}^{\pi/2} n\left(\dfrac{\sin x}{2}\right)^{2n-1} \ dx = \dfrac{1}{{2n \choose n}}$$</p>

<p>Now the sum can be found easily.</p>

<p>The formula by Alfred Van der Pooten can be proved using this approach too. </p>

<p>A proof of Wallis Product is given here: <a href="http://crypto.stanford.edu/pbc/notes/pi/wallis.xhtml" rel="nofollow noreferrer">http://crypto.stanford.edu/pbc/notes/pi/wallis.xhtml</a></p>

<p>For a (closely related) problem on this site using this, see here: <a href="https://math.stackexchange.com/questions/3502/summing-the-series-1k-frac2k2k1-a2k1">Summing the series $(-1)^k \frac{(2k)!!}{(2k+1)!!} a^{2k+1}$</a></p>

==============================
===============================
Question: <p>I am comfortable with the different sizes of infinities and Cantor's "diagonal argument" to prove that the set of all subsets of an infinite set has cardinality strictly greater than the set itself. So if we have a set $\Omega$ and $|\Omega| = \aleph_i$, then (assuming continuum hypothesis) the cardinality of $2^{\Omega}$ is $|2^{\Omega}| = \aleph_{i+1} &gt; \aleph_i$ and we have $\aleph_{i+1} = 2^{\aleph_i}$.</p>

<p>I am fine with these argument.</p>

<p>What I don't understand is why should there be a smallest $\infty$? Is there a proof (or) an axiom that there exists a smallest $\infty$ and that this is what we address as "countably infinite"? or to rephrase the question "why can't I find a set whose power set gives us $\mathbb{N}$"?</p>

<p>The reason why I am asking this question is in "some sense" $\aleph_i = \log_2(\aleph_{i+1})$. I do not completely understand why this process should stop when $\aleph_i = \aleph_0$.</p>

<p>(Though coming to think about it I can feel that if I take an infinite set with $\log_2 \aleph_0$ elements I can still put it in one-to-one correspondence with the Natural number set. So Is $\log_2 \aleph_0 = \aleph_0$ (or) am I just confused? If $n \rightarrow \infty$, then $2^n \rightarrow \infty$ faster while $\log (n) \rightarrow \infty$ slower and $\log (\log (n)) \rightarrow \infty$ even slower and $\log(\log(\log (n))) \rightarrow \infty$ even "more" slower and so on).</p>

<p>Is there a clean (and relatively elementary) way to explain this to me?</p>

<p>(I am totally fine if you direct me to some paper (or) webpage. I tried googling but could not find an answer to my question)</p>

 
Answer: <p>First, let me clear up a misunderstanding.</p>

<p>Question:  Does $2^\omega = \aleph_1$?  More generally, does $2^{\aleph_\alpha} = \aleph_{\alpha+1}$?</p>

<p>The answer of "yes" to the first question is known as the continuum hypothesis (CH), while an answer of "yes" to the second is known as the generalized continuum hypothesis (GCH).</p>

<p>Answer:  Both are undecidable using ZFC.  That is, Godel has proven that if you assume the answer to CH is "yes", then you don't add any new contradictions to set theory.  In particular, this means it's impossible to prove the answer is "no".</p>

<p>Later, Cohen showed that if you assume the answer is "no", then you don't add any new contradictions to set theory.  In particular, this means it's impossible to prove the answer is "yes".</p>

<p>The answer for GCH is the same.</p>

<p>All of this is just to say that while you are allowed to assume an answer of "yes" to GCH (which is what you did in your post), there is no way you can prove that you are correct.</p>

<p>With that out of the way, let me address your actual question.</p>

<p>Yes, there is a proof that $\omega$ is the smallest infinite cardinality.  It all goes back to some very precise definitions.  In short, when one does set theory, all one really has to work with is the "is a member of" relation $\in$.  One defines an "ordinal number" to be any transitive set $X$ such that $(X,\in)$ is a well ordered set.  (Here, "transitive" means "every element is a subset".  It's a weird condition which basically means that $\in$ is a transitive relation).  For example, if $X = \emptyset$ or $X=\{\emptyset\}$ or $X = \{\{\emptyset\},\emptyset\}$, then $X$ is an ordinal.  However, if $X=\{\{\emptyset\}\}$, then $X$ is not.</p>

<p>There are 2 important facts about ordinals.  First, <strong>every</strong> well ordered set is (order) isomorphic to a unique ordinal.  Second, for any two ordinals $\alpha$ and $\beta$, precisely one of the following holds:  $\alpha\in\beta$ or $\beta\in\alpha$ or $\beta = \alpha$.  In fact, it turns out the the collection of ordinals is well ordered by $\in$, modulo the detail that there is no set of ordinals.</p>

<p>Now, cardinal numbers are simply special kinds of ordinal numbers.  They are ordinal numbers which can't be bijected (in, perhaps NOT an order preserving way) with any smaller ordinal.  It follows from this that the collection of all cardinal numbers is also well ordered.  Hence, as long as there is one cardinal with a given property, there will be a least one.  One example of such a property is "is infinite".</p>

<p>Finally, let me just point out that for <strong>finite</strong> numbers (i.e. finite natural numbers), one usually cannot find a solution $m$ to $m = \log_2(n)$.  Thus, as least from an inductive reasoning point of view, it's not surprising that there are infinite cardinals which can't be written as $2^k$ for some cardinal $k$.</p>

==============================
===============================
Question: <p>I want to motivate the quadratic reciprocity theorem, which at first glance does not look too important to justify it being one of Gauss' favorites. So far I can think of two uses that are basic enough to be shown immediately when presenting the theorem:</p>

<p>1) With the QRT, it is immediate to give a simple, efficient algorithm (that can be done even by hand) for computing Legendre symbols.</p>

<p>2) In Euler's proof of Fermat's claim on the conditions in which a prime $p$ is of the form $x^2+ny^2$ (for certain small values of $n$) the proof is reduced to finding the conditions under which $p$ divides $x^2+ny^2$ for some $x,y$, hence to the question under which conditions is $-n$ a quadratic residue modulo $p$, which leads immediately to the QTR (for example, for $n=3$, where we get that $p\equiv_3 1$). I really like this example since it begins with an "historic" problem and proceeds to "discover" the QTR through special cases (which is what Euler did in practice - see Cox's book on "Primes of the form $x^2+ny^2$").</p>

<p>However, I am sure there are many more examples (and I'm especially curious as to how Gauss reached the theorem himself). I'd love to hear about them and receive references for further reading.</p>

 
Answer: <p>This is a good question.</p>

<p>My own take on motivating quadratic reciprocity is recorded <a href="http://math.uga.edu/~pete/4400qrlaw.pdf">here</a> (these are lecture notes from an undergraduate course on introductory number theory).  If you look there, you will find that most of what I have said is an elaboration of the two points you bring up.  I think a crisp way of explaining what QR does for you is in the idea of the "direct" and "inverse" problems attached to the Legendre symbol $(\frac{n}{p})$. </p>

<p>Namely, for the <strong>direct problem</strong> we fix $p$ and ask which integers $n$ are squares modulo $p$.  This is clearly a finite problem.  On the other hand there is the <strong>inverse problem</strong>: we fix an integer $n$ and ask for which primes $p$ we have that 
$n$ is a square modulo $p$.  This is, <em>a priori</em>, an infinite problem.  However, it is one of great relevance to classical number theory: e.g. all of the many proofs I have seen of Fermat's Two Squares theorem pass through the fact that $-1$ is a square modulo an odd prime $p$ iff $p \equiv 1 \pmod 4$.  More generally, if you look at the Diophantine equation $x^2 - n y^2 = p$, for $n$ a nonzero integer and $p$ a prime with $\operatorname{gcd}(p,n) = 1$, then reducing modulo $p$ gives the necessary condition 
$(\frac{n}{p}) = 1$.  Quadratic reciprocity to the rescue!  </p>

<p>Secondly, as you also say, quadratic reciprocity gives an efficient algorithm for answering whether a particular $n$ is a square modulo $p$, much faster than computing all $\frac{p-1}{2}$ squares modulo $p$.</p>

<p>In my experience, this is more than enough for students to appreciate the usefulness of Gauss' <em>aureum theorema</em>.</p>

==============================
===============================
Question: <p>How can I prove that if $G$ is an Abelian group with elements $a$ and $b$ with orders $m$ and $n$, respectively, then $G$ contains an element whose order is the least common multiple of $m$ and $n$?</p>

<p>It's an exercise from Hungerford's book, but it's not homework. I could not solve it when I take the course on groups and I think it should be easy. There is a hint that says to first prove when $m$ and $n$ are coprimes. I did this part. But I have no idea how to solve the general case.</p>

<p>Thanks.</p>

 
Answer: <p>Below is an inductive proof excerpted from my post in this prior <a href="https://math.stackexchange.com/questions/6852/maximum-order-of-integers-coprime-to-a-prime-p/6856#6856">thread here.</a></p>

<p><strong>LEMMA</strong> $\ $ A finite abelian group $\rm\:G\:$ has an  lcm-closed  order set, i.e. with $\rm\: o(X) = $ order of $\rm\: X$</p>

<p>$\rm\quad\quad\quad\quad\quad\quad\ X,Y \in G\ \ \Rightarrow\ \ \exists\ Z \in G:\  o(Z) = lcm(o(X),o(Y))$</p>

<p><strong>Proof</strong> $\ \ $  By induction on  $\rm o(X)\ o(Y)\:.\ $ If it's $\:1\:$ then trivially $\rm\:Z = 1\:$. $\ $ Otherwise</p>

<p>write  $\rm\ o(X)\ =\ AP,\: \ \ o(Y) = BP',\ \ \ P'|P = p^m &gt; 1\:,\ \ $  prime $\rm\: p\:$ coprime to $\rm\: A,B$</p>

<p>Then  $\rm\: o(X^P) = A,\ \ o(Y^{P'}) = B\:.\ $  By induction there's a $\rm\: Z\:$ with $\rm \: o(Z) = lcm(A,B)$</p>

<p>so  $\rm\ \ o(X^A\: Z)\: =\: P\ lcm(A,B)\: =\: lcm(AP,BP')\: =\: lcm(o(X),o(Y))\:$.</p>

<p><strong>NOTE</strong> $\ \ $ This is the element-wise form of what's known as "Herstein's hardest problem", viz. 2.5.11, p. 41 in the first edition of Herstein's popular textbook "Topics in Algebra". In the 2nd edition Herstein added  the following note (problem 2.5.26, p.48) </p>

<blockquote>
  <p>Don't be discouraged if you don't get this problem with what you know of group theory up to this stage. I don't know anybody, including myself, who has done it subject to the restriction of using material developed so far in the text.  But it is fun to try. I've had more correspondence about this problem than about any other point in the whole book."</p>
</blockquote>

==============================
===============================
Question: <p>Let $\mu\left(n\right)$ be the Möbius function. Let $\phi\left(n\right)$ be Euler's totient function. Let $\sigma\left(n\right)$ be the sum of divisors and $\tau\left(n\right)$ be the number of divisors functions. I am curious to know whether or not the system:</p>

<p>$\mu\left(n\right)=a$</p>

<p>$\phi\left(n\right)=b$</p>

<p>$\sigma\left(n\right)=c$</p>

<p>$\tau\left(n\right)=d$</p>

<p>has at most one solution. </p>

<p>Motivation: I remember a number theory assignment I had where we were given particular values for each of these functions and asked to recover the original number. I can't for the life of me remember how (or if) I managed to solve this problem. I tried to work out a general proof, but couldn't. I also wrote a loop in maple to check for counterexamples, but haven't found any yet. I feel like this is something I should know, but probably have forgotten the relevant facts to approaching this problem.</p>

 
Answer: <p>The answer is No. The smallest counterexamples I could find are {1836, 1824), {5236, 4960}, {5742, 5112}, {6764, 6368}, {9180, 9120} and {9724, 9184}. I think those are all the pairs in which both numbers are less than 10,000. </p>

<p>For example, both $n=1836$ and $n=1824$ satisfy $\mu(n)=0$, $\varphi(n)=576$, $\sigma(n)=5040$ and $\tau(n)=24$. </p>

<p>EDIT: here's the code of the program I used in GAP.</p>

<pre><code>vec := function(n)
 return [MoebiusMu(n), Phi(n), Sigma(n), Tau(n)];
end;

dic:=NewDictionary([1,2,3,4], true);

for i in [2..10000] do
 v:=vec(i);
 if (LookupDictionary(dic, v) &lt;&gt; fail) then Print(i," &lt;=&gt; ", LookupDictionary(dic, v), "\n"); fi;
 AddDictionary(dic, v, i);
od;
</code></pre>

==============================
===============================
Question: <p>Let $B$ be a Stone space (compact, Hausdorff, and totally disconnected).  Then I am basically certain (because of Stone's representation theorem) that if $a, b \in B$ are two distinct points in $B$, then $B$ can be written as a disjoint union $U \cup V$ of open sets where $a \in U, b \in V$.  </p>

<p>However, I can't seem to prove this directly.  The proof should be fairly straightforward, so I am sure I'm missing something obvious.  (As an exercise for myself, I'm trying to prove Stone's representation theorem, and I need this as a lemma.)</p>

 
Answer: <p>Before proving the fact you want, we'll need the notion of quasicomponents and some basic propositions about it. In these terms, you are just asking if distinct points are in distinct quasicomponents. Let $X$ be a topological space. Given $x,y \in X$, define $x \sim y$ if $X$ cannot be written as a disjoint union of open sets $U$ and $V$ containing $x$ and $y$, respectively. It is straightforward to verify that $\sim$ is an equivalence relation. The equivalence classes are called the quasicomponents of $X$. It's easy to prove that the quasicomponent of a point $x$ is the intersection of all closed-open subsets of $X$ containing $x$.</p>

<p>In every topological space, the component $C$ of a point $x$ is contained in the quasicomponent $Q$ of the point $x$. In fact, if $F$ is a closed-open set containing $x$, then $X = F \cup (X-F)$ is a separation of $X$. Since $C \cap F \ne \emptyset$, it follows that $C \subseteq F$. Thus we have $C \subseteq Q$.</p>

<p>I'll prove now, based on Engelking's proof in the book <em>General Topology</em>, that in every compact Hausdorff space, components and quasicomponents coincide. Let $C$ and $Q$ as above. We just need to prove that the quasicomponent $Q$ is connected. Then will follow that $ Q = C$. Suppose that $Q = X_1 \cup X_2$, where $X_1, X_2$ are two disjoint closed subsets of the space $Q$. Then $X_1$ and $X_2$ are closed in $X$, since $Q$ is closed in $X$. By normality of compact Hausdorff spaces, there exist disjoint open subsets $U,V$ of $X$ containing $X_1, X_2$, respectively. Hence, we have $Q \subseteq U \cup V$ and, by compactness, there exist closed-open sets $F_1, \ldots, F_k$ such that </p>

<p>$$Q \subseteq \bigcap_{i=1}^k F_i \subseteq U \cup V.$$</p>

<p>$F = \bigcap_{i=1}^k F_i$ is clearly closed-open. Since $ \overline{U \cap F} \subseteq \overline{U} \cap F = \overline{U} \cap (U \cup V) \cap F = U \cap F$, the intersection $U \cap F$ is also closed-open. As $x \in U \cap F$, we have $Q \subseteq U \cap F$ and $X_2 \subseteq Q \subseteq U \cap F \subseteq U$. It follows that $X_2 \subseteq U \cap V = \emptyset$, which shows that the set $Q$ is connected.</p>

<p>Now it's simple to prove your statement. Let $B$ be a Stone Space. Since $B$ is compact Hausdorff, quasicomponents coincide with components. $B$ is totally disconnected, so the quasicomponent of a point $a \in B$ is $\{a \}$. If $b \in B$ is a different point, then $b$ isn't in the quasicomponent of $a$. Thus there exist disjoint open sets $U,V$ containing $a,b$, respectively, such that $B = U \cup V$.</p>

<p><strong>Added</strong> This was motivated by Pete's answer. Actually, to prove that a locally compact Hausdorff totally disconnected space $X$ is zero-dimensional, we just need what I've proved for compact Hausdorff spaces. Indeed, let $x \in X$ and $U$ an open set containing $x$. Since $X$ is regular, there is an open set $V$ containing $x$ such that $\overline{V}$ is compact and $\overline{V} \subseteq U$. Also, $\overline{V}$ is a totally disconnected space. Using the fact that quasicomponents and components coincide in compact Hausdorff spaces, we have that the quasicomponent of $x$ in $\overline{V}$ is $\{x\}$. Now, the compactness of $\overline{V}$ guarantees that there are closed-open sets $F_1, \ldots, F_k$ such that $x \in F_1 \cap \cdots \cap F_k \subseteq V$. Let $F$ be $\bigcap_{i=1}^k F_i$. Then $F \,$ is an open set in $V$ and since $V \, $ is open in $X$, $F \, $ is open in $X$. Also, $F \,$ is compact, since each $F_i$ is a closed subset of the compact space $\overline{V}$, and then $F\,$ is closed in $X$. We conclude that for each open set $U$ containing $x$, there is a closed-open set $F \ $ such that $x \in F \subseteq U$. Thus $X$ is zero-dimensional. </p>

==============================
===============================
Question: <p>From its definition a combination $\binom{n}{k}$, is the number of distinct subsets of size $k$ from a set of $n$ elements.</p>

<p>This is clearly an integer, however I was curious as to why the expression</p>

<p>$$\frac{n!}{k!(n-k)!}$$ always evaluates to an integer.</p>

<p>So far I figured:</p>

<p>$n!$, is clearly divisible by $k!$, and $(n-k)!$, individually, but I could not seem to make the jump to proof that that $n!$ is divisible by their product.</p>

 
Answer: <p>See my <a href="https://math.stackexchange.com/questions/2158/division-of-factorials/2192#2192">post here</a> for a simple purely arithmetical proof that every binomial coefficient is an integer. The proof shows how to rewrite any binomial coefficient fraction as a product of fractions whose denominators are all coprime to any given prime $\rm\:p.\,$ This implies that no primes divide the denominator (when written in lowest terms), therefore the fraction is an integer.</p>

<p>The key property that lies at the heart of this proof is that, among all products of $\rm\, n\,$ consecutive integers, $\rm\ n!\ $ has the least possible power of $\rm\,p\,$ dividing it - for every prime $\rm\,p.\,$ Thus $\rm\ n!\ $ divides every product of $\rm\:n\:$ consecutive integers, since it has a smaller power of every prime divisor. Therefore
$$\rm\displaystyle\quad\quad {m \choose n}\ =\ \frac{m!/(m-n)!}{n!}\ =\ \frac{m\:(m-1)\:\cdots\:(m-n+1)}{\!\!n\:(n-1)\   \cdots\:\phantom{m-n}1\phantom{+1}}\ \in\ \mathbb Z$$</p>

==============================
===============================
Question: <p><a href="http://en.wikipedia.org/wiki/Lennart_Carleson">Lennart Carleson</a> proved Luzin's conjecture that <a href="http://en.wikipedia.org/wiki/Carleson%27s_theorem">the Fourier series of each $f\in L^2(0,2\pi)$ converges almost everywhere</a>. Also, <a href="http://en.wikipedia.org/wiki/Richard_Allen_Hunt">Richard Hunt</a> extended the result to <a href="http://en.wikipedia.org/wiki/Carleson%27s_theorem#CITEREFHunt1968">$L^p$ ($p>1$)</a>.</p>

<p>Some time ago I tried to read Carleson's paper, but I would say it is fairly hard to assimilate. </p>

<ol>
<li><p>Is there an easier proof? Can someone point out of the core or give an outline?</p></li>
<li><p>What did Hunt do? Can someone give an outline of that proof?</p></li>
</ol>

 
Answer: <p>A few years after Carleson's proof Fefferman came up with a shorter proof of the $L^2$ and $L^p$ results. Later, in the context of their work in multilinear harmonic analysis Lacey and Thiele came up with a quite short and easy to understand proof for the $L^2$ theorem which is to some extent a descendant of Fefferman's proof. It's only 10 pages long and can be found in</p>

<p>Lacey, Michael; Thiele, Christoph (2000), "A proof of boundedness of the Carleson operator", Mathematical Research Letters 7 (4): 361–370.</p>

<p>(By the way, this paper has an amusing Mathscinet review which begins with "This is one of the greatest papers written in Fourier analysis.")</p>

<p>They also wrote an expository article describing this and a number of related results:</p>

<p>Lacey, Michael T. (2004), "Carleson's theorem: proof, complements, variations", Publicacions Matemàtiques 48 (2): 251–307</p>

<p>They also put an expanded version of this last paper on the arxiv <a href="http://arxiv.org/abs/math/0307008v4">http://arxiv.org/abs/math/0307008v4</a></p>

==============================
===============================
Question: <p>I was wondering if the following properties of the Legendre polynomials are true in general. They hold for the first ten or fifteen polynomials.</p>

<ol>
<li><p>Are the roots always simple (i.e., multiplicity $1$)?</p></li>
<li><p>Except for low-degree cases, the roots can't be calculated exactly, only approximated (unlike Chebyshev polynomials).</p></li>
<li><p>Are roots of the entire family of Legendre Polynomials dense in the interval $[0,1]$ (i.e., it's not possible to find a subinterval, no matter how small, that doesn't contain at least one root of one polynomial)?</p></li>
</ol>

<p>If anyone knows of an article/text that proves any of the above, please let me know.  The definition of these polynomials can be found on <a href="http://en.wikipedia.org/wiki/Legendre_polynomials">Wikipedia</a>.</p>

 
Answer: <p>To resolve the second question, note first that the Legendre polynomials are odd functions for odd order (0 then is one root of the polynomial), and even functions for even order. Thus, with regards to solubility in terms of radicals, you should be able to derive (possibly complicated!) radical expressions at least up until $P_9(x)$. To use that as an example, note that</p>

<p>$$\frac{P_9(\sqrt{x})}{\sqrt{x}}$$</p>

<p>is a quartic; thus, one can use the quartic formula to derive explicit expressions for its roots, and then you can easily derive the roots of $P_9(x)$ .</p>

<p>$P_{10}(x)$ is where your trouble starts. If we take a look at the polynomial</p>

<p>$$P_{10}(\sqrt{x})$$</p>

<p>we have a quintic to contend with. I'll skip the relatively tedious details, but you can verify that its Galois group is not a solvable group, and thus the solution cannot be expressed in terms of radicals (you can use theta or hypergeometric functions, though).</p>

<p>So, not much hope in the symbolic front. In the <em>numeric</em> front, things are much easier. The slickest way of getting accurate values of the roots of the Legendre polynomial is to use the Jacobi matrix in my previous answer. Since there exist stable and efficient algorithms (e.g. QR algorithm or divide-and-conquer) for the symmetric eigenproblem (in <a href="http://www.netlib.org/lapack/">LAPACK</a>, for instance), and things can be set such that only eigenvalues are returned, you have a good way of generating good approximate values of Legendre polynomial roots. (In the context of Gaussian quadrature, where the roots of orthogonal polynomials play a pivotal role, the scheme is referred to as the <a href="http://www.ams.org/journals/mcom/1969-23-106/S0025-5718-69-99647-1/S0025-5718-69-99647-1.pdf">Golub-Welsch algorithm</a>.)</p>

<p>Alternatively, as I mentioned in the comments, there exist asymptotic approximations for the roots, which can then be subsequently polished with a few applications of Newton-Raphson. One such asymptotic approximation is due to Francesco Tricomi. Letting $\xi_{n,k}$ be the $k$-th root of $P_n(x)$, ordered in decreasing order, we have</p>

<p>$$\xi_{n,k}\approx\left(1-\frac1{8n^2}+\frac1{8n^3}\right)\cos\left(\pi\frac{4k-1}{4n+2}\right)$$</p>

<p>and $O(n^{-4})$ and further terms are omitted. Other asymptotic approximations due to Luigi Gatteschi use roots of Bessel functions, but I won't say more about those.</p>

==============================
===============================
Question: <p>I've never actually done a delta-epsilon proof, so I thought I'd try my hand at one. I decided to try it out for $f(x)=1/x$. If I understand correctly from the wikipedia article, I want to show for any $\varepsilon&gt;0$, there exists a $\delta&gt;0$ such that if $|x-c|&lt;\delta$, then $|f(x)-f(c)|&lt;\varepsilon$.</p>

<p>Anyway, I noticed that I want something like $$|f(x)-f(c)|= \left| \frac{1}{x} - \frac{1}{c} \right|=\frac{|x-c|}{|xc|}&lt;\varepsilon .$$ So $|x-c|&lt;|xc|\varepsilon$, which looks similar to the fact that I want $|x-c|&lt;\delta$. However, I've also heard that one is never supposed to let $\delta$ depend on $x$. </p>

<p>Is this the right direction?<br>
How would I use this information to find a corresponding $\delta$ for each $\epsilon$?   </p>

<p>Thanks!</p>

 
Answer: <p>There have been some confusing comments regarding dependence on $x$ or on $c$, so let me try to put it all together.</p>

<p>You are correct that $\delta$ should not depend on $x$. However, when one is proving that $f(x)$ is continuous <em>at $c$</em>, then $\delta$ is allowed to depend on both $\epsilon$  <em>and</em> $c$. </p>

<p>Remember the definition: $f(x)$ is continuous <em>at $c$</em> if and only for every $\epsilon\gt 0$ there exists a $\delta\gt 0$ such that for all $x$, if $|x-c|\lt \delta$, then $|f(x)-f(c)|\lt \epsilon$. </p>

<p>Notice how the existence of $\delta$ is mentioned <em>before</em> $x$ ever comes into the picture? That's an indication that $\delta$ cannot depend on $x$. On the other hand, both $f(x)$, $\epsilon$, and $c$ occur <em>before</em> $\delta$, which means that, absent any indication to the contrary, $\delta$ is allowed to depend on $f(x)$ (obviously), on $\epsilon$, <em>and</em> on $c$.</p>

<p>So here, you cannot pick $\delta=|xc|\epsilon$, because that would make $\delta$ depend on $x$.</p>

<p>The way to get around it is to get rid of the dependence on $x$. The key here is that since we are trying to make sure everything works if $x$ is "close enough" to $c$, then we will also have that $|x|$ will be very close to $|c|$. So we should be able to to control that division by $x$ in the expression $\frac{|x-c|}{|xc|}$. </p>

<p>How? Well, if a particular $\delta_0$ works, then any smaller one will work as well. So we can always shrink $\delta$ a bit more if needed. Wo the first thing we can note is that we can always require that $\delta$ be smaller than both $1$ and than $\frac{c}{2}$; that is, we will require $\delta\lt\min\{1,\frac{c}{2}\}$. Why $1$? Because then I know that $c-1\lt x \lt c+1$; if $c-1\gt 0$, then this means that $\frac{1}{c+1}\lt \frac{1}{x} \lt \frac{1}{c-1}$, so we can "control" the value of $\frac{1}{x}$. Why less than $\frac{c}{2}$? Just in case $c-1\lt 0$. So let $\mu=\min\{1,\frac{c}{2}\}$. Then we can conclude that $\frac{1}{x}\lt \frac{1}{c-\mu}$. (We could get away with simply putting $\delta\lt\frac{c}{2}$; restricting it to less than $1$ is a common practice, though, which is why I put it here).</p>

<p>So, by requiring that $\delta\lt\min\{1,\frac{c}{2}\}$, we guarantee that $\frac{1}{|x|}\lt \frac{1}{c-\mu}$ (remember that we are working on $(0,\infty)$). What do we gain by this? Well, look:
$$|f(x)-f(c)| = \left|\frac{1}{x}-\frac{1}{c}\right| = \left|\frac{c-x}{xc}\right| = |x-c|\frac{1}{c}\cdot\frac{1}{x} \leq |x-c|\frac{1}{c(c-\mu)}.$$
So if we <em>also</em> ask that $\delta\lt c(c-\mu)\epsilon$, then we have:
$$|f(x)-f(c)|\leq |x-c|\frac{1}{c(c-\mu)} \lt \frac{\delta}{c(c-\mu)} \lt \frac{c(c-\mu)\epsilon}{c(c-\mu)} = \epsilon$$
which is what we want!</p>

<p>So, in summary, what do we need? We need to make sure that $\delta$ is:</p>

<ul>
<li>Less than $1$;</li>
<li>Less than $\frac{c}{2}$; (both of these to ensure $\frac{1}{x}\lt\frac{1}{c-\mu}$);</li>
<li>Less than $c(c-\mu)\epsilon$, where $\mu=\min\{1,\frac{c}{2}\}$. </li>
</ul>

<p>So, for instance, we can just let $\delta = \frac{1}{2}\min(1,\frac{c}{2},c(c-\mu)\epsilon)$, where $\mu=\min\{1,\frac{c}{2}\}$. </p>

<p>In general, if you can let your $\delta$ depend only on $f(x)$ and on $\epsilon$ but not $c$, then we say $f(x)$ is <em>uniformly continuous</em>. This is a stronger condition than continuity, and often very useful. $\frac{1}{x}$ is not uniformly continuous on $(0,\infty)$, however (though it is on $[a,\infty)$ for any $a\gt 0$). </p>

==============================
===============================
Question: <p>Please excuse the naive question.  I have had two classes now in which this theorem was taught and proven, but I have only ever seen a single (indirect?) application involving the quantum harmonic oscillator.  Even if this is not the strongest spectral theorem, it still seems useful enough that there should be many nice examples illustrating its utility.  So... what are some of those examples?  </p>

<p>(I couldn't readily find any nice examples looking through a few functional analysis textbooks, either.  Maybe I have the wrong books.)</p>

 
Answer: <p>What is the spectral theorem for compact operators good for?  Here are some examples.  (I am ignoring the self-adjoint aspects, since they don't really play
a role in the theorem.  And it is valid for more general spaces than Hilbert spaces too, so I will also ignore that part, in the sense that I won't pay too much attention to whether my examples deal with Hilbert spaces on the nose, rather than some variant.)</p>

<ul>
<li><p>Proving the Peter--Weyl theorem.</p></li>
<li><p>Proving the Hodge decomposition for cohomology of manifolds (using the
fact that the inverse to the Laplacian is compact); Willie noted this example in his answer too.</p></li>
<li><p>Proving the finiteness of cohomology of coherent sheaves on compact complex analytic manifolds.</p></li>
<li><p>In its $p$-adic version, the theory of compact operators is basic to the theory of $p$-adic automorphic forms: e.g. in the construction of so-called eigenvarieties parameterizing $p$-adic families of automorphic Hecke eigenforms of finite slope.</p></li>
<li><p>It is also a basic tool in more classical problems, such as the theory of integral equations.  (It is in this context that the theory was first developed; see Dieudonne's book on the history of functional analysis for a very nice account of the historical development of the theory.)</p></li>
</ul>

==============================
===============================
Question: <p>Starting with the famous Basel problem, Euler evaluated the Riemann zeta function for all even positive integers and the result is a compact expression involving Bernoulli numbers. However, the evaluation of the zeta function at odd positive integers (in terms of getting a closed form sum) is still open. There has been some progress in the form of Apery's theorem and other results such as "infinitely many of $\zeta(2n+1)$ are irrational" or "at least one of $\zeta(5),\zeta(7),\zeta(9)$ or $\zeta(11)$ is irrational". </p>

<p>Question(s): Is there a high level understanding for this disparity between even and odd integers? Is it a case of there being a simple expression for $\zeta(3)$ that is out there waiting for an ingenious attack like Euler did with $\zeta(2)$? Or is the belief that such a closed form summation is unlikely? Where do the many many proofs powerful enough to evaluate $\zeta(2n)$ stumble when it comes to evaluating $\zeta(2n+1)$?</p>

<p>Motivation: The Basel problem and Euler's solution are my all-time favorites for the sheer surprise factor and ingenuity of proof (what do $\pi$ and $\frac{sin(x)}{x}$ have to do with $\zeta(2)$??). However, I currently lack the more advanced analytical tools to appreciate the deeper results of this area. I have wondered for a while about the questions above and Internet search hasn't helped much. I would greatly appreciate any answers/references. Thanks.</p>

 
Answer: <p>The zeta function is defined as a sum over the positive integers, but as far as actually evaluating it, it turns out to be more natural to think of it as a sum over all nonzero integers; thus we should really be thinking about $\sum_{n \neq 0} \frac{1}{n^k}$.  For $k$ even this is just $2 \zeta(k)$ and there are various ways to evaluate this more symmetric sum, e.g. by writing down a meromorphic function with the right poles, or a Fourier series with the right coefficients, etc.  But for $k$ odd this is equal to zero, since terms cancel with their negatives!  Written in this way, the zeta function at even integers reveals its alter ego as an <a href="http://en.wikipedia.org/wiki/Eisenstein_series" rel="nofollow noreferrer">Eisenstein series</a> in one dimension.</p>

<p>This cancellation phenomenon occurs in Euler's classic "proof," since the infinite product for $\sin z$ that he uses has zeroes at all integer multiples of $\pi$, not just the positive ones.  It also occurs in the general proof that proceeds by considering the generating function $\frac{z}{e^z - 1}$ for the <a href="http://en.wikipedia.org/wiki/Bernoulli_number" rel="nofollow noreferrer">Bernoulli numbers</a>.  As you might know, the closed form of $\zeta(2k)$ involves Bernoulli numbers, and again $\frac{z}{e^z - 1}$ has poles at $2 \pi i n$ for all nonzero integers $n$, not just the positive ones.  I describe how this works in slightly more detail <a href="https://math.stackexchange.com/questions/8337/different-methods-to-compute-sum-n1-infty-frac1n2/8373#8373">here</a>.</p>

<p>Another way to think about the difference between the even and odd cases is that one can think of the even cases as $L^2$ norms of appropriate Fourier series; this is precisely how a standard proof of the evaluation of $\zeta(2)$ works.  But for the odd cases we don't get an $L^2$ norm; instead we get a mysterious inner product.  </p>

==============================
===============================
Question: <p>I understand that $\pi$ and $e$ are transcendental and that these are not simple facts. I mean, I have been told that these results are deep and difficult, and I am happy to believe them. I am curious what types of techniques are used and just how difficult of a problem it is. Would this result be a reasonable capstone to any course? (any course that isn't essentially "how to prove...")</p>

<p>Another part of this is the following observation: as time passes deep results become easier to understand or rather assimilate into ones body of knowledge and some problems are just hard. I am wondering if people feel like this result is something that a grad student could spend some leisure time and understand, or if it really is something only graspable by "experts" (meaning people in the appropriate field and not a general mathematical audience). How specialized are the techniques used for the problem at hand? Have they been used to prove different results? are the techniques drastically different for $e$ and $\pi$?</p>

<p>Hope this isn't too soft of a question. I was talking with my roommate, also a math grad student, and it came up. I said that it was a classically difficult result, but then wondered if that was right, so here I am.</p>

<p>Note: I don't want a proof or a sketch of one, but maybe a heuristic as to why new techniques were needed or explaining the troubles one has when being naive or using early methods to attack the problem.</p>

<p>Edit: As Matt E pointed out I should also ask: what are the old techniques?
Also, did I even tag the question correctly? These seem to be the areas I would put them in, but I don't know the anything about this stuff.</p>

<p>In the above it also isn't clear that I am wondering if the proof of this result is gotten by some clever new trick or by lots of hard had work that people couldn't/didn't do before? essentially, is it all elbow grease, or some clever new machinery or something completely different?</p>

 
Answer: <p>This is an answer elaborating on my comment above, and largely addressing the
edits to the original question:</p>

<p>I don't think there were any "old techniques" before Hermite proved
transcendence of $e$ in the early 1870s.  As far as I know, the only transcendental numbers known before then were Liouville's interesting but
somewhat artificial examples from early that century.</p>

<p>The subject of transcendence, and the related subject of Diophantine approximation (i.e. approximating irrational numbers, especially irrational algebraic numbers, by rationals), is relatively new.  Liouville proved the first results showing that it is not so easy to approximate an irrational algebraic number by rational ones, and used this to construct his transcendental numbers, which he could recognize as being transcendental because they are too well approximated by rational numbers.  ("Too well" and "not so easy" here refer to the following problem: if you try to approximate $\alpha$ by the rational number $p/q$, can you get within a distance of $O(q^{-n})$ for some given $n$ as you let the denominator $q$ get arbitrarily large. (The larger $n$ is, the smaller $q^{-n}$ is, and so the better the rate of approximation.) Liouville showed, using the pigeon hole principal more-or-less, that if $\alpha$ is algebraic of degree $d$ then you can't do better than $n = d$.)
But this left open the problem of showing that various given numbers (like $e$ and $\pi$) are transcendental.</p>

<p>If you like, here is one way to think of the problem: if you want to show that $\alpha$ is transcendental, then
you want to show that $f(\alpha) \neq 0$ for any non-zero polynomial $f$
with rational coefficients.   The difficulty is that there will be lots of polynomials with real coefficients that have $\alpha$ as a root, and any one of them can be approximated as closely as you like by an $f$ with rational coefficients, so we <em>can</em> find (lots of!) $f$ with rational coefficients such that $f(\alpha)$ is as close to zero as we like.</p>

<p>So you have to find some way to pin down the difference between $f(\alpha)$ being zero and $f(\alpha)$ being very close to zero.  This is not so easy!
(For example, computationally, you can't tell the difference between $0$ and any real number that is smaller than your computational accuracy can recognize.)
And now one sees why Diophantine approximation ideas of the type mentioned above
are relevant.  They are related to quantifying how close we can make $f(\alpha)$ to zero while bounding the denominators of the rational numbers involved.</p>

<p>It is not coincidence that bounding the denominators is relevant: morally this is an attempt to pass from working over $\mathbb Q$ to working over $\mathbb Z$.
Why do we want to do this?  Well, as I already noted, it's pretty hard to tell the difference between $\mathbb Q$ and $\mathbb R$, since the former is dense in the latter, but we <em>can</em> tell the difference between $\mathbb Z$ and $\mathbb R$, since the former is discrete: a non-zero integer is some definite positive distance (i.e. at least 1) away from $0$.</p>

<p>The preceding remarks are somewhat philosophical, and they reflect my (limited) experience of thinking about these kinds of questions.  If you look at the proofs in the link above, it may not be obvious that they are relevant, but I believe that they in fact do have some relevance: e.g. you will see that the arguments reduce to considering integer rather than rational polynomials, and that growth considerations play a key role.  Another thing you will see is that certain auxiliary polynomials enter the proof, and a key fact about them is that they have a high order of vanishing at their zeroes.  The appearance of auxiliary polynomials, often with a high order of vanishing, is ubiquitous in this theory.  </p>

<p>One more (somewhat cultural) remark:
Roth's theorem, for which he got the Fields medal, is the ultimate strengthening of Liouville's theorem: he shows that if $\alpha$ is irrational algebraic, then one can't do better than $O(q^{-2})$ in the problem of Diophantine approximation discussed above.  The proof involves (among other things) constructions with auxiliary polynomials.  So my impression is that Liouville, Hermite, and Lindemann (and there are probably other names that should be here) invented a new subject, namely Diophantine approximation and transcendence theory, whose modern methods are an outgrowth of the methods that they introduced.  </p>

<p>P.S.  Reading the first few pages of Baker's book <a href="http://books.google.com/books?id=SmsCqiQMvvgC&amp;printsec=frontcover">Transcendental Number Theory</a>
(Google Books link) might help.</p>

==============================
===============================
Question: <p>I was wondering if there are examples of results in mathematics that were first proven using axiom of choice and later someone found a proof of the result without using the axiom of choice.</p>

 
Answer: <p><a href="http://en.wikipedia.org/wiki/Cantor%E2%80%93Bernstein%E2%80%93Schroeder_theorem">Cantor-Schroder-Bernstein</a> theorem was <a href="http://en.wikipedia.org/wiki/Cantor%E2%80%93Bernstein%E2%80%93Schroeder_theorem#Original_proof">first proved</a> by Cantor using the axiom of choice.  Proofs without using it came later. </p>

==============================
===============================
Question: <p>I am wondering how much a smooth function may be non-analytic, because in proofs, whilst there non-analytic smooth functions, it would suffice if a smooth function were analytic on only a "small set". More exactly:</p>

<p>Let $U \in \mathbb R^n$ be open, $C^\infty = C^\infty(U,\mathbb R)$. A smooth function in $C^\infty$ is analytic in $a \in U$, iff there exists $\epsilon &gt; 0$, s.t. the function is equal to its own Taylor series in $B_\epsilon(a)$. There exist smooth functions that are non-analytic, i.e. there exists $f \in C^\infty, b \in U, \epsilon &gt; 0$ s.t. the function is not its taylor series at $x$ in $B_\epsilon (b)$.</p>

<p>Let $A$ be the union of all $\epsilon$-Balls in $U$ where $f$ is analytic. By definition, $A$ is open. It's complement $C = A^c$is the closed set of points where $f$ is non-analytic.</p>

<p>Does $C$ have an interior?</p>

 
Answer: <p>Yes, that can happen. The canonical example (as far as I know) is the <a href="http://en.wikipedia.org/wiki/Fabius_function" rel="nofollow noreferrer">Fabius function</a> which is smooth and <em>nowhere</em> analytic.</p>

<p><hr>
I never really liked this answer because it's hard — if not outright impossible — to find references online on how to prove the nonanalyticity of $Fb$. So here is a short exposition on a different example adapted from the discussion archived in <a href="https://web.archive.org/web/20141230224759/http://www.math.niu.edu/~rusin/known-math/99/nowhere_analy" rel="nofollow noreferrer">this text file</a> mirrored on archive.org.</p>

<hr>

<h1>Introduction</h1>

<p>Students often see
$$ f(x) = \begin{cases}
    \exp(-\tfrac{1}{x}) &amp; \text{for } x &gt; 0 \\\\
    0                  &amp; \text{for } x \leq 0
\end{cases}$$
as an example of a smooth function that's not analytic at $0$, but this as well as the other usual examples makes it very easy to intuit that smooth functions are “mostly analytic”, i.e. everywhere analytic except possibly at some isolated points. And given that this is the only example that one typically sees this is in fact a reasonable thing to believe. But nonetheless there are plenty of examples out there — for example the following: </p>

<h1>Example</h1>

<p>Define $F: \mathbb{R} \to \mathbb{C}$ by
$$ F(x) := \sum_{n=0}^\infty \frac{\exp(i2^nx)}{n!}. $$</p>

<p><strong>Theorem:</strong> $F$ and $\Re F$, the real part of $F$, are smooth nowhere analytic functions.</p>

<p><em>Proof:</em> Computing the derivatives of $F$ we get
$$ F^{(k)}(x) = \sum_{n=0}^\infty \frac{\exp(i2^nx)(i2^n)^k}{n!}, $$
which is uniformly convergent everywhere, so it's continuous and there are no issues with moving the differentiation in under the summation. In other words $F$ and $\Re F$ are smooth. Furthermore we have that 
$$ F^{(k)}(0) = \sum_{n=0}^\infty \frac{(i2^n)^k}{n!} = i^k \exp(2^k). $$
The <a href="http://en.wikipedia.org/wiki/Cauchy-Hadamard_theorem" rel="nofollow noreferrer">Cauchy-Hadamard formula</a> for the radius of convergence, $r$, for the Taylor series for $F$ gives at $x=0$ with the usual conventions about infinities that 
$$ \frac{1}{r} = \limsup_{k \to \infty} \left\lvert \frac{F^{(k)}(0)}{k!}\right\rvert^{1/k} = \limsup_{k \to \infty} \left(\frac{\exp(2^k)}{k!} \right)^{1/k} = \infty, $$
and so $r = 0$. The same will be true for $\Re f$ as the even-indexed parts of $\Re F$ have the same magnitude as those of $F$. $F$ is $2\pi$-periodic, so the same is true for every $x$ which is an integer multiple of $2\pi$. Moreover we see that if we throw away the first $p$ terms, we get a function with period $\omega = \frac{2\pi}{2^p}$ and with points of non-analyticity at all integer multiples of $\omega$. Hence $F$ and $\Re F$ must also be nonanalytic at these points and we conclude that the set of points where the two functions are nonanalytic is dense in $\mathbb{R}$. </p>

<p>Finally observe that if a function is analytic in a point it must be analytic on a neighbourhood of that point, thus there are no possible open sets where $F$ and $\Re F$ can be analytic, i.e. they are smooth nowhere analytic functions. $\;\square$</p>

<h1>Good Questions to Ponder</h1>

<p>Suppose $\Omega \subseteq \mathbb{R}^n$ is open.</p>

<p>Is there an $f \in C^\infty(\mathbb{R}^n)$ such that $\Omega$ is its locus of analyticity?</p>

<p>Are the functions that are analytic at some point of the first category in $C^\infty(\Omega)$?</p>

==============================
===============================
Question: <p>In <a href="https://math.stackexchange.com/questions/13050/eee79-and-ultrafinitism/">this question</a>, I needed to assume in my answer that $e^{e^{e^{79}}}$ is not an integer. Is there some standard result in number theory that applies to situations like this? </p>

<p>After several years, it appears this is an open problem. As a non-number theorist, I had assumed there would be known results that would answer the question. I was aware of the difficulty in proving various constants to be transcendental -- such as $e + \pi$, which is not known to be transcendental at present. </p>

<p>However, I was looking at a question that seems simpler, naively: whether a number is an integer, rather than whether it is transcendental.  It seems that what appeared to be possibly simpler is actually not, with current techniques. </p>

<p>The main motivation for asking about this particular number is that it is very large. It is certainly possible to find a pair of very large numbers, at least one of which is transcendental. But the current lack of knowledge about this particular number is even an integer shows just how much progress remains to be made, in my opinion.  Any answers that describe techniques that would suffice to solve the problem (perhaps with other, unproven assumptions) would be very welcome. </p>

 
Answer: <p>The paper Chuangxun Cheng, Brian Dietel, Mathilde Herblot, Jingjing Huang, Holly Krieger, Diego Marques, Jonathan Mason, Martin Mereb, and S. Robert Wilson, Some consequences of Schanuel’s conjecture, Journal of Number Theory 129 (2009) 1464–1467, shows that $e,e^e,e^{e^e},\dots$ is an algebraically independent set, on the assumption of Schanuel's Conjecture. Maybe a close reading of that paper will suggest a way of applying the result to the 79-question. </p>

==============================
===============================
Question: <p>I am looking for a short proof that $$\int_0^\infty \left(\frac{\sin x}{x}\right)^2 \mathrm dx=\frac{\pi}{2}.$$
What do you think?</p>

<p>It is kind of amazing that $$\int_0^\infty \frac{\sin x}{x} \mathrm dx$$ is also $\frac{\pi}{2}.$ Many proofs of this latter one are already in this <a href="https://math.stackexchange.com/a/8350">post</a>.</p>

 
Answer: <p>Let $f(x)=\max\{0,1-|x|\}$. It is easy to calculate the Fourier transform
$$\hat{f}(\xi)=\int_{-\infty}^{\infty}f(x)e^{-ix\xi}dx=\left(\frac{\sin(\xi/2)}{\xi/2}\right)^2.$$
Taking the inverse Fourier transform, we get 
$$\int_{-\infty}^{\infty}\left(\frac{\sin(\xi/2)}{\xi/2}\right)^2e^{ix\xi}d\xi=2\pi f(x),$$ 
and the result follows.</p>

<p>The second integral can be computed in a similar way. Just take $f(x)=\chi_{[-1,1]}(x)$ (the indicator function of the interval $[-1,1]$).</p>

<hr>

<p><strong>Edit.</strong> It might be interesting to note that there are analogous formulas for the sinc 
sums
$$\sum_{n=1}^{\infty}\frac{\sin n}{n}=\sum_{n=1}^{\infty}\left(\frac{\sin n}{n}\right)^2=
\frac{\pi}{2}-\frac{1}{2}.$$</p>

<p>I learned about this from the note <em>"Surprising Sinc Sums and Integrals"</em> by Baillie, Borwein, and Borwein (can be found through a quick web search).</p>

==============================
===============================
Question: <p>A friend of mine introduced me to the following question:
Does there exist a smooth function $f: \mathbb{R} \to \mathbb{R}$ ($f \in C^{\infty}$), such that $f$ maps rationals to rationals and irrationals to irrationals and is nonlinear?</p>

<p>He has been able to prove that such a polynomial (with degree at least 2) doesn't exist.</p>

<p>The problem has been asked before at least at <a href="http://www.artofproblemsolving.com">http://www.artofproblemsolving.com</a>.</p>

 
Answer: <p>Sergei Ivanov has given a positive answer for the existence of such functions on MO:
<a href="https://mathoverflow.net/questions/48910/smooth-functions-for-which-fx-is-rational-if-and-only-if-x-is-rational">https://mathoverflow.net/questions/48910/smooth-functions-for-which-fx-is-rational-if-and-only-if-x-is-rational</a>.</p>

==============================
===============================
Question: <p>I read that any continuous function can be represented as a sum of convex and concave function, meaning for all $f(x)$, $f(x) = g(x) + h(x)$ where $g$ is convex and $h$ is concave.</p>

<p>There could be infinitely many decompositions of that sort.</p>

<p>Anyone knows where I can see a proof or this, or knows of a proof of this?</p>

<p>Thanks.</p>

 
Answer: <p>If $f$ is $C^2$ (meaning the derivatives $f&#39;$ and $f&#39;&#39;$ are defined and continuous), and if $f$ is defined on a closed interval like $[0,1]$, then there is an easy solution. Since $f&#39;&#39;$ is continuous, it has a minimal value $m$. Choose $c$ positive and greater than $m$. Then $f(x)+c x^2/2$ is convex, by the double derivative test, and $-c x^2$ is concave. Of course, $[f(x)+c x^2/2] + [-cx^2/2] = f(x)$. </p>

<p>It shouldn't be too much harder to do a general continuous function, but I don't see it right now.</p>

==============================
===============================
Question: <p>Here is an exercise, on analysis which i am stuck. </p>

<ul>
<li>How do I prove that if $F_{n}(x)=\sum\limits_{k=1}^{n} \frac{\sin{kx}}{k}$, then the sequence $\{F_{n}(x)\}$ is boundedly convergent on $\mathbb{R}$?</li>
</ul>

 
Answer: <p>First, let's note that for $x\in(0,2\pi)$
$$\sum\limits_{k=1}^{n}\frac{\sin kx}{k}=\int_{0}^{x}\sum\limits_{k=1}^{n}\cos kt\ dt=
-\frac{x}{2}+\int_{0}^{x}\frac{\sin \frac{(2n+1)t}{2}}{2\sin{\frac{t}{2}}}\ dt$$
$$=-\frac{x}{2}+\int_{0}^{x}\left(\frac{1}{2\sin{\frac{t}{2}}}-\frac{1}{t}\right)\sin \frac{(2n+1)t}{2}\ dt +\int_{0}^{x}\frac{\sin \frac{(2n+1)t}{2}}{t}dt.$$
Now, the first integral at the right-hand side tends to zero by the Riemann-Lebesgue lemma.
The second one is equal to (via a substitution $s=(2n+1)t/2$) the integral
$$\int_{0}^{\frac{(2n+1)x}{2}}\frac{\sin s}{s}\ ds\to\int_{0}^{\infty}\frac{\sin s}{s}\ ds=\frac{\pi}{2}.$$
Therefore
$$\lim\limits_{n\to\infty}\ \sum\limits_{k=1}^{n}\frac{\sin kx}{k}=\frac{\pi-x}{2}=f(x),\qquad x\in(0,2\pi).$$
The series converges on $\mathbb R$ to the periodic extension of $f(x)$. </p>

==============================
===============================
Question: <p>This is a very simple question but I believe it's nontrivial.</p>

<p>I would like to know if the following is true: </p>

<blockquote>
  <p>If $R$ and $S$ are rings and $R[x]$ and $S[x]$ are isomorphic as rings, then $R$ and $S$ are isomorphic. </p>
</blockquote>

<p>Thanks!</p>

<p>If there isn't a proof (or disproof) of the general result, I would be interested to know if there are particular cases when this claim is true. </p>

 
Answer: <p>Here is a counterexample.</p>

<p>Let $R=\frac{\mathbb{C}[x,y,z]}{(xy - (1 - z^2))}$, $S=\frac{\mathbb{C}[x,y,z]}{(x^2y - (1 - z^2))}$. Then, $R$ is not isomorphic to $S$ but, $R[T]\cong S[T]$.</p>

<p>In many variables, this is called the Zariski problem or cancellation of indeterminates and is largely open. <a href="http://www.math.lsa.umich.edu/~hochster/Lip.text.pdf">Here</a> is a discussion by Hochster (problem 3).</p>

==============================
===============================
Question: <p>Background: Let $n$ be an integer and let $p$ be a prime. If $p^{e} || n$, we write $v_{p}(n) = e$. A natural number $n$ is a sum of two integer squares if and only if for each prime $p \equiv 3 \pmod 4$, $v_{p}(n)$ is even. Every natural number is a sum of four squares. A natural number $n$ is a sum of three squares if and only if it is not of the form $4^{k}u$ where $u \equiv 7 \pmod 8$. </p>

<p>I would like to know why it is harder to prove the above result for sums of three squares as opposed to sums of two squares or four squares.</p>

<p>I've heard somewhere that one way to see this involves modular forms... but I don't remember any details. I would also like to know if there is a formula for the number of ways of representing a natural number n as a sum of three squares (or more generally, $m$ squares) that is similar in spirit to the formulas for the number of ways of representing a natural number as the sum of two squares and four squares. </p>

 
Answer: <p>The modular forms explanation is basically due to the fact
that $3$ is odd and so the generating function for representations
of sums of three squares is a modular form of half-integer weight.</p>

<p>In general if $r_k(n)$ is the number of representations of $n$
as a sum of $k$ squares then
$$\sum_{n=0}^\infty r_k(n)q^n=\theta(z)^k$$
where $q=\exp(\pi i z)$ and 
$$\theta(z)=1+2\sum_{n=1}^\infty q^{n^2}.$$
Then $f_k(z)=\theta(z)^k$ is a modular form of weight $k/2$ for the group
$\Gamma_0(4)$. This means that
$$f_k((az+b)/(cz+d))=(cz+d)^{k/2}f_k(z)$$
whenever the matrix $\begin{pmatrix}a&amp;b\\\\c&amp;d\end{pmatrix}$
lies in $\Gamma_0(4)$, that is $a$, $b$, $c$ and $d$ are integers, $4\mid c$
and $ad-bc=1$.</p>

<p>This definition is easy to understand when $k$ is even, but for odd
$k$ one needs to take the correct branch of $(cz+d)^{k/2}$, and
this is awkward. The space of modular forms of weight $k/2$ is
finite-dimensional for all $k$, and is one-dimensional for small enough $k$.
For these small $k$ the space is spanned by an "Eisenstein series".
Computing the Eisenstein series isn't too hard for even $k$, but is
much nastier for odd $k$ where again square roots need to be
dealt with. See Koblitz's book on modular forms and elliptic functions
for the calculation for $k\ge5$ odd. The calculation for $k=3$
is even nastier as the Eisenstein series does not converge absolutely.
In fact the cases where $k$ is divisible by $4$ are even easier, as
even weight modular forms behave nicer.</p>

<p>For large $k$, Eisenstein series are no longer enough, one needs
also "cusp forms". While fascinating, cusp forms have coefficients
which aren't given by nice formulae unlike Eisenstein series.</p>

<p>Of course there is a formula for $r_3(n)$, due to Gauss in his
<em>Disquisitiones Arithmeticae</em>. It involves class numbers of quadratic
fields (or to Gauss numbers of classes of integral quadratic forms).</p>

==============================
===============================
Question: <p>My algebra background: I've had 2 undergrad semesters of algebra, a reading course in Galois Theory, a graduate course in commutative algebra and one in algebraic geometry, and I've done (most of) MacLane and Birkhoff's Algebra on my own.</p>

<p>The problem is that I feel like I still don't have any idea how to do algebra. I do well in my classes and don't have any problem with most exercises in M&amp;B I do. But my process consists pretty much entirely of fiddling around with symbols until I figure out how to apply theorems I know in a completely straightforward way. I'm able to do exercises from a book, but rarely able to prove theorems in the text on my own. </p>

<p>This is a complete contrast to how I feel in topology and analysis (not that I really know any topology or analysis), where I have a halfway decent intuition and really think I know why things are true (and moreover, why anyone should care). I'm able to prove theorems. </p>

<p>In topology and analysis, I am able to visualize things pretty directly in a way that I can get insight into how things work. For algebra, I have no picture. I've tried learning about Cayley graphs to visualize groups. I think these are neat, but I have yet to successfully apply any insight from them. I hoped learning about algebraic geometry would help me visualize rings. But the geometry in algebraic geometry is dictated entirely by the algebra. So how can you use geometry to help you with the algebra, when you have to do the algebra first to figure out what the geometry looks like? I don't get it. </p>

<p>So the question I'm trying to get at is: How do I develop some insight or intuition about algebra? I don't really know what form answers might take; maybe a reading suggestion, or just a general way to look at things. Maybe this isn't a good question, but I'm kind of at the end of my rope with this stuff. </p>

<p>A particular user on MathOverflow said he fell in love with algebra the first time he saw the axioms for a group. When I first saw the axioms for a group, I spent the next year trying to figure out why the heck anybody cared about groups (and frankly still only know this in a detached and academic way). So it's possible the only answer is: I'm barking up the wrong tree; algebra isn't for me and I should move on to something that comes more naturally. </p>

 
Answer: <blockquote>
  <p>But the geometry in algebraic geometry is dictated entirely by the algebra. So how can you use geometry to help you with the algebra, when you have to do the algebra first to figure out what the geometry looks like? I don't get it.</p>
</blockquote>

<p>Roughly speaking, geometric intuition suggests to you what should be true, and suggests a strategy for proving it; and algebra is how you carry out the proofs.  For example, it's geometry that should inform your intuitions about things like intersections of varieties, but algebra that you use to actually rigorously define intersections and prove things about them.  </p>

<p>Consider the "principle of continuity."  If you intersect a circle and an ellipse, you'll generically get four points, although sometimes you might get two or one.  If you intersect a circle and a parabola the same thing happens.  In a perfect world, you might suspect that the intersection of two conic sections is always "four points," but this clearly isn't true for the usual definition of "four points."  But if you broaden your definitions (count the points with multiplicity; count the complex points; count the points at infinity), you will eventually be led to complex projective varieties, where something like the "principle of continuity" holds: if you have two varieties that intersect in $m$ points and you nudge one of them or the other continuously, they will still intersect in $m$ points, if you count the points properly.</p>

<p>It's important to keep in mind that historically a major incentive for developing commutative algebra was to rigorize parts of algebraic geometry; some algebraic geometers (the Italian school) had begun relying too heavily on geometric intuition and had been ignoring special cases, etc. and commutative algebra was one way to fix their proofs.  But the point is that they were doing algebraic geometry <em>first</em>!  There is a long and interesting history here which I think it is very instructive to learn; you should try to find Dieudonne's <em>History of Algebraic Geometry</em>, as well as (for a personal perspective) Parikh's <em>The Unreal Life of Oscar Zariski.</em></p>

<blockquote>
  <p>When I first saw the axioms for a group, I spent the next year trying to figure out why the heck anybody cared about groups (and frankly still only know this in a detached and academic way).</p>
</blockquote>

<p>The group axioms are an abstraction of the notion of symmetry, and symmetry is a natural and beautiful idea, and symmetries are everywhere in mathematics.  Perhaps you aren't acquainted with enough examples; it's hard for me to give more specific advice here without knowing what you find unsatisfying about groups.  But you might be interested in Conway, Burgiel, and Goodman-Strauss's <em>The Symmetries of Things</em>, as well as in Mumford, Series, and Wright's <em>Indra's Pearls: the Vision of Felix Klein.</em></p>

==============================
===============================
Question: <p>Does anyone know a combinatorial proof of the following identity, where $F_n$ is the $n$th Fibonacci number?</p>

<p>$$n F_1 + (n-1)F_2 + \cdots + F_n = F_{n+4} - n - 3$$</p>

<p>It's not in the place I thought it most likely to appear: Benjamin and Quinn's <em><a href="http://books.google.com/books?id=FXLGzXwbwIAC&amp;printsec=frontcover&amp;dq=proofs+that+really+count&amp;source=bl&amp;ots=cLasNhVboM&amp;sig=cgpcvX12VJy4hzDjlM8buMY1O1w&amp;hl=en&amp;ei=1RUVTY2vAY7EsAPklv3GAg&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=3&amp;ved=0CCkQ6AEwAg#v=onepage&amp;q&amp;f=false">Proofs That Really Count</a></em>.  In fact, this may be a hard problem, as they say the similar identity </p>

<p>$$ F_1 + 2F_2 + \cdots + nF_n = (n+1)F_{n+2} - F_{n+4} +2$$</p>

<p>is "in need of a combinatorial proof."</p>

<p>For reference, <a href="http://books.google.com/books?id=n8Xx2oSlz4MC&amp;pg=PA14&amp;lpg=PA14&amp;dq=benjamin+and+quinn+uncounted+fibonacci&amp;source=bl&amp;ots=UDfzehytLs&amp;sig=mcWgV3BP2_Jyl5zi1fhL2EHqqfU&amp;hl=en&amp;ei=ThIVTcmsLo7ksQPcvMXIAg&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=3&amp;ved=0CCIQ6AEwAg#v=onepage&amp;q&amp;f=false">here</a> (from Benjamin and Quinn's text) are several combinatorial interpretations of the Fibonacci numbers.</p>

 
Answer: <p>Recall that $F_{n+1}$ is the number of ways to tile a board of length $n$ with tiles of length $1$ and $2$.  So $F_{n+4}$ is the number of ways to tile a board of length $n+3$ with tiles of length $1$ and $2$.  Note that $n+3$ such tilings use at most one tile of length $2$, so $F_{n+4} - (n+3)$ such tilings use at least two tiles of length $2$.</p>

<p>Given such a tiling, look at where the second-to-last tile of length $2$ is used.  The part after this tile is a tiling of some section of length $k+1$ where exactly one tile of length $2$ is used (which can be done in $k$ ways), and the part before this tile is a tiling of the remaining portion of length $n-k$ (which can be done in $F_{n-k+1}$ ways).  Sum over $k$.</p>

<p>(The bigger lesson to take away here is that convolution is much easier to deal with than Hadamard product.  Also, since the bijection I described above preserves the number of tiles of each type, the identity can be upgraded to an identity of $q$-Fibonacci numbers.)</p>

==============================
===============================
Question: <p>I am trying to understand the notion of an orientable manifold.<br>
Let M be a smooth n-manifold. We say that M is orientable if and only if there exists an atlas $A = \{(U_{\alpha}, \phi_{\alpha})\}$ such that $\textrm{det}(J(\phi_{\alpha} \circ \phi_{\beta}^{-1}))&gt; 0$ (where defined). My question is:<br>
Using this definition of orientation, how can one prove that the Möbius strip is not orientable?  </p>

<p>Thank you!</p>

 
Answer: <p>If you had an orientation, you'd be able to define at each point $p$ a unit vector $n_p$ normal to the strip at $p$, in a way that the map $p\mapsto n_p$ is continuous. Moreover, this map is completely determined once you fix the value of $n_p$ for some specific $p$. (You have two possibilities, this uses a tangent plane at $p$, which is definable using a $(U_\alpha,\phi_\alpha)$ that covers $p$.)</p>

<p>The point is that the positivity condition you wrote gives you that the normal at any $p&#39;$ is independent of the specific $(U_{\alpha&#39;},\phi_{\alpha&#39;})$ you may choose to use, and path connectedness gives you the uniqueness of the map. Now you simply check that if you follow a loop around the strip, the value of $n_p$ changes sign when you return to $p$, which of course is a contradiction.</p>

<p>(This is just a formalization of the intuitive argument.)</p>

==============================
===============================
Question: <p>It is, of course, one of the first results in basic complex analysis that a holomorphic function satisfies the Cauchy-Riemann equations when considered as a differentiable two-variable real function. I have always seen the converse as: if $f$ is <em>continuously</em> differentiable as a function from $U \subset \mathbb{R}^2$ to $\mathbb{R}^2$ and satisfies the Cauchy-Riemann equations, then it is holomorphic (see e.g. Stein and Shakarchi, or <a href="http://en.wikipedia.org/wiki/Cauchy%E2%80%93Riemann_equations" rel="nofollow noreferrer">Wikipedia</a>). Why is the $C^1$ condition necessary? I don't see where this comes in to the proof below. </p>

<p>Assume that $u(x,y)$ and $v(x,y)$ are continuously differentiable and satisfy the Cauchy-Riemann equations. Let $h=h_1 + h_2i$. Then<br>
\begin{equation*}
u(x+h_1, y+h_2) - u(x,y) = \frac{\partial u}{\partial x} h_1 + \frac{\partial u}{\partial y}h_2 + o(|h|)
\end{equation*}
and 
\begin{equation*}
v(x+h_1, y+h_2) - v(x,y) = \frac{\partial v}{\partial x} h_1 + \frac{\partial v}{\partial y} h_2 + o(|h|).
\end{equation*}
Multiplying the second equation by $i$ and adding the two together gives 
\begin{align*}
(u+iv)(z+h)-(u+iv)(z) &amp;= \frac{\partial u}{\partial x} h_1 + i \frac{\partial v}{\partial x} h_1 + \frac{\partial u}{\partial y} h_2 + i \frac{\partial v}{\partial y} h_2 + o(|h|)\\\
 &amp;= \left( \frac{\partial u}{\partial x} + i \frac{\partial v}{\partial x} \right) (h_1+i h_2) + o(|h|).
\end{align*} 
Now dividing by $h$ gives us the desired result. </p>

<p>Does there exist a differentiable but not $C^1$ function $f: U \rightarrow \mathbb{R}^2$ which satisfies the Cauchy-Riemann equations and does NOT correspond to a complex-differentiable function?  </p>

 
Answer: <p>See <a href="http://www.jstor.org/stable/2321164" rel="nofollow noreferrer"><em>When is a Function that Satisfies the Cauchy-Riemann Equations Analytic?</em></a> J. D. Gray and S. A. Morris
The American Mathematical Monthly
Vol. 85, No. 4 (Apr., 1978), pp. 246-256. </p>

==============================
===============================
Question: <p>A friend sent me a link to this item today, which is billed as an "Irrational Numbers Wall Clock."  </p>

<p><img src="https://i.stack.imgur.com/owLvp.jpg" alt="alt text"></p>

<p>There is at least one possible mistake in it, as it is not known whether $\gamma$ is irrational.  </p>

<p>Anyway, this started me wondering about how to improve the design of this clock from a mathematical standpoint.  Here's my formulation of the problem:</p>

<ol>
<li><p>Find 12 numbers that have been proved to be irrational to place around the outside of a clock.</p></li>
<li><p>Each of eleven of the numbers must approximate as closely as possible one of the integers from 1 through 11.  The 12th can either be just smaller than 12 or just larger than 0.  </p></li>
<li><p>The numbers must have expressions that are as simple as possible (in the spirit of - or even more simple than - those in the clock given in the picture here).  Thus, for example, no infinite sums, no infinite products, and no continued fractions.  Famous constants and transcendental functions evaluated at small integers encouraged.</p></li>
<li><p>Expressions should be as varied as possible.  Better answers would include at least one use of trig functions, logarithms, roots, and famous constants.  </p></li>
</ol>

<p>Obviously, goals 2, 3, and 4 act against each other.  And, as Jonas Meyer points out, "as closely as possible" and "as simple as possible" are not well-defined.  That is intentional.  I am afraid that if I tried to define those precisely I would preclude some answers that I might otherwise consider good.  Thus, in addition to the mathematics, there's a sizable artistic component that goes into what would be considered a good answer.  Hence the "soft-question" tag.  I'm really curious as to what the math.SE community comes up with and then what it judges (via upvoting) to be the best answers, subject to these not-entirely-well-defined constraints.</p>

<p>Note that the designer of the clock given here was not trying to approximate the integers on a clock as closely as possible.</p>

<p>Finally, it's currently New Year's Day in my time zone.  Perhaps a time-related question is appropriate. :)</p>

<p>Note: There is now a community wiki answer that people can edit if they just want to add a few suggestions rather than all twelve.</p>

 
Answer: <p>Here's a list of irrational numbers which almost fulfill your criteria.</p>

<p>Each were chosen to be accurate to within &plusmn;0.1, so that no two of them implicitly express the same mathematical approximation, and so that none of them "cheats" in order to fudge an exact result involving integers to obtain a slightly inexact, irrational result. Only the last number fails to meet your criteria, as it is slightly larger than 12.</p>

<ol>
<li>$\ln(3)$</li>
<li>$7\pi/11$</li>
<li>$\sqrt 2 + \frac\pi2$</li>
<li>$7/{\sqrt[3]5}$</li>
<li>$\mathrm e^\phi$</li>
<li>$\sec^2(20)$</li>
<li>$4\sqrt3$</li>
<li>$5\phi$</li>
<li>$2\pi+\mathrm e$</li>
<li>$\sinh(3)$</li>
<li>$\pi^3-20$</li>
<li>$\csc^2(16)$</li>
</ol>

<p>I would prefer not to use cosecant, integers greater than 12, or more than two additions/subtractions &mdash; it is too easy to get results if you rely on these &mdash; but I think I've spent enough time on this diversion for now. :-)<br><br>[<strong>EDIT:</strong> revised the formula for 4 two times now: this first to change the formula for 4 from &radic;3&thinsp;+&thinsp;&radic;5 &mdash; which is too close to &radic;4&thinsp;+&thinsp;&radic;4 &mdash; and the second time to correct the formula as I somehow copied a result which was not approximately 4.]<br><br>
<strong>Added:</strong> Since it seems that I can't sleep tonight, here is a list of approximate values:</p>

<p>$\begin{align*}
\ln(3)               &amp; \approx 1.0986 \\
7\pi/11              &amp; \approx 1.9992 \\
\sqrt 2 + \tfrac\pi2 &amp; \approx 2.9850 \\
7 / \sqrt[3]5        &amp; \approx 4.0936 \\
\mathrm e^\phi       &amp; \approx 5.0432 \\
\sec^2(20)           &amp; \approx 6.0049 \\
4\sqrt3              &amp; \approx 6.9282 \\
5\phi                &amp; \approx 8.0902 \\
2\pi+\mathrm e       &amp; \approx 9.0015 \\
\sinh(3)             &amp; \approx 10.018 \\
\pi^3-20             &amp; \approx 11.006 \\
\csc^2(16)           &amp; \approx 12.064
\end{align*}$</p>

==============================
===============================
Question: <p>I am trying very hard to understand Gödel's Incompleteness Theorem.  I am really interested in what it says about axiomatic languages, but I have some questions:</p>

<p>Gödel's theorem is proved based on Arithmetic and its four operators: is all mathematics derived from these four operators (×, +, -, ÷) ?</p>

<p>Operations such as log(x) and sin(x) are indeed atomic operations, like those of arithmetic, but aren't there infinitely many such operators that have inverses (that is, + and - are "inverse" operations, × and ÷ are inverse operations).</p>

<p>To me it seems as though making a statement about the limitations of provability given 4 arbitrary operators is absurd, but that probably highlights a gap in my understanding, given that he proved this in 1931 and its unlikely that I have found a counter-argument.</p>

<p>As a follow-up remark, why the obsession with arithmetic operators?  They probably seem "fundamental" to us as humans, but to me they all seem to be derived from four possible graphical arrangements of numbers (if we consider four sides to a digit), and fundamentally derived from addition.</p>

<p>[][] o [][] addition and, its inverse, subtraction</p>

<p>[][]<br>
[][] multiplication (iterative addition) and, its inverse, division</p>

<p>There must be operators that are consistent on the natural numbers that we certainly aren't aware of, no?</p>

<p>Please excuse my ignorance, I am hoping I haven't offended any real mathematicians with this posting.</p>

<p><hr>
edit: I think I am understanding this a lot more, and I think my main difficulty in understanding this was that:</p>

<blockquote>
  <p>There are statements that are true that are unprovable.  </p>
</blockquote>

<p>Seemed like an impossible statement.  It does, however, make sense to me at the moment in the context of an axiomatic language with a limited number of axioms.  Ultimately, suggesting that there are statements that are true and expressible in the language, but are unprovable in the language (because of the limited set of axioms), is what I believe to be the point of the proof -- is this correct?</p>

 
Answer: <p>There's a fair amount of historical context to make some of Gödel's choices in his original proof clear. For a good overview of the proof, Nagel and Newman's <strong>Goedel's Proof</strong> is pretty good (though not without its detractors). I also highly recommend the late Torkel Franzen's <a href="http://rads.stackoverflow.com/amzn/click/1568812388">Godel's Theorem: An Incomplete Guide to its Use and Abuse</a>. I may myself be guilty of some of those abuses below; I'm trying to shy away from a lot of the technical details, and this usually invites imprecision and even abuse in this particular field. I hope those who know better than me will keep me honest via comments and appropriate ear-pulling.</p>

<p><strong>Some history.</strong> Sometimes I think of the 19th century as the <em>Menagerie century</em>. A "menagerie" was like a zoo of weird animals. During a lot of the 19th century, people were trying to clean up some of the logical problems that abounded in the foundations of mathematics. Calculus plainly <em>worked</em>, but a lot of the notions of infinitesimals were simply incompatible with some 'facts' about real numbers (eventually solved by Weierstrass's notion of limits using $\epsilon$s and $\delta$s). A lot of assumptions people had been making implicitly (or explicitly) were shown to be false through the construction of explicit counterexamples (the "weird animals" that lead me to call it the <em>menagerie century</em>; many mathematicians were like explorers bringing back weird animals nobody had seen before and which challenged people's notions of what was and was not the case): the Dirichlet function to show that you can have functions that are discontinuous everywhere; functions that are continuous everywhere but nowhere differentiable; the failure of Dirichlet's principle for some functions; Peano's curve that filled-up a square; etc. Then, the antinomies (paradoxes and contradictions) in the early set theory. Even some work which today we find completely without problem caused a lot of debate: Hilbert's solution of the problem of a finite basis for invariants in any number of variables was originally derided by Gordan as "theology, not mathematics" (the solution was not constructive and involved the use of an argument by contradiction). Many found a lot of these developments deeply troubling. A foundational crisis arose (see the link in Qiaochu's answer).</p>

<p>Hilbert, one of the leading mathematicians of the late 19th century, proposed a way to settle the differences between the two main camps. His proposal was essentially to try to use methods that both camps found unassailably valid to show that mathematics was <em>consistent</em>: that it was not possible to prove both a proposition and its negation. In fact, his proposal was to use methods that both camps found unassailable to prove that the methods that <em>one</em> camp found troublesome would not introduce any problems. This was the essence of the <strong>Hilbert Programme.</strong></p>

<p>In order to be able to accomplish this, however, one needed to have some way to study proofs and mathematics itself. There arose the notion of "formal proof", the idea of an axiomatization of basic mathematics, etc. There were several competing axiomatic systems for the basics of mathematics: Zermelo attempted to axiomatize set theory (later expanded to Zermelo-Fraenkel set theory); Peano had proposed a collection of axioms for basic arithmetic; and famously Russell and Whitehead had, in their massive book <strong>Principia Mathematica</strong> attempted to establish an axiomatic and deductive system for all of mathematics (as I recall, it takes hundreds of pages to finally get to $1+1=2$). Some early successes were achieved, with people showing that some parts of such theories were in fact consistent (more on this later). Then came Gödel's work.</p>

<p><strong>Consistency and Completeness.</strong> We say a formal theory is <em>consistent</em> if you cannot prove both $P$ and $\neg P$ in the theory for some sentence $P$. In fact, because from $P$ and $\neg P$ you can prove anything using classical logic, it is equivalent that a theory is consistent if and only if there is at least one sentence $Q$ such that there is no proof of $Q$ in the theory. By contrast, a theory is said to be <em>complete</em> if given any sentence $P$, either the has a proof of $P$ or a proof of $\neg P$. (Note that an inconsistent theory is necessarily complete). Hilbert proposed to find a consistent and complete axiomatization of arithmetic, together with a proof (using only the basic mathematics that both camps agreed on) that it was both complete and consistent, and that it would remain so even if some of the tools that his camp used (which the other found unpalatable and doubtful) were used with it.</p>

<p><strong>Why arithmetic?</strong> Arithmetic was a particularly good field to focus on in the early efforts. First, it was the basis of the "other camp". Kronecker famously said "God gave us the natural numbers, the rest is the work of man." It was hoped that an axiomatization of the natural numbers and their basic operations (addition, multiplication) and relations (order) would be both relatively easy, and also have a hope of being both consistent a complete. That is, it was a good testing ground, because it contained a lot of interesting and nontrivial mathematics, and yet seemed to be reasonably simple.</p>

<p><strong>Gödel</strong>. Gödel focused on arithmetic for this reason. As it happens, multiplication is key to the argument (there is something special about multiplication; some theories of the natural numbers that include only addition can be shown to be consistent using only the kinds of tools that Hilbert allowed). To answer one of your questions along the way, Gödel even defined new operations and relations on natural numbers that had little to do with addition and multiplication along the way, so that yes, there are operations other than those (no fetishism about them at all). But in fact, Gödel did not restrict himself <em>solely</em> to arithmetic. His proof is, on its face, about the entire system of mathematics set forth in Russell and Whitehead's <strong>Principia</strong>, though as Gödel notes it can easily be adapted to other systems so long as they satisfy certain criteria (that's why Gödel's original paper has a title that explicitly refers to the <em>Principia</em> "and related systems"). </p>

<p>What Gödel showed was that <em>any</em> theory, subject to some technical restrictions (for example, you must have a way of recognizing whether a given sentence is or is not an axiom), that is "strong enough" that you can use it to define a certain portion of arithmetic will necessarily be either incomplete or inconsistent (that is, either you can prove <em>everything</em> in that theory, or else there is at least one sentence $P$ such that neither $P$ nor $\neg P$ can be proven). It's not a limitation based on four operations, or an obsession with those operations: quite the opposite. What it says if that if you want your theory to include <em>at least</em> some arithmetic, then your theory is going to be so complicated that <em>either</em> it is inconsistent, or else there are propositions that can neither be proven nor disproven <em>using only the methods that both camps found valid.</em> </p>

<p>That is: what it shows is a limitation of those particular (logically unassailable) methods. If we use other methods, we are able to establish consistency of arithmetic, for example, but if you had your doubts about the consistency of arithmetic in the first place, chances are you will find those methods just as doubtful. </p>

<p>Now, about you coda, and the statement "statements that are true but unprovable"; this is not very apt. You will find a lot of criticism to this paraphrase in Franzen's book, with good reason. It's best to think that you have statements that are neither provable nor disprovable. In fact, one of the things we know is that if you have such a statement $P$, in a theory $M$, then you can find a <strong>model</strong> (an interpretation of the axioms of $M$ that makes the axioms true) in which $P$ is true, and a different model in which $P$ is false. So in a sense, $P$ is neither "true" nor "false", because whether it is true or false will depend on the <em>model</em> you are using. For example, the Gödel sentence $G$ that proves the First Incompleteness Theorem (that if arithmetic is consistent then it is incomplete, since there can be no proof of the sentence $G$ and no proof of $\neg G$) is often said to be "true but unprovable" because $G$ can be interpreted as saying "There is no proof of $G$ in this theory." But in fact, you can find a model of arithmetic in which $G$ is <em>false</em>, so why do we say $G$ is "true"? Well, the point is that $G$ is true in what is called "the standard model." There is a particular interpretation of arithmetic (of what "natural number" means, of what $0$ means, of what "successor of $n$" means, of what $+$ means, etc) which we usually have in mind; <em>in that model</em>, $G$ is true but not provable. But we know that there are different models (where 'natural number' may mean something completely different, or perhaps $+$ means something different) where we can <em>show</em> that $G$ is false <em>under that interpretation</em> of the axioms. I would stay away from "true" and "false", and stick with "provable" and "unprovable" when discussing this; it tends to prevent problems.</p>

<p><strong>First Summary.</strong> So: there were historical reasons why Gödel focused on arithmetic; the limitation is not of arithmetic itself, but rather of the formal methods in question: if your theory is sufficiently "strong" that it can represent part of arithmetic (plus it satisfies the few technical restrictions), then either your theory is inconsistent, or else the finitistic proof methods at issue cannot suffice to settle all questions (there are sentences $P$ which can neither be proven nor disproven).</p>

<p><strong>Can something be rescued?</strong> Well, ideally of course we would have liked a theory that was complete and consistent, and that we could <em>show</em> is complete and consistent using only the kinds of logical methods which we, and pretty much everyone else, finds beyond doubt. But perhaps we can at least show that the other methods don't introduce any problems? That is, that the theory is consistent, even if it is not complete? That at least would be somewhat of a victory.</p>

<p>Unfortunately, Gödel also proved that this is not the case. He showed that if your theory is sufficiently complex that it can represent the part of arithmetic at issue (and it satisfies the technical conditions alluded to earlier), and the theory <em>is</em> consistent, then in fact one of the things that it cannot settle is whether the theory is consistent! That is, one can write down a sentence $C$ which makes sense in the theory, and which essentially "means" "This theory is consistent" (much like the Gödel sentence $G$ essentially "means"  that "there is not proof of $G$ in this theory"), and which one can prove that if the theory is consistent then the theory has no proof of $C$ and no proof of $\neg C$. </p>

<p>Again, this is a limitation of those finitistic methods that everyone finds logically unassailable. In fact, there are proofs of the consistency of arithmetic using transfinite induction, but as I alluded to above, if you harbored doubts about arithmetic in the first place, you are simply not going to be very comfortable with transfinite induction either! Imagine that you are not sure that $X$ is being truthful, and $X$ suggests that you ask $Y$ about $X$s truthfulness; you don't know $Y$, but $X$ assures you that $Y$ is <em>very</em> trustworthy. Well, that's not going to help you, right?</p>

<p><strong>Key take-away:</strong> Because the theorem applies to <em>any</em> theory that is sufficiently complex (and satisfies the technical restrictions), we are not even in a position of enlarging our set of axioms to escape these problems. So long as we restrict ourselves to enlargement methods that we find logically unassailable, the technical restrictions will still be satisfied, so that the new theory, stronger and larger though it will be because it has more axioms, will <em>still</em> be incomplete (though it will possibly be <em>other</em> sentences that are now incomplete or unprovable; remember that by adding axioms, we are also potentially expanding the kinds of things about which we can talk). So the theorems are not about shortcomings of <em>particular</em> axiomatic systems, but rather about those finitistic methods within a very large class of systems. </p>

<p><strong>What about those 'technical restrictions'?</strong> They are important. Suppose that arithmetic were consistent. That means that there is at least one model for it. We could pick a model $M$, and then say "Let's make a theory whose axioms are exactly those sentences that are true when interpreted in $M$." This is a <em>complete</em> and <em>consistent</em> axiomatic system for arithmetic. Complete, because each sentence is either true in $M$ (and hence an axiom, hence provable in this theory) or else false in $M$, in which case its negation is true (and hence an axiom, and hence provable). And consistent, because it has a model, $M$, and a theory is consistent if and only if it has a model. The problem with this axiomatic theory is that if I give you a sentence, you're going to have a hard time deciding if it is or it is not an axiom! We didn't really achieve anything by taking this axiomatic system. The "technical restrictions" are both in the form of making the system actually usable, and also certain technical issues that arise from the mechanics of the proof. But the restrictions are mild enough that pretty much everyone agrees that most reasonable theories will likely satisfy them.</p>

<p><strong>Second summary.</strong> So: if you have a formal axiomatic system which satisfies certain technical (but mild) restrictions, if the theory is large enough that you can represent (a certain part of) arithmetic in it, then the theory is either inconsistent, or else the finitistic methods that everyone agrees are unassailable are insufficient to prove or disprove every sentence in the theory; worse, one of the things that the finitistic methods cannot prove or disprove is <em>whether</em> the theory is in fact consistent or not. </p>

<p>Hope that helps. I really recommend Franzen's book in any case. It will lead you away from potential misinterpretations of what the theorem says (I am likely guilty of a few myself above, which will no doubt be addresssed in comments by those who know better than I do). </p>

==============================
===============================
Question: <p>Let $f \in C[0,1]$ and $f(0)=f(1)$. </p>

<p>How do we prove $\exists a \in [0,1/2]$ such that $f(a)=f(a+1/2)$?</p>

<p>In fact, for every positive integer $n$, there is some $a$, such that $f(a) = f(a+\frac{1}{n})$.</p>

<p>For any other non-zero real $r$ (i.e not of the form $\frac{1}{n}$), there is a continuous function $f \in C[0,1]$, such that $f(0) = f(1)$ and $f(a) \neq f(a+r)$ for any $a$.</p>

<p>This is called the Universal Chord Theorem and is due to Paul Levy.</p>

<p>Note: the accepted answer answers only the first question, so please read the other answers too, and also this answer by Arturo to a different question: <a href="https://math.stackexchange.com/a/113471/1102">https://math.stackexchange.com/a/113471/1102</a></p>

<hr>

<p>This is being repurposed in an effort to cut down on duplicates, see here: <a href="http://meta.math.stackexchange.com/questions/1756/coping-with-abstract-duplicate-questions">Coping with abstract duplicate questions</a>.</p>

<p>and here: <a href="http://meta.math.stackexchange.com/questions/1868/list-of-generalizations-of-common-questions">List of abstract duplicates</a>.</p>

 
Answer: <p>You want to use the intermediate value theorem, but not applied to $f$ directly. Rather, let $g(x)=f(x)-f(x+1/2)$ for $x\in[0,1/2]$. You want to show that $g(a)=0$ for some $a$. But $g(0)=f(0)-f(1/2)=f(1)-f(1/2)=-(f(1/2)-f(1))=-g(1/2)$. This gives us the result: $g$ is continuous and changes sign, so it must have a zero.</p>

==============================
===============================
Question: <p>This is an old homework problem of mine that I was never able to solve.  The solution may or may not involve the Baire category theorem, which I am terrible at applying.</p>

<p>Let $C[0, 1]$ denote the space of continuous functions $[0, 1] \to \mathbb{R}$.  Suppose $|| \cdot ||$ is a norm on $C[0, 1]$ with respect to which the evaluation functions $f \mapsto f(x), x \in [0, 1]$ are continuous.  Show that the topology induced by $|| \cdot ||$ is the same as the usual topology induced by the sup norm.</p>

<p><strike>It is straightforward to show that any sequence converging uniformly converges with respect to $|| \cdot ||$.  I am stuck on proving the converse; I cannot seem to figure out how to use the assumption that $|| \cdot ||$ is a norm.</strike>  </p>

<p>Edit:  Zhen Lin informs me that $|| \cdot ||$ is supposed to be complete.  That should make the problem statement true now!</p>

 
Answer: <p>Here's $\DeclareMathOperator{\ev}{ev}$ the answer if $(C[0,1], \|\cdot\|)$ is assumed to be complete. Consider the family $\mathcal{F} = \{\ev_{x}\}_{x \in [0,1]}$ of <em>continuous</em> linear functionals on $(C[0,1],\|\cdot\|)$. For each $f \in C[0,1]$ we have $\sup_{x \in [0,1]} |\ev_{x}(f)| \leq \|f\|_{\infty}$, so the family $\mathcal{F}$ is <em>pointwise bounded</em>. By the <a href="http://en.wikipedia.org/wiki/Uniform_boundedness_principle">uniform boundedness principle</a> the family is <em>uniformly bounded</em>, that is to say $\sup_{x \in [0,1]} \|\ev_{x}\| \leq M$ for some constant $M$. On the other hand $|f(x)| = |\ev_{x}(f)| \leq \|ev_{x}\|\|f\| \leq M \|f\|$ gives $\|f\|_{\infty} = \sup_{x \in [0,1]} |f(x)| \leq M\|f\|$, so the identity $(C[0,1], \|\cdot\|) \to (C[0,1],\|\cdot\|_{\infty})$ has norm at most $M$. Since both spaces are complete, we may apply the <a href="http://en.wikipedia.org/wiki/Open_mapping_theorem_(functional_analysis)">open mapping theorem</a> in order to conclude that its inverse is also continuous. In other words, the norms $\|\cdot\|$ and $\|\cdot\|_{\infty}$ are equivalent.</p>

<hr>

<p><strong>Edit.</strong> Here's an example that shows that completeness of the norm is necessary:</p>

<p>Choose a <em>discontinuous</em> linear functional $\varphi: (C[0,1],\|\cdot\|_{\infty}) \to \mathbb{R}$ and define a norm on $C[0,1]$ by
\[
\|f\| = \|f\|_{\infty} + |\varphi(f)|.
\]
Since $\|f\|_{\infty} \leq \|f\|$, we have that the identity $(C[0,1],\|\cdot\|) \to (C[0,1],\|\cdot\|_{\infty})$ is continuous. Since the evaluation functionals are continuous with respect to the sup-norm, they are also continuous with respect to the norm $\|\cdot\|$. But as $\varphi$ is discontinuous, there is a sequence $f_{n}$ with $\|f_{n}\|_{\infty} = 1$ and $|\varphi(f_{n})| \to \infty$, hence the norms cannot be equivalent. Of course, $\|\cdot\|$ cannot be complete because the last sentence would be in contradiction to the open mapping theorem.</p>

<hr>

<p><strong>Edit 2.</strong></p>

<p>I forgot to argue why the topologies in the above counterexample are not the same. This is obvious: The functional $\varphi$ is continuous with respect to $\|\cdot\|$ but it isn't continuous with respect to $\|\cdot\|_{\infty}$.</p>

==============================
===============================
Question: <p>As the title says, I'm wondering if there is a continuous function such that $f$ is nonzero on $[0, 1]$, and for which $\int_0^1 f(x)x^n dx = 0$ for all $n \geq 1$. I am trying to solve a problem proving that if (on $C([0, 1])$) $\int_0^1 f(x)x^n dx = 0$ for all $n \geq 0$, then $f$ must be identically zero. I presume then we do require the $n=0$ case to hold too, otherwise it wouldn't be part of the statement. Is there ay function which is not identically zero which satisfies $\int_0^1 f(x)x^n dx = 0$ for all $n \geq 1$?</p>

<p>The statement I am attempting to prove is homework, but this is just idle curiosity (though I will tag it as homework anyway since it is related). Thank you!</p>

 
Answer: <p>(I am turning this into Community wiki, since the original version made an obvious mistake). </p>

<p>The result follows, for example, from the <a href="http://en.wikipedia.org/wiki/Stone%E2%80%93Weierstrass_theorem" rel="nofollow">Stone-Weierstrass theorem</a>, once one justifies that the limit of some integrals is the integral of the limit, which can be done (overkill) using Lebesgue's <a href="http://en.wikipedia.org/wiki/Dominated_convergence_theorem" rel="nofollow">dominated convergence theorem</a> or (more easily) using simple estimates from the fact that $f$ is bounded, since it is continuous.</p>

<p>Below I give full details, which you should probably not read until after your homework is due, since this also solves your homework.</p>

<hr>

<p>Spoilers: </p>

<p>There is a sequence of polynomials $p_n(x)$ that converges uniformly to $xf(x)$ on ${}[0,1]$. We have $\int_0^1xf(x)p_n(x)dx=0$ for all $n$, by assumption, since $xp_n(x)$ is a sum of monomials the integral of whose integral with $f$ is 0. Now take the limit as $n\to\infty$ to conclude that $\int_0^1x(f(x))^2dx=0$.</p>

<p>This gives us that $f=0$ because if $f(x_0)\ne 0$, continuity ensures a positive $\epsilon&gt;0$ and an interval $(a,b)$ with $a&gt;0$ such that $|f(x)|\ge\epsilon$ for all $x\in(a,b)$. But then $\int_0^1xf(x)^2dx\ge la\epsilon^2&gt;0$, where $l=b-a$ is the length of the interval.</p>

<p>To see that the limit of the integrals is 0 without using dominated convergence, let $M\ge|f(x)|$ for all $x\in[0,1]$. The, for any $\delta&gt;0$, if $n$ is large enough, we have $$\int_0^1f(x)xp_n(x)dx=\int_0^1f\times(p-xf+xf)dx=\int_0^1xf(x)^2dx+\int_0^1f\times(p-xf)dx,$$ and the second integral is bounded by $\int_0^1|f||p-xf|dx\le M(\delta/M)=\delta$.</p>

<p>In fact, even this is approach is an overkill. (For example, Müntz's theorem gives a more general fact, as already mentioned in another answer.)</p>

<p>(Apologies for the original mistake.)</p>

==============================
===============================
Question: <p><strong>Question:</strong> Show that $\pi_{1}({\mathbb R}^{2} - {\mathbb Q}^{2})$ is uncountable.</p>

<p><strong>Motivation:</strong> This is one of those problems that I saw in Hatcher and felt I should be able to do, but couldn't quite get there.</p>

<p><strong>What I Can Do:</strong>  There are proofs of this being path connected (though, I'm not exactly in love with any of those proofs) and this tells us we can let any point be our base-point.  Now, let $p$ be some point in ${\mathbb R}^{2} - {\mathbb Q}^{2}$ and let's let this be our base-point.  We can take one path from $p$ to $q$ and a second one from $q$ to $p$, and it's not hard to show that if these paths are different then there is at least one rational on the "inside" of it.  Since there are uncountably many $q$, this would seem to imply uncountably many different elements of the fundamental group; the problem I'm having is showing that two loops like we've described are actually different!  For example, a loop starting at $p$ and passing through $q$ should be different from a loop starting at $p$ and passing through $q&#39;$ for none of these points the same, for at least an uncountable number of elements $q&#39;$.  Is there some construction I should be using to show these elements of the fundamental group are different?</p>

 
Answer: <p>So now that Jacob has explained why the space is path connected let us finish the problem. In his explanation he points out that there are an uncountable number of lines passing through $p$ and an uncountable number of lines passing through $q$ and since we are removing only countably many points not all of these lines can hit a point in $\mathbb{Q}^2$. So we can construct a path from $p$ to $q$ missing $\mathbb{Q}^2$, in fact more than one path. That gives us a loop, inside this loop will be an element of $\mathbb{Q}^2$ just by looking at the coordinates of $p$ and $q$. This shows that the loop is not contractible, ie it is a nontrivial element of $\pi_1(\mathbb{R}^2-\mathbb{Q}^2)$. Now you can proceed to construct more loops passing through $p$ and $q$ that are not contractible or homotopic to the previously constructed loop by picking different line segments as above. Now just construct another path from $p$ to $q$ and notice that an element of $\mathbb{Q}^2$ is inside each of your new loops (there should be at least 2 new loops, try drawing a picture).</p>

<p>Does this help?</p>

<p><strong>Edit:</strong></p>

<p>Here is, in my mind, a clearer construction of uncountably many non-homotopic loops. Let $p \in \mathbb{R}^2-\mathbb{Q}^2$ and $L$ a line in $\mathbb{R}^2-\mathbb{Q}^2$ not containing $p$. As established, there is a continuum of lines passing through $p$, and once we remove all of the ones passing through a point in $\mathbb{Q}^2$ we still have uncountably many. All remaining lines, with one possible exception, intersect $L$ at distinct points. We are left with a triangle for each pair of distinct remaining lines passing through $p$. There is a rational point inside each of these triangles (maybe this is something that was unclear, let me know and I think I can make this part more explicit). There is no way to move "homotope" the triangle past one of the rational points so that it would be homotopic to any adjacent triangle. Suppose two "loops" created in this fashion were homotopic, and suppose further that the differ in the second line passing through $p$, then there would have to be a homotopy between two paths which enclose a point of $\mathbb{Q}^2$ which is impossible.</p>

<p>If you want I can draw a picture on my tablet and try and post. (I don't really know the proper way to go about posting such a picture.)</p>

==============================
===============================
Question: <p>In <a href="http://rads.stackoverflow.com/amzn/click/0071508619">this book I'm using</a> the author seems to feel a need to prove</p>

<p>$e^{u+v} = e^ue^v$</p>

<p>By</p>

<p>$\ln(e^{u+v}) = u + v = \ln(e^u) + \ln(e^v) = \ln(e^u e^v)$</p>

<p>Hence $e^{u+v} = e^u e^v$</p>

<p>But we know from basic algebra that $x^{a+b} = x^ax^b$.</p>

<p>Earlier in the chapter the author says that you should not assume $e^x$ "is an ordinary power of a base <em>e</em> with exponent <em>x</em>."</p>

<p>This is both a math and pedagogy question then, why does he do that?</p>

<p>So 2 questions really</p>

<ol>
<li><em>Do we need to prove</em> this for such a basic property?</li>
<li>If we don't need to, then why does he do it?  Fun?  To make it memorable?  Establish more neural connections?  A case of wildly uncontrolled OCD?</li>
</ol>

<p>Also I've always taken for granted the property that $x^{a+b} = x^a x^b$.  I take it as an axiom, but I actually don't know where that axiom is listed.</p>

 
Answer: <p>In fact, such a proof <em>is</em> often necessary, which is why many authors write the function $e^x$ as $\exp(x)$ until they establish that it's just a "normal" exponent. For instance, if the original definition is given as</p>

<p>$$\exp(x) = \lim_{n \to \infty} \left(1+\frac{x}{n}\right)^n,$$</p>

<p>then proving that $\exp(x + y) = \exp(x) \exp(y)$ is non-obvious, and certainly necessary.</p>

==============================
===============================
Question: <p>How can we sum up $\sin$ and $\cos$ series when the angles are in arithmetic progression? For example here is the sum of $\cos$ series:</p>

<p>$$\sum_{k=0}^{n-1}\cos (a+k \cdot d) =\frac{\sin(n \times \frac{d}{2})}{\sin ( \frac{d}{2} )} \times \cos \biggl( \frac{ 2 a + (n-1)\cdot d}{2}\biggr)$$</p>

<p>There is a slight difference in case of $\sin$, which is:
$$\sum_{k=0}^{n-1}\sin (a+k \cdot d) =\frac{\sin(n \times \frac{d}{2})}{\sin ( \frac{d}{2} )} \times \sin\biggl( \frac{2  a + (n-1)\cdot d}{2}\biggr)$$ </p>

<p>How do we prove the above two identities?</p>

 
Answer: <p>Let $$ S = \sin{(a)} + \sin{(a+d)} + \cdots + \sin{(a+nd)}$$ Now multiply both sides by $\sin\frac{d}{2}$. Then you have $$S \times \sin\Bigl(\frac{d}{2}\Bigr) = \sin{(a)}\sin\Bigl(\frac{d}{2}\Bigr) + \sin{(a+d)}\cdot\sin\Bigl(\frac{d}{2}\Bigr) + \cdots + \sin{(a+nd)}\cdot\sin\Bigl(\frac{d}{2}\Bigr)$$</p>

<p>Now, note that $$\sin(a)\sin\Bigl(\frac{d}{2}\Bigr) = \frac{1}{2} \cdot \biggl[ \cos\Bigl(a-\frac{d}{2}\Bigr) - \cos\Bigl(a+\frac{d}{2}\Bigr)\biggr]$$ and $$\sin(a+d) \cdot \sin\Bigl(\frac{d}{2}\Bigr) = \frac{1}{2} \cdot \biggl[ \cos\Bigl(a + d -\frac{d}{2}\Bigr) - \cos\Bigl(a+d+\frac{d}{2}\Bigr) \biggr]$$</p>

<p>Then by doing the same thing you will have some terms cancelled out. You can easily see which terms are going to get Cancelled. Proceed and you should be able to get the formula. </p>

<p>I tried this by seeing this post. This has been worked for the case when $d=1$. Just take a look here:</p>

<ul>
<li><a href="http://mathforum.org/library/drmath/view/72777.html">http://mathforum.org/library/drmath/view/72777.html</a></li>
</ul>

==============================
===============================
Question: <p>I want to show that any two disjoint compact sets in a Hausdorff space $X$ can be separated by disjoint open sets. Can you please let me know if the following is correct? Not for homework, just studying for a midterm. I'm trying to improve my writing too.</p>

<p>My work:</p>

<p>Let $C$,$D$ be disjoint compact sets in a Hausdorff space $X$. Now fix $y \in D$ and for each $x \in C$ we can find (using Hausdorffness) disjoint open sets $U_{x}(y)$ and $V_{x}(y)$ such that $x \in U_{x}(y)$ and $y \in V_{x}(y)$. Now the collection $\{U_{x}: x \in C\}$ covers $C$ so by compactness we can find some natural k such that</p>

<p>$C \subseteq \bigcup_{i=1}^{k} U_{x_{i}}(y)$ </p>

<p>Now for simplicity let $U = \bigcup_{i=1}^{k} U_{x_{i}}(y)$, then $C \subseteq U$ and let $W(y) = \bigcap_{i=1}^{k} V_{x_{i}}(y)$. Then $W(y)$ is a neighborhood of $y$ and disjoint from $U$.</p>

<p>Now consider the collection $\{W(y): y \in D\}$, this covers D so by compactness we can find some natural q such that $D \subseteq \bigcup_{j=1}^{q} W_{y_{j}}$.</p>

<p>Finally set $V = \bigcup_{j=1}^{q} W_{y_{j}}$, then $U$ and $V$ are disjoint open sets containing $C$ and $D$ respectively. </p>

<p>What do you think?</p>

 
Answer: <p>This is a very good start, but there is a slight problem with your argument: as you change $y$, your $U$ changes as well (since $U$ is constructed in terms of $y$); you should really call it $U(y)$. </p>

<p>Your construction gives you an open neighborhood $W(y)$ of $y$ for each $y$; $W(y)$ is disjoint from $U(y)$. But for all you know, $W(y)$ may fail to be disjoint from $U(y&#39;)$ with $y&#39;\neq y$.</p>

<p>So you really still have a bit more to go before you are done. </p>

==============================
===============================
Question: <p>I'm looking for good examples where double induction is necessary. What I mean by double induction is induction on $\omega^2$. These are intended as examples in an "Automatas and Formal Languages" course.</p>

<p>One standard example is the following: in order to cut an $n\times m$ chocolate bar into its constituents, we need $nm-1$ cuts. However, there is a much better proof without using induction.</p>

<p>Another example: the upper bound $\binom{a+b}{a}$ on Ramsey numbers. The problem with this example is that it can be recast as induction on $a+b$, while I want something which is inherently inducting on $\omega^2$.</p>

<p>Lukewarm example: Ackermann's function, which seems to be pulled out of the hat (unless we know about the primitive recursive hierarchy).</p>

<p>Better examples: the proof of other theorems in Ramsey theory (e.g. Van der Waerden or Hales-Jewett). While these can possibly be recast as induction on $\omega$, it's less obvious, and so intuitively we really think of these proofs as double induction.</p>

<p>Another example: cut elimination in the sequent calculus. In this case induction on $\omega^2$ might actually be necessary (although I'm not sure about that).</p>

<p>The problem with my positive examples is that they are all quite technical and complicated. So I'm looking for a simple, non-contrived example where induction on $\omega^2$ cannot be easily replaced with regular induction (or with an altogether simpler argument). Any suggestions?</p>

 
Answer: <p>A nice example arises by relativizing <a href="https://math.stackexchange.com/questions/3532/how-to-explain-real-big-numbers/3551#3551">Goodstein's Theorem</a> from $\rm\ \epsilon_0 = \omega^{\omega^{\omega^{\cdot^{\cdot^{\cdot}}}}}$ down to $\rm\ \omega^2\:.\ $</p>

<p><strong>$\rm\ \omega^2\ $ Goodstein's Theorem</strong> $\  $  Given naturals $\rm\ a,\:b,\:c\ $ and an arbitrary increasing "base-bumping" function $\rm\ g(n)\ $ on $\:\mathbb N\:$ the following iteration eventually reaches $0\ $ (i.e. $\rm\ a = c = 0\:$).</p>

<p>$\rm\quad\quad\quad\quad\ \ a\ b + c \ \ \to\quad\quad\ \ a\ \ \ \ \ g(b)\ +\ \ \ c\ \ -\ 1\quad if\quad\ c &gt; 0 $</p>

<p>$\rm\quad\quad\quad\quad\ \ \phantom{a\ b + c}\ \ \to\ \   (a-1)\ g(b)\  +\  g(b)-1\quad if\quad \ c = 0 $</p>

<p>Note: $\ $  The above iteration is really on triples $\rm\ (a,b,c)\ $ but  I chose the above notation in order to emphasize the relationship with radix notation and with Cantor Normal form for ordinals &lt; $\epsilon_0$. $\ \ $ For more on Goodstein's Theorem see the link in Andres's post or see my 1995\12\11 <a href="http://groups.google.com/groups?selm=WGD.95Dec11023450%40martigny.ai.mit.edu" rel="nofollow noreferrer">sci.math post.</a></p>

==============================
===============================
Question: <p>Let us start by clarifying this a bit.  I am aware of <a href="https://math.stackexchange.com/questions/732/proof-that-the-irrational-numbers-are-uncountable">some proofs</a> <a href="http://en.wikipedia.org/wiki/Cantor_diagonalization" rel="nofollow noreferrer">that irrationals/reals are uncountable</a>.  My issue comes by way of some properties of the reals. These issues can be summed up by the combination of the following questions:</p>

<ul>
<li>Is it true that between any two rationals one may find at least one irrational?</li>
<li>Is it true that between any two irrationals one may find at least one rational?</li>
<li>Why are the reals uncountable?</li>
</ul>

<p>I've been talking with a friend about why the answer of these three questions can be the case when they somewhat seem to contradict each other.  I seek clarification on the subject.  Herein lies a summary of the discussion:</p>

<p><strong>Person A:</strong>  <em>By  way of <a href="http://en.wikipedia.org/wiki/Cantor_diagonalization" rel="nofollow noreferrer">Cantor Diagonalization</a> it can be shown that the reals are uncountable.</em></p>

<p><strong>Person B:</strong>  <em>But is it not also the case that one may find at least one rational between any two irrationals and vice versa?</em></p>

<p><strong>Person A:</strong>  <em>That seems logical, I can't pose a counterexample... but why does that matter?</em></p>

<p><strong>Person B:</strong>  <em>Wouldn't that imply that for every irrational there is a corresponding rational?  And from this the Reals would be equivalent to 2 elements for every element of the rationals?</em></p>

<p><strong>Person A:</strong>  <em>That implies that the Reals are countable, but we have already shown that they weren't... where is the hole in our reasoning?</em></p>

<p><strong>And so I pose it to you... where is the hole in our reasoning?</strong></p>

 
Answer: <p>The problem is here: "Wouldn't that imply that for every irrational there is a corresponding rational? And from this the Reals would be equivalent to 2 elements for every element of the rationals?" The problem is that for <em>many</em> different pairs of irrationals you would be choosing the same rational in between. If you want to avoid this problem, you'd have to describe a procedure by means of which:</p>

<ol>
<li><p>You uniquely specify for each pair of irrationals $a&lt;b$ a rational $c$ in between.
(This is easy but non-trivial since there are infinitely many candidates for $c$.)</p></li>
<li><p>Different pairs get assigned different rationals.</p></li>
</ol>

<p>Of course, task 2 is impossible, so there is no correspondence between irrationals and rationals.</p>

==============================
===============================
Question: <p>why is $\sum\limits_{k=1}^{n} k^m$ a polynomial with degree $m+1$  in $n$?</p>

<p>I know this is well-known. But how to prove it rigorously? Even mathematical induction does not seem so straight-forward.</p>

<p>Thanks.</p>

 
Answer: <p>Let $V$ be the space of all polynomials $f : \mathbb{N}_{\ge 0} \to F$ (where $F$ is a field of characteristic zero).  Define the <em>forward difference operator</em> $\Delta f(n) = f(n+1) - f(n)$.  It is not hard to see that the forward difference of a polynomial of degree $d$ is a polynomial of degree $d-1$, hence defines a linear operator $V_d \to V_{d-1}$ where $V_d$ is the space of polynomials of degree at most $d$.  Note that $\dim V_d = d+1$.  </p>

<p>We want to think of $\Delta$ as a discrete analogue of the derivative, so it is natural to define the corresponding discrete analogue of the integral $(\int f)(n) = \sum_{k=0}^{n-1} f(k)$.  But of course we need to prove that this actually sends polynomials to polynomials.  Since $(\int \Delta f)(n) = f(n) - f(0)$ (the "fundamental theorem of discrete calculus"), it suffices to show that the forward difference is surjective as a linear operator $V_d \to V_{d-1}$.</p>

<p>But by the "fundamental theorem," the image of the integral is precisely the subspace of $V_d$ of polynomials such that $f(0) = 0$, so the forward difference and integral define an isomorphism between $V_{d-1}$ and this subspace.  </p>

<p>More explicitly, you can observe that $\Delta$ is upper triangular in the standard basis, work by induction, or use the <strong>Newton basis</strong> $1, n, {n \choose 2}, {n \choose 3}, ...$ for the space of polynomials.  In this basis we have $\Delta {n \choose k} = {n \choose k-1}$, and now the result is <em>really</em> obvious.</p>

<p>The method of finite differences provides a fairly clean way to derive a formula for $\sum n^m$ for fixed $m$.  In fact, for any polynomial $f(n)$ we have the "discrete Taylor formula"</p>

<p>$$f(n) = \sum_{k \ge 0} \Delta^k f(0) {n \choose k}$$</p>

<p>and it's easy to compute the numbers $\Delta^k f(0)$ using a finite difference table and then to replace ${n \choose k}$ by ${n \choose k+1}$.  I wrote a blog post that explains this, but it's getting harder to find; I also explained it in my <a href="https://math.berkeley.edu/~qchu/TopicsInGF.pdf" rel="nofollow">notes on generating functions</a>.</p>

==============================
===============================
Question: <p>I am trying to prove a result, for which I have got one part, but I am not able to get the converse part.</p>

<p><strong>Theorem.</strong> Let $R$ be a commutative ring with $1$. Then $f(X)=a_{0}+a_{1}X+a_{2}X^{2} + \cdots + a_{n}X^{n}$ is a unit in $R[X]$ if and only if $a_{0}$ is a unit in $R$ and $a_{1},a_{2},\dots,a_{n}$ are all <em>nilpotent</em> in $R$.</p>

<p><strong>Proof.</strong> Suppose $f(X)=a_{0}+a_{1}X+\cdots +a_{n}X^{n}$ is such that $a_{0}$ is a unit in $R$ and $a_{1},a_{2}, \dots,a_{r}$ are all nilpotent in $R$. Since $R$ is commutative, we get that $a_{1}X,a_{2}X^{2},\cdots,a_{n}X^{n}$ are all nilpotent and hence also their sum is nilpotent. Let $z = \sum a_{i}X^{i}$ then $a_{0}^{-1}z$ is nilpotent and so $1+a_{0}^{-1}z$ is a unit. Thus $f(X)=a_{0}+z=a_{0} \cdot (1+a_{0}^{-1}z)$ is a unit since product of two units in $R[X]$ is a unit. </p>

<p>I have not been able to get the converse part and would like to see the proof for the converse part.</p>

 
Answer: <p>If $R$ is a domain then easily $f(X)$ a unit implies that $a_i = 0$ for $i&gt;0$. Now $R\to R/\mathfrak p$, for $\mathfrak p$ prime, reduces to the domain case, yielding that the $a_i$, $i&gt;0$ are in every prime ideal. But the intersection of all prime ideals is the nilradical, the set of all nilpotent elements - as you proved <a href="https://math.stackexchange.com/questions/18203/x-not-nilpotent-implies-there-is-a-prime-ideal-not-containing-x">a few days ago.</a></p>

<p>See also <a href="https://math.stackexchange.com/questions/120/is-1-a-prime-number/5735#5735">my post here</a> on reduction to domains by factoring out prime ideals.</p>

==============================
===============================
Question: <p>I've never really understood why math induction is supposed to work.</p>

<p>You have these 3 steps:</p>

<ol>
<li><p>Prove true for base case (n=0 or 1 or whatever)</p></li>
<li><p>Assume true for n=k.  Call this the <em>induction hypothesis</em>.</p></li>
<li><p>Prove true for n=k+1, <strong>somewhere using the induction hypothesis</strong> in your proof.</p></li>
</ol>

<p>In my experience the proof is usually algebraic, and you just manipulate the problem until you get the induction hypothesis to appear.  If you can do that and it works out, then you say the proof holds.</p>

<p>Here's one I just worked out,</p>

<p>Show $\displaystyle\lim_{x\to\infty} \frac{(\ln x)^n}{x} = 0$</p>

<p>So you go:</p>

<ol>
<li><p>Use L'Hospital's rule.
$\displaystyle\lim_{x\to\infty} \frac{\ln x}{x} = 0$.
Since that's
$\displaystyle\lim_{x\to\infty} \frac{1}{x} = 0$.</p></li>
<li><p><strong>Assume true for $n=k$</strong>.
$\displaystyle\lim_{x\to\infty} \frac{(\ln x)^k}{x} = 0$.</p></li>
<li><p>Prove true for $n=k+1$.  You get
$\displaystyle\lim_{x\to\infty} \frac{(\ln x)^{k+1}}{x} = 0.$</p></li>
</ol>

<p>Use L'Hospital again:
$\displaystyle\lim_{x\to\infty} \frac{(k+1)(\ln x)^{k}}{x} = 0$.</p>

<p>Then you see the induction hypothesis appear, and you can say this is equal to $0$.</p>

<p>What I'm not comfortable with is this idea that you can just <em>assume</em> something to be true (n=k), then based on that assumption, form a proof for $n=k+1$ case.</p>

<p>I don't see how you can use something you've assumed to be true to prove something else to be true.</p>

 
Answer: <p>The inductive step is a proof of an implication: you are proving that <strong>if</strong> the property you want holds for $k$, <strong>then</strong> it holds for $k+1$.</p>

<p>It is a result of formal logic that if you can prove $P\rightarrow Q$ (that $P$ implies $Q$), then from $P$ you can prove $Q$; and <em>conversely</em>, that if from assuming that $P$ is true you can prove $Q$, then you can in fact prove $P\rightarrow Q$. </p>

<p>We do this pretty much every time we prove something. For example, suppose you want to prove that if $n$ is a natural number, then $n^2$ is a natural number. How do we start? "Let $n$ be a natural number." Wait! Why are you allowed to just <em>assume</em> that you already have a natural number? Shouldn't you have to start by <em>proving</em> it's a natural number? The answer is <strong>no</strong>, we don't have to, because we are not trying to prove an absolute, we are trying to prove a <em>conditional</em> statement: that <strong>if</strong> $n$ is a natural number, <strong>then</strong> something happens. So we may begin by assuming we are already in the case where the antecedent is true. (Intuitively, this is because <em>if</em> the antecedent is false, then the implication is necessarily true and there is nothing to be done; formally, it is because the Deduction Theorem, which is what I described above, tells you that if you manage to find a formal proof that ends with "$n^2$ is a natural number" by assuming that "$n$ is a natural number" is true, then you can use that proof to produce a formal proof that establishes the implication "if $n$ is a natural number then $n^2$ is a natural number"; we don't have to go through the exercise of actually producing the latter proof, we know it's "out there").</p>

<p>We do that in Calculus: "if $\lim\limits_{x\to x_0}f(x) = a$ and $\lim\limits_{x\to x_0}g(x) = b$, then $\lim\limits_{x\to x_0}(f(x)+g(x)) = a+b$." How do we prove this? We begin by <em>assuming</em> that the limit of $f(x)$ as $x\to x_0$ <em>is</em> $a$, and that the limit of $g(x)$ as $x\to x_0$ <em>is</em> $b$. We assume the premise/antecedent, and procede to try to prove the consequent.</p>

<p>What this means in the case of induction is that, since the "Inductive Step" is actually a statement that says that an implication holds:
$$\mbox{"It" holds for $k$}\rightarrow \mbox{"it" holds for $k+1$},$$
then in order to prove this implication we can begin by assuming that the <em>antecedent</em> is already true, and then procede to prove the consequent. Assuming that the antecedent is true is precisely the "Induction Hypothesis". </p>

<p>When you are done with the inductive step, you have in fact not proven that it holds for any <em>particular</em> number, you have <em>only</em> shown that <strong>if</strong> it holds for a particular number $k$, <strong>then</strong> it must hold for the next number $k+1$. It is a <em>conditional</em> statement, not an absolute one.</p>

<p>It is only when you combine that conditional statement with the base, which <em>is</em> an absolute statement that says "it" holds for a specific number, that you can conclude that the original statement holds for all natural numbers (greater than or equal to the base). </p>

<p>Since you mention dominoes in your title, I assume you are familiar with the standard metaphor of induction like dominoes that are standing all in a row falling. The inductive step is like arguing that all the dominos will fall if you topple the first one (without actually toppling it): first, you argue that each domino is sufficiently close to the <em>next</em> domino so that <strong>if</strong> one falls, <strong>then</strong> the next one falls. You are not tumbling every domino. And when you argue this, you argue along the lines of "suppose this one falls; since it's length is ...", that is, you <em>assume</em> it falls in order to argue the next one will <em>then</em> fall. This is the same with the inductive step.</p>

<p>In a sense you are right that if feels like "cheating" to assume what you want; but the point is that you aren't really assuming what you want. Again, the inductive step does not in fact establish that the result holds for <em>any</em> number, it only establishes a <em>conditional</em> statement. <strong>If</strong> the result happens to hold for some $k$, <strong>then</strong> it would <em>necessarily</em> have to also hold for $k+1$. But we are completely silent on whether it <em>actually</em> holds for $k$ or not. We are not saying anything about that at the inductive-step stage. </p>

<p><hr/>
<em>Added:</em> Here's an example to emphasize that the "inductive step" does not make any absolute statement, but only a conditional statement: Suppose you want to prove that for all natural numbers $n$, $n+1 = n$. </p>

<p><strong>Inductive step.</strong> <em>Induction Hypothesis:</em> The statement holds for $k$; that is, I'm assuming that $k+1 = k$.</p>

<p><em>To be proven:</em> The statement holds for $k+1$. Indeed: notice that since $k+1= k$, then adding one to both sides of the equation we have $(k+1)+1 = k+1$; this proves the statement holds for $k+1$. <strong>QED</strong></p>

<p>This is a perfectly valid proof! It says that <strong>if</strong> $k+1=k$, <strong>then</strong> $(k+1)+1=k+1$.  <em>This is true!</em> Of course, the antecedent is never true, but the <em>implication</em> is. The reason this is not a full proof by induction of a false statement is that there is no "base"; the inductive step only proves the conditional, nothing more. </p>

<hr/>

<p>By the way: Yes, most proofs by induction that one encounters early on involve algebraic manipulations, but not all proofs by induction are of that kind. Consider the following simplified game of Nim: there are a certain number of matchsticks, and players alternate taking $1$, $2$, or $3$ matchsticks every turn. The person who takes the last matchstick wins. </p>

<p><strong>Proposition.</strong> In the simplified game above, the first player has a winning strategy if the number of matchsticks is not divisible by $4$, and the second player has a winning strategy if the number of matchsticks is divisible by 4.</p>

<p>The proof is by (strong) induction, and it involves no algebraic manipulations whatsoever.</p>

==============================
===============================
Question: <p>I'm well aware of the standard proof based on cardinality arithmetic to show that these two sets have the same cardinality and the question of defining a bijection between the two sets came up. I worked on it a little while and was wondering if there were any gaps, or a simpler method of coming up with such a bijection. </p>

<p>The main idea I had was to take a family of sequences indexed by the real numbers. So that each one of these sequences corresponds to a unique real number. Then I can map each one of these sequences to another number, by applying the binary function from $\mathbb R$ to $\{0,1\}$ and mapping the infinite binary sequence to a real number, use one of the standard bijections.</p>

<p>First let $E$ be a family of sequences indexed by the real numbers. Such that $E_{xi}\neq E_{yj}$ for all $x,y \in \mathbb R$ and $i,j \in \mathbb N$ also with the property that</p>

<p>$\mathbb R= \bigcup_{x \in \mathbb R, i \in \mathbb N} E_{xi}$. </p>

<p>What sort of theorems would I need to prove such a family existed, is it enough to note that the reals can be represented as a uncountable union of countably infinite sets?</p>

<p>Also let $P: 2^{\mathbb N} \rightarrow \mathbb R$ be you favorite bijection.</p>

<p>Now consider an element of $2^{\mathbb R}$ as a function $f: \mathbb R \rightarrow \{0,1\}$ and $g \in \mathbb{ R^R}$ in a similar manner. Then our bijection between the two sets will be the function $\Phi$ which maps $f$ to a function $g$, such that $g(x)=P(F(E_x))$ where $F$ applies $f$ to each element of the sequence $E_x$. </p>

<p>I'm fairly sure this is an onto and one-to-one function. The one-to-one property should follow because the sequences are disjoint, cover $\mathbb R$ and $P$ is a bijection. The onto argument is a little hazier, but it should be possible to recreate the function $f$, by first inverting each element with $P$ and then defining $f$ based on these sequences. </p>

 
Answer: <p>Once you have the bijection
$P:2^\mathbb{N}\cong\mathbb{R}$, you can build your desired
bijection as follows.</p>

<p>First, note that $\mathbb{N}\times 2^\mathbb{N}\cong
2^\mathbb{N}$, essentially  by the bijection that associates $(n,A)$ with
$\{n\}\cup (n+1+A)$, except that this will miss the empty set on the right, but we can fix this by composing with a map witnessing $2^\mathbb{N}-\{\varnothing\}\cong 2^\mathbb{N}$, such as shifting on a fixed countable subset.</p>

<p>Now simply observe that
$$\mathbb{R}^\mathbb{R}\cong
(2^\mathbb{N})^{(2^\mathbb{N})}\cong 2^{(\mathbb{N}\times
2^\mathbb{N})} \cong 2^{(2^\mathbb{N})} \cong 2^\mathbb{R},
$$</p>

<p>which provides the desired bijection. The first map is conjugation by $P$, simply
composing with $P^{-1}$ and $P$ before and after; the second map is an easy exercise in parenthesis rearranging; the
third map applies the observation above; and the final map
applies $P$.</p>

==============================
===============================
Question: <p>Part of the reason I think algebraic topology has acquired something of a fearsome reputation is that the terrible properties of the topological category (e.g. the existence of space-filling curves) force us to work very hard to prove the main theorems setting up all of the big machinery to get the payoff we want (e.g. invariance of domain, fixed point theorems). But why should I care about these arbitrary and terrible spaces and functions in the first place when, as far as I can tell, any manifold which occurs in applications is at least piecewise-differentiable and any morphism which occurs in applications is at least homotopic to a piecewise-differentiable one? </p>

<p>In other words, do topological manifolds really naturally occur in the rest of mathematics (without some extra structure)?</p>

 
Answer: <p>As far as I know, historically smooth manifolds were the first manifolds studied by people like Poincare, Riemann, up to Whitney.   There were a few major events that caused people to take things like topological and PL manifolds seriously, but originally people were not motivated to study these kinds of objects.  Here are some of the big events/ideas that come to mind:</p>

<p>1) Poincare's original proof of Poincare duality was a proof for triangulated manifolds.  That smooth manifolds had triangulations (and whether or not they were essentially unique) was a problem that took some time to solve.  So the study of triangulations and PL manifolds picked up. </p>

<p>2) Smale's proof of the h-cobordism theorem, although written up for the smooth category when you look at it carefully there's a lot of "smoothing the corners" going on.  You can think carefully about it and determine all the smoothing of the corners does not kill the proof but I know many strong mathematicians that were hesitant to accept Smale's proof, insisting that it was only a PL-category proof.  FYI, the smoothing of the corners issue has been settled, there's a very nice write-up in Kosinski's manifolds text.  But this was another issue that kept people thinking about the PL category. </p>

<p>3) If anything, topological manifolds play a role simply for comparison sake -- after all the forgetful functor from the smooth to the topological category is an interesting functor.  Perhaps for different people in different ways.  I've yet to be interested by a topological manifold that admits no smooth structure but I do find multiple smooth structures on the same topological manifold interesting.  Is this purely psychological?  </p>

<p>4) Topological and PL-manifold theory is where some "nasty" constructions work, like the Alexander trick.  There are different versions of it, one being that the restriction map $Aut(D^n) \to Aut(S^{n-1})$ admits a section in the topological or PL categories.  It does not in the smooth category.  If anything, I find these kinds of facts informative on the smooth category.  The smooth category is interesting largely because of facts like these.  There's a similar Alexander trick for knots, for example, the space of topological or PL embeddings $\mathbb R^j \to \mathbb R^n$ which restrict to the standard inclusion $x \longmapsto (x,0)$ outside of the unit ball, this space is contractible, by "pulling the knot tight".  But in the smooth category, this space isn't contractible. </p>

<p>I think one of the major events in the development of this subject is simply pragmatic.  To get smooth manifold theory off the ground you need Sard's theorem and transversality.  This requires analysis to the level of measure theory, and a solid multi-variable calculus background, which in many undergraduate educations is skimped on (especially since it comes early, and many curriculums are too service-based to teach calculus "well").  PL manifolds are inherently more combinatorial and so the learning curve for people with weak analysis backgrounds is easier to deal with.  I think also some people really appreciate the combinatorial nature of the subject.  </p>

<p>Anyhow, those are some thoughts off the top of my head. </p>

<p>Getting to your conversation with Mariano:</p>

<p>PL manifold theory by-and-large isn't terribly different from smooth manifold theory.  So I think once you learn one, adapting to the other isn't so hard. But topological manifolds are really quite different.  This may be my ignorance speaking to some extent, but I'm still working my way through Kirby-Siebenmann.  I'm told various people are working on re-writing the main theorems of that text, to make it easier reading for people that are not named Larry Siebenmann.  But we're probably still several years from that.  I suspect in the next 10 years there should be several different accounts of most of that material.  But I'm still some ways from understanding smoothing theory.</p>

<p>Manifolds when they come up "in nature" like in physics or engineering applications tend to always be smooth, and usually with plenty of extra structure.  Sometimes the objects that come up aren't manifolds, but algebraic varieties, or even more degenerate (but smooth) stratified spaces.   </p>

==============================
===============================
Question: <p>Claim:If $(x_\alpha)_{\alpha\in A}$ is a collection of real numbers $x_\alpha\in [0,\infty]$
such that $\sum_{\alpha\in A}x_\alpha&lt;\infty$, then $x_\alpha=0$ for all but at most countably many $\alpha\in A$ (A need not be countable).</p>

<p>Proof: Let $\sum_{\alpha\in A}x_\alpha=M&lt;\infty$. Consider $S_n=\{\alpha\in A \mid x_\alpha&gt;1/n\}$.</p>

<p>Then $M\geq\sum_{\alpha\in S_n}x_\alpha&gt;\sum_{\alpha\in S_n}1/n=\frac{N}{n}$, where $N\in\mathbb{N}\cup\{\infty\}$ is the number of elements in $S_n$.</p>

<p>Thus $S_n$ has at most $Mn$ elements. </p>

<p>Hence $\{\alpha\in A \mid x_\alpha&gt;0\}=\bigcup_{n\in\mathbb{N}}S_n$ is countable as the countable union of finite sets. $\square$</p>

<p>First, is my proof correct? Second, are there more concise/elegant proofs?</p>

 
Answer: <p>Just so the question gets an answer: <strong>yes</strong>, your proof is correct and is one of several phrasings of the shortest proof that I know.  </p>

==============================
===============================
Question: <p>The more general version of this theorem in Munkres' 'Topology' (p. 290 - 2nd edition) states that </p>

<p>Given a locally compact Hausdorff space $X$ and a metric space $(Y,d)$; a family $\mathcal F$ of continuous functions has compact closure in $\mathcal C (X,Y)$ (topology of compact convergence) if and only if it is equicontinuous under $d$ and the sets</p>

<p>$$ \mathcal F _a = \{f(a) | f \in \mathcal F\} \qquad a \in X$$</p>

<p>have compact closure in $Y$.</p>

<p>Now I do not see why the Hausdorff condition on $X$ should be necessary? Why include it then? Am I maybe even missing something here (and there are counterexamples)?</p>

<p>btw if you are looking up the proof: Hausdorffness is needed for the evaluation map $e: X \times \mathcal C(X,Y) \to Y, \, e(x,f) = f(x)$ to be continuous. But the only thing really used in the proof is the continuity of $e_a: \mathcal C(X,Y) \to Y, \, e_a(f) = f(a)$ for fixed $a \in X$.</p>

<p>Cheers, S.L.</p>

 
Answer: <p>I think this question has been already been answered through the helpful comments. So thanks to Henno Brandsma and t.b.! This is just to finally tick it off.</p>

<p>My conclusion: It seems that $X$ being Hausdorff is rather a matter of convenience (maybe to avoid issues with the definition of local compactness for non-Hausdorff spaces, as pointed out in the comments), than a necessary condition.</p>

<p>Also this version of the theorem seems quite general enough for most uses.</p>

==============================
===============================
Question: <p>I'm just working through Conway's book on complex analysis and I stumbled across this lovely exercise:</p>

<blockquote>
  <p>Use Cauchy's Integral Formula to prove the Cayley-Hamilton Theorem: If $A$ is an $n \times n$ matrix over $\mathbb C$ and $f(z)  = \det(z-A)$ is the characteristic polynomial of $A$ then $f(A) = 0$. (This exercise was taken from a paper by C. A. McCarthy, <em>Amer. Math. Monthly</em>, <strong>82</strong> (1975), 390-391)</p>
</blockquote>

<p>Unfortunately, I was not able to find said paper. I'm completely lost with this exercise. I can't even start to imagine how one could possibly make use of Cauchy here...</p>

<p>Thanks for any hints.</p>

<p>Regards, S.L.</p>

 
Answer: <p>The idea is to use <a href="http://en.wikipedia.org/wiki/Holomorphic_functional_calculus" rel="nofollow noreferrer">holomorphic functional calculus</a> and to show that for a matrix $A$ and a polynomial $p(z)$ we have for $r \gt \|A\|$ 
\begin{equation}\tag{$\ast$}
p(A) = \frac{1}{2\pi i} \int_{|z| = r} p(z) \cdot (z - A)^{-1}\ \,dz
\end{equation}
in complete analogy with the Cauchy formula for complex numbers. The integral of a matrix of holomorphic functions is defined by integrating each entry separately.</p>

<p>By <a href="http://en.wikipedia.org/wiki/Cramer%27s_rule" rel="nofollow noreferrer">Cramer's rule</a>, the $(k,l)$-entry of $(z-A)^{-1}$ is $\displaystyle ((z-A)^{-1})_{k,l} = \frac{1}{\det(z-A)} c_{k,l}(z)$ where $c_{k,l}(z)$ is some polynomial in $z$. Let $p(z) = \det(z-A)$ be the characteristic polynomial of $A$. Conclude using&nbsp;$(\ast)$ by applying <a href="http://en.wikipedia.org/wiki/Cauchy_integral_theorem" rel="nofollow noreferrer">Cauchy's integral theorem</a> to $c_{k,l}$.</p>

<hr>

<p>To see that the identity&nbsp;$(\ast)$ holds, proceed as follows (this is a slight variant of McCarthy's argument):</p>

<ul>
<li>The <a href="http://en.wikipedia.org/wiki/Matrix_norm" rel="nofollow noreferrer">usual matrix norm</a> induced by the Euclidean norm on $\mathbb{C}^{n}$ satisfies $\|A^{n}\| \leq \|A\|^{n}$.</li>
<li>Use this to show that $(z - A)^{-1} = \sum_{n = 0}^{\infty} \frac{A^{n}}{z^{n+1}}$, where the right hand side converges uniformly on $\{|z| \gt \|A\| + \varepsilon\}$.</li>
<li>It follows that we can interchange integration and summation. Conclude that $$ A^{k} = \int_{|z| = r} z^{k} (z - A)^{-1}\,dz$$ and $(\ast)$ follows by linearity.</li>
</ul>

<hr>

<p>Here's a <a href="http://dx.doi.org/10.2307/2318415" rel="nofollow noreferrer">link to McCarthy's article</a> (you need a university subscription to download it, but the first page is almost the entire article).</p>

==============================
===============================
Question: <p>Better yet, what I'm asking is how do you actually <em>write</em> your mathematics?  </p>

<p>I think I need to give brief background: Through most of my childhood, I'd considered myself pretty good at math, up through the high school level. I easily followed mathematical concepts introduced in my classes and even did a few competitions; I definitely wouldn't say I was a star of the caliber one meets when one ventures out into the bigger ponds, but I thought I was decent and convinced myself I would major in math when I entered college.</p>

<p>That changed after a couple of years when I hit my first Real Analysis class that used Rudin's book; that was the first class, I think, I took that really required more than "expand-a-definition" type proofs and my struggle to find intuition and understanding there impacted my mathematical self-confidence.   I eventually switched majors, with a bit of regret.</p>

<p>One thing that got me, I think, was the veritable explosion of superscripts and subscripts that one encounters for the first time in Real Analysis.  I'd often find myself struggling to set up the machinery of what I was trying to prove, lost in the notation.  <strong>How do good mathematicians format their work on paper so as not to get lost in the $i$s, $j$s, and $k$s and keep track of what they're investigating?</strong>  I remember dealing with subsequences of sequences to show that limits did or did not exist got especially hairy in this way...writing things like $s_{n_{k_{\epsilon}}}$ and remembering what my goal at each "level" was difficult.  I'd be interested in knowing if aspiring mathematicians and/or professional mathematicians scribble marginalia or have a system to overcome such problems.</p>

<p>Another thing that got me were what I personally called "consider..." statements.  Many times, on this site, the most talented commenters will say "Consider $f(n)$" or "Consider transformation $T:$ $U \rightarrow V$" that in the first case gives a summation that wonderfully telescopes/has an obvious bound, or in the second case transforms the problem into a trivial application of the rank-nullity theorem, or something like that.  Mathematics is a subject replete with geniuses , I understand that, but how do mere mortals investigate such functions and "massage" them into doing what they want?  <strong>When good mathematicians get intuitionistic ideas, what (explicit) steps do they take to formalize them, especially when it is likely that first idea is murky or wrong</strong>? (Aside: I've been given "use numerical examples" as advice before, but sometimes I think to myself, "I've been dealing with $\mathbb{Z}$ since I was 6 years old, and not so much with Dedekind's definition of the real numbers...") </p>

<p>There's lots more I could ask, but I want to keep this question tractable, so I guess I might summarize by asking: <strong>How do you [professional and aspiring mathematicians] organize your math "notebook", and what perhaps idiosyncratic methods do you employ to be original and clever within it?</strong> I know there will be no strict formulas anyone can give; mathematicians are scientists of the abstract; I understand that the subject is acclaimed partly because it's so intellectually and individually demanding.   But I think even acclaimed scientists draw on Springer's Protocols and <em>Nature Methods</em>...There seems to me a bit of a jump between the dryly algorithmic way one is taught to do math in high school and the more abstruse methods at the undergraduate level.  I'd be interested if anyone here could help me bridge that gap, if only for my personal fulfillment.</p>

<p>(Apologies in advance if the question is ill-posed or too subjective in its current form to meet the requirements of the FAQ; I'd certainly appreciate any suggestions for its modification if need be.)</p>

 
Answer: <p>In many ways, I am atypical in the way that I approach a problem, but it works for me. Specifically, I try to understand an example in as much detail as I possibly can. If the example, is too complicated, then I make a simpler example. As much of the intricate detail that I can bring to bear on the example is brought. </p>

<p>For example, instead of trying to understand Lie groups and Lie algebras in general, start with the circle and the line that is tangent at the point (1,0). What is the exponential map? Oh, OK. Now how about $SU(2)$ and $su(2)$? Can you understand that the Lie group is the $3$-dimensional sphere? Can you understand the coordinates? Can you understand the equators? How do $i,j$ and $k$ really work?
What is the difference between the multiplication rule $i\times i =0$ and $i^2=-1$? </p>

<p>I spend time pondering. And often my notebooks will contain tangential problems or specific computations. I will keep doing the computation until I get it right! If necessary, I will write a program to complete the computation. When I understand the example completely, it is usually easy to abstract. </p>

<p>Then I follow up, usually writing in a notebook or several notebooks before I begin writing on the computer. I have an advantage in that I have long-distance collaborators, so it becomes necessary to explain the idea to the collaborator(s). That is the first writing stage: write for someone who knows your short-hand and your metaphors. the second stage is to write for someone who does not. Then I write with a set of colleagues in mind, but I assume the colleagues do not remember anything from the previous work. I also try to explicate the notation writing for example "the function $f$, the knot $k$, or the tubular neighborhood $N$. </p>

<p>A complex analytical colleague only uses $z$ for a complex number, $x$ for a real variable, and $n$ for an integer. These variable choices are culturally determined, and so one keeps with the culture of the discipline unless there is good reason to deviate. As a final example of this, the variable $A$ in the bracket polynomial is known to everyone in the field. The variables $q$, $t$, $X$ etc. are less known and involve different normalizations. So it is the burden of the author to relate these to the more well known choices.</p>

==============================
===============================
Question: <p>In the <strong>few</strong> linear algebra texts I have read, the determinant is introduced in the following manner;</p>

<p>"Here is a formula for what we call $detA$. Here are some other formulas. And finally, here are some nice properties of the determinant."</p>

<p>For example, in very elementary textbooks it is introduced by giving the co-factor expansion formula.  In Axler's "Linear Algebra Done Right" it is defined, for $T\in L(V)$ to be $(-1)^{dimV}$ times the constant term in the characteristic polynomial of $T$.</p>

<p>However I find this somewhat unsatisfactory. Its like the real definition of the determinant is hidden. Ideally, wouldn't the determinant be defined in the following manner:</p>

<p>"Given a matrix $A$, let $detA$ be an element of $\mathbb{F}$ such that x, y and z."</p>

<p>Then one would proceed to prove that this element is unique, and derive the familiar formulae.</p>

<p>So my question is: Does a definition of the latter type exist, is there some minimal set of properties sufficient to define what a determinant is? If not, can you explain why?</p>

 
Answer: <p>Let $V$ be a vector space of dimension $n$. For any $p$, the construction of the <a href="http://en.wikipedia.org/wiki/Exterior_algebra">exterior power</a> $\Lambda^p(V)$ is <a href="http://en.wikipedia.org/wiki/Functor">functorial</a> in $V$: it is the universal object for alternating multilinear functions out of $V^p$, that is, functions</p>

<p>$$\phi : V^p \to W$$</p>

<p>where $W$ is any other vector space satisfying $\phi(v_1, ... v_i + v, ... v_p) = \phi(v_1, ... v_i, ... v_p) + \phi(v_1, ... v_{i-1}, v, v_{i+1}, ... v_p)$ and $\phi(v_1, ... v_i, ... v_j, ... v_p) = - \phi(v_1, ... v_j, ... v_i, ... v_p)$. What this means is that there is a map $\psi : V^p \to \Lambda^p(V)$ (the exterior product) which is alternating and multilinear which is universal with respect to this property; that is, given any other map $\phi$ as above with the same properties, $\phi$ factors uniquely as $\phi = f \circ \psi$ where $f : \Lambda^p(V) \to W$ is linear.</p>

<p>Intuitively, the universal map $\psi : V^p \to \Lambda^p(V)$ is the universal way to measure the oriented $p$-dimensional volumes of <a href="http://en.wikipedia.org/wiki/Parallelepiped#Parallelotope">paralleletopes</a> defined by $p$-tuples of vectors in $V$, the point being that for geometric reasons oriented $p$-dimensional volume is alternating and multilinear. (It is instructive to work out how this works when $n = 2, 3$ by explicitly drawing some diagrams.)</p>

<p>Functoriality means the following: if $T : V \to W$ is any map between two vector spaces, then there is a natural map $\Lambda^p T : \Lambda^p V \to \Lambda^p W$ between their $p^{th}$ exterior powers satisfying certain natural conditions. This natural map comes in turn from the natural action $T(v_1, ... v_p) = (Tv_1, ... Tv_p)$ defining a map $T : V^p \to W^p$ which is compatible with the passing to the exterior powers.</p>

<p>The top exterior power $\Lambda^n(V)$ turns out to be one-dimensional. We then define the <strong>determinant</strong> $T : V \to V$ to be the scalar $\Lambda^n T : \Lambda^n(V) \to \Lambda^n(V)$ by which $T$ acts on the top exterior power. This is equivalent to the intuitive definition that $\det T$ is the constant by which $T$ multiplies oriented $n$-dimensional volumes. But it requires <em>no arbitrary choices</em>, and the standard properties of the determinant (for example that it is multiplicative, that it is equal to the product of the eigenvalues) are extremely easy to verify.</p>

<p>In this definition of the determinant, all the work that would normally go into showing that the determinant is the unique function with such-and-such properties goes into showing that $\Lambda^n(V)$ is one-dimensional. If $e_1, ... e_n$ is a basis, then $\Lambda^n(V)$ is in fact spanned by $e_1 \wedge e_2 \wedge ... \wedge e_n$. This is not so hard to prove; it is essentially an exercise in row reduction.</p>

<p>Note that this definition does not even require a definition of oriented $n$-dimensional volume as a number. Abstractly such a notion of volume is given by a choice of isomorphism $\Lambda^n(V) \to k$ where $k$ is the underlying field, but since $\Lambda^n(V)$ is one-dimensional its space of endomorphisms is already <em>canonically</em> isomorphic to $k$. </p>

<p>Note also that just as the determinant describes the action of $T$ on the top exterior power $\Lambda^n(V)$, the $p \times p$ minors of $T$ describe the action of $T$ on the $p^{th}$ exterior power $\Lambda^p(V)$. In particular, the $(n-1) \times (n-1)$ minors (which form the matrix of cofactors) describe the action of $T$ on the second-to-top exterior power $\Lambda^{n-1}(V)$. This exterior power has the same dimension as $V$, and with the right extra data can be identified with $V$, and this leads to a quick and natural proof of the explicit formula for the inverse of a matrix.</p>

<hr>

<p>As an advance warning, the determinant is sometimes defined as an alternating multilinear function on $n$-tuples of vectors $v_1, ... v_n$ satisfying certain properties; this properly defines a linear transformation $\Lambda^n(V) \to k$, not a determinant of a linear transformation $T : V \to V$. If we fix a basis $e_1, ... e_n$, then this function can be thought of as the determinant of the linear transformation sending $e_i$ to $v_i$, but this definition is basis-dependent. </p>

==============================
===============================
Question: <p>Let $ V $ be a normed vector space (over $\mathbb{R}$, say, for simplicity) with norm $ \lVert\cdot\rVert$.</p>

<p>It's not hard to show that if $\lVert \cdot \rVert = \sqrt{\langle \cdot, \cdot \rangle}$ for some (real) inner product $\langle \cdot, \cdot \rangle$, then the parallelogram equality
$$ 2\lVert u\rVert^2 + 2\lVert v\rVert^2 = \lVert u + v\rVert^2 + \lVert u - v\rVert^2 $$
holds for all pairs $u, v \in V$.</p>

<p>I'm having difficulty with the converse.  Assuming the parallelogram identity, I'm able to convince myself that the inner product should be
$$ \langle u, v \rangle = \frac{\lVert u\rVert^2 + \lVert v\rVert^2 - \lVert u - v\rVert^2}{2} = \frac{\lVert u + v\rVert^2 - \lVert u\rVert^2 - \lVert v\rVert^2}{2} = \frac{\lVert u + v\rVert^2 - \lVert u - v\rVert^2}{4} $$</p>

<p>I cannot seem to get that $\langle \lambda u,v \rangle = \lambda \langle u,v \rangle$ for $\lambda \in \mathbb{R}$.  How would one go about proving this?</p>

 
Answer: <p>It's not immediate or trivial, so I wouldn't feel too bad for having trouble. This is an exercise in Friedberg, Insel, and Spence's <strong>Linear Algebra</strong>, 4th Edition, which has an extensive 8 part "Hint." Here's an edited sequence of hints, following theirs:</p>

<ol>
<li><p>First, prove that the result holds for $\lambda = 2$, that is, $\langle 2u,v\rangle = 2\langle u,v\rangle$.</p></li>
<li><p>Then, prove that the inner product is additive in the first component: $\langle x+u,v\rangle = \langle x,v\rangle + \langle u,v\rangle$. </p></li>
<li><p>Then, prove the result holds for $\lambda$ any positive integer. Then for the reciprocal $\frac{1}{m}$ of any positive integer. Then for any rational number.</p></li>
<li><p>Then prove that $|\langle u,v\rangle|\leq ||u||\,||v||$</p></li>
<li><p>Then prove that for every $\lambda\in\mathbb{R}$, every $r\in\mathbb{Q}$, you have
$$|\lambda\langle u,v\rangle - \langle \lambda  u,v\rangle | = |(\lambda-r)\langle u,v\rangle - \langle(\lambda-r)u,v\rangle|\leq 2|\lambda-r|\,||u||\,||v||.$$</p></li>
<li><p>Finally, use that to prove homogeneity: for every $\lambda\in\mathbb{R}$, $\langle\lambda u,v\rangle = \lambda\langle u,v\rangle$. </p></li>
</ol>

==============================
===============================
Question: <p>Let $\pi: X \times Y \to X$ be the projection map where $Y$ is compact. Prove that $\pi$ is a closed map.</p>

<ul>
<li><p>First I would like to see a proof of this claim. </p></li>
<li><p>I want to know that here why compactness is necessary or do we have any other weaker condition other than compactness for the same result to hold.</p></li>
</ul>

 
Answer: <p>There is a standard example for why some hypothesis on $Y$ is necessary: let $X=Y=\mathbb R$, and consider the closed subset $F=\{(x,y)\in \mathbb R\times\mathbb R:xy=1\}\subset\mathbb R\times\mathbb R$. What is its projection to the first factor?</p>

<p>In fact, one can prove that a space $Y$ is compact iff for all spaces $X$ the projection $X\times Y\to X$ is closed. So while compactness is not necessary (I think...) for the closedness of the projection for one $X$, it is necessary if you want <em>all</em> such projections to be closed.</p>

<p>As for the proof you want in the first bullet point... this is a standard exercise in topology: what have you tried?</p>

==============================
===============================
Question: <p>I'm trying to prove that any group $G$ of infinite order has an infinite number of subgroups.</p>

<p>I think that if the group has an element of infinite order, then it's easy because I can take the groups generated by the powers of this element.</p>

<p>What if it doesn't? Every element generates a cyclic subgroup. Every element belongs to at least one cyclic subgroup (that generated by itself). So the group is the union of its cyclic subgroups. If all these are finite, we would have to have an infinite collection of subgroups anyway.</p>

<p>Is that correct?</p>

 
Answer: <p>Yes, it's correct, though perhaps somewhat disorganized.</p>

<p>The fact that a group is a union of its cyclic subgroups holds regardless of any hypothesis on the group. So you can state and prove that first.</p>

<p>Then: an infinite cyclic group has infinitely many (cyclic) subgroups. So, a group is infinite if and only if it has infinitely many cyclic subgroups: If the group is finite, then it has only finitely many subsets, so finitely many subgroups, so finitely many cyclic subgroups. If the group is infinite, then being a union of its cyclic subgroups, either one of the cyclic subgroups is infinite (and hence there will be infinitely many cyclic subgroups, since <em>that</em> subgroup has infinitely many cyclic subgroups), or else there are infinitely many finite cyclic subgroups in the union. Either way you are done.</p>

<p>That is your argument, just organized a bit more. </p>

==============================
===============================
Question: <p>Or, in general, what does the magnitude of the cross product mean? How would you prove or disprove this?</p>

 
Answer: <p>No - for example, the cross product of any unit vector with itself is 0. In general, the magnitude of the cross product of vectors $\vec{a}$ and $\vec{b}$ is $$|\vec{a}\times\vec{b}|=|\vec{a}||\vec{b}|\sin(\theta)$$
where $\theta$ is the angle between the vectors $\vec{a}$ and $\vec{b}$. Thus, the cross product of two unit vectors $\vec{u}$ and $\vec{v}$ is itself a unit vector if and only if $\vec{u}$ and $\vec{v}$ are orthogonal, i.e. meet at right angles (this makes $\sin(\theta)=\sin(\frac{\pi}{2})=1$).</p>

<p>As to the general interpretation of the magnitude of the cross product, see <a href="http://en.wikipedia.org/wiki/Cross_product#Geometric_meaning">Wikipedia</a>:</p>

<blockquote>
  <p>The magnitude of the cross product can be interpreted as the positive area of the parallelogram having $a$ and $b$ as sides.</p>
</blockquote>

==============================
===============================
Question: <p>I have no idea about the underlying theory from which the mathematical induction was derived.</p>

<p>How to prove the mathematical induction is true?</p>

 
Answer: <p>A "proof" in mathematics always means a proof in some <em>system/theory</em>. You have to specify the system/theory that you want a proof for the induction axiom. (You should also formally specify what you mean by the induction axiom since there are various axioms that are called induction axiom.)</p>

<p>The induction axiom in an arithmetical theory (like Peano arithmetic) is an <em>axiom</em>, i.e. it is one of the axioms of the theory, and therefore the proof is just a single line stating the axiom.</p>

<p>In a set theory like $ZFC$ we can prove the induction axiom for the set of natural numbers using the fact that the set of natural numbers is <em>defined</em> as the smallest inductive set that contains zero, and the proof is almost trivial. (An inductive set means a set that contains the successor of $x$ whenever it contains $x$).</p>

<p>In high school or undergraduate courses, when one is asked to prove induction axiom, they are usually asked to derive the induction axiom from some other axioms like the least number principle for natural numbers.</p>

<p>Another possible question is what are the justifications for believing that the induction axiom is <em>true</em> (or for accepting it as an axiom), which is a question in philosophy of mathematics and might be more suitable for MathOverflow.</p>

==============================
===============================
Question: <p>This is one of those perhaps rare occasions when someone takes the advice of the FAQ and asks a question to which they already know the answer.  This puzzle took me a while, but I found it both simple and satisfying.  It's also great because the proof doesn't use anything fancy at all but it's still a very nice little result.</p>

 
Answer: <p>Here's another argument that has the disadvantage of being less elementary, but the advantage of working on all $\mathbb{C}P^{2k}$ simultaneously.  (This also answers Pete's question in the comments).</p>

<p>We're going to apply the Lefshetz fixed point theorem which states the following:  Suppose $f:M\rightarrow M$ with $M$ "nice enough" (certainly, this applies to compact manifolds - I think it applies to all compact CW complexes).  Then $f$ induces a (linear) map $f_*:H_*(M)/Torsion\rightarrow H_*(M)/Torsion$.  Let $Tr(f)\in\mathbb{Z}$ denote the trace of this map.  If $Tr(f)\neq 0$, then $f$ has a fixed point.</p>

<p>Now, we'll show that every diffeomorphism $f:\mathbb{C}P^{2k}\rightarrow \mathbb{C}P^{2k}$ has trace $\neq 0$, so that every diffeomorphism has a fixed point.  Believing this for a second, note that every element of $\pi_1(X)$ for a hypothetical space $X$ covered by $\mathbb{C}P^{2k}$ acts by diffeomorphisms, and thus has a fixed point.  But it is easy to show that the only element of the deck group which fixes any point must be the identity.  It follows that $\pi_1(X)$ is trivial, so $X=\mathbb{C}P^{2k}$.</p>

<p>So, why does every diffeomorphism of $\mathbb{C}P^{2k}$ have a fixed point?  Well, every diffeomorphism (or even homotopy equivalence!) must act as multiplication by $\pm 1$ on each of the $2k+1$ $\mathbb{Z}$s in the cohomology ring of $\mathbb{C}P^{2k}$ and the trace  of the induced map is the sum of all the $\pm 1$s.  But since there is an odd number of $\pm 1$s, they can't sum to 0 (by, say, checking the parity), so by the Lefshetz fixed point theorem, every diffeomorphism (or even homotopy equivalence) must have a fixed point.</p>

<p>What about $\mathbb{C}P^{2k+1}$?  Now we must investigate using the ring structure of $\mathbb{C}P^{2k+1}$.  Since there is a single multiplicative generator, once we know what happens on $H^2(\mathbb{C}P^{2k+1})$ we know what happens everywhere.  It's easy too see that every orientation preserving homotopy equivalence must have a fixed point: if $f$ is orientation preserving, it's the identity on $H^{4k+2}(\mathbb{C}P^{2k+1})$, which implies it must have been the identity on $H^2(\mathbb{C}P^2)$ so it's the identity on all cohomology groups.  Thus, the trace of such an $f$ is $2k+1\neq 0$, and so, by the Lefshetz theorem, this map has a fixed point.</p>

<p>As an immediate corollary, if $\mathbb{C}P^{2k+1}$ covers anything, it can only double cover it.  For the product of any two nontrivial elements in the deck group must be trivial: any nontrivial map must be orientation reversing and the composition of two orientation reversing maps is orientation preserving, hence has a fixed point, hence is the identity.  That is, any two nontrivial elements product to $e$.  It's easy to show that this implies the Deck group is $\mathbb{Z}/2\mathbb{Z}$ (or trivial).</p>

<p>In fact $\mathbb{C}P^{2k+1}$ <em>does</em> double cover something (though, to my knowledge, it doesn't have a more common name, except in the case of $\mathbb{C}P^1 = S^2$ double covering $\mathbb{R}P^2$).  In homogeneous coordinates, the involution maps $[z_0:z_1:...:z_{2k+1}:z_{2k+2}]$ to $[-z_1:z_0:...:-z_{2k+2}:z_{2k+1}]$.  This involution acts freely, and the quotient of $\mathbb{C}P^{2k+1}$ by the involution is a space which $\mathbb{C}P^{2k+1}$ double covers.</p>

<p>I do not know if $\mathbb{C}P^{2k+1}$ covers anything else.</p>

<p>Incidentally, just to preempt a bit, the space $\mathbb{H}P^{n}$ doesn't cover anything unless $n=1$.  The proof is much more complicated in general (though the case where $n$ is even follows precisely as it did in the $\mathbb{C}P^{2k}$ case).</p>

<p>In general, one needs to compute Pontrjagin classes and note that they are preserved by diffeomorphisms.</p>

<p>We have $p_1(\mathbb{H}P^n) = 2(n-1)x$ where $x$ is a particular choice of generator for $H^4(\mathbb{H}P^n)$.  Since any diffeomorphism must preserve $p_1$, it follows that so long as $n\neq 1$, we must have $x\rightarrow x$ on $H^4$.  Then, the Lefshetz theorem once again guarantees a fixed point.</p>

==============================
===============================
Question: <p>I have solutions to Exercises 5.16&ndash;5.19 in Atiyah&ndash;Macdonald's Introduction to Commutative Algebra, but not in the order desired; I find myself needing later exercises to do earlier ones, and it's been frustrating me. Online solution sets (I count five, in various stages of completion) seem to either not notice this problem or treat it as something too obvious to merit consideration. </p>

<p>For context, the first part of 5.16 is Noether's normalization lemma, which is fine, and 5.18 is Zariski's Lemma, which is proved in the text two times, and is accessible to (at least) two  natural proofs at this point. </p>

<p>What I can't do is to obtain the second part of 5.16 without using 5.17, or prove 5.17 without using 5.18. Moreover, 5.19 specifically asks one to prove 5.17 using 5.18 (which I can do), so the strong implication is that the original solutions should not require use of Zariski's Lemma. </p>

<p>$k$ is an infinite field, assumed algebraically closed in 5.17 but not 5.16.</p>

<p>The first part of 5.17 is that if an affine variety $X$ in $k^n$ has ideal $I(X)$ a proper subset of $k[t_1,\ldots,t_n]$, then $X$ is not empty. This follows immediately from the second part of 5.16.</p>

<p>The second part of 5.16 is that for any subvariety $X$ of $k^n$ there are an $r \leq n$ 
and a linear map $k^n \to k^r$ taking $X$ onto all of $k^r$. The natural candidate map follows from Noether normalization, but my approach to surjectivity seems to require the second part of 5.17.</p>

<p>The second part of 5.17 is that every maximal ideal of $k[t_1,\ldots,t_n]$ is of the form $(t_1 - a_1,\ldots,t_n - a_n)$ for some $a_i \in k$. From this one can show a similar result for the coordinate ring of a subvariety of $k^n$.</p>

<p>So this mess will be fixed if I can prove the second parts of 5.16 and 5.17 without reference to later material.</p>

<p>In more detail, my current approach to the second part of 5.16 is as follows. Noether normalization shows $A$ is integral over some polynomial ring $A&#39; := k[y_1,\ldots,y_r]$ in $r \leq n$ indeterminates. The proof of Noether normalization, at least in case $k$ is infinite, gives the $y_i$ as $k$-linear combinations of the natural generators $x_1,\ldots,x_n$ of $A$, the coordinate functions on $X$. If we say $y_i = \sum a_{ij} x_j$, then the projection $k^n \to k^r$ should be given by $(z_1,\ldots,z_n) \mapsto
\big(\sum_{j=1}^n a_{1j}z_j,\ldots,\sum_{j=1}^n a_{rj}z_j,\big)$. It's not immediately obvious to me that it is surjective. However, letting $\textrm{Max}(A) \subseteq \textrm{Spec}(A)$ denote the set of maximal ideals of $A$, results of Chapter 5 show that the map $\textrm{Max}(A) \to \textrm{Max}(A&#39;)$ induced by $k^n \to k^r$ is surjective. If we know each maximal ideal of $A$ is of the form $(x_1-c_1,\ldots,x_n-c_n)$ for some $(c_1,\ldots,c_n) \in X$, then we can identify $X$ and $\textrm{Max}(A)$, and that will show the map $X \to k^r$ is surjective. That seems, however, not to be what they want, and also like too much work.</p>

<p>My current approach to the second part of 5.17 is to use the weak Nullstellensatz (if $k$ is algebraically closed and $\mathfrak a$ is a proper ideal of $k[t_1,\ldots,t_n]$, then there is at least one point of $k^n$ at which $\mathfrak a$ vanishes). The weak Nullstellensatz implies the first part of 5.17, but the reverse implication is not obvious to me. This implication is certainly proved by, e.g., the strong Nullstellensatz, but that would be completely missing the point.</p>

<p><strong>Update</strong>: To clarify, the text of 5.16, excluding a long hint about the first part, is as follows.</p>

<blockquote>
  <p>Let $k$ be a field and let $A \neq 0$ be a finitely generated $k$-algebra.
  Then there exist elements $y_1,\ldots,y_r \in A$ which are algebraically 
  independent over $k$ and such that $A$ is integral over 
  $k[y_1,\ldots,y_r]$. We shall assume that $k$ is <em>infinite</em>.
  (The result is still true if $k$ is finite, but a different proof is needed.)</p>
  
  <p>...</p>
  
  <p>From the proof  it follows that $y_1,\ldots, y_r$ 
  may be chosen to be linear combinations of $x_1,\ldots,x_n$.
  This has the following geometrical interpretation:
  if $k$ is algebraically closed and $X\!$ is an affine algebraic variety in $k^n$
  with coordinate ring $A \neq 0$, then there exists a linear subspace $L$ 
  of dimension $r$ in $k^n$ and a linear mapping of $k^n$ onto $L$ 
  which maps $X\!$ <em>onto</em> $L$ [Use Exercise 2].</p>
</blockquote>

<p>I had forgotten about that hint... Here is what Ex. 5.2 says.</p>

<blockquote>
  <p>Let $A$ be a subring of a ring $B$ such that $B$ is integral over $A$,
  and let $f\colon A \to \Omega$ be a homomorphism of $A$ into 
  an algebraically closed field $\Omega$.
  Show that $f\!$ can be extended to a homomorphism of $B$ into $\Omega$. [Use (5.10).]</p>
</blockquote>

 
Answer: <p>You haven't said what it means in this context for $X$ to be "nonempty", but I presume it means that there is a $\overline{k}$-valued point of $X$.  (Certainly $X$ need not admit a $k$-valued point if $k$ is not algebraically closed, so considering $\overline{k}$-valued points seems to be the most sensible interpretation.)</p>

<p>With this interpretation, the non-emptiness of $X$ follows directly from Noether normalization together with Exercise 5.2:</p>

<p>If $A$ is the coordiante ring of $X$, assumed to be non-zero, then Noether normalization gives an integral injective map $k[y_1,\ldots,y_r] \hookrightarrow A,$ for some $0 \leq r \leq n$.  Exercise 5.2 then guarantees that any
map $k[y_1,\ldots,y_r] \to \overline{k}$ can be extended to a map
$A \to \overline{k}$; this is the desired surjectivity.</p>

<p>[Added:] Having read the comments below, let me try again.  Rereading the second part of 5.16, I see that in fact $k$ is to be assumed algebraically closed, so that $k = \overline{k}$; this simplifies the above discussion, by removing the need to talk about $\overline{k}$-valued points.</p>

<p>So we have $X \subset k^n$ cut out by some non-unit ideal $I \subset k[x_1,\ldots,x_n]$, an integral injection $k[y_1,\ldots,y_r] \hookrightarrow A := k[x_1,\ldots,x_n]/I,$ and our goal is to prove that the induced map
$X \to k^r$ is surjective.  The argument written above proves this: any point of $k^r$ corresponds to a map $k[y_1,\ldots,y_r] \to k.$  Exercise 5.2 extends this to a map $A \to k.$  This gives a point of $X$ mapping to the given point of $k^r$. QED.</p>

==============================
===============================
Question: <p>I wonder is there an elementary proof for Fermat's last theorem. Why it's so difficult to prove this theorem by elementary method? </p>

<p>Thanks,  </p>

 
Answer: <p>It is a common false hunch that shortly-stated theorems should have short proofs. This hunch is easily falsified by employing basic results in logic. For any formal system that has nontrivial power (e.g. Peano arithmetic) there is no recursive algorithm that decides theoremhood.  Now if  there existed a recursive bound $\rm\ L(n)\ $ on the length of proofs of a statement of length $\rm\:n\:,\:$ then we could test for theoremhood simply be enumerating and testing all possible proofs of length $\rm\le L(n)\ $. Hence there can be no such recursive bound on the length of proofs. It follows that there exist short stated theorems with proofs so long that they are probably not amenable to human comprehension (these results date back to Goedel's 1936 paper on speedup theorems). </p>

<p>It remains to be seen whether or not there exists <em>mathematically interesting</em> theorems like this. There may be examples in Collatz-like congruential iterations (similar to the difficult open $\rm\: 3\ x + 1\: $ problem) that were <a href="http://groups.google.com/group/comp.lang.scheme/msg/b8c43aee2bc12241">discovered in the wild</a> while analyzing Busy-beaver holdout machines (while attempting to find the smallest universal Turing machines). John Conway has shown that there exists such congruential iterations with undecidable halting problem. That such undecidable problems may be encoded so succinctly in programs for tiny Turing machines should not come as a surprise to anyone familiar with the above simple results from logic. They are a testament to the power of ingenuity - whether it be human (in powerful mathematical theories) or nature (the DNA-based programs designed by evolution).</p>

<p>For a chess-theoretic analog see <a href="http://groups.google.com/group/sci.math/msg/c9440917b82ca5fc">my post here,</a> which discusses some massive brute-force computated chess endgame databases revealing optimal move sequences that are completely incomprehensible to human experts. </p>

<p>Returning to the specific topic at hand, it is known that Fermat's Last Theorem cannot be proved by certain types of descent proofs similar to the classical simple proofs known for small exponents. References to such work can probably be located by Googling "Tate Shafarevich obstruction".</p>

==============================
===============================
Question: <p>It is very elementary to show that $\mathbb{R}$ isn't homeomorphic to $\mathbb{R}^m$ for $m&gt;1$: subtract a point and use the fact that connectedness is a homeomorphism invariant.</p>

<p>Along similar lines, you can show that $\mathbb{R^2}$ isn't homeomorphic to $\mathbb{R}^m$ for $m&gt;2$ by subtracting a point and checking if the resulting space is simply connected. Still straightforward, but a good deal less elementary.</p>

<p>However, the general result that $\mathbb{R^n}$ isn't homeomorphic to $\mathbb{R^m}$ for $n\neq m$, though intuitively obvious, is usually proved using sophisticated results from algebraic topology, such as invariance of domain or extensions of the Jordan curve theorem.</p>

<p>Is there a more elementary proof of this fact? If not, is there intuition for why a proof is so difficult?</p>

 
Answer: <p>There are reasonably accessible proofs that are purely general topology. First one needs to show Brouwer's fixed point theorem (which has an elementary proof, using barycentric subdivion and Sperner's lemma), or some result of similar hardness. Then one defines a topological dimension function (there are 3 that all coincide for separable metric spaces, dim (covering dimension), ind (small inductive dimension), Ind (large inductive dimension)), say we use dim, and then we show (using Brouwer) that $\dim(\mathbb{R}^n) = n$ for all $n$. As homeomorphic spaces have the same dimension (which is quite clear from the definition), this gives the result. This is in essence the approach Brouwer himself took, but he used a now obsolete dimension function called Dimensionsgrad in his paper, which does coincide with dim etc. for locally compact, locally connected separable metric spaces. Lebesgue proposed the covering dimension, but had a false proof for $\dim(\mathbb{R}^n) = n$, which Brouwer corrected.</p>

<p>One can find such proofs in Engelking (general topology), Nagata (dimension theory), or nicely condensed in van Mill's books on infinite dimensional topology. These proofs do not use homology, homotopy etc., although one could say that the Brouwer proof of his fixed point theorem (via barycentric division etc.) was a precursor to such ideas.</p>

==============================
===============================
Question: <p>I've just sat through several lectures that proved most of the results in Tate's thesis: the self-duality of the adeles, the construction of "zeta functions" by integration, and the proof of the functional equation. However, while I was able to follow at least some of the arguments in the individual steps,  I understand almost nothing about the big picture. My impression so far is that Tate invented a new and fancier way of proving the functional equation that the Hecke analytic approach. But is there more to the story than "this is a neat way of proving something already known"?
I'm under the impression that Tate's thesis laid the foundations for the Langlands program, but I don't understand this properly yet. </p>

<p>Can someone explain to me what's the real significance and meaning of Tate's thesis? </p>

 
Answer: <p>Tate's thesis introduces the concept, ubiquitous now, of doing analysis, and especially Fourier analysis, on the locally compact ring of adeles.    In this setting, the discrete subgroup $\mathbb Z \subset \mathbb R$ is replaced
by the discrete subgroup $\mathbb Q \subset \mathbb A$.</p>

<p>This has a number of implications, some of which are:</p>

<ol>
<li><p>$\mathbb Q$ is a field, and $\mathbb A$ is essentially a product of fields.
It is technically almost always easier to work with fields rather than more general rings (such as $\mathbb Z$).  The adelic formalism allows one to have one's cake and eat it too (in some sense): one is working with the field $\mathbb Q$, not the ring $\mathbb Z$, but the primes are still present, in the factorization of $\mathbb A$ as a product.  (And this product structure of 
$\mathbb A$, which is formally very simple, captures in some subtle way the
deeper sense of "product" in the statement of the fundamental theorem of arithmetic, i.e. that any natural number is a unique product of prime powers.)</p></li>
<li><p>Tate writes zeta-functions, or more generally, Hecke $L$-series, as integrals over $\mathbb A^{\times}$.  The Euler product structure of the $L$-series then becomes simply a factorization of this integral according to the product structure of $\mathbb A^{\times}$.  (This is a manifestation of the parenthetical remark at the end of point (1).)</p></li>
<li><p>The proof of the functional equation becomes (more-or-less) just an application of Poisson summation (in the adelic context).  </p>

<p>It is worth comparing this with the classical proof (which one can read in Lang's book, among other places, if memory serves).   Classically, one takes
the sum over ideals representation of the $L$-function, and decomposes it first
into a finite collection of sums, indexed by the ideal class group, each sum taking place over all the integral ideals in a given ideal class.  These individual series are then described as Mellin transforms of theta series, 
and the functional equation is derived from the transformation properties of the
theta series, the latter being proved by an application of Poisson summation in the classical setting.   </p>

<p>Once one unpacks all the details, Tate's proof and Hecke's proof don't look so different; but the difference in packaging is enormous!  In Tate's approach there is no need to unpack everything (for example, the ideal class group is just lurking around in the background implicitly, and there is no need to bring it out explicitly), while in the classical arguments such unpacking is key to the whole thing.   </p>

<p>As another example of the conceptual clarity and simplification that Tate's approach gives, you might consider the way he derives the formula for the residue at $s = 1$ of the zeta function of a number field (i.e. the general class number formula) and compare it with the classical derivation.</p></li>
<li><p>Working in the case of a function field over a finite field, Tate derives the Riemann--Roch formula (in the form $\dim H^0(C,\mathcal O(D)) - \dim
H^0(C,\mathcal O(K - D)) = 1 + \deg D - g$) as a straightforward consequence of Poisson summation.  Among other things, this provides a rather striking unification of (what we now call) Serre duality and Fourier duality.  (Although I don't know the precise history, this probably has antecedents in the literature: the original proof of the functional equation of the $\zeta$-function for a curve over a finite field, by  Schmidt, proceeded by applying Riemann--Roch; so Tate is essentially reversing this argument.)</p></li>
<li><p>Tate's explication of the functional equation of $L$-series in terms of local functional equations shows that the global root number --- i.e. the constant that appears in the functional equation --- is a product of local numbers.  As far as I understand, this wasn't known (and perhaps not even suspected) prior to Tate's proof.  </p>

<p>This may seem slightly esoteric, but experience shows that one should regard global root numbers, and their factorization into a product of local root numbers (or $\epsilon$-factors), to be of essentially equal importance to global $L$-series, and their (Euler product) factorization into local $L$-factors.</p></li>
</ol>

<p>Summary/Conclusion: The aim of the above list is just to highlight some of the points to watch out for while studying Tate's thesis.  Let me now make some remarks at a more general level.</p>

<p>In the classical theory of zeta and $L$-functions, there is a tension between the analytic tools, which are essentially additive Fourier theory (e.g. Poissson summation) and the multiplicative aspects of the theory (exemplified by the Euler product).  Tate's thesis resolves these tensions by moving to the adelic context.</p>

<p>In the general theory of automorphic forms (say on a quotient $\Gamma
\backslash G(\mathbb R)$) for some congruence subgroup $\Gamma$ of the integral points $G(\mathbb Z)$ of a semi-simple or reductive Lie group $G(\mathbb R)$) there is the same tension between the harmonic analysis and Lie theory (which $\Gamma \backslash G(\mathbb R)$ is well set-up to accommodate) and the theory of Hecke operators (which pertain to the finite primes, which are not particular visible in this classical description), which is resolved by moving to the adelic picture $G(\mathbb Q)\backslash G(\mathbb A)$.</p>

<p>Another thing to bear in mind is that the theories of $L$-series and of automorphic forms are quite technical in nature, and so conceptual and aesthetic simplifications (as in Tate's thesis) go hand in hand with technical simplifications.  (See e.g. points (1) and (3) above.)  One instance of this in the automorphic forms context is that conjugacy classes in $G(\mathbb Q)$ are much easier to understand than in a congruence subgroup $\Gamma$ of $G(\mathbb Z)$.  (Another instance of the technical superiority of fields over more general rings.)  One might also consider the <a href="http://en.wikipedia.org/wiki/Weil_conjecture_on_Tamagawa_numbers">Tamagawa number one theorem</a>, which gives an elegant reformulation and generalization of a myriad of classical results.</p>

<p>So, to finish, Tate's thesis is significant because it improves the classical point of view in a number of ways, achieving conceptual, technical, and aesthetic simplifications.  At the same time, it suggests a way of unifying harmonic analytic and arithmetic considerations in the general context of automorphic forms, by working in the adelic context.</p>

<p>Finally, I strongly suggest working through the details of Tate's thesis in the particular case of the Riemann zeta function, and seeing how his arguments and construction compare with the classical ones.  If you haven't already done this, it should be quite enlightening.  (In particular, it will illuminate points (1), (2), and (3) above.)</p>

==============================
===============================
Question: <p>I am trying to understand Apery's 1978 proof that $\zeta(3) = \displaystyle \sum_{n=1}^\infty \frac{1}{n^3}$ is irrational. The idea behind the proof is to find an 'accelerated' series for $\zeta(3)$ which converges too fast to $\zeta(3)$, thus proving that $\zeta(3)$ cannot be rational. In particular, a particular quantity is defined:</p>

<p>$$e_{n,k} = \displaystyle \sum_{m=1}^k \frac{(-1)^{m-1} (m!)^2 (n-m)!}{2m^3 (n+m)!},\quad k \leq n.$$</p>

<p>The key is to show that $\displaystyle \lim_{n \rightarrow \infty} e_{n,k} = 0$ uniformly in $k$, and I have no idea why this sum converges to 0. Any ideas?</p>

 
Answer: <p>By the triangular inequality, $|e_{n,k}|\leqslant\frac12 a_n$ with
$$
a_n=\sum_{m=1}^nb_{n,m},\qquad b_{n,m}=\frac{(m!)^2(n-m)!}{m^3(n+m)!},
$$
hence the desired uniform convergence holds as soon as $a_n\to0$. </p>

<p>To prove that $a_n\to0$, note that
$$
b_{n,m}=\frac{(m-1)!(m-1)!(n-m)!}{m(n+m)!}\leqslant\frac{(m-1)!(m-1)!(n-m)!}{(n+m)!},
$$
and use twice the fact that $i!j!\leqslant (i+j)!$ for every nonnegative integers $i$ and $j$. This yields
$$
b_{n,m}\leqslant\frac{(n+m-2)!}{(n+m)!}=\frac1{(n+m-1)(n+m)}=\frac1{n+m-1}-\frac1{n+m}.
$$
Thus $a_n$ is bounded by a telescoping sum, namely
$$
a_n\leqslant\sum_{m=1}^n\left(\frac1{n+m-1}-\frac1{n+m}\right)=\frac1{n}-\frac1{2n}=\frac1{2n},
$$
This shows that $|e_{n,k}|\leqslant\frac1{4n}$ for every $n\geqslant1$ and uniformly over $k\leqslant n$, hence the proof is complete.</p>

<p><strong>Edit</strong> One can refine the estimates above, taking into account the variations of the sequence  $(b_{n,m})_{1\leqslant m\leqslant n}$ for some fixed $n$, which is nonincreasing on $1\leqslant m\leqslant m_n$ for some $m_n\approx n/\sqrt2$ and nondecreasing on $m_n\leqslant m\leqslant n$. Thus, $|e_{n,k}|\leqslant\frac12  b_{n,1}+\frac12 b_{n,n}$. Hence, $n^2e_{n,k}\to\frac12 $ uniformly over $k$.</p>

==============================
===============================
Question: <p>This question is motivated by a step in the proof given <a href="https://math.stackexchange.com/questions/25206/n8-lt-8n-1/25212#25212">here</a>.</p>

<blockquote>
  <p>$\begin{align*}
8^{n+1}-1&amp;\gt 8(8^n-1)\gt 8n^8\\
 &amp;=(n+1)^8\left(8\left(\frac{n}{n+1}\right)^8\right)\\
 &amp;\geq (n+1)^8\left(8\left(\frac{9}{10}\right)^8\right)\\
&amp;\gt (n+1)^8 .
\end{align*}$</p>
</blockquote>

<p>I had no trouble following along with the proof until I hit the step that relied on
$$8\left(\frac{9}{10}\right)^8 &gt; 1$$. So I whipped out a calculator and confirmed that this is indeed correct. And I could see, after some fooling around with pen and paper that any function in the form
\begin{align}
k \; \left(\frac{n}{n+1}\right)^k
\end{align}
where $n \in \mathbb{Z}$ and $k \rightarrow \infty$ is bound to fall below one and stay there. So it's not a given that any function in the above form will be greater than one.</p>

<p>What I'm actually curious about is <strong>whether there are nifty or simple little tricks or calculations you can do in your head or any handwavy type arguments that you can make</strong> to confirm that $$8\left(\frac{9}{10}\right)^8 &gt; 1$$ and even more generally, to confirm for certain natural numbers $k,n$ whether
\begin{align}
k \; \left(\frac{n}{n+1}\right)^k &gt; 1
\end{align}</p>

<p>So are there? And if there are, what are they? </p>

<p>It can be geometrical. It can use arguments based on loose bounds of certain log values. It doesn't even have to be particularly simple as long as it is something you can do in your head and it is something you can explain reasonably clearly so that others can do also it (so if you're able to mentally calculate numbers like Euler, it's not useful for me).</p>

<p>You can safely assume that I have difficulties multiplying anything greater two single digit integers in my head. But I do also know that $$\limsup_{k\rightarrow \infty} \log(k) - a\cdot k &lt; 0$$ for any $a&gt;0$ without having to go back to a textbook.</p>

 
Answer: <p>Note that $(1-0.1)^8\geq 1-0.8$ by <a href="http://en.wikipedia.org/wiki/Bernoulli%27s_inequality" rel="nofollow noreferrer">Bernoulli's inequality</a>, as mentioned in a comment by lvb.  For other cases you can use $\left(1-\frac{1}{n+1}\right)^k\geq 1-\frac{k}{n+1}$, which makes it easier to find a sufficient condition on $n$ for $k\left(\frac{n}{n+1}\right)^k$ to be larger than $1$.</p>

<p>In the motivating problem, the idea was that $k$ is fixed (at $8$), and since $\frac{n}{n+1}$ goes to $1$ as $n$ goes to infinity, $k\left(\frac{n}{n+1}\right)^k$ approaches $k$, and in particular is eventually bigger than $1$. One then finds out in a particular case what "eventually" means; here $n=9$ suffices.  In general, Bernoulli's inequality leads to the conclusion that $n&gt;k$ suffices.</p>

==============================
===============================
Question: <p>I am comfortable with the definition of adjoint functors. I have done a few exercises proving that certain pairs of functors are adjoint (tensor and hom, sheafification and forgetful, direct image and inverse image of sheaves, spec and global sections ect) but I am missing the bigger picture.</p>

<p>Why should I care if a functor has a left adjoint? What does it tell me about the functor? </p>

 
Answer: <p>The answer to this question is the same as the answer to every question of this genre ("why should I care about groups," "why should I care about rings"): they show up everywhere and are an extremely useful organizing principle.</p>

<p>There is a meta-principle that any time you're trying to understand something about categories, it's a good idea to restrict to the special case of posets first, regarded as categories where $a \le b$ means there is a single arrow $a \to b$. For example:</p>

<ul>
<li>Products are the same thing as infima. In particular, the terminal object is the empty infimum, which is the maximum element. (This may seem backwards, but it really is what you get out of the definitions.)</li>
<li>Coproducts are the same thing as suprema. In particular, the initial object is the empty supremum, which is the minimum element.</li>
</ul>

<p>So what's a pair of adjoint functors in this context? Well, if $P, Q$ are two posets, then a functor $f : P \to Q$ is just an order-preserving function. So a pair of adjoint functors is first of all a pair $f : P \to Q, g : Q \to P$ of order-preserving functions. The definition I think is most convenient when studying posets is that $f, g$ must satisfy</p>

<p>$$\text{Hom}_Q(fa, b) \cong \text{Hom}_P(a, gb)$$</p>

<p>for all $a \in P, b \in Q$. But this is the same thing as requiring that</p>

<p>$$fa \le b \Leftrightarrow a \le gb.$$</p>

<p>This relationship is called a <a href="http://en.wikipedia.org/wiki/Galois_connection">Galois connection</a>. Important examples of Galois connections include:</p>

<ul>
<li>$K \to L$ is a finite Galois extension, $P$ is the poset of subgroups of $\text{Gal}(L/K)$, $Q$ is the poset of subfields $K \to M \to L$, $f$ sends a subgroup to its fixed field, $g$ sends a subfield to $\text{Gal}(L/M)$. (One has to reverse the order of one of these posets for this to work.) </li>
<li>$P$ is the poset of ideals of $\mathbb{C}[x_1, ... x_n]$, $Q$ is the poset of subsets of $\mathbb{C}^n$, $f$ sends an ideal to the set of points defined by its elements vanishing, $g$ sends a set of points to the ideal of functions vanishing on it. (Again, one has to reverse the order of one of these posets.)</li>
</ul>

<p>Galois connections exist in extreme generality and are, by themselves, already an important organizing principle in mathematics. So adjoint functors are <em>even more important than that!</em></p>

<hr>

<p><strong>Edit:</strong> It's probably worth explaining what's going on in the above examples abstractly. Let $A, B$ be two sets, and let $r : A \times B \to \{ 0, 1 \}$ be a relation. Then $r$ induces an order-reversing Galois connection (a pair of contravariant adjoint functors) between the poset $\mathcal{P}(A)$ of subsets of $A$ and the poset $\mathcal{P}(B)$ of subsets of $B$ as follows: if $S \subset A$ then $f(S) = \{ b \in B : r(a, b) = 1 \forall a \in S \}$ and if $S \subset B$ then $g(S) = \{ a \in A : r(a, b) = 1 \forall b \in S \}$. I'll leave it as an exercise to figure out what $A, B, r$ are in the above examples. </p>

<p>Note also that the fact that left adjoints preserve colimits and right adjoints preserve limits continues to hold for Galois connections, and shows that some of the properties of the Galois connections above are purely formal (in the sense that they follow from this "abstract nonsense"). Unfortunately it is generally not emphasized which properties those are. </p>

<hr>

<p>The <a href="http://en.wikipedia.org/wiki/Adjoint_functors#Motivation">Wikipedia article</a> does a nice job of explaining some broad general motivation (and has a lot of good discussion on this question besides): very roughly, an adjoint is the best substitute for an inverse that exists in a lot of cases that we care about. You can sort of see how this works in the above examples.</p>

<p>An important property of adjoint pairs is that they restrict to equivalences on subcategories, and this is what we get in the Galois theory and algebraic geometry examples above: the first adjoint pair is an equivalence by the fundamental theorem of Galois theory, and the second adjoint pair restricts to an equivalence between reduced ideals and varieties by the Nullstellensatz. </p>

<hr>

<p>Since your question is tagged [algebraic-geometry], here is an important <em>non-example</em> related to the second half of Arturo's answer. There is a functor $F : \text{Aff} \to \text{Set}$ sending an affine scheme to its set of points (the prime ideals of the corresponding ring), and it does <em>not</em> have a left adjoint: there is no "free affine scheme" on a set. The reason is that $F$ does not preserve limits. (Note that a functor <em>has</em> a left adjoint if and only if it <em>is</em> a right adjoint.) In fact, it does not even preserve products. The product of two affine schemes $\text{Spec } R, \text{Spec } S$ is $\text{Spec } R \otimes_{\mathbb{Z}} S$, and it is a basic property of schemes that this is not the set-theoretic product. </p>

<p>It follows that the functor $F : \text{Aff} \to \text{Top}$ sending an affine scheme to its set of points in the Zariski topology also does not have a left adjoint. If you've ever wondered why the Zariski topology on $\mathbb{A}^2$ isn't the product topology on $\mathbb{A}^1 \times \mathbb{A}^1$, now you know. </p>

==============================
===============================
Question: <p>This is something that confuses me.
I have read a few mathematical texts and they often seem to use Lemma/Proposition/Theorem if they have a particular statement.</p>

<p>Now, which one to use? A lemma can be something you need to prove a more important theorem, but then what about Fatou's Lemma?</p>

<p>When to pick Proposition or Theorem?</p>

 
Answer: <p>There seem to be two issues here.  One is why certain well-known results are called Lemmas, such as Zorn's, Yoneda's, Nakayama's, and so on.  I don't know the answer to this; presumably it is a mixture of what was written in some original source and the results of the transmission of that original source through the mathematical tradition.  (As one interesting example of how labels can be changed in the course of transmission, there is a result in the theory of automorphic forms and Galois representations, very well known to experts, universally referred to as "Ribet's Lemma"; however, in the original paper it is labelled as a proposition!)</p>

<p>The second issue is how contemporary writers label the results in their papers.  My experience is that typically the major results of the paper are called theorems, the lesser results are called propositions (these are typically ingredients in the proofs of the theorems which are also stand-alone statements that may be of independent interest), and the small technical results are called lemmas.   This probably varies quite a bit from writer to writer (and perhaps also from field to field?).  </p>

==============================
===============================
Question: <p>I was working on this problem here below, but seem to not know a precise or clean way to show the proof to this question below. I had about a few ways of doing it, but the statements/operations were pretty loosely used. The problem is as follows:</p>

<p>Show that ${\bf A}^{-1}$ exists if and only if the eigenvalues $ \lambda _i$ ,  $1 \leq i \leq n$ of $\bf{A}$ are all non-zero, and then ${\bf A}^{-1}$ has the eigenvalues given by $ \frac{1}{\lambda _i}$, $1 \leq i \leq n$.</p>

<p>Thanks.</p>

 
Answer: <p>(Assuming $\mathbf{A}$ is a square matrix, of course). Here's a solution that does not invoke determinants or diagonalizability, but only the definition of eigenvalue/eigenvector, and the characterization of invertibility in terms of the nullspace. (<em>Added for clarity:</em> $\mathbf{N}(\mathbf{A}) = \mathrm{ker}(\mathbf{A}) = \{\mathbf{x}\mid \mathbf{A}\mathbf{x}=\mathbf{0}\}$, the nullspace/kernel of $\mathbf{A}$.) </p>

<p>\begin{align*}
\mbox{$\mathbf{A}$ is not invertible} &amp;\Longleftrightarrow \mathbf{N}(\mathbf{A})\neq{\mathbf{0}}\\
&amp;\Longleftrightarrow \mbox{there exists $\mathbf{x}\neq\mathbf{0}$ such that $\mathbf{A}\mathbf{x}=\mathbf{0}$}\\
&amp;\Longleftrightarrow \mbox{there exists $\mathbf{x}\neq\mathbf{0}$ such that $\mathbf{A}\mathbf{x}=0\mathbf{x}$}\\
&amp;\Longleftrightarrow \mbox{there exists an eigenvector of $\mathbf{A}$ with eigenvalue $\lambda=0$}\\
&amp;\Longleftrightarrow \mbox{$\lambda=0$ is an eigenvalue of $\mathbf{A}$.}
\end{align*}</p>

<p>Note that this argument holds even in the case where $\mathbf{A}$ has no eigenvalues (when working over a non-algebraically closed field, of course), where the condition "the eigenvalues of $\mathbf{A}$ are all nonzero" is true by vacuity.</p>

<p>For $\mathbf{A}$ invertible:
\begin{align*}
\mbox{$\lambda\neq 0$ is an eigenvalue of $\mathbf{A}$} &amp;\Longleftrightarrow \mbox{$\lambda\neq 0$ and there exists $\mathbf{x}\neq \mathbf{0}$ such that $\mathbf{A}\mathbf{x}=\lambda\mathbf{x}$}\\
&amp;\Longleftrightarrow\mbox{there exists $\mathbf{x}\neq\mathbf{0}$ such that $\mathbf{A}({\textstyle\frac{1}{\lambda}}\mathbf{x}) = \mathbf{x}$}\\
&amp;\Longleftrightarrow\mbox{there exists $\mathbf{x}\neq \mathbf{0}$ such that $\mathbf{A}^{-1}\mathbf{A}({\textstyle\frac{1}{\lambda}}\mathbf{x}) = \mathbf{A}^{-1}\mathbf{x}$}\\
&amp;\Longleftrightarrow\mbox{there exists $\mathbf{x}\neq \mathbf{0}$ such that $\frac{1}{\lambda}\mathbf{x} = \mathbf{A}^{-1}\mathbf{x}$}\\
&amp;\Longleftrightarrow\mbox{$\frac{1}{\lambda}$ is an eigenvalue of $A^{-1}$.}
\end{align*}</p>

==============================
===============================
Question: <p>The union of a sequence of $\sigma$-algebras need not be a $\sigma$-algebra, but how do I prove the stronger statement below?</p>

<blockquote>
  <p>Let $\mathcal{F}_n$ be a sequence of
  $\sigma$-algebras. If the inclusion
  $\mathcal{F}_n \subsetneqq \mathcal{F}_{n+1} $ is strict, then
  the union
  $\bigcup_{n=1}^{\infty}\mathcal{F}_n$
  is <strong>not</strong> a $\sigma$-algebra.</p>
</blockquote>

 
Answer: <p><strong>This is not a complete solution as is indicated in the comments. Joriki's addition is also important. For complete solution, see A. Broughton and B. W. Huff: <em>A comment on unions of sigma-fields. The American Mathematical Monthly</em>, 84, no. 7 (1977), 553-554. (Thanks Didier for the reference)</strong></p>

<p>The idea is to find a sequence of pairwise disjoint sets $F_n$ in $\mathcal F_{n + 1} \setminus \mathcal F_n$ and then prove that $F_n$ must actually be an element of $\mathcal F_n$ if $\mathcal F = \bigcup_n \mathcal F_n$ were a $\sigma$-algebra.</p>

<p>First pick a partition $N_1, N_2,\ldots$ of infinite sets of $\mathbb N$ and set</p>

<p>$$A_i = \bigcup_{n \in N_i} F_n.$$</p>

<p>So, by assumption $A_i$ is an element of $\mathcal F$. So, for every $i$ we have an $n_i$ such that $A_i \in \mathcal F_{n_i}$. Now, note that since $(\mathcal F_n)$ is strictly increasing, so we can choose $(n_i)$ to be strictly increasing as well.</p>

<p>Okay, nice. So now for every $j$ we can pick an integer $m_j \in N_j$ such that $m_j &gt; n_j$. So now we set</p>

<p>$$B = \bigcup_n \, F_{m_n} \in \mathcal F.$$</p>

<p>So, eventually (for large $n$) $B$ will belong to all $\mathcal F_n$. So, eventually $B$ is in some $\mathcal F_{n_k}$(since $n_i$ is strictly increasing). By construction we now have that</p>

<p>$$A_k \cap B = A_{m_k} \in \mathcal F_{n_k}.$$</p>

<p>But! $n_k &lt; m_k$ so $A_{m_k} \notin \mathcal F_{n_k}$. Contradiction.</p>

<p>So, now what is left is to show that such a disjoint sequence exists. Well, that is quite messy, so I will only add it if you want.</p>

<p>I would like to add that this is not my idea but that I have got the idea from somewhere in the past, but I forgot exactly where from.</p>

==============================
===============================
Question: <p>I know that there are isomorphic projective varieties which have nonisomorphic coordinate rings, but I'm a little mystified as to "why" this is the case. Why doesn't a usual functoriality proof go through to prove this, and is there any insight into this other than that the definitions just work out this way? </p>

 
Answer: <p>The homogeneous coordinate ring of a projective variety embedded in $\mathbb{P}^n$ is not the "ring of functions" on the variety but actually the direct sum of sections of symmetric powers of some <a href="http://en.wikipedia.org/wiki/Line_bundle">line bundle</a>. The point is that this construction actually depends on the line bundle, and the same variety can have many line bundles which give rise to non-isomorphic rings.</p>

<p>I'm not sure what "a usual functoriality proof" is, but you should find either that you end up proving something about the category of projective varieties together with an embedding or that you can't define the homogeneous coordinate ring at <em>all</em> without a choice of embedding.</p>

<hr>

<p>I'm not totally comfortable with this answer since I can't claim to have much experience with line bundles, so here's a more straightforward version. First, the reason this issue doesn't come up for affine varieties is that once you have a definition of a morphism of affine varieties, the ring of functions $k[V]$ on an affine variety $V$ really is just the set of morphisms $V \to \mathbb{A}^1(k)$, and this definition is clearly functorial.</p>

<p>The same cannot be said for the homogeneous coordinate ring of a projective variety $V \subset \mathbb{P}^n$. First of all, its elements are not functions on the variety. Quotients of two elements of the same degree do define <strike>morphisms</strike> rational maps $V \dashrightarrow \mathbb{P}^1$, but you're considering much more than just such quotients. When $V$ is irreducible you might be tempted to replace the ring of functions with the field $k(V)$ of rational functions, but $k(V)$ does not completely capture $V$ (for example it ignores the removal of finitely many points).</p>

<p>After you think about this problem for awhile you should realize that the problem here is that the homogeneous coordinate ring really is defined in terms of the embedding, and so there's no reason to expect it to be independent of the choice of embedding. So next you might look for a definition of projective variety that is independent of the choice of embedding, and then sooner or later you have to start studying schemes. </p>

==============================
===============================
Question: <p>The question is from Axler's "<em>Linear Algebra Done Right</em>", which I'm using for self-study.</p>

<p>We are given a linear operator $T$ over a finite dimensional vector space $V$. We have to show that $T$ is a scalar multiple of the identity iff $\forall S \in {\cal L}(V), TS = ST$. Here, ${\cal L}(V)$ denotes the set of all linear operators over $V$.</p>

<p>One direction is easy to prove. If $T$ is a scalar multiple of the identity, then there exists a scalar $a$ such that $Tv = av$, $\forall v \in V$. Hence, given an arbitrary vector $w$, $$TS(w) = T(Sw) = a(Sw) = S(aw) = S(Tw) = ST(w)$$ where the third equality is possible because $S$ is a linear operator. Then, it follows that $TS = ST$, as required.</p>

<p>I am, however, at a loss as to how to tackle the other direction. I thought that a proof by contradiction,  ultimately constructing a linear operator $S$ for which $TS \neq ST$, might be the way to go, but haven't made much progress. </p>

<p>Thanks in advance!</p>

 
Answer: <p>Suppose $TS = ST$ for every $S$. Show that $Tv = a_{v}v$ for every $v\in V$ where $a_v$ could depend on $v$. In other words, show that $v$ and $Tv$ are linearly dependent for each $v \in V$. </p>

<p>Suppose for contradiction that they are linearly independent. Since $(v, Tv)$ is linearly independent, it can be extended to a basis $(v,Tv, u_1, \dots, u_n)$ of $V$. So define $S$ as following: $Sv = v$, $S(Tv) = v$ and $S(u_1) = 0, \dots, S(u_n) = 0$. Then, $Tv = TSv = STv = v$. Hence $v$ and $Tv$ are linearly dependent, which is a contradiction. Then you have to show uniqueness. </p>

==============================
===============================
Question: <p>You are given positive integers N, m, and k.  Is there a way to check if
$$\sum_{\stackrel{p\le N}{p\text{ prime}}}p^k\equiv0\pmod m$$
faster than computing the (modular) sum?</p>

<p>For concreteness, you can assume $e^k&lt;m&lt;N.$</p>

<p>I don't know of a way, but it's not obvious to me that no method exists.  Fast ways to prove or refute the equivalence would be of interest.  You can assume that the particular instance of the problem is 'hard', that is, the modulus is not close enough to N so that Rosser-type bounds on the sum would rule it out.</p>

<p>With $k=0$ this is just asking if $m|\pi(N)$, so it is possible to compute the sum in time $O(N^{1/2+\varepsilon})$ using the <a href="http://www.dtc.umn.edu/~odlyzko/doc/arch/analytic.pi.of.x.pdf" rel="nofollow noreferrer">Lagarias-Odlyzko</a> method.  (Or more practically, one of the combinatorial $\pi(x)$ methods.)  For $k&gt;0$ the sum is superlinear and so cannot be stored directly (without, e.g., modular reduction) but it's not clear whether a fast algorithm exists.</p>

<p>You can think of the problem as "Your friend, who has access to great computational resources, makes the claim (N, m, k). If her claim is true, can you prove it?  If her claim is false, can you refute it?".</p>

<p>Edit: I posted <a href="https://cstheory.stackexchange.com/q/5578/962">a related problem</a> on cstheory, asking if there is a short proof or interactive proof that the sum is correct.</p>

 
Answer: <p>Deléglise-Dusart-Roblot [1] give an algorithm which determines the number of primes up to $x$ that are congruent to $l$ modulo $k,$ in time $O(x^{2/3}/\log^2x).$ A modification of the algorithm of Lagarias-Odlyzko [2] allows the same to be computed in time $O(x^{1/2+o(1)}).$</p>

<p>So using either algorithm, find the number of primes in all residue classes mod primes up to $\log m.$ For each prime $q,$ take the total number of primes in each residue class times that residue class to the $k$-th power; this gives the value of
$$\sum_{\stackrel{p\le N}{p\text{ prime}}}p^k\pmod q.$$</p>

<p>Use the Chinese Remainder Theorem to determine the value of the sum mod $2\cdot3\cdots\log m.$ The Prime Number Theorem ensure that this, or a little more, is greater than $m$ and hence sufficient to determine the result uniquely. (Note that if $m&gt;N^{k+1}/\log N$ or so, the calculations can be done exactly working mod $k\log N$ or so.)</p>

<p>This gives the sum (mod m or in Z) in time $O(N^{1/2+o(1)})$ since the number of calculations needed is logarithmic.</p>

<h1>References</h1>

<p>[1] Marc Deléglise, Pierre Dusart, and Xavier-François Roblot, <a href="http://www.ams.org/journals/mcom/2004-73-247/S0025-5718-04-01649-7/S0025-5718-04-01649-7.pdf" rel="nofollow noreferrer">Counting primes in residue classes</a>, <em>Mathematics of Computation</em> <strong>73</strong>:247 (2004), pp. 1565-1575. <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.100.779" rel="nofollow noreferrer">doi 10.1.1.100.779</a></p>

<p>[2] J. C. Lagarias and A. M. Odlyzko, <a href="http://www.dtc.umn.edu/~odlyzko/doc/arch/analytic.pi.of.x.pdf" rel="nofollow noreferrer">Computing $\pi(x)$: An analytic method</a>, <em>Journal of Algorithms</em> <strong>8</strong> (1987), pp. 173-191.</p>

<p>[3] Charles, <a href="https://mathoverflow.net/questions/81443/fastest-algorithm-to-compute-the-sum-of-primes/81533#81533">answer on MathOverflow</a>. (Yes, this is the same person. See the other answers there for different approaches.)</p>

==============================
===============================
Question: <p>A little reading suggests:</p>

<p>It is known that either $\pi + e$ or $\pi \times e$ is transcendental (or possibly both), but no proof is known that one of those two numbers in particular is transcendental.</p>

<p>If we just want irrationality rather than transcendence, is a proof known?</p>

<p>Can we prove $\pi+e$ is irrational?  Can we prove $\pi \times e$ is irrational?</p>

 
Answer: <p>It is not known whether $\pi + e$ is irrational, nor whether $\pi \times e$ is irrational. See $\# 22$ <a href="http://www.math.ou.edu/~jalbert/courses/openprob2.pdf">here</a>. </p>

==============================
===============================
Question: <p>I know some nice ways to prove that $\zeta(2) = \sum_{n=1}^{\infty} \frac{1}{n^2} = \pi^2/6$.  For example, see <a href="http://empslocal.ex.ac.uk/people/staff/rjchapma/etc/zeta2.pdf" rel="noreferrer">Robin Chapman's list</a> or the answers to the question "<a href="https://math.stackexchange.com/questions/8337/different-methods-to-compute-sum-n-1-infty-frac1n2">Different methods to compute $\sum_{n=1}^{\infty} \frac{1}{n^2}$</a>?"</p>

<p>Are there any nice ways to prove that $$\zeta(4) = \sum_{n=1}^{\infty} \frac{1}{n^4} = \frac{\pi^4}{90}?$$</p>

<p>I already know some proofs that give all values of $\zeta(n)$ for positive even integers $n$ (like #7 on Robin Chapman's list or Qiaochu Yuan's answer in the linked question).  I'm not so much interested in those kinds of proofs as I am those that are specifically for $\zeta(4)$.</p>

<p>I would be particularly interested in a proof that isn't an adaption of one that $\zeta(2) = \pi^2/6$.</p>

 
Answer: <p>In the same spirit of the 1st proof of <a href="https://math.stackexchange.com/questions/8337/different-methods-to-compute-sum-n-1-infty-frac1n2/8378#8378">this answer</a>. If we substitute  $\pi $ for $ x $ in the Fourier trigonometric series expansion of $%
f(x)=x^{4}$, with $-\pi \leq x\leq \pi $, </p>

<p>$$x^{4}=\frac{1}{5}\pi ^{4}+\sum_{n=1}^{\infty }\frac{8n^{2}\pi ^{2}-48}{n^{4}}\cos n\pi \cdot \cos nx,$$</p>

<p>we obtain</p>

<p>$$\begin{eqnarray*}
\pi ^{4} &amp;=&amp;\frac{1}{5}\pi ^{4}+\sum_{n=1}^{\infty }\frac{8n^{2}\pi ^{2}-48}{n^{4}}\cos ^{2}n\pi  \\
 &amp;=&amp;\frac{1}{5}\pi ^{4}+8\pi ^{2}\sum_{n=1}^{\infty }\frac{1}{n^{2}}
-48\sum_{n=1}^{\infty }\frac{1}{n^{4}}.
\end{eqnarray*}$$</p>

<p>Hence</p>

<p>$$\sum_{n=1}^{\infty }\frac{1}{n^{4}}=\frac{\pi ^{4}}{48}\left( -1+\frac{1}{5}+
\frac{8}{6}\right) =\frac{\pi ^{4}}{48}\cdot \frac{8}{15}=\frac{1}{90}\pi
^{4}.$$</p>

==============================
===============================
Question: <p>Thomson et al. provide a proof that $\lim_{n\rightarrow \infty} \sqrt[n]{n}=1$ in <a href="http://classicalrealanalysis.com/TBB.aspx">this book</a>. It has to do with using an inequality that relies on the binomial theorem. I tried to do an alternate proof now that I know (from elsewhere) the following:</p>

<p>\begin{align}
\lim_{n\rightarrow \infty} \frac{ \log n}{n} = 0
\end{align}</p>

<p>Then using this, I can instead prove:
\begin{align}
\lim_{n\rightarrow \infty} \sqrt[n]{n} &amp;= \lim_{n\rightarrow \infty} \exp{\frac{ \log n}{n}} \newline
&amp; = \exp{0} \newline
&amp; = 1
\end{align}</p>

<p>On the one hand, it seems like a valid proof to me. On the other hand, I know I should be careful with infinite sequences. The step I'm most unsure of is:
\begin{align}
\lim_{n\rightarrow \infty} \sqrt[n]{n} = \lim_{n\rightarrow \infty} \exp{\frac{ \log n}{n}}
\end{align}</p>

<p>I know such an identity would hold for bounded $n$ but I'm not sure I can use this identity when $n\rightarrow \infty$.</p>

<p>If I am correct, then would there be any cases where I would be wrong? Specifically, given any sequence $x_n$, can I always assume:
\begin{align}
\lim_{n\rightarrow \infty} x_n = \lim_{n\rightarrow \infty} \exp(\log x_n)
\end{align}
Or are there sequences that invalidate that identity?</p>

<p>(Edited to expand the last question) 
given any sequence $x_n$, can I always assume:
\begin{align}
\lim_{n\rightarrow \infty} x_n &amp;=  \exp(\log \lim_{n\rightarrow \infty} x_n) \newline
&amp;=  \exp(\lim_{n\rightarrow \infty} \log x_n) \newline
&amp;=  \lim_{n\rightarrow \infty} \exp( \log x_n)
\end{align}
Or are there sequences that invalidate any of the above identities?</p>

<p>(Edited to repurpose this question).
Please also feel free to add different proofs of $\lim_{n\rightarrow \infty} \sqrt[n]{n}=1$.</p>

 
Answer: <p>Since $x \mapsto \log x$ is a continuous function, and since continuous functions respect limits:
$$
\lim_{n \to \infty} f(g(n)) = f\left( \lim_{n \to \infty} g(n) \right),
$$
for continuous functions $f$, (given that $\displaystyle\lim_{n \to \infty} g(n)$ exists), your proof is entirely correct.  Specifically, 
$$
\log \left( \lim_{n \to \infty} \sqrt[n]{n} \right) = \lim_{n \to \infty} \frac{\log n}{n},
$$</p>

<p>and hence</p>

<p>$$
\lim_{n \to \infty} \sqrt[n]{n} = \exp \left[\log \left( \lim_{n \to \infty} \sqrt[n]{n} \right) \right] =  \exp\left(\lim_{n \to \infty} \frac{\log n}{n} \right) = \exp(0) = 1.
$$</p>

==============================
===============================
Question: <p>Can you give me some hints to prove equality:</p>

<p>$$\sum_{m,n=1}^{\infty} \frac1{(m^2+n^2)^2} =\zeta (2)\ G-\zeta(4)=\frac{\pi^2}{6}\ G-\frac{\pi^4}{90}$$</p>

<p>where $\zeta (t):= \sum\limits_{n=1}^{+\infty} \frac{1}{n^t}$ is the <em>Riemann zeta function</em> and $G := \sum\limits_{n=0}^{\infty} \frac{(-1)^{n}}{(2n+1)^2} \approx 0.915 965 594$ is <em>Catalan's constant</em>?</p>

<p>I tried with some <em>reverse engineering</em>, but I wasn't able to solve the problem at all. Even a good reference may be useful.</p>

<p>Thanks a lot in advance, guys.</p>

 
Answer: <p>This problem can be recast in terms of the famous <a href="http://mathworld.wolfram.com/SumofSquaresFunction.html">problem of the number of ways to represent a positive integer as a sum of squares</a>.  With this perspective, we can see that the following more general statement is true for any $p &gt; 1$ (so that each of the infinite series actually converges):
$$\sum_{n=1}^{\infty} \frac{1}{(n^2)^p} + \sum_{m,n = 1}^{\infty} \frac{1}{(m^2+n^2)^p}  = \left(\sum_{n=1}^{\infty} \frac{1}{n^p}\right) \left(\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)^p}\right).$$</p>

<p>The left-hand side is
$$\sum_{s=1}^{\infty} \frac{n_2(s)}{s^p},$$ where $n_2(s)$ is the number of ways of representing $s$ as the sum of one or of two squares of positive integers, in which order is distinguished (i.e., $1^2 + 2^2$ is counted separately from $2^2+1^2$).</p>

<p>It is known that $n_2(s) = d_1(s) - d_3(s)$ (see eq. 24 in the site linked above), where $d_k(s)$ is the number of divisors of $s$ congruent to $k \bmod 4$.   </p>

<p>The first sum on the right side of the equation has (the $p$th powers of) all positive integers as denominators and the second sum on the right has (the $p$th powers of) all odd numbers as denominators.  After multiplying those sums together, then, $1/s^p$ (ignoring signs) appears on the right as many times as there are odd divisors of $s$.  Each odd divisor of $s$ congruent to $1 \bmod 4$ contributes a $+1/s^p$, and each odd divisor of $s$ congruent to congruent to $3 \bmod 4$ contributes a $-1/s^p$.  Thus the coefficient of $1/s^p$ on the right side is exactly $d_1(s) - d_3(s)$.  Therefore, the right-hand side is also 
$$\sum_{s=1}^{\infty} \frac{n_2(s)}{s^p}.$$</p>

==============================
===============================
Question: <p>I'm a beginner in mathematics and there is one thing that I've been wondering about recently. The formula for the normal distribution is:</p>

<p>$$f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\displaystyle{\frac{(x-\mu)^2}{2\sigma^2}}},$$</p>

<p>However, what are $e$ and $\pi$ doing there? $\pi$ is about circles and the ratio to its diameter, for example. $e$ is mostly about exponential functions, specifically about the fact that $\frac{\mathrm{d}}{\mathrm{d}x} e^x = e^x$.</p>

<p>It is my firm conviction that proofs and articles are available, but could someone perhaps  shed some light on this and please explain in a more 'informal' language what they stand for here?</p>

<p>I'm very curious to know as those numbers have very different meanings as far as I'm concerned.</p>

 
Answer: <p>So I think you want to know "why" $\pi$ and $e$ appear here based on an explanation that goes back to circles and natural logarithms, which are the usual contexts in which one first sees these.</p>

<p>If you see $\pi$, you think there's a circle hidden somewhere. And in fact there is. As has been pointed out, in order for this expression to give a probability density you need $\int_{-\infty}^\infty f(x) \: dx = 1$. (I'm not sure how much you know about integrals -- this just means that the area between the graph of $f(x)$ and the $x$-axis is 1.) But it turns out that this can be derived from $\int_{-\infty}^\infty e^{-x^2} dx = \sqrt{\pi}$. </p>

<p>And it turns out that this is true because the square of this integral is $\pi$. Now, why should the square of this integral have anything to do with circles? Because it's the total volume between the graph of $e^{-(x^2+y^2)}$ (as a function $g(x,y)$ of two variables) and the $xy$-plane.  And of course $x^2+y^2$ is just the square of the distance of $(x,y)$ from the origin -- so the volume I just mentioned is rotationally symmetric. (If you know about multiple integration, see the <a href="http://en.wikipedia.org/wiki/Gaussian_integral" rel="noreferrer">Wikipedia article "Gaussian integral", under the heading "brief proof"</a> to see this volume worked out.)</p>

<p>As for where $e$ comes from -- perhaps you've seen that the normal probability density can be used to approximate the binomial distribution. In particular, the probability that if we flip $n$ independent coins, each of which has probability $p$ of coming up heads, we'll get $k$ heads is
$$ {n \choose k} p^{k} (1-p)^{n-k} $$
where ${n \choose k} = n!/(k! (n-k)!)$. And then there's 
<a href="http://en.wikipedia.org/wiki/Stirling%27s_approximation" rel="noreferrer">Stirling's approximation</a>, 
$$ n! \approx \sqrt{2\pi n} (n/e)^{n}. $$
So if you can see why $e$ appears here, you see why it appears in the normal. Now, we can take logs of both sides of $n! = 1 \cdot 2 \cdot \ldots \cdot n$ to get
$$ \log (n!) = \log 1 + \log 2 + \cdots + \log n $$
and we can approximate the sum by an integral,
$$ \log (n!) \approx \int_{1}^{n} \log t \: dt. $$
But the indefinite integral here is $t \log t - t$,  and so we get the definite integral
$$ \log (n!) \approx n \log n - n. $$
Exponentiating both sides gives $n! \approx (n/e)^n$. This is off by a factor of $\sqrt{2\pi n}$ but at least explains the appearance of $e$ -- because there are logarithms in the derivation. This often occurs when we deal with probabilities involving lots of events because we have to find products of many terms; we have a well-developed theory for sums of very large numbers of terms (basically, integration) which we can plug into by taking logs.</p>

==============================
===============================
Question: <p>This question might be easy.</p>

<p>The hard question is this: prove that if $a,b,c\geq3$ then there are no solutions in positive integers $x,y,z$ to $x^a+y^b=z^c$ with $x,y,z$ <em>coprime</em>. This implies Fermat, most cases of Catalan, etc., and is an open problem.</p>

<p>But it's really crucial that $x,y,z$ are coprime to make this question hard. For example if I want to find <em>any</em> solution to $x^9+y^{10}=z^{11}$ in positive integers, I just start with a random solution to $A+B=C$, e.g. $1+1=2$, and now I multiply by an appropriate power of all the primes dividing $ABC$ to get a solution. For example, if I start with $1+1=2$ then I multiply both sides by $2^N$ and deduce $2^N+2^N=2^{N+1}$. Now it's easy to find a positive $N$ with $N=0$ mod 9, $N=0$ mod 10 and $N=-1$ mod 11, and for this value of $N$ we get a solution in positive integers to $x^9+y^{10}=z^{11}$.</p>

<p>But this trick relies on the fact that 9, 10, 11 are pairwise coprime. It wouldn't surprise me if an extension of the trick could give a solution in positive integers to $x^6+y^{10}=z^{15}$, where the point is that the exponents aren't pairwise coprime, but 5 minutes on the back of an envelope didn't give me the trick I needed, and I thought that here might be a great place to ask.</p>

<p>What's the trick I've missed?</p>

 
Answer: <p>I agree with Qiaochu; there can't be a similar trick in this case. You can't profit from multiplying by common factors because in this case all solutions can be reduced to coprime solutions.</p>

<p>To see this, consider the number of factors of an arbitrary prime $p$ in the equation. We must have</p>

<p>$$rp^{6k}+sp^{10l}=tp^{15m}$$</p>

<p>with $p \nmid r,s,t$. The lowest two powers of $p$ must coincide, since otherwise we could divide through by the lowest and the remaining equation couldn't be fulfilled mod $p$. So we can divide through by this common lowest power of $p$ and leave a power of $p$ in only one of the terms. But since the factors $6$, $10$ and $15$ are such that the least common multiple of each pair is a multiple of the third, dividing through by a multiple of that least common multiple will just substract a multiple of the third factor in the exponent of the third term, still leaving a multiple of that factor. It follows that we could have divided each of the numbers by an appropriate power of $p$ to begin with, leaving a power of $p$ in only one of the three. Doing this for all primes, we can reduce all solutions to coprime solutions.</p>

==============================
===============================
Question: <p>Similar to <a href="https://math.stackexchange.com/questions/29022/counting-number-of-sequences-under-cyclic-permutation">a previous question here</a>, I wonder if cyclic permutations are the only relations amongst traces of (non-commutative) monomials.  Since the evaluations $\operatorname{tr}:k\langle x,y,\dots \rangle \to k$ take an infinite dimensional vector space to a one-dimensional vector space there must be quite a few relations, but I wonder if any of them are on binomials other than the cyclic permutations.</p>

<p>At any rate, for small dimensions, we probably get some extra relations.</p>

<p>It appears that $\operatorname{tr}(AABABB−AABBAB) = 0$ for all $2×2$ matrices.  Is this true?  How does one prove it?</p>

 
Answer: <p>First if $N$ is $2\times2$ matrix with $\operatorname{tr}(N)=0$, then $N^2$ is scalar (either $N$ is nilpotent or its eigenvalues are opposite and have same square). This implies that $\operatorname{tr}(N^3)=0$. </p>

<p>And 
$$\begin{eqnarray}
(AB-BA)^3 &amp;=&amp; (ABABAB - BABABA) + (ABBABA + BABAAB + BAABBA) \\
 &amp;&amp; - (ABABBA + ABBAAB + BAABAB)

\end{eqnarray}
$$</p>

<p>taking the trace this gives</p>

<p>$$0 = 0 + 3\operatorname{tr}(ABBABA) - 3 \operatorname{tr}(ABABBA) = 3 \operatorname{tr}(AABBAB - AABABB).$$</p>

==============================
===============================
Question: <p>Let $(B_i)_{i\in I}$ be an indexed family of closed, connected sets in a compact space X. Suppose $I$ is ordered, sucht that $i &lt; j \implies B_i \supset B_j$.</p>

<p>Is $B = \bigcap_i B_i$ necessarily connected?</p>

<p>I can prove it, if I assume $X$ to be Hausdorff as well: If $B$ is not connected, then there are two disjoint, closed, nonempty sets $C$, $D$ in $B$, such that $C \cup D = B$. Now these sets are also closed in $X$, hence by normality there exist open disjoint neighborhoods $U$, $V$ of $C$ and $D$, respectively.</p>

<p>Then for all $i$: $B_i \cap U^c \cap V^c \ne \emptyset$, since $B$ is contained in $B_i$ and $B_i$ is connected. Thus we must also have</p>

<p>$$ B \cap U^c \cap V^c = \bigcap_i B_i \cap U^c \cap V^c \ne \emptyset $$</p>

<p>by compactness and the fact that the $B_i$ satisfy the finite intersection property. This is a contradiction to the choice of $U$ and $V$.</p>

<p>I can neither see a counterexample for the general case, nor a proof. Any hints would be greatly appreciated!</p>

<p>Thanks,</p>

<p>S. L.</p>

 
Answer: <p>I think the following is a counterexample: take $Y=[-1,1]\times\{a,b\}$, where $[-1,1]$ has the standard topology, and $\{a,b\}$ the discrete topology, and let $X=Y/\sim$, $y\sim y&#39;$ if and only if there exist $x\in[0,1]$ such that $y=(x,a)$ and $y&#39;=(x,b)$, or $y=(x,b)$ and $y&#39;=(x,a)$. That is, identify all points except $0$. Give $X$ the quotient topology</p>

<p>This is the interval $[-1,1]$ with "a doubled origin", a common proving ground because the space is $T_1$ but not $T_2$, but any two points other than the doubled origins can be separated by open neighborhoods. (So, in a sense, it is "almost" Hausdorff; the Hausdorff property only fails for one choice of points, and there are lots of other points around). </p>

<p>Since $Y$ is compact and the quotient map is continuous and onto, $X$ is compact. </p>

<p>For every positive integer $n$, let $\mathcal{B}_n\subseteq Y$ be the set $[-\frac{1}{n},\frac{1}{n}]\times\{a,b\}$, and let $B_n$ be the image of $\mathcal{B_n}$ in $X$; that is, $B_n$ is the interval from $-\frac{1}{n}$ to $\frac{1}{n}$, including both origins. </p>

<p>$B_n$ is closed, since $X-B_n = [-1,-\frac{1}{n})\cup(\frac{1}{n},1]$ is a union of two open sets. It is also connected, because $B_n$ is a union of two connected subsets (the two copies of the interval $[-\frac{1}{n},\frac{1}{n}]$ obtained by removing one of the two $0$s) and the two subsets intersect.</p>

<p>What is $\cap_{n=1}^{\infty}B_n$? It's a set whose only two elements are the doubled origin points. But this subset of $X$ is not connected, because $X$ is $T_1$, so there exist open neighborhoods $U$ and $V$ such that $(0,a)\in U-V$ and $(0,b)\in V-U$. So $B\subseteq U\cup V$, $U\cap B\neq\emptyset \neq V\cap B$, and $B\cap U\cap V = \emptyset$. </p>

==============================
===============================
Question: <p>How can I prove that if I have $n$ eigenvectors from different eigenvalues, they are all linearly independent?</p>

 
Answer: <p>I'll do it with two vectors. I'll leave it to you do it in general.</p>

<p>Suppose $\mathbf{v}_1$ and $\mathbf{v}_2$ correspond to distinct eigenvalues $\lambda_1$ and $\lambda_2$, respectively. </p>

<p>Take a linear combination that is equal to $0$, $\alpha_1\mathbf{v}_1+\alpha_2\mathbf{v}_2 = \mathbf{0}$. We need to show that $\alpha_1=\alpha_2=0$.</p>

<p>Applying $T$ to both sides, we get
$$\mathbf{0} = T(\mathbf{0}) = T(\alpha_1\mathbf{v}_1+\alpha_2\mathbf{v}_2) = \alpha_1\lambda_1\mathbf{v}_1 + \alpha_2\lambda_2\mathbf{v}_2.$$
Now, instead, multiply the original equation by $\lambda_1$:
$$\mathbf{0} = \lambda_1\alpha_1\mathbf{v}_1 + \lambda_1\alpha_2\mathbf{v}_2.$$
Now take the two equations,
$$\begin{align*}
\mathbf{0} &amp;= \alpha_1\lambda_1\mathbf{v}_1 + \alpha_2\lambda_2\mathbf{v}_2\\
\mathbf{0} &amp;= \alpha_1\lambda_1\mathbf{v}_1 + \alpha_2\lambda_1\mathbf{v}_2
\end{align*}$$
and taking the difference, we get:
$$\mathbf{0} = 0\mathbf{v}_1 + \alpha_2(\lambda_2-\lambda_1)\mathbf{v}_2 = \alpha_2(\lambda_2-\lambda_1)\mathbf{v}_2.$$</p>

<p>Since $\lambda_2-\lambda_1\neq 0$, and since $\mathbf{v}_2\neq\mathbf{0}$ (because $\mathbf{v}_2$ is an eigenvector), then $\alpha_2=0$. Using this on the original linear combination $\mathbf{0} = \alpha_1\mathbf{v}_1 + \alpha_2\mathbf{v}_2$, we conclude that $\alpha_1=0$ as well (since $\mathbf{v}_1\neq\mathbf{0}$).</p>

<p>So $\mathbf{v}_1$ and $\mathbf{v}_2$ are linearly independent.</p>

<p>Now try using induction on $n$ for the general case.</p>

==============================
===============================
Question: <p>To prove the convergence of the p-series </p>

<p>$$\sum_{n=1}^{\infty} \frac1{n^p}$$</p>

<p>for $p &gt; 1$, one typically appeals to either the Integral Test or the Cauchy Condensation Test.</p>

<p>I am wondering if there is a self-contained proof that this series converges which does not rely on either test.  </p>

<p>I suspect that any proof would have to use the ideas behind one of these two tests.</p>

 
Answer: <p>We can bound the partial sums by multiples of themselves:</p>

<p>$$\begin{eqnarray}
S_{2k+1}
&amp;=&amp;
\sum_{n=1}^{2k+1}\frac{1}{n^p}\\
&amp;=&amp;
1+\sum_{i=1}^k\left(\frac{1}{(2i)^p}+\frac{1}{(2i+1)^p}\right)\\
&amp;&lt;&amp;1+\sum_{i=1}^k\frac{2}{(2i)^p}\\
&amp;=&amp;1+2^{1-p}S_k\\
&amp;&lt;&amp;1+2^{1-p}S_{2k+1}\;.
\end{eqnarray}$$</p>

<p>Then solving for $S_{2k+1}$ yields</p>

<p>$$S_{2k+1}&lt;\frac{1}{1-2^{1-p}}\;,$$</p>

<p>and since the sequence of partial sums is monotonically increasing and bounded from above, it converges.</p>

==============================
===============================
Question: <p>This question relates to a discussion on <a href="http://newcafe.org/motet/bin/motet.cgi?show%20-uwRlEv%20-h%20Science%207%20671">another message board</a>. Euclid's proof of the infinitude of primes is an indirect proof (a.k.a. proof by contradiction, reductio ad absurdum, modus tollens). My understanding is that Intuitionists reject such proofs because they rely on the Law of the Excluded Middle, which they don't accept. Does there exist a direct and constructive proof of the infinitude of primes?</p>

 
Answer: <p>Due to a widely propagated historical error, it is commonly misbelieved that Euclid's proof was by contradiction. This is false. Euclid's proof was in fact presented in the obvious constructive fashion. See Hardy and Woodgold's <a href="http://www.artofproblemsolving.com/Forum/download/file.php?id=27070" rel="nofollow noreferrer">Intelligencer article[1]</a> for a detailed analysis of the history (based in part on many sci.math discussions [2]). </p>

<p>A variant that deserves to be much better known is the following folklore one-line proof that there are infinitely many prime integers</p>

<p>$\rm\qquad\qquad N\ (N+1)\ $ has a larger set of prime factors than does $\rm\:N.$</p>

<p>because $\rm\,N+1&gt;1\,$ is coprime to $\,\rm N\,$ so it has a prime factor which does not divide $\rm\,N.$
Curiously, Ribenboim believes this proof to be of recent vintage, attributing it to Filip Saidak. But I recall seeing variants published long ago. Does anyone know its history?</p>

<p>For even further variety, here is a version of Euclid's proof reformulated into infinite <em>descent</em> form. If there are only finitely many primes, then given any prime $\rm\:p\:$ there exists a smaller prime, namely the least factor $&gt; 1$ of $\rm\ 1 + $ product of all primes $\rm \ge p\:.$</p>

<p>It deserves to be much better known that Euclid's constructive proof generalizes very widely - to any fewunit ring, i.e. any ring having fewer units than elements - <a href="http://www.artofproblemsolving.com/Forum/viewtopic.php?p=1209616#p1209616" rel="nofollow noreferrer">see my proof here</a>. $ $ The key idea is that Euclid's construction of a new prime generalizes from elements to ideals, i.e. given some maximal ideals $\rm\ P_1,\ldots,P_k\:,\: $ 
a simple pigeonhole argument employing $\rm CRT$ deduces that  $\rm\ 1+P_1\:\cdots\:P_k\ $ contains a nonunit, which lies in some maximal ideal  which, by construction, 
is comaximal (so distinct) from the initial max ideals $\rm\:P_1,\ldots,P_k\:.$</p>

<p>[1] Michael Hardy; Catherine Woodgold<br>
Prime Simplicity.<br>
The Mathematical Intelligencer, Volume 31, Number 4, 44-52.<br>
<a href="http://dx.doi.org/10.1007/s00283-009-9064-8" rel="nofollow noreferrer">DOI link</a> $ $  or $ $  <a href="http://www.springerlink.com/content/m0t8727288823ug5/" rel="nofollow noreferrer">Springer link</a> $ $ or $ $
<a href="http://www.artofproblemsolving.com/Forum/download/file.php?id=27070" rel="nofollow noreferrer">free link</a>  </p>

<p>[2] Note: Although the article [1] makes no mention of such, it appears to have strong roots in frequent sci.math discussions - in which the first author briefly participated. A Google groups search in the usenet newsgroup sci.math for "Euclid plutonium" will turn up many long discussions on various misinterpretations of Euclid's proof.</p>

==============================
===============================
Question: <p>I would like to know if someone can explain in a somehow down to earth (almost logic free) way why is it true that in an axiom system where there is some statement $P$ such that $P$ and its negation $\lnot P$ are true, then every statement in the system is true?</p>

<p>I'm not sure if this can be done, but basically since I don't know any formal logic at all, I'm interested in seeing if at least the argument can be conveyed in an intuitive way, or if the idea can be explained without talking about first or second order logic and using symbols like $\top$, $\bot$, and $\vdash$.</p>

<p>This <a href="https://math.stackexchange.com/questions/5564/why-an-inconsistent-formal-system-can-prove-everything">previous question</a> is like the formal version (which I don't understand) so maybe my question can be thought of as a version for dummies of that question. </p>

<p>Thanks a lot in advance.</p>

 
Answer: <p>I'll try to say this all in plain English:</p>

<p>Let's say we decide to accept the following two facts: (1) "I am a fish", and (2) "I am not a fish". Just keep those in mind.</p>

<p>Now let's pick any old statement, say: (3) "You can fly". Now let's prove that the statement is true!</p>

<p>Alright, we've already accepted that (1) "I am a fish". Of course, any time I have a true statement <em>P</em>, I can make a new true statement by making the statement "<em>P</em> or <em>Q</em> is true." Because to check if an 'or' statement is true, I only need to check that one of them is true. (If I tell you "My name is Dylan OR I can spit fire," you don't need to wait around with a fire extinguisher to tell if that statement is true. It's true because the first part of it is true).</p>

<p>So by this logic, the statement (4) "I am a fish or you can fly" must be true (since the first part is true.)</p>

<p>OK, but now let's say, in general, I have some 'or' statement "<em>P</em> or <em>Q</em>" and I know for a fact that the whole statement is true. If I also know that <em>P</em> is <em>false</em> then I can conclude that <em>Q</em> is true. Right? Because an 'or' statement is true if and only if <em>at least one</em> of the statements inside it is true, so if I rule out one of them the other one <em>must</em> be true. (So if I always tell the truth and I tell you that you have a billion dollars in your bank account OR I just ate a sandwich, you can check your bank account and quickly conclude that I just ate lunch... unless you're very wealthy.)</p>

<p>Alright, so far so good. We <em>know</em> the statement "I am a fish or you can fly" is definitely true. But wait, we <em>also</em> know that the statement "I am a fish" is <em>false</em> (remember, it's one of the things we assumed in the very beginning!). So that means, by what we just talked about, that the statement "You can fly" must be true.</p>

<p>So voilà! Using the magic of a contradictory system, we've proven you can fly!</p>

==============================
===============================
Question: <p>Suppose $R$ is a finite ring (commutative ring with $1$) of characteristic $3$ and suppose that for every unit $u \in R\:,\ 1+u\ $ is also a unit or $0$. We need to show that $R$ is a field. Is this true if ${\rm char}(R) &gt; 3$?</p>

<p>Here is what I attempted to do. $\:$  First of all, $\:$ I noticed that the statement is not true if $\ R\ $ is infinite ($ \mathbb F_3[x]$ is an example of an infinite ring which is not a field but it satisfies all the required properties). Now, in a finite ring, a non-zero element is either a unit or a $\:0\:$ divisor, so I tried to show that $R$ has no $\:0\:$ divisors. Clearly, $R$ has no nonzero nilpotent elements (if $x$ is nilpotent, then $1+x$ is a unit, but then $1+(1+x)$ and $1+(2+x)$ is either a unit or $\:0\:.\:$ Hence $x$ is either a unit or $\:0\:,\:$ and since $x$ is nilpotent, it can't be a unit, so we must have $x = 0$). But this does not solve the problem, since $R$ could have elements that are $\:0\:$ divisors but not nilpotent (for example, $\ (1,0)\ $ is a $\:0\:$ divisor in $\ \mathbb Z/3\:\mathbb Z \times \mathbb Z/3\:\mathbb Z\ $ but it is not nilpotent).</p>

<p>Another observation I made is that the set of units, together with $\:0\:$ forms a group under addition, so that $J = R^{*}$, together with $\:0\:$ is a subring of $R$. hence we may view $R$ as a $J$-module (and since $J$ is clearly a field, $R$ is a $J$-vector space). </p>

<p>Another thing I tried is to show that $R$ has no proper nontrivial ideals. Viewing $R$ and $J$ as abelian groups, I noticed that a non-trivial ideal of $R$ can contain at most one element from each coset of $J$ in $R$, because if an ideal contains two distinct elements from the same coset of $J$ in $R$, this ideal would have to contain their difference, hence it'd have to contain a unit, hence it would not be a proper ideal. But again, I don't see how this observation leads to a solution.</p>

<p>As for the last part, I suspect that this statement will remain true if ${\rm char}(R) &gt; 3$. Since $1$ is a unit, it follows that $1,2,3,\ldots$ are all either units or $0$, which can only happen if ${\rm char}(R) = p$, a prime number (and then I suspect that $R$ will have to be a finite field), but again  I do not see how to prove (or disprove) this.</p>

<p>By the way, this is not a homework problem. I am studying algebra on my own, and after thinking about it for a few days and making the observations I listed above, I still don't see how to finish the proof. I would appreciate your suggestions. Thank you in advance. </p>

 
Answer: <p>The map $f: x\rightarrow {x^3}$ is a homomorphism from $R$ to $R$.  The kernel of $f$ is $\{0\}$ because $x^3=0$ implies $(x-1)^3=-1$, which means that $x-1$ is a unit, hence $x$ is a unit or zero, hence that $x=0$.  So $f$ is 1-1, and, since $R$ is finite, it is thus an automorphism of $R$.</p>

<p>Then there must be an $n&gt;0$ such that $f^n$ is the identity, that is: $x^{3^n}=x$ for all $x\in{R}$</p>

<p>Assume $r$ is not a unit, and let $s=r^{3^n-1}+1$.  A quick computation shows that $s^2=1$, so $s$ must be a unit.  But that means that $s+2$ must be a unit or zero, and $s+2$ is a power of $r$, a non-unit, so $r^{3^n-1}=0$ and $r=r^{3^n} = 0$.</p>

<p>The same argument works for arbitrary prime $p$.  First you prove that $x \rightarrow x^p$ is an ring automorphism, find n such that $r^{p^n}=r$, and then using $s=r^{p^n-1} +1$, prove that $s^{p-1}=1$.  A little harder to prove, requiring to know that</p>

<p>$${{p-1}\choose{i}} \equiv (-1)^i \pmod{p}$$</p>

<p>[That doesn't work when $p=2$, of course, and the theorem is not true for p=2.  In that case, you can take the ring $\{0,1,x,x+1\}$ with the rule $x^2=x$.]</p>

==============================
===============================
Question: <p>How can I evaluate
$$\sum_{n=1}^\infty\frac{2n}{3^{n+1}}$$
I know the answer thanks to <a href="http://www.wolframalpha.com/input/?i=Sum%5B%282n%29/3%5E%28n%20%2b%201%29,%20%7Bn,%201,%20Infinity%7D%5D" rel="noreferrer" title="Wolfram Alpha">Wolfram Alpha</a>, but I'm more concerned with how I can derive that answer. It cites tests to prove that it is convergent, but my class has never learned these before so I feel that there must be a simpler method.</p>

<p>In general, how can I evaluate $$\sum_{n=0}^\infty (n+1)x^n?$$</p>

 
Answer: <p>No need to use Taylor series, this can be derived in a similar way to the formula for geometric series. Let's find a general formula for the following sum: $$S_{m}=\sum_{n=1}^{m}nr^{n}.$$ </p>

<p>Notice that 
\begin{align*}
S_{m}-rS_{m} &amp; = -mr^{m+1}+\sum_{n=1}^{m}r^{n}\\
  &amp; = -mr^{m+1}+\frac{r-r^{m+1}}{1-r} \\
&amp; =\frac{mr^{m+2}-(m+1)r^{m+1}+r}{1-r}.
\end{align*}<br>
Hence 
$$S_m = \frac{mr^{m+2}-(m+1)r^{m+1}+r}{(1-r)^2}.$$<br>
This equality holds for any $r$, but in your case we have $r=\frac{1}{3}$ and a factor of $\frac{2}{3}$ in front of the sum.    That is 
\begin{align*}
\sum_{n=1}^{\infty}\frac{2n}{3^{n+1}} 
&amp; = \frac{2}{3}\lim_{m\rightarrow\infty}\frac{m\left(\frac{1}{3}\right)^{m+2}-(m+1)\left(\frac{1}{3}\right)^{m+1}+\left(\frac{1}{3}\right)}{\left(1-\left(\frac{1}{3}\right)\right)^{2}} \\
&amp; =\frac{2}{3}\frac{\left(\frac{1}{3}\right)}{\left(\frac{2}{3}\right)^{2}} \\
&amp; =\frac{1}{2}.
\end{align*}</p>

<p><strong>Added note:</strong>  </p>

<p>We can define $$S_m^k(r) = \sum_{n=1}^m n^k r^n.$$  Then the sum above considered is $S_m^1(r)$, and the geometric series is $S_m^0(r)$.  We can evaluate $S_m^2(r)$ by using a similar trick, and considering $S_m^2(r) - rS_m^2(r)$.  This will then equal a combination of $S_m^1(r)$ and $S_m^0(r)$ which already have formulas for.  </p>

<p>This means that <em>given</em> a $k$, we could work out a formula for $S_m^k(r)$, but can we find $S_m^k(r)$ in general for any $k$?  It turns out we can, and the formula is similar to the formula for $\sum_{n=1}^m n^k$, and involves the Bernoulli numbers. In particular, the denominator is $(1-r)^{k+1}$.</p>

==============================
===============================
Question: <p>This problem comes from <em>Calculus</em> by Spivak, namely in Chapter 14- "The Fundamental Theorem of Calculus". </p>

<blockquote>
  <p>Suppose that $f$ is a differentiable function with $f(0)=0$ and $0&lt;f&#39;\le1$. Prove that for all $x\ge0$ we have $$ \int_0^x f^3 \le \left(\int_0^x f\right)^2. $$</p>
</blockquote>

<p>Now, I have a (proposed) solution, so my question is whether the following is correct.</p>

<p>We know that both the l.h.s. and r.h.s. of the inequality begin at 0, so we can prove the inequality by showing that the same inequality holds for the derivatives of each side. (If both begin at the same value and one increases more quickly or at the same rate than the other, then that one will also take on a value greater than or equal to the other for all $x\ge0$.) So, we have $$f^3 \le 2f\int_0^x f. $$ If $f=0$ the inequality is clearly satisfied, otherwise we have that $$f^2 \le 2\int_0^x f. $$ We then apply the same logic as before, showing that this inequality holds after differentiating (since, again, both expressions evaluate to 0 when $x=0$). So, we have that $$2ff&#39; \le 2f.$$ We have already taken care of the case that $f=0$ (and the inequality holds anyway for $f=0$) so we end up with $$f&#39; \le 1.$$ This is given, so the first inequality is proven. </p>

<p>I sort of feel (for no particular reason) like part of this may be incorrect, which is why I'm asking here. So if any part (or the whole thing) <em>is</em> incorrect, could someone please point to the mistake? If not, great. Thanks.  </p>

 
Answer: <p>Basically, this is fine, but you seem slightly confused about the logical structure of a backward argument and the $f=0$ business. Every time you say "So, we have that", you should say "So, we want". And going through the proof from bottom to top, you will see that there is no issue at all about potentially multiplying by 0. </p>

<p>I might add as a bonus question that at first sight I wondered if there is any relation to the fact that $\sum_{k=0}^n k^3 = (\sum_{k=0}^n k)^2$ </p>

==============================
===============================
Question: <p>Today I was fooling around a bit trying to count the topologies on a finite set. I didn't make much progress, so I did some googling and quickly discovered it is an open problem to give a closed form expression for the number $T_n$ of topologies on a set with $n$ elements. At this point I asked myself "if I can't compute $T_n$, can I perhaps compute $T_\omega$?". </p>

<p>First I wondered whether it is even obvious that there are uncountably many ways to topologize a countably infinite set $X$. It is. For each $S \subset X$, $\{\varnothing, S, X\}$ is a topology so there are at least $c$ ways to topologize $X$. This is a bit of a cheat though since, up to homeomorphism, this topology depends only on the cardinalities of $S$ and $X-S$ for which there are only countably many possibilities. Thus we are lead naturally to the question in the title:</p>

<blockquote>
  <p>Are there uncountably many non homeomorphic topologies on a countably infinite set?</p>
</blockquote>

<p>The most obvious approach that I could think of was to look at order topologies. Distinct ordinal numbers are not order-isomorphic and there are uncountably many countable ordinals so surely by considering the countable ordinals in their order topologies we exhibit uncountably many nonhomeomorphic spaces... right? There is a gap though because distinct ordinals can be homeomorphic. For instance, if $\alpha \geq \omega$ then $\alpha + 1, \alpha +2, \alpha +3, \ldots$ are all homeomorphic (we can sneak the $n$ isolated points at the end of $\alpha + (n+1)$ into the copy of the $\omega$ at the beginning of $\alpha + 1$). To close the gap, we need to prove that for any countable ordinal $\alpha$ there exists a countable ordinal $\beta &gt; \alpha$ homeomorphic to no ordinal in $[0,\alpha]$. I would be flabbergasted if this did not hold, but to prove it would probably require more set theory than I have at my disposal.</p>

<p>If my title question is easily answered (in the affirmative) then, as a follow up question, I would also be interested to know if we can actually determine the number of topologies on a countable set (either topologies proper, or topologies up to homeomorphism). At the moment it would seem I can do little more than supply the obvious upper bound of $2^c$ for both quantities...</p>

<p><strong>Added:</strong> There have been several nice answers. Nate (whose answer I accepted) provided probably the slickest way to resolve the title question. </p>

<p>Martin answers the follow up question by showing that the existence of $2^c$ ultrafilters on $\omega$ (this is proved at his first link) implies the existence of $2^c$ topologies on $\omega + 1$ (hence $2^c$ topologies up to homeomorphism since there are only $c$ permutations of a countable set). Actually it seems the proof that there are $2^c$ ultrafilters can easily be adapted to prove the existence of $2^c$ topologies directly. I'll sketch the argument below while I convince myself I understand what's going on.</p>

<p>Let $X$ be the (countable) set of all subsets of $\mathbf{R}$ which are finite unions of intervals with rational endpoints. For any of the $2^c$ sets $S \subset \mathbf{R}$ we get a basis $\mathscr{B}_S$ for a toplogy on $X$ consisting of all sets $U_S(F) := \{ x \in X : x \cap F = S \cap F \}$ as $F$ ranges over finite subsets of $\mathbf{R}$. This is a basis since if $x \in B(F_1) \cap B(F_2)$ then $x \in B(F_1 \cup F_2) \subset B(F_1) \cap B(F_2)$. It remains to check that different subsets of $\mathbf{R}$ give rise to different topologies. In fact, if $\mathscr{B}_T$ is a refinement of $\mathscr{B}_S$ then $S \subset T$. Suppose that $s \in S$. If $\mathscr{B}_T$ refines $\mathscr{B}_S$ then there should exist a finite subset $F \subset \mathbf{R}$ so that $U_T(F) \subset U_S(\{s\})$. Wlog $s \in F$ since $U_T(F \cup \{s\}) \subset U_T(F)$. If $s \notin T$ then we have $s \notin x$ for all $x \in U_T(F)$ while $s \in x$ for all $x \in U_S(\{s\})$ so these basis elements are disjoint. Thus $s \in T$ must obtain and we are done.  </p>

 
Answer: <p>Here's a simple, though non-optimal, answer.</p>

<p>In any topological space $(X,\tau)$, let us say an open set $U$ is <strong>minimal</strong> if for every open $V \subset U$, either $V=U$ or $V=\emptyset$.  (That is, it has no nonempty proper open subsets; it is in some sense an "atom".)  For a natural number $n$, let $F_\tau(n)$ be the number of minimal open sets which contain $n$ elements.  It's easy to see that the function $F_\tau$ is preserved by homeomorphisms, so topologies with different $F_\tau$s are non-homeomorphic.</p>

<p>If $X = \{x_1, x_2, \dots\}$ is a countable set, for any function $F : \mathbb{N} \to \mathbb{N}$, we can produce a topology $\tau$ on $X$ with $F_\tau = F$.  Just choose any partition $P$ of $X$ which contains $F(n)$ sets of size $n$, and take the topology $\tau$ generated by $P$ (and note that in $\tau$, the sets of $P$ are minimal open).  For instance, if $F(n) = n$, we could take a partition like
$$\{ \{x_1\}, \{x_2,x_3\},\{x_4,x_5\}, \{x_6,x_7,x_8\}, \{x_9, x_{10}, x_{11}\}, \{x_{12},x_{13},x_{14} \}, \cdots \}.$$</p>

<p>Since $\mathbb{N}^\mathbb{N}$ is uncountable, this produces uncountably many non-homeomorphic topologies on $X$.  </p>

<p>Of course there are only $\mathfrak{c}$ of these, not $2^\mathfrak{c}$, but at least they are simple.</p>

==============================
===============================
Question: <p>I recently saw a lecturer prove the following theorem (assuming the result that every analytic function is locally 1-1 whenever its derivative is nonzero): Let $\Omega \subset \mathbb{C}$ be open, and let $f : \Omega \to \mathbb{C}$ be 1-1 and analytic on $\Omega$.  Then $f&#39;(z_0) \not = 0$ for every $z_0 \in \Omega$.</p>

<p>I got the basic idea behind the proof: we assume for contradiction that $f&#39;(z_0) = 0$, and, assuming without loss of generality that $z_0 = f(z_0) =0$, we have (from the power-series expansion) that $f(z) = z^kg(z)$ for some analytic $g$ in some disk at the origin (i.e., $z_0$) and some $k \ge 2$. Since $z^k$ is not 1-1 in any such disk (because there are multiple roots of unity), then $f$ isn't either.</p>

<p>However, the proof he gave was rather awkward and technical- it involved defining three different axillary functions, even though the idea was simple, and I've since forgotten how it exactly worked.  In any case, I'm convinced there's a better way.</p>

<p>The problem is that I'm having trouble turning the idea into a real proof- I know that it obviously follows if $g$ is 1-1, but I'm also pretty sure that that is too strong an assumption.  Am I missing something, or does the argument just have to be more complicated?</p>

 
Answer: <p>I like proving this theorem via its contrapositive rather than by contradiction (though the computations are essentially the same).  </p>

<p>Suppose $f:\Omega\to\mathbb{C}$ is analytic with $f'(z_0)=0$.  The goal is to show that every disc about the origin contains distinct $z_1,z_2$ with $f(z_1)=f(z_2)$.  We may assume that $z_0=f(z_0)=f'(z_0)=0$ (using $f(z+z_0)-f(z_0)$ if necessary, as translation doesn't affect injectivity).  Since $f$ is analytic at $z=0$ and $f'(0)=f(0)=0$, $f$ has a power series expansion $$f(z)=a_k z^k + a_{k+1} z^{k+1} + \dots$$ where $k&gt;1$.  Pulling out a $z^k$ gives $$f(z)=z^k (a_k + a_{k+1}z + \dots) = z^k g(z)$$ where $g$ is analytic with $g(0)\neq0$.  Since $g$ is nonzero on a sufficiently small disc centered at the origin, we can define an appropriate branch its log so that its k<sup>th</sup> root is well-defined.  Call this function $h$, so that $h$ is analytic with $h(z)^k=g(z)$ near the origin.  Hence $$f(z)=\left(zh(z)\right)^k.$$  Note that $\phi(z)=zh(z)$ is analytic (near $z=0$).  Therefore, for any $\epsilon&gt;0$ (sufficiently small), $\phi(D(0,\epsilon))$ is open (by the Open Mapping Theorem) and hence contains a disc $D(0,2\delta)$.  In particular, there exist $z_1,z_2\in D(0,\epsilon)$ with $\phi(z_1)=\delta$ and $\phi(z_2)=\delta \exp\left(\frac{2\pi i}{k}\right)$.  Therefore $$f(z_2)=\delta^k \exp\left(\frac{2\pi i}{k}\right)^k = \delta^k = f(z_1)$$ as desired.</p>

<hr>

<p>The proof does look a bit clunky, especially with all the auxilliary functions.  However, it's actually fairly simple and the extra functions are really just to show why each step is valid.  In fact, the gist of the proof is:</p>

<ol>
<li><p>Show that $f$ is the k<sup>th</sup> power of some analytic function $\phi$</p></li>
<li><p>Show that you can always find $z_1,z_2$ where $\phi(z_1)$ and $\phi(z_2)$ lie on the same circle and their arguments differ by $\frac{2\pi}{k}$, so that their k-th powers are equal.</p></li>
</ol>

==============================
===============================
Question: <p>The <a href="http://en.wikipedia.org/wiki/Catalan_number">Catalan numbers</a> have a reputation for turning up everywhere, but the occurrence described below, in the analysis of an (incorrect) algorithm, is still mysterious to me, and I'm curious to find an explanation.</p>

<hr>

<p>For situations where a quadratic-time sorting algorithm is fast enough, I usually use the following:</p>

<pre><code>//Given array a[1], ... a[n]
for i = 1 to n:
    for j = i+1 to n:
        if a[i] &gt; a[j]:
            swap(a[i],a[j])
</code></pre>

<p>It looks like bubble sort, but is closer to selection sort. It is easy to see why it works: in each iteration of the outer loop, <code>a[i]</code> is set to be the smallest element of <code>a[i…n]</code>.</p>

<p>In a programming contest many years ago, one of the problems essentially boiled down to sorting:</p>

<blockquote>
  <p>Given a list of distinct values $W_1, W_2, \dots, W_n$, find the indices when it is sorted in ascending order. In other words, find the permutation $(S_1, S_2, \dots, S_n)$ for which $W_{S_1} &lt; W_{S_2} &lt; \dots &lt; W_{S_n}$.</p>
</blockquote>

<p>This is simply a matter of operating on the indices rather than on the array directly, so the correct code would be:</p>

<pre><code>//Given arrays S[1], ..., S[n] (initially S[i]=i ∀i) and W[1], ..., W[n]
for i = 1 to n:
    for j = i+1 to n:
        if W[S[i]] &gt; W[S[j]]:
            swap(S[i],S[j])
</code></pre>

<p>But in the heat of the contest, I instead coded a program that did, incorrectly:</p>

<pre><code>for i = 1 to n:
    for j = i+1 to n:
        if W[i] &gt; W[j]:
            swap(S[i],S[j])
</code></pre>

<p>I realised the mistake after the contest ended, and later while awaiting the results, with desperate optimism I tried to figure out the odds that for some inputs, my program would accidentally give the right answer anyway. Specifically, I counted the number of permutations of an arbitrary list $W_1, \dots, W_n$ with distinct values (since only their <em>order</em> matters, not their actual values) for which the incorrect algorithm above gives the correct answer, for each n:</p>

<pre><code>n       Number of "lucky" permutations
0       1
1       1
2       2
3       5
4       14
5       42
6       132
7       429
8       1430
9       4862
10      16796
11      58786
12      208012
</code></pre>

<p>These are the Catalan numbers! But why? I've tried to prove this occasionally in my free time, but never succeeded.</p>

<hr>

<p>What I've tried:</p>

<ul>
<li><p>The (pseudo)algorithm can be represented in more formal notation as the product of all inversions in a permutation. That is, we want to prove that the number of permutations $\sigma \in S_n$ such that $$\prod_{i=1}^{n}\prod_{j=i+1}^{n}_{\sigma_i &gt; \sigma_j}(i,j) = \sigma^{-1}$$ (with the convention that multiplication is done left to right) is $C_n$. This change of notation does not make the problem any simpler.</p></li>
<li><p>I briefly skimmed through <a href="http://www-math.mit.edu/~rstan/ec/">Stanley's famous list of Catalan problems</a>, but this does not seem to be (directly) in the list. :-)</p></li>
<li><p>Some computer experimentation suggests that the lucky permutations are those that avoid the <a href="http://en.wikipedia.org/wiki/Permutation_pattern">pattern</a> 312, the number of which is apparently the Catalan numbers. But I have no idea how to prove this, and it may not be the best approach...</p></li>
</ul>

 
Answer: <p>Your suspicions are correct. Let's show that a permutation is lucky iff it avoids the pattern 312.</p>

<p>For an injection $W$ from $\{1,\ldots,k\}$ to $\{n-k+1,\ldots,n\}$, let $N(W)$ denote the operation of removing $W(1)$ and increasing all elements below $W(1)$ by $1$. For example, $N(32514) = N(3524)$.</p>

<p><b>Lemma 1.</b>
If $W$ avoids $312$ then so does $N(W)$.</p>

<p><b>Proof.</b>
Clear since the relative order of elements in $N(W)$ is the same as the corresponding elements in $W$.</p>

<p><b>Lemma 2.</b>
Suppose $W$ avoids $312$. After running one round of the algorithm, $S(1)$ contains the index of the minimal element in $W$, and $W \circ S = N(W)$.</p>

<p><b>Proof.</b>
The lemma is clear if $W(1)$ is the minimal element. Otherwise, since $W$ avoids $312$, all elements below $W(1)$ form a decreasing sequence $W(1) = W(i_1) &gt; \cdots &gt; W(i_k)$. The algorithm puts the minimal one $W(i_k)$ at $S(1)$, and puts $W(i_t)$ at $W(i_{t+1})$.</p>

<p><b>Theorem 1.</b>
If $W$ avoids $312$ then $W$ is lucky.</p>

<p><b>Proof.</b>
Apply Lemma 2 repeatedly. Lemma 1 ensures that the injection always avoids $312$.</p>

<p>For the other direction, we need to be slightly more careful.</p>

<p><b>Lemma 3.</b>
If $W$ contains a pattern $312$ in which $3$ doesn't correspond to $W(1)$ then $N(W)$ contains a pattern $312$.</p>

<p><b>Proof.</b>
The pattern survives in $N(W)$ since all relative positions are maintained.</p>

<p><b>Lemma 4.</b>
If $W$ doesn't contain a pattern $312$ in which $3$ corresponds to $W(1)$ and $1$ corresponds to the minimum of $W$ then after running one round of the algorithm, $S(1)$ contains the index of the minimal element, and $W \circ S = N(W)$.</p>

<p><b>Proof.</b>
Follows directly from the proof of Lemma 2.</p>

<p>Thus we should expect trouble if there are $i&lt;j$ such that $W(1) &gt; W(j) &gt; W(i)$. However, if $W(i)$ is not the minimal element, the trouble won't be immediate. </p>

<p>List the elements which are smaller than $W(1)$ as $W(t_1),\ldots,W(t_k)$, and suppose that $W(t_r) &lt; W(t_{r+1}) &gt; \cdots &gt; W(t_k)$. One round of the algorithm puts $t_r$ at the place of $t_{r+1}$. The following rounds maintain the relative order of the elements in positions $t_{r+1},\ldots,t_k$, and so in the final result, the position which should have contained $t_{r+1}$ will contain $t_r$.</p>

<p>Example: $W = 632541$. The final result is $S = 652134$, which corresponds to the permutation $143625$. We can see that $S(1)$ is correct since $W$ satisfies the conditions of Lemma 4. We have $t_r = 3$ and $W(t_r) = 2, W(t_{r+1}) = 5$. We see that indeed $W(S(5)) = 2$ instead of $5$.</p>

<p><b>Theorem 2.</b>
If $W$ contains $312$ then $W$ is unlucky.</p>

<p><b>Proof.</b>
Along the lines of the discussion above.</p>

==============================
===============================
Question: <p>While going through <a href="http://www.math.duke.edu/~rtd/PTE/pte.html" rel="noreferrer">Probability: Theory and Examples</a> by Rick Durrett (4th edition, p.9), I came across the familiar definition of $\sigma$-algebras where, if $A_i \in \mathcal{F}$ is a countable sequence of sets for some $\sigma$-algebra $\mathcal{F}$ and $\cup_i A_i \in \mathcal{F}$ by definition, then it follows that $\cap_i A_i^C \in \mathcal{F}$ by de Morgan's law.</p>

<p>That's when it occurred to me that I had never seen a proof that de Morgan's law holds over a countably infinite number of sets. I don't have my measure theory/probably theory books with me right now, but I'm quite sure that I've never seen any of them prove this before extending $\sigma$-algebras to countable union or intersection, depending on which definition it started with.</p>

<p>On the one hand, it seems obvious that it would hold. On the other hand, seeming obvious is not a proof, especially when it comes to something involving infinity.</p>

<p>I can imagine an inductive proof where I</p>

<ol>
<li>assume de Morgan's law holds for an index set of size $n$</li>
<li>Then prove that it holds for an index set of size $n+1$</li>
</ol>

<p>and wrap it up by $n \rightarrow \infty$ but I'm not convinced that's right. For example, an argument like that doesn't work for countable intersection being closed on a collection of open sets.</p>

<p>So what's a good proof that can extend de Morgan's law to an infinite collection of sets.</p>

 
Answer: <p>The result holds for every family, countable or not, of sets A(i) and <em>it is a simple matter of logic</em>. </p>

<p>To wit, the assertion "x belongs to the union" means "There exists i such that x belongs to A(i)" hence its negation "x belongs to the complement of the union" is also "For all i, x does not belong to A(i)", that is, "For all i, x belongs to the complement of A(i)". We are done.</p>

==============================
===============================
Question: <p>I have trouble following the category-theoretic statement and proof of the Yoneda Lemma. Indeed, I followed a category theory course for 4-5 lectures (several years ago now) and felt like I understood everything <em>until</em> we covered the Yoneda Lemma, after which point I lost interest.</p>

<p>I guess what I'm asking for are some concrete examples of the Yoneda Lemma in action. For example, how does it apply to specific categories, like a category with one element, or the category <strong>Grp</strong> or <strong>Set</strong>? What results does it generalize? Is there a canonical route to understanding the statement of the Lemma?</p>

<p>If you need to assume knowledge, then assume I have a fairly rigorous education in pure/applied mathematics at the undergraduate level but no further.</p>

 
Answer: <p>Roughly speaking, the Yoneda lemma says that one can recover an object $X$ up to isomorphism from knowledge of the hom-sets $\text{Hom}(X, Y)$ for all other objects $Y$. Equivalently, one can recover an object $X$ up to isomorphism from knowledge of the hom-sets $\text{Hom}(Y, X)$. </p>

<p>As I have said before on math.SE, there is a meta-principle in category theory that to understand something for all categories, you should first understand it for <a href="http://en.wikipedia.org/wiki/Partially_ordered_set">posets</a>, regarded as categories where $a \le b$ if and only if there is a single arrow $a \to b$, and otherwise there are no morphisms from $a$ to $b$. For posets, Yoneda's lemma says that an object is determined up to isomorphism by the set of objects less than or equal to it (equivalently, the set of objects greater than or equal to it). In other words, it is determined by a <a href="http://en.wikipedia.org/wiki/Dedekind_cut">Dedekind cut</a>! In other other words, Yoneda's lemma for posets says the following:</p>

<blockquote>
  <p>$a \le b$ if and only if for all objects $c$ we have $c \le a \Rightarrow c \le b$.</p>
</blockquote>

<p>This is a surprisingly useful idea in real analysis. More generally it leads to the idea that Yoneda's lemma, among other things, embeds a category into a certain "completion" of that category: in fact the standard contravariant Yoneda embedding embeds a category into its <a href="http://ncatlab.org/nlab/show/free+cocompletion">free cocompletion</a>, the category given by "freely adjoining colimits." </p>

<p>As far as examples go, it turns out that in many categories one can restrict attention to a few specific objects $Y$. For example:</p>

<ul>
<li>In $\text{Set}$ one can completely recover an object $S$ from $\text{Hom}(1, S)$. </li>
<li>In $\text{Grp}$ one can completely recover an object $G$ from $\text{Hom}(\mathbb{Z}, G)$. This is because a homomorphism from $\mathbb{Z}$ is freely determined by where it sends $1$, and one can recover the multiplication because $\mathbb{Z}$ is naturally a <a href="http://en.wikipedia.org/wiki/Group_object">cogroup object</a>, which is equivalent to the claim that $\text{Hom}(\mathbb{Z}, G)$ naturally carries a group structure (that of $G$).</li>
<li>In $\text{CRing}$ (the category of commutative rings) one can completely recover an object $R$ from $\text{Hom}(\mathbb{Z}[x], R)$. The story is similar to that above; it is explained in <a href="http://qchu.wordpress.com/2011/01/21/structures-on-hom-sets/">this blog post</a>. Geometrically this means that one can completely recover an affine scheme $\text{Spec } R$ from $\text{Hom}(\text{Spec } R, \mathbb{A}^1(\mathbb{Z}))$, the ring of functions on it. </li>
<li>In $\text{Top}$ (the category of topological spaces) one can completely recover an object $X$ from $\text{Hom}(1, X)$ (the points of $X$) and $\text{Hom}(X, \mathbb{S})$, where $\mathbb{S}$ is the <a href="http://en.wikipedia.org/wiki/Sierpi%C5%84ski_space">Sierpinski space</a>. The latter precisely gives you the open sets of $X$, and together with knowledge of the composition map $\text{Hom}(1, X) \times \text{Hom}(X, \mathbb{S}) \to \text{Hom}(1, \mathbb{S})$ you can recover the knowledge of which points sit inside which open sets.</li>
</ul>

==============================
===============================
Question: <p>I puzzled two high school Pre-calc math teachers today with a little proof (maybe not) I found a couple years ago that infinity is equal to -1:</p>

<ol>
<li><p>Let x equal the geometric series: $1 + 2 + 4 + 8 + 16 \ldots$</p>

<p>$x = 1 + 2 + 4 + 8 + 16 \ldots$</p></li>
<li><p>Multiply each side by 2:</p>

<p>$2x = 2 + 4 + 8 + 16 + 32 \ldots$</p></li>
<li><p>Again from the equation in step 1, move the $1$ term to the left hand of the equation:</p>

<p>$x - 1 = 2 + 4 + 8 + 16 + 32 \ldots$</p></li>
<li><p>So the following appears to be true:</p>

<p>$2x = x - 1 \implies x = -1$</p></li>
</ol>

<p>This is obviously illogical. The teachers told me the problem has to do with adding the two infinite geometric series, but they weren't positive. I'm currently in Pre-calc, so I have extremely little knowledge on calculus, but a little help with this paradox would be appreciated.</p>

 
Answer: <p>When we talk about an "infinite sum", we are <em>really</em> talking about a limit. In this case, we are talking about the limit of the "partial sums" of the series. The partial sums are:
$$\begin{align*}
s_1 &amp;= 1;\\
s_2 &amp;= 1+2;\\
s_3 &amp;= 1+2+4;\\
&amp;\vdots
\end{align*}$$
That is, $s_n$ is the sum of the first $n$ summands in the series. When we talk about the "value" of a series (an infinite sum), we are <em>really</em> talking about the limit of the $s_n$: that is, a specific real number $L$ that the $s_n$ are approaching as $n\to\infty$.  Or we say that a series "equals $\infty$" if the values of $s_n$ grow without limit.</p>

<p>When you say $x = 1+2+4+\cdots$, what you are <strong>really</strong> saying is that the limit of $s_n$. In this case, the limit of the $s_n$ does <em>not</em> exist, because
$$\lim_{n\to\infty}s_n = \infty.$$
The values of $s_n$ get arbitrarily large as $n\to\infty$.</p>

<p>It is certanly true as well that the sum $2+4+8+\cdots$ is also $\infty$, since $2\times\infty = \infty$ (in the extended reals). And if you subtract one, then you still get $\infty$ because $\infty -1  = \infty$ (in the extended reals).</p>

<p>So you can write $2x = x-1$.</p>

<p>What you <strong>cannot</strong> do, however, is "subtract $x$ from both sides"; because that would be writing
$$2\times\infty - \infty = \infty -1 -\infty$$
and the problem is that even in the extended reals, $\infty-\infty$ is <em>undetermined</em>. It does <em>not</em> equal anything, and certainly not zero. In short, you cannot just cancel infinities.</p>

==============================
===============================
Question: <p>A triangular grid has $N$ vertices, labeled from 1 to $N$. Two vertices $i$ and $j$ are adjacent if and only if $|i-j|=1$ or $|i-j|=2$. See the figure below for the case $N = 7$.</p>

<p><img src="https://i.stack.imgur.com/q7Glg.jpg" alt="Triangular grid with 7 vertices"></p>

<p>How many trails are there from $1$ to $N$ in this graph? A trail is allowed to visit a vertex more than once, but it cannot travel along the same edge twice.</p>

<p>I wrote a program to count the trails, and I obtained the following results for $1 \le N \le 17$.</p>

<p>$$1, 1, 2, 4, 9, 23, 62, 174, 497, 1433, 4150, 12044, 34989, 101695, 295642, 859566, 2499277$$</p>

<p>This sequence is not in the <a href="http://oeis.org" rel="nofollow noreferrer">OEIS</a>, but <a href="http://oeis.org/ol.html" rel="nofollow noreferrer">Superseeker</a> reports that the sequence satisfies the fourth-order linear recurrence</p>

<p>$$2 a(N) + 3 a(N + 1) - a(N + 2) - 3 a(N + 3) + a(N + 4) = 0.$$</p>

<p>Question: Can anyone prove that this equation holds for all $N$?</p>

 
Answer: <p>Regard the same graph, but add an edge from $n-1$ to $n$ with weight $x$ (that is, a path passing through this edge contributes $x$ instead of 1).</p>

<p>The enumeration is clearly a linear polynomial in $x$, call it $a(n,x)=c_nx+d_n$ (and we are interested in $a(n,0)=d_n$).</p>

<p>By regarding the three possible edges for the last step, we find $a(1,x)=1$, $a(2,x)=1+x$ and</p>

<p>$$a(n,x)=a(n-2,1+2x)+a(n-1,x)+x\,a(n-1,1)$$</p>

<p>(If the last step passes through the ordinary edge from $n-1$ to $n$, you want a trail from 1 to $n-1$, but there is the ordinary edge from $n-2$ to $n-1$ and a parallel connection via $n$ that passes through the $x$ edge and is thus equivalent to a single edge of weight $x$, so we get $a(n-1,x)$.</p>

<p>If the last step passes through the $x$-weighted edge this gives a factor $x$, and you want a trail from $1$ to $n-1$ and now the parallel connection has weight 1 which gives $x\,a(n-1,1)$.</p>

<p>If the last step passes through the edge $n-2$ to $n$, then we search a trail to $n-2$ and now the parallel connection has the ordinary possibility $n-3$ to $n-2$ and two $x$-weighted possibilities $n-3$ to $n-1$ to $n$ to $n-1$ to $n-2$, in total this gives weight $2x+1$ and thus $a(n-2,2x+1)$.)</p>

<p>Now, plug in the linear polynomial and compare coefficients to get two linear recurrences for $c_n$ and $d_n$. </p>

<p>\begin{align} 
c_n&amp;=2c_{n-2}+2c_{n-1}+d_{n-1}\\
d_n&amp;=c_{n-2}+d_{n-2}+d_{n-1}
\end{align}</p>

<p>Express $c_n$ with the second one, eliminate it from the first and you find the recurrence for $d_n$.</p>

<p>(Note that $c_n$ and $a(n,x)$ are solutions of the same recurrence.)</p>

==============================
===============================
Question: <p>I'm trying to prove the following:</p>

<blockquote>
  <p>If $(a_n)$ is a sequence of positive numbers such that $\sum_{n=1}^\infty a_n b_n&lt;\infty$ for all sequences of positive numbers $(b_n)$ such that $\sum_{n=1}^\infty b_n^2&lt;\infty$, then $\sum_{n=1}^\infty a_n^2 &lt;\infty$.</p>
</blockquote>

<p>The context here is functional analysis homework, in the subject of Hilbert spaces.</p>

<p>Here's what I've thought:</p>

<p>Let $f=(a_n)&gt;0$. Then the problem reads: if $\int f\overline{g}&lt;\infty$ for all $g&gt;0,g\in \ell^2$, then $f\in \ell^2$. This brings the problem into the realm of $\ell^p$ spaces.</p>

<p>I know the inner product is defined only in $\ell^2$, but it's sort of like saying: if $\langle f,g\rangle &lt;\infty$ for all $g&gt;0,g\in \ell^2$ then $f\in \ell^2$.</p>

<p>I read this as: "to check a positive sequence is in $\ell^2$, just check its inner product with any positive sequence in $\ell^2$ is finite, then you're done", which I find nice, but I can't prove it :P</p>

<p>From there, I don't know what else to do. I thought of Hölder's inequality which in this context states:
$$\sum_{n=1}^\infty a_nb_n \leq \left( \sum_{n=1}^\infty a_n^2 \right)^{1/2} \left( \sum_{n=1}^\infty b_n^2 \right)^{1/2}$$</p>

<p>but it's not useful here.</p>

 
Answer: <p>Following the idea left by david as an answer, I'll post a detailed solution.</p>

<p>Let $T_n:\ell^2 \to \mathbb{C}, T_n(c)=\sum_{j=1}^n a_j c_j$. Then clearly $T_n \in (\ell^2)^*$ for every $n$.</p>

<p>I claim that for every $c\in \ell^2$, the limit $\lim_n T_n(c)=\sum_{j=1}^\infty a_jc_j$ exists.</p>

<p>Indeed, we know it does for $c\in \ell^2$ such that $c(n)\geq 0$ for all $n$. But then, for an arbitrary $c\in \ell^2$, we can decompose $c$ as:</p>

<p>$c=(\mbox{Re }  c)^+ - (\mbox{Re } c)^- + i\left( (\mbox{Im }c)^+ - (\mbox{Im } c)^-\right)$</p>

<p>which proves the claim.</p>

<p>As a consequence we have that $\sup_n \lVert T_n(c) \rVert &lt;\infty$ for all $c\in \ell^2$, but then by the uniform boundedness principle, $\sup_n \lVert T_n \rVert &lt;\infty$.</p>

<p>Now, $T_n(c) = \langle c, a^{(n)}\rangle_{\ell^2}$ where $a^{(n)}(j)=\begin{cases} a_j &amp; \mbox{if }j\leq n \\ 0 &amp; \mbox{if } j&gt;n \end{cases}$.</p>

<p>By Riesz' representation theorem on Hilbert spaces, we know that $\lVert T_n \rVert = \lVert a^{(n)}\rVert_2= \left( \sum_{j=1}^n a_j^2 \right)^{\frac{1}{2}}$.</p>

<p>To conclude, since $a_n\geq 0$ for all $n$, we have that $\left( \sum_{n=1}^\infty a_n^2 \right)^{\frac{1}{2}} = \sup_n \lVert a^{(n)} \rVert_2 = \sup_n \lVert T_n \rVert &lt; \infty$, and then $\sum_{n=1}^\infty a_n^2 &lt;\infty$.</p>

==============================
===============================
Question: <p>It's not difficult to show that</p>

<p>$$(1-z^2)^{-1/2}=\sum_{n=0}^\infty \binom{2n}{n}2^{-2n}z^{2n}$$</p>

<p>On the other hand, we have $(1-z^2)^{-1}=\sum z^{2n}$.  Squaring the first power series and comparing terms gives us</p>

<p>$$\sum_{k=0}^n \binom{2k}{k}\binom{2(n-k)}{n-k}2^{-2n}=1$$</p>

<p>that is,</p>

<p>$$\sum_{k=0}^n \binom{2k}{k}\binom{2(n-k)}{n-k}=2^{2n}$$</p>

<p>My question: is there a more direct, combinatorial proof of this identity?  I've been racking my brains trying to come up with one but I'm not having much success.</p>

 
Answer: <p>It is possible to give a direct combinatorial proof, but it is quite difficult to find it.</p>

<p>One possibility is to use paths between points with integer coordinates and steps $(1,1)$ and $(1,-1)$.</p>

<p>1) $\binom{2n}{n}$ counts all paths from $(0,0)$ to $(2n,0)$.</p>

<p>2) $2^{2n}$ counts all paths starting from $(0,0)$ with $2n$ steps.</p>

<p>3) $\binom{2n}{n}$ counts all paths with $2n$ steps that never touch the  $x$-axis again after the start. (This one is not obvious, but can be proved 
with a bijection.)</p>

<p>Now you can conclude that all paths are a concatenation of a path that returns a certain number of times to the $x$-axis and a path that never does.</p>

<p>Note that the main difficulty here was that the two binomial coefficients are interpreted differently.</p>

<p>Edited to add reference: 
In Richard P. Stanley: Enumerative Combinatorics Volume 1, Chapter 1, Solution to exercice 2c the following reference is given:</p>

<blockquote>
  <p>The problem of giving a combinatorial proof was raised by P. Veress and solved by G. Hajos in the 1930s. A recent proof appears in D.J. Kleitman, Studies in Applied Math. 54 (1975), 289 - 292. See also M. Sved, Math. Intelligencer, vol.6, no. 4 (1984), 44-45.</p>
</blockquote>

<p>But I have not looked to check which article gives the proof I have outlined above.</p>

==============================
===============================
Question: <p>The following facts are standard: an irreducible quartic polynomial $p(x)$ can only have Galois groups $S_4, A_4, D_4, V_4, C_4$. Over a field of characteristic not equal to $2$, depending on whether or not the discriminant $\Delta$ is a square and whether or not the resolvent cubic $q(x)$ is irreducible, we can distinguish four cases:</p>

<ul>
<li>If $\Delta$ is not a square and the resolvent cubic is irreducible, then the Galois group is $S_4$.</li>
<li>If $\Delta$ is a square and the resolvent cubic is irreducible, then the Galois group is $A_4$.</li>
<li>If $\Delta$ is a square and the resolvent cubic is reducible, then the Galois group is $V_4$.</li>
<li>If $\Delta$ is not a square and the resolvent cubic is reducible, then the Galois group is either $D_4$ or $C_4$.</li>
</ul>

<p>How can we resolve the ambiguity in the last case? For $p$ a monic polynomial in $\mathbb{Z}[x]$, I know the following approaches:</p>

<ul>
<li>In the simplest cases one can work directly with the splitting field. But this is rare, although it can work if $p = x^4 + ax^2 + b$ for some $a, b$. </li>
<li>If $p$ has two complex roots (equivalently, if the discriminant is negative), there is a transposition in the Galois group, so the Galois group is $D_4$.</li>
<li>If $p$ factors as the product of two linear factors and an irreducible quadratic factor modulo a prime, there is a transposition in the Galois group, so the Galois group is $D_4$. </li>
</ul>

<p>In practice, the last two often work to identify a Galois group of $D_4$ (and in principle it must eventually work by the Frobenius density theorem). But I don't know a corresponding practical way to identify a Galois group of $C_4$. There is a criterion due to Kappe and Warren which I learned about from one of Keith Conrad's expository notes <a href="http://www.math.uconn.edu/~kconrad/blurbs/galoistheory/cubicquartic.pdf">here</a>. However, in an upcoming exam I'm taking, I'll only be able to cite results proven in the course, and this criterion isn't one of them. </p>

<p>So what are my other options in general? </p>

 
Answer: <p>Let $F$ be a field of characteristic not equal to 2.
One option is to can look at the reducibility of $p(x)$ over $F(\sqrt{\Delta})$. If $\Delta$ is not a square and the resolvent cubic is reducible, then we have the following classification:
$$\text{Gal}(p/F) = D_4 \iff p(x)\text{ is irreducible in } F(\sqrt{\Delta}).$$</p>

<p>To see this, note that if $\alpha$ is a root of $p$ and $\text{Gal}(p/F) = D_4$, then $p$ splits over $F(\sqrt{\Delta},\alpha)$ as $F(\sqrt{\Delta},\alpha)$ sits inside the splitting field for $p$ and has degree 8 over $F$. But this implies that $[F(\sqrt{\Delta},\alpha):F(\sqrt{\Delta})] = 4$, from which we can derive that $p$ must be irreducible over $F(\sqrt{\Delta})$.</p>

<p>Alternatively, if $\text{Gal}(p/F) = C_4$, then the splitting field for $p$ over $F(\sqrt{\Delta})$ has degree $\#\text{Gal}(p/F)/[F(\sqrt{\Delta}):F]=2$, and thus $p$ must be reducible over $F(\sqrt{\Delta})$.</p>

==============================
===============================
Question: <p>I have read that for any group $G$ of order $2m+1$ (odd) with $n$ conjugacy classes, it is always the case that $16$ divides the value $(2m+1)-n = |G|-n$. </p>

<p>This seems to me like an astonishing result: what on earth would $16$ have to do with every single odd group and its conjugacy classes? At any rate, I am wondering, assuming it is true, how would you go about proving it? I would like to show it in a reasonably simple way, but nothing whatsoever comes to mind, could anyone help? Many thanks - M.</p>

 
Answer: <p>The number of conjugacy classes is the same as the number of irreducible representations; if $d_i$ is the set of dimensions of the irreducible representations, we know that $d_i | |G|$, hence $d_i$ is odd, and $|G| = \sum d_i^2$. Since $d_i$ is odd, we compute that $d_i^2 \equiv 1, 9 \bmod 16$, so it already follows that $|G| \equiv n \bmod 8$. To get the result $\bmod 16$ it suffices to show that the representations such that $d_i^2 \equiv 9 \bmod 16$ occur an even number of times.</p>

<p>In fact, we claim that no non-trivial irrep is self-dual, from which the above follows (since we can take the dual of an irrep with $d_i^2 \equiv 9 \bmod 16$ to get another one). This is equivalent to the claim that no non-identity element is conjugate to its inverse, which follows from the fact that no element of $G$ can act by a permutation of order two. </p>

==============================
===============================
Question: <p>Quite a while ago, I heard about a statement in measure theory, that goes as follows:</p>

<blockquote>
  <p>Let $A \subset \mathbb R^n$ be a Lebesgue-measurable set of positive measure. Then we follow that $A-A = \{ x-y \mid x,y\in A\}$ is a neighborhood of zero, i.e. contains an open ball around zero.</p>
</blockquote>

<p>I now got reminded of that statement as I have the homework problem (Kolmogorov, Introductory Real Analysis, p. 268, Problem 5):</p>

<blockquote>
  <p>Prove that every set of positive measure in the interval $[0,1]$ contains a pair of points whose distance apart is a rational number.</p>
</blockquote>

<p>The above statement would obviously prove the homework problem and I would like to prove the more general statement. I think that assuming the opposite and taking a sequence $\{x_n\}$ converging to zero such that none of the elements are contained in $A$, we might be able to define an ascending/descending chain $A_n$ such that the union/intersection is $A$ but the limit of its measures zero. I am in lack of ideas for the definition on those $A_n$.</p>

<p>I am asking specifically not for an answer but a hint on the problem. Especially if my idea turns out to be fruitful for somebody, a notice would be great. Or if another well-known theorem is needed, I surely would want to know. Thank you for your help.</p>

 
Answer: <p>Here's an attempt at a hint for the first result you ask about: Assume without loss of generality that $A$ has finite measure. Let $f$ be the characteristic function of $A$ and let $\tilde{f}$ be the one of $-A$. The <a href="http://en.wikipedia.org/wiki/Convolution" rel="nofollow noreferrer">convolution</a> $g = f \ast \tilde{f}$ is continuous and $0$ is in the support of $g$.</p>

<p><strong>Added later:</strong> One nice standard application is that every measurable homomorphism $\phi: \mathbb{R} \to \mathbb{R}$ is continuous. For more on that and related matters have a look at these two MO-threads: </p>

<ol>
<li>On <a href="https://mathoverflow.net/questions/57616/">measurable homomorphisms $\mathbb{C} \to \mathbb{C}$</a>.</li>
<li>On <a href="https://mathoverflow.net/questions/64116/">measurable automorphisms of locally compact groups</a></li>
</ol>

<p>They might elucidate what is mentioned in another answer.</p>

<hr>

<p><strong>Update:</strong></p>

<p>What I wrote above is the way I prefer to prove this.</p>

<p>Another approach is to appeal to regularity of Lebesgue measure $\lambda$ (used in $1$ and $2$ below).</p>

<ol>
<li>Since $A$ contains a compact set of positive measure, we can assume $A$ to be compact right away (as $B-B \subset A - A$ if $B \subset A$).</li>
<li>There is an open set $U \supset A$ such that $\lambda(U) \lt 2 \lambda(A)$.</li>
<li>Since $A$ is compact there is $I = (-\varepsilon, \varepsilon)^{n}$ such that $A + x \subset U$ for all $x \in I$.</li>
<li>Since $\lambda (U) \lt 2\lambda(A)$ we must have $\lambda((A + x) \cap A) \gt 0$.</li>
</ol>

<p>This is of course very closely related to the argument given by Chandru1 below.</p>

==============================
===============================
Question: <p>I'm having trouble understanding Cantor's diagonal argument.  Specifically, I do not understand how it proves that something is "uncountable".  My understanding of the argument is that it takes the following form (modified slightly from the <a href="http://en.wikipedia.org/wiki/Cantor%27s_diagonal_argument">wikipedia</a> article, assuming base 2, where the numbers must be from the set $ \lbrace 0,1 \rbrace $):</p>

<p>$\begin{align}
s_1 &amp;= (\mathbf{0},1,0,\dots)\\
s_2 &amp;= (1,\mathbf{1},0,\dots)\\
s_3 &amp;= (0,0,\mathbf{1},\dots)\\
\dots &amp; (s_n \mathit{\ continues\dots})
\end{align}$</p>

<p>In this case, the diagonal number is the bold diagonal numbers $(0, 1, 1)$, which when "flipped" is $(1,0,0)$, neither of which is $s_1$, $s_2$, or $s_3$.</p>

<p>My question, or misunderstanding, is: When there exists the possibility that more $s_n$ exist, as is the case in the example above, how does this "prove" anything?  For example:</p>

<p>$\begin{align}
s_0 &amp;= (1,0,0,\mathbf{0},\dots)\ \ \textrm{ (...the wikipedia flipped diagonal)}\\
s_1 &amp;= (\mathbf{0},1,0,\dots)\\
s_2 &amp;= (1,\mathbf{1},0,\dots)\\
s_3 &amp;= (0,0,\mathbf{1},\dots)\\
s_4 &amp;= (0,1,1,\mathbf{1},\dots)\\
s_4 &amp;= (1,0,0,\mathbf{1},\dots)\ \ \textrm{ (...alternate, flipped } s_4\textrm{)}\\
s_5 &amp;= (1,0,0,0,\dots)\\
s_6 &amp;= (1,0,0,1,\dots)\\
\dots &amp; (s_n \mathit{\ continues\dots})
\end{align}$</p>

<p>&hellip; in other words, as long as there is a $\dots (continues\dots)$ at the end, the very next number could be the "impossible diagonal number"... with the caveat that it's not strictly identical to the "impossible diagonal number" as the wikipedia article defines it:</p>

<blockquote>
  <p>For each $m$ and $n$ let $s_{n,m}$ be the $m^{th}$ element of the $n^{th}$ sequence on the list; so for each $n$,</p>
  
  <p>$s_n = (s_{n,1}, s_{n,2}, s_{n,3}, s_{n,4}, \dots)$.</p>
  
  <p><em>...snip...</em></p>
  
  <p>Otherwise, it would be possible by the above process to construct a sequence $s_0$ which would both be in $T$ (because it is a sequence of 0s and 1s which is by the definition of $T$ in $T$) and at the same time not in $T$ (because we can deliberately construct it not to be in the list). $T$, containing all such sequences, must contain $s_0$, which is just such a sequence. But since $s_0$ does not appear anywhere on the list, $T$ cannot contain $s_0$.</p>
  
  <p>Therefore $T$ cannot be placed in one-to-one correspondence with the natural numbers. In other words, it is uncountable.</p>
</blockquote>

<p>... but I'm not sure this definition is correct, because if we assume that $m = (1, \dots)$, then this definition says that "$s_n$ is equal to itself"- there is no "diagonalization" in this particular description of the argument, nor does it incorporate the "flipping" part of the argument, never mind the fact that we have very clearly constructed just such an impossible $T$ list above.  An attempt to correct the "diagonalization" and "flipping" problem:</p>

<p>$s_n = (\lnot s_{m,m}, \lnot s_{m,m}, \dots)$ where $m$ is the element index and $\begin{equation}\lnot s_{m,m} = \begin{cases}0 &amp; \mathrm{if\ } s_{m,m} = 1\\1 &amp; \mathrm{if\ } s_{m,m} = 0\end{cases}\end{equation}$</p>

<p>... but this definition doesn't quite work either, as we immediately run in to problems with just $s_1 = (0),$ which is impossible because by definition $s_1$ must be $ = (1)$ if $s_1 = (0)$, which would also be impossible because... <em><a href="http://en.wikipedia.org/wiki/Turtles_all_the_way_down">it's turtles all the way down!?</a></em>  Or more generally, with the revised definition there is a contradiction whenever $n = m$, which would seem to invalidate the revised formulation of the argument / proof.</p>

<p>Nothing about this argument / proof makes any sense to me, nor why it only applies to real numbers and makes them "uncountable". As near as I can tell it would seem to apply equal well to natural numbers, which are "countable".</p>

<p>What am I missing?</p>

 
Answer: <p>First, let me give you a proof of the following:</p>

<blockquote>
  <p>Let $\mathbb{N}$ be the natural numbers, $\mathbb{N}=\{1,2,3,4,5,\ldots\}$, and let $2^{\mathbb{N}}$ be the set of all <em>binary sequences</em> (functions from $\mathbb{N}$ to $\{0,1\}$, which can be viewed as "infinite tuples" where each entry is either $0$ or $1$). </p>
  
  <p>If $f\colon\mathbb{N}\to 2^{\mathbb{N}}$ is a function, then $f$ is not surjective. That is, there exists some binary sequence $s_f$, which depends on $f$, such that $f(n)\neq s_f$ for all natural numbers $n$.</p>
</blockquote>

<p>What I denote $2^{\mathbb{N}}$ is what Wikipedia calls $T$.</p>

<p>I will represent elements of $2^{\mathbb{N}}$ as tuples,
$$(a_1,a_2,a_3,\ldots,a_n,\ldots)$$
where each $a_i$ is either $0$ or $1$; these tuples are <em>infinite</em>; we think of the tuple as defining a function whose value at $n$ is $a_n$, so it really corresponds to a function $\mathbb{N}\to\{0,1\}$. Two tuples are equal if and only if they are identical: that is,
$$(a_1,a_2,a_3,\ldots,a_n,\ldots) = (b_1,b_2,b_3,\ldots,b_n,\ldots)\text{ if and only if } a_k=b_k\text{ for all }k.$$</p>

<p>Now, suppose that $f\colon\mathbb{N}\to 2^{\mathbb{N}}$ is a given function. 
For each natural number $n$, $f(n)$ is a tuple. Denote this tuple by
$$f(n) = (a_{1n}, a_{2n}, a_{3n},\ldots,a_{kn},\ldots).$$
That is, $a_{ij}$ is the $i$th entry in $f(j)$.</p>

<p>I want to show that this function is not surjective. To that end, I will construct an element of $2^{\mathbb{N}}$ that is not in the image of $f$. Call this tuple $s_f = (s_1,s_2,s_3,\ldots,s_n,\ldots)$. I will now say what $s_k$ is. Define 
$$s_k = \left\{\begin{array}{ll}
1 &amp;\mbox{if $a_{nn}=0$;}\\
0 &amp;\mbox{if $a_{nn}=1$.}
\end{array}\right.$$</p>

<p>This defines an element of $2^{\mathbb{N}}$, because it defines an infinite tuple of $0$s and $1$s; this element depends on the $f$ we start with: if we change the $f$, the resulting $s_f$ may change; that's fine.  (This is the "diagonal element").</p>

<p>Now, the question is whether $s_f = f(n)$ for some $n$. The answer is "no." To see this, let $n\in\mathbb{N}$ be any natural number. Then 
$$f(n) = (a_{1n},a_{2n},a_{3n},\ldots,a_{nn},\ldots)$$
so the $n$th entry of $f(n)$ is $a_{nn}$. If the $n$th entry of $f(n)$ is $0$, then by construction the $n$th entry of $s_f$, $s_n$ is $1$, so $f(n)\neq s_f$. If the $n$th entry of $f(n)$ is $1$, then by construction the $n$th entry of $s_f$, $s_n$, is $0$. Then $f(n)\neq s_f$ again, because they don't agree on the $n$th entry.</p>

<p>This means that for every $n\in\mathbb{N}$, $s_f$ cannot equal $f(n)$, because they differ in the $n$th entry. So $s_f$ is <em>not</em> in the image of $f$.</p>

<p>What we have shown is that given a function $f\colon\mathbb{N}\to 2^{\mathbb{N}}$, there is some element of $2^{\mathbb{N}}$ that is not in the image of $f$. The element depends on what $f$ is, of course; different functions will have possibly different "witnesses" to the fact that they are not surjective. </p>

<p>Think of the function $f$ being hauled before a judged and accused of Being Surjective; to prove its innocence, $f$ produces a witness to verify its alibi that it's not surjective; this witness is $s_f$, who can swear to the fact that $f$ is not surjective because $s_f$ <em>demonstrates</em> that $f$ is not surjective: $s_f$ is not in $\mathrm{Im}(f)$; if the police hauls in some <em>other</em> function $g$ and accuse <em>that</em> function of being surjective, $g$ will also have to produce a witness to verify its alibi that it isn't surjective; but that witness does not have to be the same witness that $f$ produced. The "witness" we produce will depend on who the "accused" is.</p>

<hr/>

<p>The reason this is called the "diagonal argument" or the sequence $s_f$ the "diagonal element" is that just like one can represent a function $\mathbb{N}\to \{0,1\}$ as an infinite "tuple", so one can represent a function $\mathbb{N}\to 2^{\mathbb{N}}$ as an "infinite list", by listing the image of $1$, then the image of $2$, then the image of $3$, etc:
$$\begin{align*}
f(1) &amp;= (a_{11}, a_{21}, a_{31}, \ldots, a_{k1},\ldots )\\
f(2) &amp;= (a_{12}, a_{22}, a_{32}, \ldots, a_{k2},\ldots)\\
&amp;\vdots\\
f(m) &amp;= (a_{1m}, a_{2m}, a_{3m},\ldots, a_{km},\ldots)
\end{align*}$$
and if one imagines the function this way, then the way we construct $s_f$ is by "going down the main diagonal", looking at $a_{11}$, $a_{22}$, $a_{33}$, etc.</p>

<hr/>

<p>Now, remember the definition of "countable":</p>

<blockquote>
  <p><strong>Definition.</strong> A set $X$ is said to be <em>countable</em> if and only if there exists a function $f\colon\mathbb{N}\to X$ that is surjective. If no such function exists, then $X$ is said to be <em>uncountable.</em></p>
</blockquote>

<p>That means that the theorem we proved above shows that:</p>

<blockquote>
  <p><strong>Theorem.</strong> The set of all binary sequences, $2^{\mathbb{N}}$, is <strong>not</strong> countable.</p>
</blockquote>

<p>Why? Because we showed that there are no surjective functions $\mathbb{N}\to 2^{\mathbb{N}}$, so it is not countable. </p>

<p>How does this relate to the real numbers? The real numbers are <em>bijectable</em> with the set $2^{\mathbb{N}}$. That is, there is a function $H\colon 2^{\mathbb{N}}$ to $\mathbb{R}$ that is both one-to-one and onto. If we had a surjection $\mathbb{N}\to\mathbb{R}$, then composing this surjection with $H$ we would get a surjection from $\mathbb{N}$ to $2^{\mathbb{N}}$, and no such surjection exists. So there can be no surjection from $\mathbb{N}$ to $\mathbb{R}$, so $\mathbb{R}$ is not countable (that is, it is uncountable).</p>

<p>Bijecting $\mathbb{R}$ with $2^{\mathbb{N}}$ is a bit tricky; you can first biject $\mathbb{R}$ with $[0,1]$; then you would want to use the binary representation (as in wikipedia's article), so that each sequence corresponds to a binary expansion, and each number in $[0,1]$ corresponds to a binary sequence (its digits when written in binary); the problem is that just like some numbers in decimal have two representations ($1$ and $0.999\ldots$ are equal), so do some numbers have two representations in binary (for example, $0.01$ and $0.0011111\ldots$ are equal). There is a way of fixing this problem, but it is a bit technical and may obscure the issue, so I would rather not get into it.</p>

<p>Instead, let me note that the set $2^{\mathbb{N}}$ can be mapped in a one-to-one way <em>into</em> $(0,1)$: simply take a binary sequence
$$(a_1,a_2,a_3,\ldots,a_n,\ldots)$$
and map it to the decimal number that has a $5$ in the $k$th decimal position if $a_k=0$, and has a $6$ in the $k$th decimal position if $a_k=1$. Using $5$ and $6$ ensures that each number has only one decimal representation, so the map is one-to-one. Call this map $h$. Define $H\colon\mathbb{R}\to 2^{\mathbb{N}}$ as follows: given a real number $x$, if $x$ is in the image of $h$, then define $H(x)$ to be the unique sequence $s$ such that $h(s)=x$. If $x$ is <em>not</em> in the image of $h$, then define $H(x)$ to be the sequence $(0,0,0,\ldots,0,\ldots)$. Notice that $H$ is surjective, because $h$ is defined on all of $2^{\mathbb{N}}$. </p>

<p>This is enough to show that there can be no surjection from $\mathbb{N}$ to $\mathbb{R}$: suppose that $f\colon\mathbb{N}\to\mathbb{R}$ is any function. Then the function $H\circ f\colon \mathbb{N}\stackrel{f}{\to}\mathbb{R}\stackrel{H}{\to}2^{\mathbb{N}}$ is a function from $\mathbb{N}$ to $2^{\mathbb{N}}$. Since any function from $\mathbb{N}$ to $2^{\mathbb{N}}$ is not surjective, there is some $s\in 2^{\mathbb{N}}$ that is not in the image of $H\circ f$. Since $s$ <em>is</em> in the image of $H$, there exists some $x\in\mathbb{R}$ such that $H(x)=s$. That means that $f(n)\neq x$ for all $n$ (since $H\circ f(n)\neq s$). </p>

<p>Since there can be no surjection from $\mathbb{N}$ to $\mathbb{R}$, that means that $\mathbb{R}$ is <strong>uncountable.</strong></p>

<hr/>

<p>So, as to your questions. First, you should understand that the diagonal argument is applied to a <em>given list</em>. You <em>already</em> have all of $s_1$, $s_2$, $s_3$, etc., in front of you. Nobody is allowed to change them. You construct the "diagonal number" (my $s_f$ above) on the basis of that list. Yes, if you change the list then you can put the diagonal number $s_f$ in the new list; but $s_f$ is only a witness to the fact that the <em>original</em> list was not a list of all sequences. If you change to a different list, then I will have to produce a different witness. The witnesses depend on the given list. You <em>know</em> that $s_4$ is not equal to $s_f$ because $s_f$ is constructed <em>precisely</em> so that it disagrees with $s_4$ in the $4$th position, and one disagreement is enough to guarantee inequality.</p>

<p>Wikipedia's presentation seems to argue by contradiction; I don't like to introduce that into these discussions because the argument is difficult enough to "grok" without the added complication.  (The "Otherwise..." part is an argument by contradiction, arguing that <em>if</em> you could 'list' the elements of $T$, then you would apply the argument to show that this 'complete list' is not 'complete', etc). There's no need. Simply, there is no surjection from $\mathbb{N}$ to $T$, as discussed above.</p>

<p>Now, there is a common "first reaction" that this argument would apply "just as well" to the natural numbers: take a list of natural numbers listed in binary, and engineer an argument like the diagonal argument (say, by "reflecting them about the decimal point", so they go off with a tail of zeros to the right; or by writing them from left to right, with least significant digit first, instead of last) to produce a "number" not on the list. You can do that, but the problem is that natural numbers only corresponds to sequences that end with a tail of $0$s, and trying to do the diagonal argument will necessarily product a number that does <strong>not</strong> have a tail of $0$s, so that it cannot represent a natural number. The reason the diagonal argument works with binary sequences is that $s_f$ is certainly a binary sequence, as there are no restrictions on the binary sequences we are considering.</p>

<p>I hope this helps.</p>

==============================
===============================
Question: <p>I’ve often wondered about this, and I conjecture the affirmative, based mainly on that it is so much easier to prove the transcendence of $e$ than that of $\pi$.</p>

<p>I would be surprised if, just as numbers form a linearly ordered classes ranging from algebraic of degree $n$ and culminating in the class of transcendental numbers, the transcendental numbers themselves are not further divided into a linearly ordered classes, with $\pi$ belonging to the top class, and $e$ belonging to some class below it, so this is really a reference request. Could someone please cite chapter and verse where this is done?</p>

 
Answer: <p><a href="https://mathoverflow.net/questions/53724/are-some-numbers-more-irrational-than-others">This question at MathOverflow</a> has several answers discussing several senses in which one can say that one real number is more irrational than another, including irrationality measures and other hierarchies of complexity for real numbers.</p>

==============================
===============================
Question: <p>There are many proofs lying around that games like Lemmings or Sudoku or Tetris are NP-hard (generalized version of those games, of course). The proofs, as I recall, are not difficult but not simple either.</p>

<p>I wish to give my students a question in their homework assignment which tackles some known game or something similar, so I'm interested in examples to such problem for which the proof of hardness is not hard (at least, the student can solve it with some direction).</p>

 
Answer: <ul>
<li>The <a href="http://en.wikipedia.org/wiki/SameGame">SameGame</a> (random arrangement of colored blocks; clicking on a block removes the group of connected blocks of the same color and then the blocks above fall down to fill the void) <a href="http://erikdemaine.org/papers/ClickomaniaGameTheory2000/">is NP-Complete</a> for instances as small as 3 colors and 5 columns.  The reduction from 3-SAT isn't incredibly straightforward, though.</li>
<li>The problem of deciding if a partially filled <a href="http://mathworld.wolfram.com/LatinSquare.html">Latin square</a> can be completed <a href="http://dx.doi.org/10.1016/0166-218X%2884%2990075-1">is also NP-complete</a> (Latin squares are a generalization of Sudoku), however, the reduction used to prove this isn't very straightforward.</li>
<li><a href="http://en.wikipedia.org/wiki/Battleship_%28game%29">Battleship</a> (which is similar to Minesweeper and Sipser's problem from Michaël's answer) is NP-Complete, but <a href="http://www.mountainvistasoft.com/docs/BattleshipsAsDecidabilityProblem.pdf">the reduction from 3-SAT is likewise complicated</a>.</li>
<li>I don't know if you would consider it "real life", but <a href="http://en.wikipedia.org/wiki/Bayesian_network#Inferring_unobserved_variables">exact inference in Bayesian networks</a> is NP-Hard; it's a straightforward reduction from 3-SAT (I guess one could argue that Bayesian inference is used in the <em>playing</em> of many games).</li>
<li>There are also all sorts of vehicle routing and depot location problems that are very easy to conceptualize that have relatively straightforward reductions from TSP.</li>
</ul>

<p><strong>Edit:</strong></p>

<ul>
<li>Scheduling with profits and deadlines is NP-Complete.  The decision version goes something like,
<blockquote>
  <p>Let $A$ be a set of $n$ tasks, $\{a_1, \ldots, a_n\}$, each with an associated execution time, $t_i$, profit, $p_i$, and deadline, $d_i$.  You can only execute one task at a time; if the task does not complete before its associated deadline, then you do not receive its profit.  Does there exist a schedule that returns a profit of $k$?</li>
  </ul>

<p>It's relatively easy to show, <em>e.g.</em>, Hamiltonian cycle $\leq_P$ scheduling with profits and deadlines.</p>
</blockquote></p>

==============================
===============================
Question: <p>On an <a href="https://www.maths.cam.ac.uk/sites/www.maths.cam.ac.uk/files/pre2014/undergrad/pastpapers/2009/Part_2/PaperII_3.pdf" rel="noreferrer">exam question</a> (Question 21H), it is claimed that if $K$ is compact and $f_n : K \to \mathbb{R}$ are continuous functions increasing pointwise to a continuous function $f : K \to \mathbb{R}$, then $f_n$ converges to $f$ uniformly. I have tried proving this claim for the better part of an hour but I keep coming short. I suspect a hypothesis on equicontinuity has been omitted — partly because the first half of the question is about the Arzelà–Ascoli theorem — but I don't have access to the errata for the exam so I can't be sure.</p>

<p>Here is my attempted proof: let $g_n = f - f_n$, so that $(g_n)$ is a sequence of continuous functions decreasing pointwise to $0$. Clearly, $0 \le \cdots \le \| g_n \| \le \| g_{n-1} \| \le \cdots \le \| g_1 \|$, so we must have $\| g_n \| \longrightarrow L$ for some constant $L$. $K$ is compact, so for each $g_n$, there is an $x_n \in K$ such that $g_n(x_n) = \| g_n \|$, and there is a convergent subsequence with $x_{n_k} \longrightarrow x$ for some $x \in K$. By hypothesis, $g_n(x) \longrightarrow 0$, and by construction $g_{n_k} (x_{n_k}) \longrightarrow L$. I'd like to conclude that $L = 0$, but to do this I would need to know that the two sequences have the same limit. This is true if, say, $\{ g_n \}$ is an equicontinuous family, but this isn't one of the hypotheses, so I'm stuck.</p>

 
Answer: <p>The result is true as stated and is called <strong>Dini's Theorem</strong>.  A proof can be found in Chapter III, Section 1.4 of <a href="http://math.uga.edu/~pete/3100supp.pdf" rel="nofollow noreferrer">these notes</a> or indeed in <a href="http://en.wikipedia.org/wiki/Dini%27s_theorem" rel="nofollow noreferrer">this wikipedia article</a>.  (My notes are for a sophomore-junior level undergraduate class, so it is stated in the case in which $K$ is a closed interval.  But it is clear that the argument works for any compact topological space.)</p>

<p>(For some reason this is one of those named theorems that tends to be assigned as an exercise or come up on exams...)</p>

==============================
===============================
Question: <p>The set of fusible numbers is a fantastic set of rational numbers defined by a simple rule. The story is well told <a href="http://www.mathpuzzle.com/fusible.pdf">here</a> but I'll repeat the definitions. It's the formula on slide 17 that I'm trying to understand. </p>

<p>Define $\displaystyle a \oplus b = \frac{a+b+1}{2}$. A number is <strong><em>fusible</em></strong> if it is $0$ or if it can be written as $a \oplus b$ where $a, b$ are fusible and $|a-b|&lt;1$. Let $F$ be the set of fusible numbers. More formally, $F$ is the intersection of all sets of real numbers that are closed under $\oplus$ applied to arguments at a distance at most 1. </p>

<p>The set $F$ is a well-ordered set of non-negative rational numbers. The proof that it's well-ordered isn't included in the PDF file I linked to, but it's not hard to show this. (It wouldn't be true if we hadn't insisted on the condition $|a-b|&lt;1$, by the way.)</p>

<p>Amazingly, the order type of $F$ is $\varepsilon_0$. It's also true that $F$ is closed under ordinary addition; this isn't hard to prove either but I don't know if it plays a part in what follows.</p>

<p>Because $F$ is well-ordered, we may define $f(x)$ to be the least fusible number greater than $x$, for any real $x$. Further, set $m(x) = f(x)-x$. We obviously have $m(x) = -x$ for $x&lt;0$, while for $x \geq 0$, it is posited that
$$m(x) = \frac{1}{2}m(x-m(x-1))$$ 
The question is: <strong>why is this last formula true?</strong></p>

<p>I'm able to show one of the necessary inequalities, namely that $\displaystyle m(x) \leq \frac{1}{2}m(x-m(x-1))$: <br>
Given $x$, observe that 
$$(x-1+t) \oplus (x-t+u) = x + u/2$$ 
Take $t = m(x-1)$, which guarantees that ($x-1+t$) is indeed fusible. Now set $u = m(x-t)$ which makes ($x-t+u$) fusible as well, and the distance between those two fusible numbers can't be greater than $1$. It follows that ($x+u/2$) is fusible, and so $m(x)$ is at most $u/2$ for that particular $u$, which is indeed $m(x-m(x-1))$. </p>

<p>The question, then, is: </p>

<p><em>How can we prove that no other choice of $t$ yields an even smaller value for $m(x)$?</em> </p>

<p>It's not hard to show that there's no loss of generality in focusing on $x-1+t$ and $x-t+m(x-t)$, but greedily minimizing $t$ by setting $t=m(x-1)$ is not in any obvious way guaranteed to yield the minimum value for $m(x)$, as far as I can see. </p>

<p>What am I missing?</p>

 
Answer: <p>That formula is wrong -- see <a href="https://docs.google.com/document/d/1BI0ju7fEfXAne1QMSjS1BqgrR9EusPYLYa6p9ekrFKE/edit?hl=en&amp;authkey=CLz0tMQH&amp;pli=1#" rel="nofollow noreferrer">here</a> (linked to from <a href="https://mathoverflow.net/questions/61929/naturally-occurring-orderings">here</a>). That note also contains other interesting thoughts about the fusible numbers, including a new conjecture that would also imply that the order type of $F$ is $\epsilon_0$.</p>

<p>Here's some Java code I wrote to explore these numbers. You can place a red line somewhere by shift-clicking there, and then by clicking or dragging (without Shift) you can move a pair of green lines such that $a\oplus b = c$, where $a$ and $b$ are the numbers corresponding to the green lines and $c$ is the number corresponding to the red line. I used this to find for instance that 101/64 can be generated in three different ways: $101/64=3/4\oplus45/32=15/16\oplus39/32=31/32\oplus19/16$.</p>

<pre><code>import java.awt.Color;
import java.awt.Dimension;
import java.awt.Graphics;
import java.awt.event.MouseAdapter;
import java.awt.event.MouseEvent;
import java.awt.event.MouseMotionAdapter;
import java.awt.event.MouseMotionListener;

import javax.swing.JFrame;
import javax.swing.JPanel;

public class FusibleNumbers {
    static class BinaryNumber {
        long mantissa;
        int exponent;

        public BinaryNumber (long mantissa,int exponent) {
            this.mantissa = mantissa;
            this.exponent = exponent;

            normalize ();
        }

        public void normalize () {
            if (mantissa == 0)
                exponent = 0;
            else
                while ((mantissa &amp; 1) == 0) {
                    mantissa &gt;&gt;= 1;
                    exponent--;
                }
        }

        public double toDouble () {
            return mantissa / (double) (1L &lt;&lt; exponent);
        }

        public String toString () {
            return mantissa + "/2^" + exponent;
        }
    }

    static BinaryNumber getMargin (BinaryNumber x) {
        if (x.mantissa &lt; 0)
            return new BinaryNumber (-x.mantissa,x.exponent);
        BinaryNumber m = getMargin (new BinaryNumber (x.mantissa - (1L &lt;&lt; x.exponent),x.exponent));
        int newExponent = Math.max (x.exponent,m.exponent);
        m = getMargin (new BinaryNumber ((x.mantissa &lt;&lt; (newExponent - x.exponent)) - (m.mantissa &lt;&lt; (newExponent - m.exponent)),newExponent));
        m.exponent++;
        m.normalize ();
        if (m.exponent &gt; 50)
            throw new Error ("exponent overflow");
        return m;
    }

    static int xmin;
    static int xother;

    public static void main (String [] args) {
        JFrame frame = new JFrame ();

        final JPanel panel = new JPanel () {
            public void paintComponent (Graphics g) {
                super.paintComponent (g);
                int exponent = 9;
                int scale = 1 &lt;&lt; exponent;
                Dimension size = getSize ();
                for (int i = 0;i &lt; size.width;i++) {
                    BinaryNumber b = new BinaryNumber (i,exponent);
                    BinaryNumber m = getMargin (b);
                    double d = b.toDouble () + m.toDouble ();
                    int x = (int) (d * scale + .5);
                    g.drawLine (x,0,x,size.height);
                }
                drawLine (g,size,xmin,Color.RED);
                drawLine (g,size,xother,Color.GREEN);
                drawLine (g,size,2*xmin - scale - xother,Color.GREEN);
            }

            private void drawLine (Graphics g,Dimension size,int x,Color color) {
                g.setColor (color);
                g.drawLine (x,0,x,size.height);
            }
        };

        panel.addMouseListener (new MouseAdapter () {
            boolean ctrl;

            MouseMotionListener motionListener = new MouseMotionAdapter () {
                public void mouseDragged (MouseEvent me) {
                    update (me);
                }
            };

            public void mouseReleased (MouseEvent me) {
                update (me);
                panel.removeMouseMotionListener (motionListener);
            }

            public void mousePressed (MouseEvent me) {
                ctrl = (me.getModifiers () &amp; MouseEvent.SHIFT_MASK) != 0;
                panel.addMouseMotionListener (motionListener);
                update (me);
            }

            void update (MouseEvent me) {
                if (ctrl)
                    xmin = me.getX ();
                else
                    xother = me.getX ();
                panel.repaint ();
            }
        });

        frame.getContentPane ().add (panel);
        frame.setBounds (0,0,1200,200);
        frame.setVisible (true);
    }
}
</code></pre>

==============================
===============================
Question: <p>I have a long-term goal of acquiring graduate-level knowledge in Analysis, Algebra and Geometry/Topology. Once that is achieved, I am interested in applying this knowledge to both pure and applied mathematics. In particular, I am interested in various aspects of smooth manifolds, co/homology and mathematical physics. I have acquired a smattering of knowledge in all of these areas but feel that I need to become more focused to make make coherent progress. I have a very bad habit of picking up a book, reading a bit, working out a few details, and then moving on to other random topics in other random books. In doing this, I don't really feel like I accomplish much. </p>

<p>To rectify this admittedly undisciplined approach, I have decided to select core source material from each of the three major areas listed above and focus on it until I have assimilated all the information in that material. For analysis, I have selected Amann and Eschers' Analysis, volumes I, II, and III. I made this choice because out of the analysis texts I have surveyed, theirs seems to be the most comprehensive and treats elementary and advanced analysis as a unified discipline. </p>

<p>My basic strategy is to treat each theorem, example, etc. as a problem and give a fair amount of effort to proving before consulting the text. I think this is probably the best way to approach the material for maximum understanding but it requires a considerable amount of time. There are probably thousands of these sorts of "problems" among the three volumes. Ulitimately, I would like to end up with a notebook (which would probably number in the thousands of pages) that contains all of the details to all of the theorems completely worked out, as much as possible, with my own thoughts. Again, this seems like it will take forever and my time on this earth is unfortunately finite. I'm reasonably confident though that the production of such a set of notes would lead to at least a fair level of mastery of the material in question.</p>

<p>Can anyone suggest an alternate strategy that might be more effective in terms of time but that would lead to a comparable level of mastery?</p>

<p>It is also a problem that I might actually prove a fact completely on my own but then, a month later, might not be able to recall it in a time of need. What strategies are helpful for best ingraining this material (other than the obvious "Work lots of problems" approach)? </p>

<p>Would appreciate any tips or pointers.</p>

 
Answer: <p>This was supposed to be a comment, but it is too long and there may be lessons in it from what I've experienced.</p>

<hr>

<p>This is a great question (I would add a bounty from my own rep if this wasn't community wiki), and it is also a very personal issue that I struggle with myself. I have a similar style of study to the one you described when it comes to things I am <em>really</em> interested in, rather than things that happen to be part of the syllabus on an undergraduate/graduate course I am taking (those subjects falling into the latter category tend to all get the same treatment from me -- go to the lecture, absorb the main ideas, briefly look at my notes later to see they make sense, then ignore it until I need it for some problem set or an examination).</p>

<p>However, I find that your style of study (call it <strong>the hard grift method</strong>) means that I am often a little behind classes or lectures, despite the fact that I am trying to pursue a deeper understanding of the material I enjoy. Unfortunately, the style of exam questions means that this level of understanding rarely helps. One can ask oneself whether it is worth the trouble, and ultimately the answer to that question depends on what you want to get out of your learning.*</p>

<p>I am keenly aware of the approach of what Stefan Walter above calls the 'superficial' mathematician, which I do not see as at all disparaging (and for the record, I do not think he does either). I do not really believe in innate talent, but there are many mathematicians smarter than I who seem to pick up just as much knowledge as I might from the hard grift method, by instead coasting from an article to a textbook, to a set of exercises, to a pre-print, while making minimal notes and seemingly picking up the salient points naturally, and then having a fruitful discussion with others about their new findings almost immediately (call this <strong>the flowing method</strong>). From what I read of Terence Tao's blog this is the natural progression from an undergraduate mathematician to a so-called <a href="http://terrytao.wordpress.com/career-advice/there%E2%80%99s-more-to-mathematics-than-rigour-and-proofs/">'post-rigorous' mathematician</a>.</p>

<p>The flowing method seems to reap more benefits, but it also doesn't seem to be a ticket you can buy. I have a few friends already on their PhDs (I am about to finish my humble MMath) and, without wanting to make this sound like a cop-out, their brains seem to work in a different way to mine. It may very well be the case that I am yet to make the transition because I have not yet put in the hours, but I believe that 'putting in the hours' boils down to passion. If you aren't passionate about what you are studying, you won't put in effective hours, and you won't make the transition to post-rigour.</p>

<p>(Aside: I would like to think that one day I might make that transition, but as it stands, I am not sure the life of a professional mathematician is for me!)</p>

<hr>

<p>*To answer your question succinctly: you need to find out what it is you <em>want</em> out of your learning. If it is pure mastery, an effective method for you to try might be: stick to hard grift for a little while, but if you find you've reached a level where your intuition is guiding you more than rigour is, then stop and evaluate, and consider taking your learning to a higher level where the details of proofs are not the most important thing any more. In particular, re-read Terry Tao's post in the above link.</p>

<p>If, however, you enjoy learning for its own sake and want to pursue personal understanding (which I think the hard grift method is best suited for) then you should always keep this goal in mind. Personal understanding is more gratifying than pure mastery; it should be the goal of any true autodidact (see the last section of <a href="http://arxiv.org/pdf/math/9404236v1">this great article</a> by William Thurston).</p>

==============================
===============================
Question: <p>I came across a statement online and have been looking for a proof :</p>

<p>It states that 1, 6 and 120 are the only numbers which are both triangular and factorials.</p>

<p>Is there any way I can prove this? This claim looks too 'big' and I've tried to prove it but</p>

<p>I couldn't. Can anyone help me to prove this?</p>

 
Answer: <p>I've e-mailed Christopher Tomaszewski who, according to the <a href="http://oeis.org/A000142" rel="nofollow noreferrer">OEIS</a>, is the source of this information. I'll report here if he responds.</p>

<p><del>I will point out that, as far as I can tell, the paper Matthew Conroy links to does not answer this question. (Great survey though!)</del></p>

<p>As discovered by user Charles in a comment below, deep <a href="http://oeis.org/history?seq=A000142&amp;start=420" rel="nofollow noreferrer">in the OEIS history (find page with edit #105 and see "Discussion")</a> the following comment by Vladimir Reshetnikov can be seen:</p>

<blockquote>
  <p>From e-mail communication with Christopher M. Tomaszewski I learnt
  that he found that his purported proof of 1-6-120 conjecture was
  incorrect. But he claimed that there is no counterexample below
  10^77337, so it still remains an interesting conjecture.</p>
</blockquote>

==============================
===============================
Question: <p>I've been working on this problem listed in Herstein's <em>Topics in Algebra</em> (Chapter 2.3, problem 4):</p>

<blockquote>
  <p>If $G$ is a group such that $(ab)^i = a^ib^i$ for three consecutive integers $i$ for all $a, b\in G$, show that $G$ is abelian.</p>
</blockquote>

<p>I managed to prove it, but I'm not very happy with my result (I think there's a neater way to prove this). Anyway, I'm just looking to see if there's a different approach to this. </p>

<p><strong>My approach</strong>:</p>

<p>Let $j=i+1, k=i+2$ for some $i\in \mathbb{Z}$.<br></p>

<p>Then we have that $(ab)^i = a^ib^i$, $(ab)^j = a^jb^j$ and $(ab)^k = a^kb^k$.</p>

<p>If $(ab)^k = a^kb^k$, then $a^jb^jab =a^jab^jb$. </p>

<p>We cancel on the left and right and we have $b^ja = ab^j$, that is $b^iba = ab^j$.<br> 
Multiply both sides by $a^i$ on the left and we get $a^ib^iba = a^jb^j$, so $(ab)^iba = (ab)^j$.<br> But that is $(ab)^iba = (ab)^iab$. </p>

<p>Cancelling on the left yields $ab=ba$, which holds for all $a,b \in G$, and therefore, $G$ is abelian.</p>

<p>Thanks!</p>

 
Answer: <p>A very similar solution, but maybe slightly shorter: again let $i$, $i+1$ and $i+2$ be the three consecutive integers that work for $a$ and $b$.  From $a^{i+1} b^{i+1}  = (ab)^{i+1} = (ab)(ab)^i = aba^i b^i$ we get $a^i b = b a^i$.  The same proof with $i$ replaced by $i+1$ gives
$a^{i+1} b = b a^{i+1}$. Now $a b = a b a^i a^{-i} = a a^i b a^{-i} = a^{i+1} b a^{-i} = b a^{i+1} a^{-i} = b a$.</p>

==============================
===============================
Question: <p>Let $G$ be a group and let $a,b$ be two elements of $G$. What can we say about the order of their product $ab$?</p>

<p><a href="http://en.wikipedia.org/w/index.php?title=Order_%28group_theory%29&amp;oldid=430774926">Wikipedia</a> says "not much":</p>

<blockquote>
  <p>There is no general formula relating the order of a product $ab$ to the orders of $a$ and $b$. In fact, it is possible that both $a$ and $b$ have finite order while $ab$ has infinite order, or that both $a$ and $b$ have infinite order while $ab$ has finite order.</p>
</blockquote>

<p>On the other hand no examples are provided. $(\mathbb{Z},+), 1$ and $-1$ give an example of elements of infinite order with product of finite order. I can't think of any example of the other kind! So:</p>

<ul>
<li>What's an example of a group $G$ and two elements $a,b$ both of finite order such that their product has infinite order?</li>
</ul>

<hr>

<p>Wikipedia then states:</p>

<blockquote>
  <p>If $ab = ba$, we can at least say that $\mathrm{ord}(ab)$ divides $\mathrm{lcm}(\mathrm{ord}(a), \mathrm{ord}(b))$</p>
</blockquote>

<p>which is easy to prove, but not very effective. So:</p>

<ul>
<li>What are some similar results about the order of a product, perhaps with some additional hypotheses?</li>
</ul>

 
Answer: <p>Simple examples are given by free products, assuming you know the normal form for a free product; otherwise, I'm not really saying much.</p>

<p>If you want a more concrete example, take the $2\times 2$ matrices with coefficients in $\mathbb{Q}$, and
$$a = \left(\begin{array}{cc}0&amp;1\\1&amp;0\end{array}\right),\qquad b=\left(\begin{array}{cc}0 &amp; 2\\\frac{1}{2}&amp; 0\end{array}\right).$$
Then $a^2=b^2=1$, but
$$ab = \left(\begin{array}{cc}\frac{1}{2} &amp; 0 \\0 &amp; 2\end{array}\right)$$
has infinite order.</p>

<p>If $a$ and $b$ commute, with $\mathrm{ord}(a)=m$ and $\mathrm{ord}(b)=n$, then you can do better than Wikipedia. We have that:
$$\frac{\mathrm{lcm}(m,n)}{\mathrm{gcd}(m,n)}\quad\text{divides}\quad \frac{\mathrm{lcm}(m,n)}{|\langle x\rangle\cap\langle y\rangle|}\quad\text{divides}\quad \mathrm{ord}(ab)\quad\text{divides}\quad \mathrm{lcm}(m,n).$$
For example, if for every prime $p$ that divides $\mathrm{lcm}(m,n)$, the highest power of $p$ that divides $m$ is different from the highest power of $p$ that divides $n$, then $\mathrm{ord}(ab)=\mathrm{lcm}(m,n)$. </p>

<p>If you are willing to impose global conditions (conditions on $G$), then for example Easterfield proved in 1940 that if $G$ is a $p$-group of class $c$, $a$ has order $p^{\alpha}$, and $b$ has order $p^{\beta}$, then the order of $ab$ is at most $p^m$, where
$$ m  = \max\left\{\alpha,\beta+\left\lfloor\frac{c-1}{p-1}\right\rfloor\right\}.$$
From this you can get similar results for a finite nilpotent group (which is necessarily a product of $p$-groups), and hence for the product of two elements of finite order in any nilpotent group (or in fact, in any locally nilpotent group, or even more strongly, in any group in which the 2-generated subgroups are nilpotent).</p>

==============================
===============================
Question: <p>I was told by a tutor that if $f: \mathbb{R}^n \longrightarrow \mathbb{R}^n$ has an invertible <a href="http://mathworld.wolfram.com/Jacobian.html">Jacobian Matrix</a> for all $x \in \mathbb{R}^n$ and $\lim_{|x_k| \rightarrow \infty}|f(x_k)|=\infty$ for all such sequences, then $f$ is already <strong>globally</strong> bijective.</p>

<p>This was very surprising for me (as this seems to be a very strong statement), so I tried to search on the internet for this theorem but I only came up with theorems about local inverses. I hope someone here can give me a reference or a name of this theorem so I could read a detailed proof. I sanity checked it for $n=1$ where it works perfectly.</p>

 
Answer: <p>The result you ask about is called <em>Hadamard's global inverse function theorem</em> or sometimes <em>Hadamard-Cacciopoli theorem</em>. Googling these keywords reveals an entire industry of such local invertibility + something implies global bijectivity results.</p>

<p>Unfortunately, I was unable to find an accessible proof of this result. Among several sources I looked at, by far the best bet seems to be the presentation in Section 6.2 of the beautiful book by S.G.&nbsp;Krantz and H.R.&nbsp;Parks, <em><a href="http://books.google.com/books?id=ya5yy5EPFD0C&amp;pg=PA121">The implicit function theorem: history, theory, and applications</a></em>, Birkh&auml;user, 2002. The proof given there is essentially self-contained and doesn't assume much knowledge on the reader's side. Nevertheless, I should point out that the title of Chapter 6 is <em>Advanced implicit function theorems</em>, so it's definitely not for the faint-hearted.</p>

<hr>

<p>In fact, a more general result is the following, also due to <a href="http://en.wikipedia.org/wiki/Jacques_Hadamard">Jacques Hadamard</a>. It is a bit, but not very much, harder to prove than the result you ask about.</p>

<p>If you don't know what a manifold is, simply replace $M_1$ and $M_2$ by $\mathbb{R}^n$ in the theorem below, and you obtain the result you're asking about &mdash; for $\mathbb{R}^n$ condition 3. is  satisfied and condition 1. translates precisely to the condition $\lim\limits_{|x| \to \infty} |f(x)| = \infty$ your tutor told you.</p>

<blockquote>
  <p><strong>Theorem (Hadamard)</strong></p>
  
  <p>Let $M_1, M_2$ be smooth and connected $n$-dimensional manifolds. Suppose $f: M_1 \to M_2$ is a $C^1$-function such that</p>
  
  <ol>
  <li>$f$ is proper</li>
  <li>The Jacobian of $f$ is everywhere invertible</li>
  <li>$M_2$ is simply connected.</li>
  </ol>
  
  <p>Then $f$ is a homeomorphism (hence globally bijective).</p>
</blockquote>

<p>So, as I said, this theorem is not trivial at all and both this and the result you're interested in can be found in the book I mentioned above. Quite a bit of googling didn't yield a simple(r) proof of the theorem you ask about, but as you have the key-words now, maybe you find something that suits you.</p>

<hr>

<p><strong>Added:</strong> I should have mentioned the better known <a href="http://en.wikipedia.org/wiki/Cartan%2dHadamard_theorem">Cartan-Hadamard theorem</a> which is closely related but seems a bit more geometric in its nature.</p>

==============================
===============================
Question: <p>For example, the square can be described with the equation $|x| + |y| = 1$. So is there a general equation that can describe a regular polygon (in the 2D Cartesian plane?), given the number of sides required?</p>

<p>Using the Wolfram Alpha site, this input gave an almost-square:
<code>PolarPlot(0.75 + ArcSin(Sin(2x+Pi/2))/(Sin(2x+Pi/2)*(Pi/4))) (x from 0 to 2Pi)</code></p>

<p>This input gave an almost-octagon:
<code>PolarPlot(0.75 + ArcSin(Sin(4x+Pi/2))/(Sin(4x+Pi/2)*Pi^2)) (x from 0 to 2Pi)</code></p>

<p>The idea is that as the number of sides in a regular polygon goes to infinity, the regular polygon approaches a circle. Since a circle can be described by an equation, can a regular polygon be described by one too? For our purposes, this is a regular convex polygon (triangle, square, pentagon, hexagon and so on).</p>

<p>It can be assumed that the centre of the regular polygon is at the origin $(0,0)$, and the radius is $1$ unit.</p>

<p>If there's no such equation, can the non-existence be proven? If there <em>are</em> equations, but only for certain polygons (for example, only for $n &lt; 7$ or something), can those equations be provided?</p>

 
Answer: <p>Any polygon (regular or not) can be described by an equation involving only absolute values and polynomials. Here is a small explanation of how to do that.</p>

<p>Let's say that a curve $C$ is given by the equation $f$ if we have $C = \{(x,y) \in \mathbb{R}^2, \, f(x,y) = 0\}$.</p>

<ul>
<li><p>If $C_1$ and $C_2$ are given by $f_1$ and $f_2$ respectively, then $C_1 \cup C_2$ is given by $f_1 . f_2$ and $C_1 \cap C_2$ is given by $f_1^2 + f_2^2$ (or $|f_1| + |f_2|$). So if $C_1$ and $C_2$ can be described by an equation involving absolute values and polynomials, then so do $C_1 \cup C_2$ and $C_1 \cap C_2$.</p></li>
<li><p>If $C = \{(x,y) \in \mathbb{R}^2, \, f(x,y) \ge 0\}$, then $C$ is given by the equation $|f|-f$.</p></li>
</ul>

<p>Now, any segment $S$ can be described as $S = \{(x,y) \in \mathbb{R}^2, \, a x + b y = c, \, x_0 \le x \le x_1, \, y_0 \le y \le y_1\}$, which is given by a single equation by the above principles. And since union of segments also are given by an equation, you get the result.</p>

<p>EDIT : For the specific case of the octagon of radius $r$, if you denote $s = \sin(\pi/8)$, $c = \cos(\pi/8)$, then one segment is given by $|y| \le rs$ and $x = rc$, for which an equation is</p>

<p>$$f(x, y) = \left||rs - |y|| - (rs - |y|)\right| + |x-rc| = 0$$</p>

<p>So I think the octagon is given by</p>

<p>$$f(|x|,|y|) \ f(|y|,|x|) \ f\left(\frac{|x|+|y|}{\sqrt{2}}, \frac{|x|-|y|}{\sqrt{2}}\right) = 0$$  </p>

<p>To get a general formula for a regular polygon of radius $r$ with $n$ sides, denote $c_n = \cos(\pi/n)$, $s_n = \sin(\pi/n)$ and</p>

<p>$$f_n(x+iy) = \left||rs_n - |y|| - (rs_n - |y|)\right| + |x-rc_n|$$</p>

<p>then your polygon is given by</p>

<p>$$\prod_{k = 0}^{n-1} f_n\left(e^{-\frac{2 i k \pi}{n}} (x+iy)\right) = 0$$</p>

<p>Depending on $n$, you can use symmetries to lower the degree a bit (as was done with $n = 8$).</p>

==============================
===============================
Question: <p>How would someone go about doing this? Assume that the first "click" will never be a bomb, and that the number of mines and the area are both known. Rather hoping there is a clever way to do this, but I will not be so surprised if there isn't.</p>

<p>EDIT:
I would assume (though without any real proof) that a program could be written that could solve minesweeper in linear time (as the board gets bigger linearly, if the mines/area ratio stays the same).</p>

<p>It would seem to me that in general no more than 9 blocks need to be considered (the high end of what i've see playing minesweeper at expert) to determine if</p>

<ol>
<li>its a mine</li>
<li>its a safe square</li>
<li>the odds that its a mine</li>
</ol>

<p>That would support my earlier assertion.</p>

<p>EDIT 2: This would also seem to contradict the fact that minesweeper is NP complete, and with probably not so much work one (maybe even I, but probably not) could write an algorithm that can play a perfect game of minesweeper that would have a linearly increasing runtime which would contradict (summery of) the paper <a href="http://web.mat.bham.ac.uk/R.W.Kaye/minesw/ordmsw.htm">here</a>. So I guess this raises the next question which is: where is the flaw in my logic?</p>

<p>EDIT 3: I really am more interesting in the odds than in the algorithm to solve minesweeper. And it would be helpful to me if someone could explain why the number of checks/tests/calculations one has to do does not rise linearly with respect to area.</p>

 
Answer: <p>I am a very good minesweeper player, and I can say that perfect play can get you to win in $99\%$ of the easy ($8\times 8$ with $10 $mines) or intermediate ($16 \times 16$ with $40$ mines) levels. In the expert level ($16 \times 30$ with $99$ mines) it becomes harder to win without making any guesses.</p>

<p>About first click not being a mine, this is obvious, since the mine positions should be generated after your first click, and I think this is the case in the known minesweeper games. </p>

<p>Although, perfect play is not enough, if the distribution of mines is completely random. For instance, I encountered many times the following configuration in a corner of the board
$\begin{matrix} \square&amp; X &amp; M \\ M &amp; M &amp; M \end{matrix}$, where $\square$ is free square, $M$ is a marked mine, and $X$ is an unknown mine. Imagine this configuration in the upper left corner of the table, and the counter says that there is only $1$ mine left. You would have to guess and have only $50\%$ chances of winning, since there is no clue as to where the mine is.</p>

<p>About implementing an algorithm of solving minesweeper games with perfect play, there are some things you should consider, since some of the mines are not always obvious to find. I have in mind a few steps when I solve minesweeper games:</p>

<ul>
<li><p>first mark the obvious mines;</p></li>
<li><p>open the safe squares;</p></li>
<li><p>look for some patterns learned before (e.g. $1-2-1$ or $1-2-2-1$);</p></li>
</ul>

<p>If at one point, none of these steps can be applied, you can only guess the next step. Considering probabilities, is not very conclusive, since the values would be relatively close to $50\%$.</p>

==============================
===============================
Question: <p>Let $\ell^1$ be the space of absolutely summable real or complex sequences. Let us say that a sequence $(x_1, x_2, \ldots)$ of vectors in $\ell^1$ converges weakly to $x \in \ell^1$ if for every bounded linear functional $\varphi \in (\ell^1)^*$, $\varphi(x_n) \rightarrow \varphi(x)$ as $n \to \infty$. How may I show that weak convergence, in this sense, is the same as the usual convergence-in-norm? It's clear the weak convergence implies pointwise convergence, but that's not good enough to conclude strong convergence...</p>

<p>By linearity, it suffices to prove that if $\varphi(x_n) \longrightarrow 0$ for every $\varphi \in (\ell^1)^*$, then $\| x_n \| \longrightarrow 0$. Let $x_n(k)$ be the $k$-th component of the vector $x_n$. Then, $x_n(k) \longrightarrow 0$ for every $k$, so $\sup_n |x_n(k)| &lt; \infty$ for each $k$, and this implies
$$\lim_{N \to \infty} \lim_{n \to \infty} \sum_{k=1}^{N} |x_n(k)| = 0$$
This is almost what I want, but the limits are the wrong way around. The obvious next thing to try is to construct some clever functional, or even a family of clever functionals, but I can't think of anything useful here. I can see that pointwise convergence alone is not good enough — if $x_n$ is the standard basis vector, then $x_n \longrightarrow 0$ pointwise, but $\| x_n \| = 1$ for all $n$. The fact that it doesn't converge strongly can be detected by the linear functional $\varphi(x_n) = \sum_k x_n(k)$, but I'm at a loss as to how to generalise this.</p>

 
Answer: <p>Let $\left\{y^{(n)}\right\}\subset \ell^1$ a sequence which converges weakly to $0$ in $\ell^1$. We assume this sequence doesn't converge in norm, there exists $\varepsilon &gt;0$ such that $\lVert y^{(n)}\rVert\geqslant 3\varepsilon$ (if it's not the case, we will take a subsequence). We will show that there exists $x\in \ell^{\infty}$ and a subsequence $\left\{y^{(k_j)}\right\}$ such that $\langle x,y^{(k_j)}\rangle &gt;\varepsilon$.
Let $n_0$ such that $\sum_{n\geqslant n_0+1}|y^{(0)}_n|&lt;\varepsilon$. For $0\leqslant k\leqslant n_0$, we take $x_k = \operatorname{sgn}y^{(0)}_k$. For all $x\in \ell^{\infty}$ whose $n_0$ first coordinates are $x_k$ we have $\langle x,y^{(0)}\rangle&gt;\varepsilon$.
From the weak convergence, we can find $k_1$ such that for $k\geqslant k_1$ we have $\sum_{n=0}^{n_0} x_ny_n^{(k)}&lt;\varepsilon$. 
We can find $n_1&gt;n_0$ and $x_{n_0+1},\cdots,x_{n_1}$ with $|x_j|\leqslant 1$ such that if $x\in \ell^{\infty}$ with the $n_1$-first coordinates are $x_j$ we have $\langle x,y^{(1)}\rangle&gt;\varepsilon$.
By this way, we will get a subsequence $\left\{ y^{(k_j)}\right\}$ and a $x\in \ell^{\infty}$ such that $\langle x,y^{(k_j)}\rangle&gt;\varepsilon$. This contradicts the weak convergence to $0$.</p>

==============================
===============================
Question: <p>According to <a href="http://en.wikipedia.org/wiki/Triviality_%28mathematics%29#Triviality_in_mathematical_reasoning">Wikipedia</a>:</p>

<blockquote>
  <p>...proofs by mathematical induction
  have two parts: the "base case" that
  shows that the theorem is true for a
  particular initial value such as n = 0
  or n = 1 and then an inductive step
  that shows that if the theorem is true
  for a certain value of n, it is also
  true for the value n + 1. The base
  case is often trivial and is
  identified as such, although there are
  <strong>cases where the base case is difficult
  but the inductive step is trivial</strong>.</p>
</blockquote>

<p>What are some examples of proofs by induction where the base case is difficult but the inductive step is trivial?</p>

 
Answer: <p>Bolzano-Weierstrass theorem: every bounded sequence in $\mathbb{R}^n$ has a convergent subsequence.</p>

<p>The inductive step is very easy and most of the work is in showing that this is true for $n=1$.</p>

==============================
===============================
Question: <p>The infamous "$\pi = 4$" proof was already discussed here:</p>

<p><a href="https://math.stackexchange.com/questions/12906/is-value-of-pi-4">Is value of $\pi = 4$?</a></p>

<p>And I have read all the answers, yet I think that they will not be of much help to me if I try to explain this thing to a non mathematician. The main missing point, in my opinion, is the fact that length of curves is defined using polygonal approximations (discrete approximation of the curve obtained by taking the straight-lines connecting a finite sequence of points on the curve). </p>

<p>However, a layman would ask "why is your strange 'polygonal approximation' method correct, but the $\pi = 4$ proof's method incorrect?" and I have to admit I fail to see strong arguments to convince him here.</p>

<p>So my question might be better stated as "convince a layman the correct way to measure lengths of curves is our (the mathematician's) way"; however, I'm interested specifically in the $\pi = 4$ proof and will be glad to hear totally different approaches to it.</p>

 
Answer: <p>Use a similar "zig-zag" approach to "show" that the diagonal of a $100$ meter by $100$ meter field is $200$.  Everybody who has ever crossed a field will know that walking $1$ meter north, then $1$ meter east, then $1$ north, then $1$ east, and so on is a lousy way to do it.</p>

==============================
===============================
Question: <p>I am going through the problems from Project Euler and I notice a strong insistence on Primes and efficient algorithms to compute large primes efficiently. </p>

<p>The problems are interesting per se, but I am still wondering what the real-world applications of primes would be. </p>

<p>What real tasks require the use of prime numbers?</p>

<hr>

<p>Edit: A bit more context to the question:
I am trying to improve myself as a programmer, and having learned a few good algorithms for calculating primes, I am trying to figure out where I could apply them. </p>

<p>The explanations concerning cryptography are great, but is there nothing else that primes can be used for? </p>

 
Answer: <p>The most popular example I know comes from Cryptography, where many systems rely on problems in number theory, where primes have an important role (since primes are in a sense the "building blocks" of numbers).</p>

<p>Take for example the RSA encryption system: All arithmetic is done modulo $n$, with $n=pq$ and $p,q$ large primes. Decryption in this system relies on computing Euler's phi function, $\varphi(n)$, which is hard to compute (hence the system is hard to break) <strong>unless</strong> you know the prime factorization of $n$ (which is also hard to compute unless you know it upfront). Hence you need a method to generate primes (the Miller-Rabin primality checking algorithm is usually used here) and then you construct $n$ by multiplying the primes you have found.</p>

==============================
===============================
Question: <p>Due to my ignorance, I find that most of the references for mathematical analysis (real analysis or advanced calculus) I have read do not talk much about the "multivariate calculus". After dealing with the single variable calculus theoretically, it usually directly goes to the topic of measure theory.  </p>

<p>After reading the wiki article "<a href="http://en.wikipedia.org/wiki/Second_partial_derivative_test" rel="noreferrer">Second partial derivative test</a>", I'd like to find the rigorous proof for this test. The first book comes to my mind is Courant's <em>Introduction to Calculus and Analysis</em> which includes the multivariate case in the second volume. </p>

<p>Motivated by this, I'd like to put the question here:</p>

<blockquote>
  <p>What are the usual references for the
  <strong>theoretical</strong> treatment for
  <a href="http://en.wikipedia.org/wiki/Multivariable_calculus" rel="noreferrer">Multivariable calculus</a>?</p>
</blockquote>

 
Answer: <p>I usually think of multivariable calculus as being divided into four parts:</p>

<ul>
<li>(Partial) Differentiation</li>
<li>(Multiple) Integration</li>
<li>Curves and Surfaces in $\mathbb{R}^3$</li>
<li>Vector Calculus (Green's Theorem, Stokes' Theorem, Divergence Theorem)</li>
</ul>

<p>For differentiation, you can use <a href="http://rads.stackoverflow.com/amzn/click/007054235X">Principles of Mathematical Analysis</a> by Rudin (Chapter 9).  Actually, this text also discusses integration and vector calculus (Chapter 10), but I personally found Rudin's treatment of such hard to follow when I was first learning the subject.</p>

<p>For differentiation, integration, and vector calculus you can use <a href="http://rads.stackoverflow.com/amzn/click/0805390219">Calculus on Manifolds</a> by Spivak, or <a href="http://rads.stackoverflow.com/amzn/click/0201315963">Analysis on Manifolds</a> by Munkres.</p>

<p>For curves and surfaces, you can use basically any book on elementary differential geometry.  One of the most widely-used is <a href="http://rads.stackoverflow.com/amzn/click/0132125897">Differential Geometry of Curves and Surfaces</a> by do Carmo, though I highly recommend <a href="http://rads.stackoverflow.com/amzn/click/184882890X">Elementary Differential Geometry</a> by Pressley.</p>

<hr>

<p>A few remarks as to where these topics end up going, with a slant towards differential geometry:</p>

<p>Differentiation of functions $f\colon \mathbb{R}^n \to \mathbb{R}^m$ can be generalized to <a href="http://en.wikipedia.org/wiki/Pushforward_%28differential%29">differentials</a> (a.k.a. <em>pushforwards</em>) of maps $f\colon M \to N$ between <a href="http://en.wikipedia.org/wiki/Smooth_manifold">differentiable manifolds</a>.</p>

<p>All of the references I mentioned above treat multiple <em>Riemann</em> integration of functions $f\colon \mathbb{R}^n \to \mathbb{R}$.  This can be generalized to multiple <em>Lebesgue</em> integration via consideration of <a href="http://en.wikipedia.org/wiki/Product_measure">product measures</a>.</p>

<p>The theory of curves and surfaces leads naturally towards <a href="http://en.wikipedia.org/wiki/Riemannian_geometry">Riemannian geometry</a>, though certainly other branches of geometry also generalize this subject.</p>

<p>In vector calculus, one discusses line integrals and surface integrals of both functions and (co)vector fields.  To my mind, the intricacies of such processes are not fully realized until one studies the integration of <a href="http://en.wikipedia.org/wiki/Differential_form">differential forms</a> on differentiable manifolds.</p>

==============================
===============================
Question: <p>It is easy to find 3 squares (of integers) in arithmetic progression. For example, $1^2,5^2,7^2$.</p>

<p>I've been told Fermat proved that there are no progressions of length 4 in the squares. Do you know of a proof of this result? </p>

<p>(Additionally, are there similar results for cubes, 4th powers, etc? If so, what would be a good reference for this type of material?)</p>

<hr>

<p><strong>Edit, March 30, 2012:</strong> The following <a href="https://mathoverflow.net/questions/92707/squares-in-an-arithmetic-progession">question</a> in MO is related and may be useful to people interested in the question I posted here.</p>

 
Answer: <p>Here are a few proofs: <a href="http://www.math.uconn.edu/~kconrad/blurbs/ugradnumthy/4squarearithprog.pdf">1</a>, <a href="http://www.math.ku.dk/~kiming/lecture_notes/2007-2008-elliptic_curves/4_squares_in_arithmetic_progression.pdf">2</a> (which is excellent), and the somewhat bizarre <a href="http://www.mathpages.com/home/kmath044/kmath044.htm">3</a>.</p>

<p>Unfortunately, there are no cases where you have nontrivial arithmetic progressions of higher powers. This is a string of proofs. Carmichael himself covered this for n = 3 and 4, about a hundred years ago. But it wasn't completed until Ribet wrote a paper on it in the 90s. His paper can be found <a href="http://math.berkeley.edu/~ribet/Articles/acta.pdf">here</a>. The statement is equivalent to when we let $\alpha = 1$. Funny enough, he happens to have sent out a notice on scimath with a little humor, which can still be found <a href="http://www.math.niu.edu/~rusin/known-math/96/fermatlike">here</a>.</p>

==============================
===============================
Question: <p>I met a student that is trying to prove for fun that there are infinitely many primes of the form $n^2+1$. I tried to tell him it's a hard problem, but I lack references. Is there a paper/book covering the problem? Is this problem really hard or I remember incorrectly?</p>

 
Answer: <p>This is an <em>incredibly</em> difficult problem.</p>

<p>It is one of <a href="http://en.wikipedia.org/wiki/Landau%27s_problems">Landau's 4 problems</a> which were presented at the 1912 international congress of mathematicians, all of which remains unsolved today nearly 100 years later.</p>

==============================
===============================
Question: <p>(Note that I have used bold text frequently simply to highlight the key points of my question for those who do not have the time to read through it thoroughly (it is not very long, however); I hope this is not considered offensive.)</p>

<p>There are many textbooks on multivariable calculus. However, some textbooks on multivariable calculus do not focus very much on the <strong>theoretical foundations</strong> of the subject. For example, a textbook might state a result along the lines of "the order of partial differentiation is immaterial" without proof and ask the student to use this rule to solve problems. Similarly, theorems such as those due to Green and Stokes are often not proved in their full generality. </p>

<p>Therefore, I ask the following question: </p>

<blockquote>
  <p>What are some good <strong>theoretical
  multivariable calculus textbooks</strong>?</p>
</blockquote>

<p>Since "theoretical" is somewhat ambiguous, let me state the following criteria which I would like a "theoretical" textbook on multivariable calculus to satisfy:</p>

<ul>
<li>The textbook should be <strong>rigorous</strong> and it should <strong>not state a theorem without proof</strong> if the theorem is proved in at least one other multivariable calculus textbook. (Of course, the textbook may <em>omit</em> certain theorems; however, this criterion at least ensures that major theorems in multivariable calculus are not stated without proof and used purely for the sake of computations. Also, this criterion permits the textbook to state an interesting theorem if it is beyond the scope of all multivariable calculus textbooks.)</li>
<li>The textbook should be <em>primarily</em> based on developing the theoretical foundations of multivariable calculus; therefore, applications such as learning how to compute the partial derivative of a function, learning how to solve extremum problems, learning how to compute etc. <strong>should be kept to a minimum</strong>. In particular, the textbook can <em>assume</em> that the reader has already seen at least an informal treatment of the subject where these aspects are emphasized.</li>
<li>The textbook should have a rigorous treatment of <strong>differentiability in $n$-dimensional Euclidean space</strong> (e.g., the inverse and implicit function theorems should be proven), <strong>Riemann integration in $n$-space</strong>, and <strong>differential forms</strong> (e.g., Stokes theorem should be proven). It would also be a bonus if the book treated the general concept of a manifold.</li>
<li><strong>Textbooks with minimal prerequisites are preferred</strong>; however, please feel free to suggest books meeting the above criteria even if the prerequisites are quite demanding.</li>
<li>Finally, it would also be preferable, but not essential, for the book to <strong>only treat multivariable calculus</strong>.</li>
</ul>

<p>Examples of books meeting the above criteria: "Analysis on Manifolds" by James Munkres, "Principles of Mathematical Analysis" by Walter Rudin, and "Calculus on Manifolds" by Michael Spivak. </p>

<p>Although I have studied theoretical multivariable calculus already (four years ago), I could never find "the perfect book" (relative to myself, of course). Every book has its virtues; Rudin for its elegance, Munkres for its beautiful exposition, and Spivak for its "quick and dirty" approach. I am hoping that someone will be able to suggest a book that (relative to myself) is "perfect". Also, this question can be useful to other students who have not yet studied the subject and wish to learn it. </p>

<p>Thank you very much for all answers! <strong>Please do feel free to suggest as many books as you can think of</strong> so we can form a big list. Also, please try to <strong>explain why a particular book is good</strong> or at least why <em>you think</em> it is good. I suppose it is fine to suggest a book that is already suggested provided you have a different view as to why the book is good.</p>

 
Answer: <p>A book fitting your description quite well is </p>

<p><a href="http://rads.stackoverflow.com/amzn/click/0521551145">Multidimensional Real Analysis</a> by Duistermaat and Kolk, a 2-volume set: Differentiation and Integration.</p>

<p>It has rigorous, slick proofs, is highly theoretical, but with lots of (advanced) examples and many, many exercises. Much attention is given to the Inverse and Implicit Function theorem, and submanifolds of $\mathbb{R}^n$. The book is used in a second-year course at Utrecht University. I have to admit that it was quite hard to read for me when I took the course. But it is great as a reference, and years later I still consult it now and then.</p>

<p>Another nice book is Loomis &amp; Sternberg - <a href="http://rads.stackoverflow.com/amzn/click/0867201223">Advanced Calculus</a> (freely available from <a href="http://www.math.harvard.edu/~shlomo/">Sternberg's website</a>.)</p>

==============================
===============================
Question: <p>Here's my problem. I'm studying math and when I really work hard, I think I understand things very good, but that comes at a big cost: in the last few years, I've had practically zero physical exercise, I've gained $30$&nbsp;kg, I've spent countless hours studying at night, constantly had sleep deprivation, I've lost my social life, and I got health problems. My grades are quite good, but I feel as though I'm wasting my life.</p>

<p>I love mathematics when it's done my way, but that's hardly ever. I would very much like my career to be centered around mathematics (topology, algebra or something similar). I want to really understand things and I want the proofs to be done in a (reasonably) rigorous way. I've been accused of being a formalist before, but I don't consider myself one at all. However, I am a perfectionist, I admit. For comparison, the answers of Theo, Arturo, Jim Belk, Mariano, etc. are absolutely rigorous enough for me. From my experience, 
$80$% or more mathematics in our school is done in a sketchy, "hmm, probably true" kind of way (just like reading cooking recipes), which bugs the hell out of me. Most classmates adapt to it. I for some reason can't. I don't understand things until I understand them (almost) completely. They learn "how one should do things", but less often do they ask themselves WHY is this correct. I have two friend physicists, who have the exact same problem. One is at the doctorate level, constantly frustrated, while the other abandoned physics altogether after getting a diploma. Apart from one $8$, he had a perfect record, all are $10$s. He said that he doesn't feel he understands physics well enough. From my experience, ALL his classmates understand less than he does, they just go with the flow and accept certain statements as true.</p>

<p>Also, my problem is having weak memory. I forget a lot. Having to study a different subject each day is killing me. If it were up to me, I'd change the way lectures are done. We'd study only ONE subject for a month or two, then have the exams, and the next month or two the next subject. Mixing it up has a terrible effect: I forget things, because I constantly change the topic. That's why I'm always behind schedual. For example, in the second year, during the school year, I understood almost nothing of multivariable calculus, because I had to simultaneously study abstract algebra, topology, computer programming, etc, and couldn't keep up. But then, I devoted the whole three months of summer and got through all $330$ pages of theory, understood it very good, including all the proofs ( which I was forgetting along the way), got a $9/10$ grade, and had absolutely no vacations (stayed at home), no free time, no sport, no nothing. It was complete crap.</p>

<ul>
<li>should I not read the proofs at all?</li>
<li>should I try less hard, get worse grades and understanding, and 'have a life'?</li>
<li>abandon the idea of doing math for a living?</li>
<li>how can I spot the important/illustrative proofs, <em>without</em> studying them completely (it often happens, that I 'get the whole point' only after I've understood the whole proof)</li>
</ul>

<p>I'm not gifted/bright at all, I'm completely <strong>average with a bad memory</strong>, but I do have interest in math, good grades, and a horrible lifestyle for the last few years. <strong>This question is directed at people who have a career doing mathematics. How did you manage to study everything on time, AND sufficiently rigorous, that you were able to understand it?</strong></p>

<p>ADDITIONS:</p>

<p>I often tend to be the only one to find serious issues in the proofs, in the formulations of theorems, and also in the worked out exercises at classes. Everyone else either understands everything/most, or doesn't understand and also doesn't care for possible issues. Often do I find holes in the proofs and that hypotheses are missing in the theorem. When I present them to the professor, he says that I'm right, and says that I'm very precise. How is this precise, when the theorem doesn't hold in it's current state. Are we even supposed to understand proofs. Are the proofs actually really just sketches? How on earth is one then supposed to be able to discover mathematical truths? Is the study of mathematics just one big joke and you're not supposed to take it too seriously?</p>

<p>NOTE:</p>

<p>I have a bunch of sports I like and used to do. Also, I had a perfectly good social life before, so you don't need to give advice regarding that. I don't socialize and do sport because digesting proofs and trying to understand the ideas behind it all eats up all my time. If I go hiking, it will take away $2$ days, one to actually walk + one to rest and regenerate. If I go train MMA, I won't be focused for the whole day. I can't just switch from boxing to diagram chasing in a moment. Also, I can't just study for half an hour. The way I study is I open the book, search up what I already know but forgot from the previous day, and then go from theorem to theorem, from proof to proof, correcting mistakes, adding clarifications, etc. etc. Also, I have a bad habit of having <strong>difficulty starting</strong> things, but when I do start 'my engine', I have <strong>difficulty stopping</strong>, especially if it's going good. That's why I unintentionally spend an hour or two before studying just doing the most irrelevant stuff, just to avoid study. This happens especially when I've had more math than I can shove down my throat, I have mental preparations to begin studying. But when my engine does start and studying goes well (proven a lot, understood a lot), it's hard for me to stop, so I often stay late at night, up to 4&nbsp;a.m., 5&nbsp;a.m., 6&nbsp;a.m. When the day of the exam arrives, I don't go to sleep at all, and the <strong>night and day are reversed</strong>. I go to sleep at 13h, and wake at 21h... I know it's not good but I can't seem to break this habit. If I'm useless through the whole day, I <strong>feel a need (guilty conscience) to do at least smth. useful before I go to sleep</strong>. I know this isn't supposed to happen if one loves mathematics, but when it's 'forced upon you' what and how much and in what amount of time you have to study, you start being put off by math. It stops being enjoyment/fun and becomes hard work that just needs to be done.
<img src="https://i.stack.imgur.com/dDlSD.jpg" alt="enter image description here"></p>

 
Answer: <p>In my view the central question that you should ask yourself is what is the end <em>goal</em> of your studies. As an example, American college life as depicted in film is hedonistic and certainly not centered on actual studies. Your example is the complete opposite - you describe yourself as an ascetic devoted to scholarship.</p>

<p>Many people consider it important to lead a <em>balanced</em> life. If such a person were confronted with your situation, they might look for some compromise, for example investing fewer time on studies in return for lower grades. If things don't work out, they might consider opting out of the entire enterprise. Your viewpoint might be different - for you the most important dimension is intellectual growth, and you are ready to sacrifice all for its sake.</p>

<p>It has been mentioned in another answer that leading a healthy lifestyle might contribute to your studies. People tend to "burn out" if they work too hard. I have known such people, and they had to periodically "cool off" in some far-off place. On the contrary, non-curricular activities can be invigorating and refreshing.</p>

<p>Another, similar aspect is that of "being busy". Some people find that by multitasking they become more productive in each of their individual "fronts". But that style of life is not for every one.</p>

<p>Returning to my original point, what do you expect to accomplish by being successful in school? Are you aiming at an academic career? Professional career? In North America higher education has become a rite of passage, which many graduates find very problematic for the cost it incurs. For them the issue is often economical - education is expensive in North America.</p>

<p>You might find out that having completed your studies, you must turn your life to some very different track. You may come to realize that you have wasted some best years of your life by studying hard to the exclusion of everything else, an effort which would eventually lead you nowhere. This is the worst-case scenario.</p>

<p>More concretely, I suggest that you plan ahead and consider whether the cost is worth it. That requires both an earnest assessment of your own worth, and some speculation of the future job market. You should also estimate how important you are going to consider these present studies in your future - both from the economical and the "cultural" perspective.</p>

<p>This all might sound discouraging, but your situation as you describe it is quite miserable. Not only are you not satisfied with it, but it also looks problematic for an outside observer. However, I suspect that you're exaggerating, viewing the situation from a romantic, heroic perspective. It's best therefore to talk to people who know you personally.</p>

<p>Even better, talk to people who're older than you and in the next stage of "life". They have a wider perspective on your situation, which they of their acquaintances have just still vividly recall. However, even their recommendations must be taken with a grain of salt, since their present worries are only part of the larger picture, the all-encompassing "life".</p>

<hr>

<p>Finally, a few words more pertinent to the subject at hand.</p>

<p>First, learning strategy. I think the best way to learn is to solve challenging exercises. The advice given here, trying to "reconstruct" the textbook before reading it, seems very time consuming, and in my view, concentrating the effort at the wrong place</p>

<p>The same goes for memorizing theorems - sometimes one can only really "understand" the proof of a theorem by studying a more advanced topic. Even the researcher who originally came out with the proof probably didn't "really" understand it until a larger perspective was developed.</p>

<p>Memorizing theorems is not your choice but rather a necessity. I always disliked regurgitation and it is regrettable that this is forced unto you. I'm glad that my school would instead give us actual problems to solve - that's much closer to research anyway. Since you have to go through this lamentable process, try to come up with a method of memorization which has other benefits as well - perhaps aim at a better understanding of "what is going on" rather than the actual steps themselves. This is an important skill.</p>

<p>Second, one of the answers suggests trying to deduce as many theorems as possible as the "mathematical" thing that ought to be done after seeing a definition. I would suggest rather the opposite - first find out what the definition entails, and then try to understand why the concept was defined in the first place, and why in that particular way.</p>

<p>It is common in mathematics to start studying a subject with a long list of "important definitions", which have no import at all at that stage. You will have understood the subject when you can explain where these definitions are coming from, what objects they describe; and when you can "feel" these objects intuitively. This is a far cry from being able to deduce some facts that follow more-or-less directly from the definitions.</p>

==============================
===============================
Question: <p>I've seen both counterexamples and proofs to "compact implies sequentially compact", and I'm not sure what's going on.</p>

<p>Apparently there are compact spaces which are not sequentially compact; quick googling and wikipedia checks will turn up examples floating around; they tend to be variants of $[0,1]^{[0,1]}$ with the product topology.  Here's a demonstration(?):</p>

<blockquote>
  <p>$[0,1]^{[0,1]}$ is compact by Tychonoff's theorem.  So, we demonstrate failure of sequential compactness.</p>
  
  <p>Choose a unique binary representation for each $x\in [0,1]$.</p>
  
  <p>For each $n\in\mathbb{N}$, let $f_n : [0,1]\to[0,1]$ (an element of $[0,1]^{[0,1]}$) be the function which maps each $x$ to its $n$-th place digit in its binary expansion.</p>
  
  <p>Let $f_{n_k}$ be a subsequence of this sequence.</p>
  
  <p>Let $x&#39;\in [0,1]$ be such that the $n_{2m}$-th digit is $0$ and the $n_{2m+1}$-th digit is $1$, for all $m\in\mathbb{N}$.</p>
  
  <p>Then $f_{n_k} (x&#39;)$ does not converge (it alternates between $0$ and $1$), and hence $f_{n_k}$ cannot converge.</p>
  
  <p>Thus we have found a sequence in $[0,1]^{[0,1]}$ without any convergent subsequence and so it is not sequentially compact.</p>
</blockquote>

<p>(Aside: this is apparently based off of an example in Steen's Counterexamples in Topology, according to <a href="http://ncatlab.org/nlab/show/sequentially+compact+space">http://ncatlab.org/nlab/show/sequentially+compact+space</a> )</p>

<p>Nevertheless, there's also some proofs(?) floating around that compactness of a space implies sequential compactness, along these lines (this proof(?) is of the contrapositive):</p>

<blockquote>
  <p>Suppose $X$ is not sequentially compact.</p>
  
  <p>By definition, this means there is some sequence $(x_n)$ over $X$ with no convergent subsequence.</p>
  
  <p>If any $x\in X$ had for each of its neighborhood $U$ infinitely many $n$ for which $x_n \in U$, then we could define a convergent subsequence of $(x_n)$, contradicting our assumption.  (Presumably this is done by choosing for each neighborhood a sufficiently-large-indexed term in that neighborhood.)</p>
  
  <p>Thus, for each $x \in X$ we can select an open set $U_x$ such that $x\in U_x$ but with $x_n \in U_x$ for only finitely many $n$.</p>
  
  <p>The collection $\mathcal{U}=\{U_x : x\in X\}$ is clearly an open cover of $X$.</p>
  
  <p>If $\mathcal{U}$ had a finite subcover $\{U_1, \dots, U_k\}$ then the union $U_1 \cup \cdots \cup U_k$ would contain all of $X$ but only contain $x_n$ for finitely many $n$, which is impossible.</p>
  
  <p>Thus $X$ is not compact, since we have found an open cover without a finite subcover.</p>
</blockquote>

<p>(Aside: this proof is essentially the same as the proof appearing in Rudin's Principles of Mathematical Analysis for Thm 2.37 that infinite subsets of compact spaces have limit points.)</p>

<p>So, what's going on here?  It can't be that what both the counterexample and the proof are telling us is correct.  Is there some subtle (or more embarassingly for me -- glaring) flaw in the proof?</p>

 
Answer: <p>The problem is here:</p>

<blockquote>
  <p>If any $x\in X$ had for each of its neighborhood $U$ infinitely many $n$ for which $x_n \in U$, then we could define a convergent subsequence of $(x_n)$, contradicting our assumption.  (Presumably this is done by choosing for each neighborhood a sufficiently-large-indexed term in that neighborhood.)</p>
</blockquote>

<p>In general topological spaces this only implies that we are able to construct a convergent net, not a convergent sequence. (A point $x$ is an accumulation point of a subset $S$ $\Leftrightarrow$ there exists a net of points of $S\setminus\{x\}$ converging to $x$.)</p>

<p>If $X$ is first countable at $x$ (the point $x$ has a countable base), then a sequence can be constructed. (This is more-or-less standard. We first construct a decreasing base $U_n$ at $x$ and then choose a point from each $U_n$). In particular, this works for metric spaces. Note that Rudin works only with compact subset of metric spaces in that chapter.</p>

==============================
===============================
Question: <p>Let's fix some terminology first. A category $\mathcal{C}$ is <em>preabelian</em> if:</p>

<p>1) $Hom_{\mathcal{C}}(A,B)$ is an abelian group for every $A,B$ such that composition is biadditive,</p>

<p>2) $\mathcal{C}$ has a zero object,</p>

<p>3) $\mathcal{C}$ has binary products,</p>

<p>4) $\mathcal{C}$ has kernels and cokernels.</p>

<p>A category $\mathcal{C}$ is <em>abelian</em> if it is preabelian and satisfies:</p>

<p>5) every monomorphism is a kernel and every epimorphism is a cokernel.</p>

<p>Define the coimage of a map to be the cokernel of its kernel, and the image to be the kernel of its cokernel. We have the following commutative diagram:</p>

<p><img src="https://i.stack.imgur.com/uOziO.png" alt="enter image description here"></p>

<p>where $\overline{f}$ is the only existing map (because of universality of kernel and cokernel).</p>

<p>I'm having trouble proving the following:</p>

<blockquote>
  <p>A preabelian category $\mathcal{C}$ is abelian iff $\overline{f}$ is an isomorphism.</p>
</blockquote>

<p>The converse is easily shown, I'm having trouble proving $\Rightarrow$...</p>

 
Answer: <p>Here is an argument for $\Rightarrow$. There is not much more to it than chasing diagrams (as it should be). Also, I didn't really bother to check which (parts of the) axioms are actually needed:</p>

<ol>
<li><p>In presence of 1),2),3) we have that <a href="https://math.stackexchange.com/q/25213/">$\mathcal{C}$ has biproducts</a> as well: every binary coproduct is also a binary product. (This is not used below but I added it for the sake of completeness)</p></li>
<li><p>Assuming 1)-5), an epi $e:B \to C$ is the cokernel of its kernel. <img src="https://i.stack.imgur.com/RQDx3.png" alt="cokernel of kernel diagram"><br>
Indeed, let $f$ be a morphism such that $e = \operatorname{coker}\,{f}$ and let $k = \operatorname{ker}{e}$. Since $ef = 0$, we see that $f = kf'$. If $y$ is such that $yk =0$ then $ykf' = yf = 0$ and hence $y = y'e$,  and thus $e$ is a cokernel of $k$.<br><br> Dually, a mono is the kernel of its cokernel.</p></li>
<li><p>Assuming 1)-5) a morphism which is both an epimorphism and a monomorphism is an isomorphism. <br><br>I leave that as an easy exercise (I gave the argument in the comments above).</p></li>
<li><p>Let $f: A \to B$. The morphism $i: \operatorname{Coim}{f} \to B$ is monic.<img src="https://i.stack.imgur.com/kwqQh.png" alt="i monic"><br> To this end, let $x: X \to \operatorname{Coim}{f}$ be such that $ix = 0$. Let $q = \operatorname{coker}{x}$ and let $j: \operatorname{Coker}{x} \to B$ be the unique map such that $i = jq$. Since $qp$ is epi we have a morphism $h: H \to A$ such that $qp = \operatorname{coker}{{h}}$. Now $fh = iph = jqph = 0$ so $h = kh'$. This gives that $ph = pkh' = 0$, 
<img src="https://i.stack.imgur.com/J6FJa.png" alt="factorization of p"><br>
so $p$ factors as $p = p'(qp) = (p'q)p$. But $p$ is epi, so $p'q = 1_{\operatorname{Coim}{f}}$. This implies that $q$ is a monomorphism and finally $qx = 0$ implies that $x = 0$. We have shown that $ix = 0$ implies $x = 0$ and thus $i$ is a monomorphism.<br><br>
Dually $j: A \to \operatorname{Im}f$ is an epimorphism.</p></li>
<li><p>Consider the factorization of $f$:
<img src="https://i.stack.imgur.com/NiInl.png" alt="Analysis of a morphism">
By step 4 we have that $A \to \operatorname{Im}{f}$ and $\operatorname{Coim}{f} \to B$ are epi and mono, respectively. Therefore $\bar{f}$ is both epi and mono and we're done by step 3.</p></li>
</ol>

==============================
===============================
Question: <p>When I was studying linear algebra in the first year, from what I remember, vector spaces were always defined over a field, which was in every single concrete example equal to either $\mathbb{R}$ or $\mathbb{C}$.</p>

<p>In Associative Algebra course, we sometimes mentioned (when talking about $R$-modules) that if $R$ is a division ring, everything becomes trivial and known from linear algebra.</p>

<p>During the summer, I'm planning to revisit my notes of linear algebra, write them in tex, and try to prove as much as possible in a general setting. </p>

<p><strong>Are there any theorems in linear algebra, that hold for vector spaces over a field and not over a division ring?</strong> How much linear algebra can be done over a division ring?</p>

<p>Also, <strong>what are some examples of division rings, that aren't fields?</strong> $\mathbb{H}$ is the only one that comes to mind. I know there aren't any finite ones (Wedderburn). Of course, I'm looking for reasonably nice ones...</p>

 
Answer: <p>In my experience, when working over a division ring $D$, the main thing you have
to be careful of is the distinction between $D$ and $D^{op}$.</p>

<p>E.g. if $F$ is a field, then $End_F(F) = F$ ($F$ is the ring of $F$-linear endomorphisms of itself, just via multiplication), and hence $End(F^n) = M_n(F)$;
and this latter isomorphism is what links matrices and the theory of linear transformations.</p>

<p>But, for a general division ring $D$, the action of $D$ by left multiplication on itself is not $D$-linear, if $D$ is not commutative.  Instead, the action of $D^{op}$ on $D$ via right multiplication is $D$-linear, and so we find that
$End_D(D) = D^{op}$, and hence that $End_D(D^n) = M_n(D^{op}).$</p>

<hr>

<p>As for examples of division algebras, they come from fields with non-trivial <a href="http://en.wikipedia.org/wiki/Brauer_group" rel="nofollow noreferrer">Brauer groups</a>, although this may not help particularly with concrete examples.  </p>

<p>A standard way to construct examples of central simple algebra over a field $F$ is via a <em>crossed product</em>.  (Unfortunately, there does not seem to be a wikipedia entry on this topic.)</p>

<p>What you do is you take an element $a\in F^{\times}/(F^{\times})^n$, and
a cyclic extension $K/F$, with Galois group generated by an element $\sigma$
of order $n$, and then define a degree $n^2$ central simple algebra $A$ over $F$
as follows:</p>

<p>$A$ is obtained from $K$ by adjoining a non-commuting, non-zero element $x$,
which satisfies the conditions</p>

<ol>
<li>$x k x^{-1} = \sigma(k)$ for all $k \in K$, and</li>
<li>$x^n = a$.</li>
</ol>

<p>This will sometimes produce division algebras.  </p>

<p>E.g. if we take $F = \mathbb R$, $K = \mathbb C$, $a = -1$, and $\sigma =$ complex conjugation, then $A$ will be $\mathbb H$, the Hamilton quaternions.</p>

<p>E.g. if we take $F = \mathbb Q_p$ (the $p$-adic numbers for some prime $p$),
we take $K =$ the unique unramified extension of $\mathbb Q_p$ of degree $n$,
take $\sigma$ to be the Frobenius automorphism of $K$,
and take $a = p^i$ for some $i \in \{1,\ldots,n-1\}$ coprime to $n$,
then we get a central simple division algebra over $\mathbb Q_p$, which is called <em>the division algebra over $\mathbb Q_p$ of invariant $i/n$</em> (or perhaps $-i/n$, depending on your conventions).</p>

<p>E.g. if we take $F = \mathbb Q$, $K =$ the unique cubic subextension of $\mathbb Q$ contained in $\mathbb Q(\zeta_7)$, and $a = 2$, then we will get 
a central simple division algebra of degree $9$ over $\mathbb Q$.
(To see that it is really a division algebra, one can extend scalars to $\mathbb Q_2$, where it becomes a special case of the preceding construction.)</p>

<p>See Jyrki Lahtonen's answer to this question, as well as Jyrki's answer <a href="https://math.stackexchange.com/questions/45085/an-example-of-a-division-ring-d-that-is-not-isomorphic-to-its-opposite-ring/45086#45086">here</a>, for some more detailed examples of this construction.  (Note that a key condition for getting a division algebra is that the element $a$ not be norm from the extension $K$.)</p>

<hr>

<p>Added: As the OP remarks in a comment below, it doesn't seem to be so easy to find non-commutative division rings.  Firstly, perhaps this shouldn't be so surprising, since there was quite a gap (centuries!) between the discovery of complex numbers and Hamilton's discovery of quaternions, suggesting that the latter are not so easily found.</p>

<p>Secondly, one easy way to make interesting but tractable non-commutative rings is to form group rings of non-commutative finite groups, and if you do this over e.g. $\mathbb Q$, you can find interesting division rings inside them.  The one problem with this is that a group ring of a non-trivial group is never itself a division ring; you need to use Artin--Wedderburn theory to break it up into a product of matrix rings over division rings, and so the interesting division rings that arise in this way lie a little below the surface.  </p>

==============================
===============================
Question: <p>if $X$ and $Y$ are Hausdorff spaces, $f:X \to Y$ is a local homeomorphism, $X$ is compact, and $Y$ is connected, is $f$ a covering map?</p>

<p>It seems to be, and I almost have a proof, but I'm stuck at the very end of it:</p>

<p>I've already proved that $f$ is surjective (using the connectedness), and that for each $y \in Y$, $f^{-1}(y)$ is finite. Because $X$ is compact, there exists a finite open cover of $X$ by $ \{ U_i \}$ such that $f(U_i)$ is open and $f |_{U_i}:U_i \to f(U_i) $ is a homeomorphism.<br>
For each $y \in Y$, we choose the subset $ \lbrace U_{i_j} \rbrace $ such that $y \in U_{i_j}$, and then define $V = \bigcap_{j=1}^k f(U_{i_j})$, and $U'_j = U_{i_j} \bigcap f^{-1}(V)$.</p>

<p>... and this is were I got stuck. I really want to write that $f^{-1}(V) = \bigcup_{j=1}^k U'_j$ (more or less proving it's a covering map), but I can't justify that, and I actually think that it's not true. I think I might need an extra step, and to take an even smaller neighborhood of $y$, in order to make sure that extra sets from $ \lbrace U_i \rbrace $ didn't sneak into $f^{-1}(V)$.</p>

<p>Any help would be greatly appreciated as I've already spent several hours working on this problem.</p>

 
Answer: <p>For $y \in Y$, let $\{x_1, \dots, x_n\}= f^{-1}(y)$ (the $x_i$ all being different points). Choose pairwise disjoint neighborhoods $U_1, \dots, U_n$ of $x_1, \dots, x_n$, respectively (using the Hausdorff property).</p>

<p>By shrinking the $U_i$ further, we may assume that each one is mapped homeomorphically onto some neighborhood $V_i$ of $y$.</p>

<p>Now let $C = X \setminus (U_1 \cup \dots \cup U_n)$ and set $$V = (V_1 \cap \dots \cap V_n)\setminus f(C)$$</p>

<p>If I'm not mistaken this $V$ should be an evenly covered nbh of $y$.</p>

==============================
===============================
Question: <p>I post this question with some personal specifications. I hope it does not overlap with old posted questions.</p>

<p>Recently I strongly feel that I have to review the knowledge of measure theory for the sake of starting my thesis.</p>

<p>I am not totally new with measure theory, since I have taken and past one course at the graduate level. Unfortunately, because the lecturer was not so good at teaching, I followed the course by self-study. Now I feel that all the knowledge has gone after the exam and still don’t have a clear overview on the structure of measure theory.
And here come my specified requirements for a reference book.</p>

<ol>
<li><p>I wish the book elaborates the proofs, since I will read it on my own again, sadly. And this is the most important criterion for the book.</p></li>
<li><p>I wish the book covers most of the topics in measure theory. Although the topic of my thesis is on stochastic integration, I do want to review measure theory at a more general level, which means it could emphasize on both aspects of analysis and probability. If such a condition cannot be achieved, I'd like to more focus on probability.</p></li>
<li><p>I wish the book could deal with convergences and uniform integrability carefully, as Chung’s probability book. </p></li>
</ol>

<p>My expectation is after thorough reading, I could have strong background to start a thesis on stochastic integration at an analytic level.</p>

<p>Sorry for such a tedious question.</p>

<p>P.S: the textbook I used is Schilling’s book: measures, integrals and martingales. It is a pretty good textbook, but misprints really ruin the fun of reading.</p>

 
Answer: <p>Schilling was my introduction to the subject too. There are a few misprints, but a lot of them are corrected in the errata.</p>

<p>I've found Rudin's Real and Complex Analysis useful as a reference / second text. You could also take a look at <a href="http://rads.stackoverflow.com/amzn/click/0471317160">Folland's Real Analysis</a>. Terry Tao has notes about the subject on his blog, see <a href="http://en.wordpress.com/tag/245a-real-analysis/">here</a>.</p>

<p>One of the most comprehensive books, besides Kallenberg's Foundations of Modern Probability, is probably <a href="http://rads.stackoverflow.com/amzn/click/3540345132">Bogachev's Measure Theory</a> (2-volumes). Its Table of Contents can be viewed <a href="http://www.google.nl/url?sa=t&amp;source=web&amp;cd=1&amp;ved=0CBsQFjAA&amp;url=http://www.springer.com/mathematics/analysis/book/978-3-540-34513-8&amp;ei=tMr9Tf-wGoSc-wbMncTfAw&amp;usg=AFQjCNFy_Bj8xUxxV6_1Zx1lt2vha5553Q">at Springer</a>.</p>

==============================
===============================
Question: <p>I learned the following theorem about the properties of permutation from Gallian's <em>Contemporary Abstract Algebra</em>.</p>

<blockquote>
  <p><strong>Theorem 5.4</strong> $\;$ <em>Always Even or Always Odd</em></p>
  
  <p>If a permutation $\alpha$ can be expressed as a product of an even number of $2$-cycles, then every decomposition of $\alpha$ into a product of $2$-cycles must have an even number of $2$-cycles. In symbols, if
  $$
  \alpha = \beta_1 \beta_2 \dotsm \beta_r
  \quad\text{and}\quad
  \alpha = \gamma_1 \gamma_2 \dotsm \gamma_s
$$
  where the $\beta$'s and the $\gamma$'s are $2$-cycles, then $r$ and $s$ are both even or both odd.</p>
</blockquote>

<p>When I tried to reconstruct the proof myself, I found that it suffices to prove the following lemma:</p>

<blockquote>
  <p>If $\epsilon=\beta_1\beta_2\cdots\beta_r$ where $\beta$'s are $2$-cycles, then $r$ is even. </p>
</blockquote>

<p>The original proof for this lemma uses the following key property of the product of $\beta_1\beta_2$:</p>

<blockquote>
  <p>The product can always be expressed in one of the following forms on the left:
  $$\begin{align}(ab)(ab)&amp;=\epsilon\\
(ab)(ac)&amp;=(bc)(ab)\\
(ab)(cd)&amp;=(cd)(ab)\\
(ab)(bc)&amp;=(bc)(ac)\end{align}$$</p>
</blockquote>

<p>The proof for the lemma is based on such property and mathematical induction. I found it really hard to remind of such property, so I set it as an exercise to give another proof. However, I have no idea how to actually do it. </p>

<p>So here is my <strong>question</strong>:</p>

<blockquote>
  <p>Does anybody know an alternative proof of the lemma or the theorem?</p>
</blockquote>

 
Answer: <p>Here's a nice proof that uses group actions.</p>

<p>Let $x_1,\ldots,x_n$ be $n$ unknowns, and consider
$$\Delta= \prod_{1\leq i\lt j\leq n} (x_j-x_i).$$</p>

<p>For example, for $n=4$, we would have
$$\Delta = (x_2-x_1)(x_3-x_1)(x_4-x_1)(x_3-x_2)(x_4-x_2)(x_4-x_3).$$</p>

<p>Given a permutation $\sigma\in S_n$, define a function $f_{\sigma}\colon\{\Delta,-\Delta\}$ by letting
$$f_{\sigma}(\Delta) = \prod_{1\leq i\lt j\leq n} (x_{\sigma(j)}-x_{\sigma(i)}),$$
and $f_{\sigma}(-\Delta)=-f_{\sigma}\Delta$. </p>

<p>Note that since $\sigma$ is a permutation, $f_{\sigma}(\Delta)=\Delta$ or $f_{\sigma}(\Delta) = -\Delta$. Also, if $\sigma,\rho$ are two permutations, then $f_{\sigma}\circ f_{\rho} = f_{\sigma\rho}$, as is easy to verify.</p>

<p>Now, let's consider what a transposition $\tau=(a,b)$ does to $\Delta$. Without loss of generality, say $a\lt b$. </p>

<p>The factors $(x_j-x_i)$ with neither $i$ nor $j$ equal to $a$ nor $b$ are unchanged.</p>

<p>For the pairs with exactly one index in $\{a,b\}$, we have two classes: those in which the other index is between $a$ and $b$, and those where the other index is not between $a$ and $b$.</p>

<p>If the other index is between $a$ and $b$, then $x_j-x_a$ is sent to $-(x_b-x_j)$ and $x_b-x_j$ is sent to $-(x_j-x_a)$; the two sign changes cancel each other out.</p>

<p>If the other index is larger than $b$, then $x_j-x_a$ and $x_j-x_b$ are swapped, with no sign changes.</p>

<p>If the other index is smaller than $a$, then $x_a-x_i$ and $x_b-x_i$ are swapped, with no sign changes.</p>

<p>Finally, the factor $x_b-x_a$ is sent to $-(x_b-x_a)$.</p>

<p>In summary, if $\tau$ is a transposition, then $f_{\tau}(\Delta)=-\Delta$, $f_{\tau}(-\Delta)=\Delta$.</p>

<p>Now take an arbitrary permutation $\sigma$, and express it as a product of transpositions in two different ways:
$$\sigma = \tau_1\cdots \tau_r = \rho_1\cdots\rho_s.$$
Then
$$f_{\sigma}(\Delta) = f_{\tau_1\cdots\tau_r}(\Delta) = f_{\tau_1}\circ\cdots\circ f_{\tau_r}(\Delta) = (-1)^r\Delta$$
and
$$f_{\sigma}(\Delta) = f_{\rho_1\cdots\rho_s}(\Delta) = f_{\rho_1}\circ\cdots\circ f_{\rho_s}(\Delta) = (-1)^s\Delta.$$
Therefore, $(-1)^r\Delta = (-1)^s\Delta$, so $r$ and $s$ have the same parity: both odd, or both even.</p>

==============================
===============================
Question: <p>In many proofs I see that some variable is "fixed" and/or "arbitrary". Sometimes I see only one of them and I miss a clear guideline for it. Could somebody point me to a reliable source (best a well-known standard book) which explains, when and how to use both in proofs?</p>

<p>EDIT: A little add-on to the question: Take a usual induction on natural numbers and assume that you are teaching it to students in their first semester. How do you explain "fixed" and "arbitrary" in this scenario?</p>

 
Answer: <p>Both "arbitrary" and "fixed" are just shorthand for a universal quantifier. When I say something like "fix $\epsilon > 0$" it means I am about to prove a statement that is true for all $\epsilon &gt; 0$ (and thereby prove that some function is continuous, for example) but I don't want to actually write out "for all $\epsilon > 0$" in front of every sentence I'm about to write. That's really all there is to it. </p>

==============================
===============================
Question: <p>I came across the following problem:</p>

<blockquote>
  <p>Show that if $x$ and $y$ are real numbers with $x &lt;y$, then there exists an irrational number $t$ such that $x &lt; t &lt; y$.</p>
</blockquote>

<p>We know that $y-x&gt;0$. <br>
By the Archimedean property, there exists a positive integer $n$ such that $n(y-x)&gt;1$ or $1/n &lt; y-x$. There exists an integer $m$ such that $m \leq nx &lt; m+1$ or $\displaystyle \frac{m}{n} \leq x \leq \frac{m+1}{n} &lt; y$. </p>

<p>This is essentially the proof for the denseness of the rationals. Instead of $\large \frac{m+1}{n}$ I need something of the form $\large\frac{\text{irrational}}{n}$. How would I get the numerator? </p>

 
Answer: <p>Pick your favorite positive irrational, which is $\sqrt{2}$. By the Archimedean property, there exists $n$ such that $\frac{\sqrt{2}}{n}\lt \frac{y-x}{2}$. Again by the Archimedean property, we know there exists an integer $m$ such that $m\left(\frac{\sqrt{2}}{n}\right)\gt x$. Pick $M$ to be the <em>least</em> such $m$. Can you show that $M\left(\frac{\sqrt{2}}{n}\right)$ is strictly between $x$ and $y$?</p>

==============================
===============================
Question: <p>I recently had the occasion to think about <a href="http://en.wikipedia.org/wiki/Hall%27s_marriage_theorem">Hall's Marriage Theorem</a> for the first time since my undergraduate combinatorics class more than a decade ago.  Reading the wikipedia article linked above, I was interested to see that it is regarded as equivalent to several other fundamental theorems in combinatorics, for instance <a href="http://en.wikipedia.org/wiki/Dilworth%27s_theorem">Dilworth's Theorem</a> on posets of finite width and <a href="http://en.wikipedia.org/wiki/K%C3%B6nig%E2%80%93Egerv%C3%A1ry_theorem">König's Theorem</a> on matching in (finite?) graphs.  I was able to track down the proofs of these equivalences online.</p>

<p>However, the article also claims that Hall's Marriage Theorem is equivalent to the <a href="http://en.wikipedia.org/wiki/Birkhoff%E2%80%93Von_Neumann_theorem">(König-)Birkhoff - von Neumann Theorem</a>, which asserts that a real matrix is doubly stochastic iff it is a convex combination of permutation matrices (if you know the Minkowski-Krein-Milman theory of extreme points in convex sets, then an equivalent assertion is that the doubly stochastic matrices form a compact convex subset of $M_n(\mathbb{R})$ with extreme points precisely the permutation matrices, and since there are finitely many extreme points one has in fact a convex polytope, the <strong>Birkhoff polytope</strong>).</p>

<p>But the attribution here is strange: the only citation is to <a href="http://robertborgersen.info/Presentations/GS-05R-1.pdf">this series of slides by R.D. Borgersen</a>, for which the title is "Equivalence of seven major theorems in combinatorics"...but it only shows some of the implications!  In particular, it is not shown that Birkhoff - von Neumann implies any of the theorems as above.  So now we get to the question in my title: does it?</p>

<p>As a secondary question, is there a nice source which treats all these theorems (maybe not Birkhoff - von Neumann, but the other five or six, depending on how you count) at once?  In particular much of the literature I've found seems to be a bit sloppy on whether the structures involved need to be finite: it seems that "some, but not all" finiteness conditions are needed for these theorems to hold and that the folkloric equivalence is understood to apply in the finite case only. Is this correct?</p>

 
Answer: <p>The book you want is Reichmeider, The Equivalence of Some Combinatorial Matching Theorems. Alas, it is long out of print. </p>

<p>[<b>Added</b> by PLC: I am taking the liberty of reproducing the MathSciNet review.  Note that it does not mention Birkhoff - von Neumann, though this is hardly conclusive.]</p>

<blockquote>
  <p>It is well known that various theorems concerning bipartite matchings and network flows are all "equivalent'', in the sense that any one may be deduced easily from any other. This expository work painstakingly organises and presents various proofs of these results and of the relationships. It focusses on theorems of König and Egerváry, Hall, Dilworth, Menger, Ford and Fulkerson, and Hoffman. The book deals only with the finite case, and does not consider matroids or algorithms.  (Reviewed by Colin J.H. McDiarmid)</p>
</blockquote>

==============================
===============================
Question: <p>I came across this formula in a list: 
The number of ways of distributing $n$ identical objects among $r$ groups such that each group can have $0$ or more $(\le n)$ objects</p>

<p>I know that standard way of doing this is to solve the problem of distributing n identical objects and $(r-1)$ partitions among themselves which can be done in $C(n+r-1,r-1)$ ways. </p>

<p>But I am unable to prove to myself why it is not $(r+1)^n$. 
Because each of the n objects has r+1 choices, either group1, group2,... group r or none at all. </p>

 
Answer: <p>The post quotes the standard expression for the number of ways of distributing $n$ identical objects among $r$ groups.  The wording used seems to indicate that you are aware of the counting argument that leads to this expression. In case I am wrong about that, please look at the Wikipedia <a href="http://en.wikipedia.org/wiki/Stars_and_bars_%28combinatorics%29">Stars and Bars</a> article.</p>

<p>What is  meant by "prove to myself <strong>why</strong> it is not $(r+1)^n$?" I will write about this question for a while, and towards the end describe reasoning that <em>might</em> be connected with your $(r+1)^n$.</p>

<p>Let us first look at a simpler question, proving <strong>that</strong> it is not $(r+1)^n$. If you can find even a <strong>single</strong> pair $(r, n)$ of integers for which the expression $(r+1)^n$ gives the wrong answer, you will know that $(r+1)^n$ is not (always) correct.</p>

<p>To do this, just follow the excellent suggestion of Gerry Myerson.  Look at a small example, like $r=2$, $n=2$.  In how many ways can you distribute $2$ identical jelly beans between two people, $A$ and $B$?  Maybe $A$ gets both of them. Maybe $B$ does. Maybe $A$ gets one and $B$ gets one. That's all, the total number of ways is $3$.  </p>

<p>If the expression $(r+1)^n$ was correct for $r=2$, $n=2$, the number of ways would be $3^2$, which is clearly not equal to the correct answer $3$ that we are absolutely sure of. (We are absolutely sure because the count is so simple, so direct, that we could not possibly have made a mistake.)  By the way, if you check, you will find that the expression $C(n+r-1,r-1)$ gives the right answer, for $C(3,1)=3$.</p>

<p>When you are trying to solve a combinatorial problem, it is important to experiment, to try to look at small cases where you can do the count "by hand." Unless the problem is very standard, that is the right way to start.  And any concrete counting that you do can later serve as a check.</p>

<p>So we know <strong>that</strong> $(r+1)^n$, at least sometimes, gives the wrong answer.  (Actually, it usually gives  an answer that is <em>much larger</em> than the truth.) </p>

<p>Next let us try to deal with <strong>why</strong> $(r+1)^n$ gives the wrong answer.  Is there any good reason to think that it should give the right answer?  You think there might be.  Let's look for a problem for which $(r+1)^n$ is the right answer.</p>

<p>I have $n$ <strong>distinct</strong> gifts to give out, to $r$ people, except that I may choose to not give out some of the gifts, and keep them for myself.  For any gift, I have $r+1$ choices of what to do with it.  Then there are $(r+1)^n$ ways to do the gift-giving. It is crucial here that the gifts be distinct. </p>

<p>I cannot see any direct connection between this gift giving and the problem of distributing $n$ <strong>identical</strong> objects among $r$ people.</p>

<p>If the gifts are distinct, and I cannot keep any of them, there are $r^n$ ways to do the distribution.  One might think that then one could adjust this for the fact that the gifts are all identical.  That kind of adjustment can be made when you count the number of $6$-letter  "words" you can make using all the letters of CANADA.  You first imagine the A's to be distinct, getting $6!$, and then divide by $3!$ to deal with the fact that the A's are not distinct. But such a strategy will not work for our distributing identical objects problem. It would grossly over count.</p>

<p>Any strategy for counting by thinking of giving out the objects one at a time quickly runs into trouble.  It usually greatly overcounts the number of ways.  For example, in how many ways can we distribute $n$ jelly beans among $2$ people, $A$ and $B$?  Person $A$ can get $0$, or $1$, or $2$, and so on up to $n$, a total of $n+1$ possibilities.  That's probably where your intuition about the $+{}1$ came from, though you applied it to $r$, not to $n$.  </p>

<p>What about $n$ jelly beans and $3$ people? You might think there are $n+1$ ways to decide how many $A$ gets, and then $n+1$ ways to decide how many $B$ gets, with $C$ getting the rest.  That argument would give a count of $(n+1)^2$.  But that count would be <strong>incorrect</strong>.  If you have $3$ people, and $8$ jelly beans, and have given $6$ to $A$, you can't then give $5$ to $B$.  So although there are $n+1$ choices for how many to give to $A$, it is not true that for every one of these choices there are $n+1$ ways to decide how many to give to $B$.</p>

==============================
===============================
Question: <p>I need a hint. The problem is: is there a continuous bijection from $\mathbb{R}$ to $\mathbb{R}^2$</p>

<p>I'm pretty sure that there aren't any, but so far I couldn't find the proof.</p>

<p>My best idea so far is to consider $f&#39; = f|_{\mathbb{R}-\{*\}}: \mathbb{R} - \{*\} \to \mathbb{R}^2 - \{f(*)\}$, and then examine the de Rham cohomologies: $$H^1_{dR}(\mathbb{R}^2 - \{f(*)\}) = \mathbb{R} \  \xrightarrow{H^1_{dR}(f&#39;)} \ 0 = H^1_{dR}(\mathbb{R} - \{*\}),$$ but so far I failed to derive a contradiction here. Am I on the right path? Is it possible to complete the proof in this way e.g. by proving that $H^1_{dR}(f&#39;)$ must be a mono? Or is there another approach that I missed?</p>

 
Answer: <p>Suppose $f(x)$ were such a function. Note that each $A_n = f([-n,n])$ is a closed (actually compact) set, with $\cup A_n = {\mathbb R}^n$. By the Baire category theorem, there is one such $A_n$ that contains a closed ball $B$. Since $[-n,n]$ is compact, the image of any relatively closed subset of $[-n,n]$ is compact and thus closed. Hence $f^{-1}$ is continuous when restricted to $A_n$, and thus when restricted to $B$. So in particular $f^{-1}(B)$ is a connected subset of ${\mathbb R}$. Since all connected subsets of ${\mathbb R}$ are intervals, $f^{-1}(B)$ is a closed interval $I$. </p>

<p>Let $x$ be any point in the interior of $B$ such that $f^{-1}(x)$ is not an endpoint of $I$. Then $B - \{x\}$ is still connected, but $f^{-1}(B - \{x\})$ is the union of two disjoint intervals, which is not connected. Since $f^{-1}$ when restricted to $B - \{x\}$ is continuous, you have a contradiction. </p>

==============================
===============================
Question: <p>$2^4=16=4^2$. In fact, $\{2,4\}$ is the only pair of natural numbers with that property, i.e. if $m&lt;n$ are natural numbers and $m^n=n^m$, then $m=2$ and $n=4$. </p>

<p>This is easily seen with some analysis: For $m,n\in\mathbf{N}\backslash\{0\}$, the equation $m^n=n^m$ is equivalent to $\sqrt[m]{m}=\sqrt[n]{n}$. By calculus, we can show that the real function  $t\mapsto \sqrt[t]{t}$ is strictly increasing for $t&lt;e$ and strictly decreasing for $t&gt;e$. So the smaller of the two numbers has to be $&lt;e$ and the proposition follows.</p>

<p>My question: Is there an elementary proof? By elementary I mean most of all no irrational numbers, no calculus.</p>

 
Answer: <p>The relation $m^n=n^m$ implies that $n,m$ have the same prime factors $p_1&lt;p_2&lt;...&lt;p_k$. Suppose $m=\prod p_i^{\alpha_i},\ n=\prod p_i^{\beta_i}$. By the unique factorization theorem and the relation $m^n=n^m$ we get that $\alpha_i n=\beta_i m$. Suppose $m&gt;n$. This implies $\alpha_i&gt;\beta_i$ since $\alpha_i/\beta_i=m/n$. Therefore $n|m$.</p>

<p>Denote $m=dn$ and $(dn)^n=n^{(dn)}$ i.e. $dn=n^d$ or $d=n^{d-1}$. For $n \geq 2$ we have $n^{d-1}\geq d$ with equality for $d=1$ (which is not good since $m>n$) or $d=2,n=2$ and therefore $m=4$.</p>

==============================
===============================
Question: <p>I'm having a little trouble here and would appreciate some hints.</p>

<p>Let $M$ be a compact manifold without boundary and let $X$ be a smooth vector field on $M$ with only isolated zeros. Let $\theta_t$ denote the flow of $X$.</p>

<p>I would like to show that the following is true:</p>

<p>For small enough $t &gt; 0$ the only fixed points of $\theta_t$ are the zeros of $X$.</p>

<p>I need this, since I was trying to write down a proof of Poincaré-Hopf by showing that for the index $\iota(X)$ of $X$ we have $$\iota(X) = L(\theta_t)$$ where $L(\theta_t)$ denotes the Lefschetz fixed point number of $\theta_t$. 
From the above equality it would immediately follow that $\iota(X) = L(\theta_t) = L(id) = \chi(M)$. </p>

<p>However I got stuck in proving that we can choose $t$ sufficiently small to ensure that no unwanted fixed points of $\theta_t$ turn up.</p>

<p>I think the statement should be true (I'm guessing compactness will be key). At least, it seems right to me.</p>

<p>Thanks!</p>

 
Answer: <p>I think I have found a more elementary approach to the problem, so I'll post it for anyone who might be interested (and maybe to check whether I haven't made some silly mistake). </p>

<p>The idea is actually quite simple: I approximate the flow to the first order and use this to get a lower bound on the periods of nonfixed points.</p>

<p><strong>Proposition</strong>: Let $X$ be a smooth vector field on $\mathbb R^n$ such that $|X|$ and $|dX|$ are bounded. Then there is a $\tau &gt;0$ such that for all $0&lt;t&lt;\tau$: $$\theta(t,p) = p \quad \iff\quad X(p) = 0$$</p>

<p><em>Proof:</em> By Taylor expansion we have</p>

<p>$$\theta(t,p) = p + tX(p) + \int_0^t (t-\tau) \; dX\left(\theta\left(\tau,p\right)\right) X\left(\theta\left(\tau,p\right)\right) \; d\tau$$</p>

<p>By choosing $t_0$ small enough, we may assume</p>

<p>$$\left|X\left(\theta\left(\tau,p\right)\right)\right| \le 2\left|X(p)\right|$$</p>

<p>for all $p\in \mathbb R^n$ and $0\le \tau \le t &lt; t_0$.</p>

<p><strong>Edit:</strong> As has been pointed out by David Speyer in the comments, the existence of such a $t_0$ isn't as clear as I had initially thought. To see that such $t_0$ exists, we assume $|dX|&lt;M$ for some $M&gt;0$ and $|X| &lt; \tilde M$. By Taylorexpansion we have</p>

<p>$$\left|X\left(\theta\left(\tau,p\right)\right)\right| \le |X(p)| + \tau M |X\left(\theta\left(s,p\right)\right)|$$</p>

<p>where $s \in [0,\tau]$ is chosen to maximize $|X\left(\theta\left(s,p\right)\right)|$. Now let $t_0 := 1/(2M)$. By iterating the same argument with $|X\left(\theta\left(s,p\right)\right)|$ we get the estimate</p>

<p>\begin{align*}
\left|X\left(\theta\left(\tau,p\right)\right)\right| &amp;\le |X(p)| + \tau M \; \big(\; |X(p)| + \tau M |X\left(\theta\left(s,p\right)\right)|\; \big) \\
&amp;\vdots \\
&amp;\le \sum_{k=0}^\infty \left(\tau M\right)^k |X(p)| + \lim_{k\to \infty} (\tau M)^k\tilde M \\ 
&amp;\le 2|X(p)|
\end{align*}</p>

<p>Now let us define $$\Phi(t,p) = p + t X(p)$$
From the above and the properties of $X$, there is some $C&gt;0$ and $t_0&gt;0$ such that for $0&lt;t&lt;t_0$</p>

<p>$$|\theta(t,p) - \Phi(t,p) | = \left|\int_0^t (t-\tau) \; dX\left(\theta\left(\tau,p\right)\right) X\left(\theta\left(\tau,p\right)\right) \; d\tau\right| \le C|X(p)|t^2$$</p>

<p>for all $p$. But then </p>

<p>\begin{align*}
|\theta(t,p) - \theta(0,p)| &amp;\ge |\Phi(t,p) - \theta(0,p)| - |\theta(t,p) - \Phi(t,p)| \\
&amp;\ge t|X(p)|  - t^2C|X(p)| \\
&amp;= t|X(p)| (1 - Ct)
\end{align*}</p>

<p>So if $p$ is a point such that $\theta(T,p) = \theta(0,p)=p$ it follows that either $X(p)=0$ or $T \ge C^{-1}$. Proving the proposition.</p>

==============================
===============================
Question: <p>A number of economists do not appreciate rigor in their usage of mathematics and I find it very discouraging.</p>

<p>One of the examples of rigor-lacking approach are proofs done via graphs or pictures without formalizing the reasoning. I would like thus to come up with a few examples of theorems (or other important results) which may be true in low dimensions (and are pretty intuitive graphically) but fail in higher dimensions.</p>

<p>By the way, these examples are directed towards people who do not have a strong mathematical background (some linear algebra and calculus), so avoiding technical statements would be appreciated.</p>

<p><a href="http://en.wikipedia.org/wiki/Jordan%E2%80%93Sch%C3%B6nflies_theorem">Jordan-Schoenflies theorem</a> could be such an example (though most economists are unfamiliar with the notion of a homeomorphism). Could you point me to any others?</p>

<p>Thanks.</p>

 
Answer: <p>Here's an example that doesn't require too much mathematical knowledge, and the low-dimensional result is intuitive graphically:</p>

<p>We know that if a differentiable function $ f : \mathbb{R} \to \mathbb{R} $ has only one stationary point, which is a local minimum, then it must be a global minimum (this is intuitively obvious, and can be proved using Rolle's theorem). However, this result does not generalise to higher dimensions. An example would be $f : \mathbb{R}^2 \to \mathbb{R} $ with $ f(x,y) = x^2 + y^2(1-x)^3 $. This function has a unique stationary point at $ (0,0) $, which is a local minimum but not a global minimum (this can be seen by considering $ x >> 1 $). 
(<a href="http://www.wolframalpha.com/input/?i=3D%20plot%20%7C%20x%5E2%2by%5E2%20%281-x%29%5E3&amp;cdf=1">Interactive 3D plot</a>)</p>

==============================
===============================
Question: <p>Claim: Let $X$ be a metric space. If $A,B\in X$ are disjoint, if A is compact, and if B is closed, then $\exists \delta&gt;0: |\alpha-\beta|\geq\delta\;\;\;\forall\alpha\in A,\beta\in B$.</p>

<p>Proof. Assume the contrary. Let $\alpha_n\in A,\beta_n\in B$ be chosen such that $|\alpha_n-\beta_n|\rightarrow0$ as $n\rightarrow \infty$.</p>

<p>Since A is compact, there exists a convergent subsequence of $\alpha_n\;(n\in\mathbb{N})$, $\alpha_{n_m}\;(m\in\mathbb{N})$, which converges to $\alpha\in A$.</p>

<p>We have </p>

<p>$$|\alpha-\beta_{n_m}|\leq|\alpha-\alpha_{n_m}|+|\alpha_{n_m}-\beta_{n_m}|\rightarrow0 \;\;\;as\;\;m\rightarrow\infty.$$
Hence $\alpha$ is a limit point of B and since B is closed $\alpha\in B$, contradiction.</p>

<p>Is my proof correct? I feel as though I am missing something simple which would trivialize the proof.</p>

 
Answer: <p>For the sake of having an answer addressing your question:</p>

<p>Yes, your proof is perfectly okay and I don't think you can get it any cheaper than you did it.</p>

<hr>

<p>Let me expand a little on what you can do with these arguments (also providing details to gary's answer). I'm not saying my proof at the end is better than yours in any way, I'm just showing a slightly  alternative way of looking at it.</p>

<p>Define the distance between two non-empty subsets $A,B \subset X$ to be $d(A,B) = \inf_{a \in A, b \in B} d(a,b)$ and write $d(x,B)$ if $A = \{x\}$.</p>

<blockquote>
  <ol>
  <li>If $B \subset X$ is arbitrary and non-empty then $x \mapsto d(x,B)$ is $1$-Lipschitz continuous, that is $|d(x,B) - d(y,B)|\leq d(x,y)$ for all $x,y \in X$.</li>
  <li>We have $d(x,B) = 0$ if and only if $x \in \overline{B}$.</li>
  <li>If $d(\cdot,A) = d(\cdot,B)$ then $\overline{A} = \overline{B}$. </li>
  </ol>
</blockquote>

<ol>
<li><p>Choose $b\in B$ such that $d(x,b) \leq d(x,B) + \varepsilon$. Then the triangle inequality yields $d(y,B) - d(x,B) \leq d(y,b) - d(x,b) + \varepsilon \leq d(y,x) + \varepsilon$. By symmetry we get $|d(x,B) - d(y,B)| \leq d(x,y) + \varepsilon$, and 1. follows because $\varepsilon$ was arbitrary. <strong>Update:</strong> In <a href="https://math.stackexchange.com/questions/48850/continuity-of-the-metric-function/48853#48853">this closely related answer</a> I show that $1$ is in fact the best Lipschitz constant as soon as $B$ isn't dense. Don't miss Didier's answer to the same thread which relies on a useful general fact which is as easy to prove and Zarrax's answer providing a cleaned-up argument of the one I'm giving here. </p></li>
<li><p>Choose $b_n \in B$ with $d(x,b_n) \leq d(x,B) + \frac{1}{n} = \frac{1}{n}$. Then $d(x,b_n) \to 0$ and hence $x \in \overline{B}$. Conversely, if $b_n \to x$ then $d(x,b_n) \to 0$ hence $d(x,B) = 0$.</p></li>
<li><p>Immediate from 2.</p></li>
</ol>

<hr>

<p>Let me combine these facts: assume $A$ is compact and $B$ is closed. As $d(\cdot, B): X \to [0,\infty)$ is continuous by 1. above, we conclude from compactness of $A$ that $d(\cdot,B)$ assumes its minimum when restricted to $A$ (if you think about how one usually proves this, you'll find your argument again!). Hence there is $a \in A$ with the property that $d(a',B) \geq d(a,B)$ for all $a' \in A$. But if $d(a,B) = 0$ then $a \in B$ by 2. above, since $B = \overline{B}$. So either $A$ and $B$ are <em>not</em> disjoint or $d(a',B) \geq d(a,B) \gt 0$. By choosing $\delta \in (0,d(a,B))$, we get the claim again.</p>

<hr>

<p>Finally, if you don't assume that one among $A$ and $B$ is compact, then the result is false. There was the example $A = \mathbb{N}$ and $B = \{n + \frac{1}{n}\}_{n\in\mathbb{N}}$ given in the comments, or, a bit more geometrically appealing to me, let $A$ be the $x$-axis in $\mathbb{R}^2$ and $B$ the graph of the function $x \mapsto \frac{1}{x}$, $x \neq 0$.</p>

==============================
===============================
Question: <p>Let $(X,d)$ be a metric space. How to prove that for any closed $A$ a function $d(x,A)$ is continuous - I know that it is even Lipschitz continuous, but I have a problem with the proof: 
$$
|d(x,a) - d(y,a)| \leq d(x,y)
$$
for any $a\in A$ - but we cannot just replace it by $|d(x,A) - d(y,A)|\leq d(x,y)$ since the minimum (or infimum in general) can be attained in different points $a\in A$ for $x$ and $y$, so we only have that
$$
|d(x,A)-d(y,A)|\leq d(x,y)+\sup\limits_{a,b\in A}d(a,b)
$$
which does not mean continuity.</p>

 
Answer: <p>If $A = X$ (or if $\overline{A} = X$) then $d(\cdot,A) = 0$ and there's nothing to prove. If $A$ is empty, the usual conventions in the infimum yield $d(\cdot,\emptyset) = \infty$ and Lipschitz continuity doesn't really make sense. However a constant function is certainly continuous.</p>

<p>So, assume that $\emptyset \neq A$ and let $\varepsilon \gt 0$. Choose $a\in A$ such that $d(x,a) \leq d(x,A) + \varepsilon$. Then the triangle inequality yields $d(y,A) - d(x,A) \leq d(y,a) - d(x,a) + \varepsilon \leq d(y,x) + \varepsilon$. By symmetry we get $|d(x,A) - d(y,A)| \leq d(x,y) + \varepsilon$ and the desired result follows because $\varepsilon$ was arbitrary. Note that I didn't use that $A$ is closed. <strong>Update:</strong> Alternatively, you can choose Zarrax's way and permute two steps in this paragraph and make the argument nicer by getting rid of the explicit mentioning of $\varepsilon$ or appeal to the valuable general result mentioned by Didier.</p>

<p>If $A$ is non-empty and not dense, i.e., $\overline{A} \neq X$ then $1$ is in fact the best Lipschitz constant. Indeed, there are $x$ and $r\gt0$ such that $B_r(x) \cap \overline{A} = \emptyset$, so $d(x,A) \geq r \gt 0$. For every $\varepsilon \gt 0$ we can find $a \in A$ such that $d(x,a) \leq (1+\varepsilon)d(x,A)$. But then $|d(a,A) - d(x,A)| = d(x,A)\geq \frac{1}{1+\varepsilon} d(x,a)$ and the claim follows.</p>

<p>For a closely related thread, <a href="https://math.stackexchange.com/q/48714/">see here</a>.</p>

==============================
===============================
Question: <p>How to prove $\text{Rank}(AB)\leq \min(\text{Rank}(A), \text{Rank}(B))$?</p>

 
Answer: <p>I used a way to prove this, which I thought may not be the most concise way but it feels very intuitive to me.
The matrix $AB$ is actually a matrix that consist the linear combination of $A$ with $B$ the multipliers. So it looks like...
$$\boldsymbol{AB}=\begin{bmatrix}
 &amp;  &amp;  &amp; \\ 
a_1 &amp; a_2 &amp; ... &amp; a_n\\ 
 &amp;  &amp;  &amp; 
\end{bmatrix}
\begin{bmatrix}
 &amp;  &amp;  &amp; \\ 
b_1 &amp; b_2 &amp; ... &amp; b_n\\ 
 &amp;  &amp;  &amp; 
\end{bmatrix}
=
\begin{bmatrix}
 &amp;  &amp;  &amp; \\ 
\boldsymbol{A}b_1 &amp; \boldsymbol{A}b_2 &amp; ... &amp; \boldsymbol{A}b_n\\ 
 &amp;  &amp;  &amp; 
\end{bmatrix}$$
Suppose if $B$ is singular, then when $B$, being the multipliers of $A$, will naturally obtain another singular matrix of $AB$. Similarly, if $B$ is non-singular, then $AB$ will be non-singular. Therefore, the $rank(AB) \leq rank(B)$.</p>

<p>Then now if $A$ is singular, then clearly, no matter what $B$ is, the $rank(AB)\leq rank(A)$. The $rank(AB)$ is immediately capped by the rank of $A$ unless the the rank of $B$ is even smaller.</p>

<p>Put these two ideas together, the rank of $AB$ must have been capped the rank of $A$ or $B$, which ever is smaller. Therefore, $rank(AB) \leq min(rank(A), rank(B))$.</p>

<p>Hope this helps you!</p>

==============================
===============================
Question: <blockquote>
  <p>Let $A$ be an integral domain of finite Krull dimension. Let $\mathfrak{p}$ be a prime ideal. Is it true that $$\operatorname{height} \mathfrak{p} + \dim A / \mathfrak{p} = \dim A$$
  where $\dim$ refers to the Krull dimension of a ring? </p>
</blockquote>

<p>Hartshorne states it as Theorem 1.8A in Chapter I (for the case $A$ a finitely-generated $k$-algebra which is an integral domain) and cites Matsumura and Atiyah–Macdonald, but I haven't been able to find anything which looks relevant in either. (Disclaimer: I know nothing about dimension theory, and very little commutative algebra.) If it is true (under additional assumptions, if need be), where can I find a complete proof?</p>

<p>It is obvious that $$\operatorname{height} \mathfrak{p} + \dim A/\mathfrak{p} \le \dim A$$ by a lifting argument, but the reverse inequality is eluding me.  Localisation doesn't seem to be the answer, since localisation can change the dimension...</p>

 
Answer: <p>Yours is a very interesting and subtle question, which  often generates  confusion. First let us give a name to the property you are interested in: a ring  $A$ will be said to satisfy  <strong>(DIM)</strong> if for all $\mathfrak p \in \operatorname{Spec}(A)$ we have $$\operatorname{height}(\mathfrak p) +\dim A/\mathfrak p=\dim(A) \quad \quad (\text{DIM})$$<br>
The main misconception is to believe that this follows from catenarity:<br>
<strong>Fact 1: A catenary ring, or even a universally catenary ring, does not satisfy (DIM) in general.</strong><br>
<strong>Counterexample:</strong> Let $(R,\mathfrak m)$ be a discrete valuation ring whose maximal ideal has uniformizing parameter $\pi$, i.e.  $\mathfrak m =(\pi)$. Let $A=R[T]$,  the polynomial ring over $R$. The ring $A$ has dimension $2.$ Then for the maximal ideal $\mathfrak p=(\pi T-1)$, the relation  (DIM) is false: 
$\operatorname{height}(\mathfrak p)+\dim A/\mathfrak p= 1+0=1\neq 2=\dim (A)$.<br>
And this even though $A$ is as nice as can be: an integral domain, noetherian, regular, <em>universally catenary</em>,...</p>

<p>Happily here are two  positive results:    </p>

<p><strong>Fact 2: A finitely generated integral algebra over a field satisfies (DIM)</strong> (and is universally catenary).<br>
So, by the algebro-geometric dictionary, an affine variety $X$ has the pleasant property that for each  integral subvariety $Y\subset X$ we have, as hoped, $\operatorname{dimension}(Y) + \operatorname{codimension}(Y)$ $=$ $\operatorname{dimension}(X).$ </p>

<p><strong>Fact 3: A Cohen-Macaulay local ring satisfies (DIM)</strong> (and is universally catenary).<br>
For example a regular ring is Cohen-Macaulay. This "explains" why my counter-example above was not local.</p>

<p><strong>The paradox resolved.</strong>  How is it possible for a catenary ring $A$ not to satisfy (DIM)? Here is how. If you have an inclusion of two primes $\mathfrak p\subsetneq \mathfrak q$ catenarity says that you can complete it to a saturated chain of primes 
$\mathfrak p\subsetneq  \mathfrak p_1\subsetneq \ldots \subsetneq \mathfrak p_{r-1} \subsetneq \mathfrak q$ and that all such completions will have length the same length $r$. Fine. But what can you say if you have just one prime $\mathfrak p$ ? Not much! The catenary ring $A$ may have dimension $\dim(A) &gt; \operatorname{height}( \mathfrak p) +\dim(A/\mathfrak p)$ because it possesses a long chain of primes <em>avoiding</em> the prime  $\mathfrak p$ altogether. In my counterexample above the only saturated chain of primes containing $\mathfrak p=(\pi T-1)$ is $0\subsetneq \mathfrak p$. However the ring $A$ has dimension 2 because of the saturated chain of primes $0\subsetneq (\pi)  \subsetneq (\pi,T)$, which <em>avoids</em> $\mathfrak p$.</p>

<p><strong>Addendum.</strong> Here is why the ideal $\mathfrak p$ in the counter-example is maximal. We have $A/\mathfrak p=R[T]/(\pi T-1)=R[1/\pi]=\operatorname{Frac}(R)$, since the fraction field of a discrete valuation ring can be obtained just by inverting a uniformizing parameter. So $A/\mathfrak p$ is a field and $\mathfrak p$ is maximal. </p>

==============================
===============================
Question: <p>This is just a curiosity. I have come across multiple proofs of the fact that there are infinitely many primes, some of them were quite trivial, but some others were really, really fancy. I'll show you what proofs I have and I'd like to know more because I think it's cool to see that something can be proved in so many different ways.</p>

<p>Proof 1 : Euclid's. If there are finitely many primes then $p_1 p_2 ... p_n + 1$ is coprime to all of these guys. This is the basic idea in most proofs : generate a number coprime to all previous primes.</p>

<p>Proof 2 : Consider the sequence $a_n = 2^{2^n} + 1$. We have that 
$$
2^{2^n}-1 = (2^{2^1} - 1) \prod_{m=1}^{n-1} (2^{2^m}+1),
$$ 
so that for $m &lt; n$, $(2^{2^m} + 1, 2^{2^n} + 1) \, | \, (2^{2^n}-1, 2^{2^n} +1) = 1$. Since we have an infinite sequence of numbers coprime in pairs, at least one prime number must divide each one of them and they are all distinct primes, thus giving an infinity of them.</p>

<p>Proof 3 : (Note : I particularly like this one.) Define a topology on $\mathbb Z$ in the following way : a set $\mathscr N$ of integers is said to be open if for every $n \in \mathscr N$ there is an arithmetic progression $\mathscr A$ such that $n \in \mathscr A \subseteq \mathscr N$. This can easily be proven to define a topology on $\mathbb Z$. Note that under this topology arithmetic progressions are open and closed. Supposing there are finitely many primes, notice that this means that the set
$$
\mathscr U \,\,\,\, \overset{def}{=} \,\,\, \bigcup_{p} \,\, p \mathbb Z
$$
should be open and closed, but by the fundamental theorem of arithmetic, its complement in $\mathbb Z$ is the set $\{ -1, 1 \}$, which is not open, thus giving a contradiction. </p>

<p>Proof 4 : Let $a,b$ be coprime integers and $c &gt; 0$. There exists $x$ such that $(a+bx, c) = 1$. To see this, choose $x$ such that $a+bx \not\equiv 0 \, \mathrm{mod}$ $p_i$ for all primes $p_i$ dividing $c$. If $a \equiv 0 \, \mathrm{mod}$ $p_i$, since $a$ and $b$ are coprime, $b$ has an inverse mod $p_i$, call it $\overline{b}$. Choosing $x \equiv \overline{b} \, \mathrm{mod}$ $p_i$, you are done. If $a \not\equiv 0 \, \mathrm{mod}$ $p_i$, then choosing $x \equiv 0 \, \mathrm{mod}$ $p_i$ works fine. Find $x$ using the Chinese Remainder Theorem. </p>

<p>Now assuming there are finitely many primes, let $c$ be the product of all of them. Our construction generates an integer coprime to $c$, giving a contradiction to the fundamental theorem of arithmetic.</p>

<p>Proof 5 : Dirichlet's theorem on arithmetic progressions (just so that you not bring it up as an example...)</p>

<p>Do you have any other nice proofs?</p>

 
Answer: <p>When I taught undergraduate number theory I subjected my students to a barrage of proofs of the infinitude of the prime numbers: see <a href="http://math.uga.edu/~pete/4400primes.pdf">these lecture notes</a>.  I gave eight proofs altogether.  Of course by now the list which has been currently compiled has a large overlap with mine, but one proof which has not yet been mentioned is Washington's algebraic number theory proof:</p>

<p>Proposition: Let $R$ be a Dedekind domain with fraction field $K$.  If $R$ has only finitely many prime ideals, then for every finite degree field extension $L/K$, the integral closure $S$ of $R$ in $L$ is a PID.</p>

<p>(The proof boils down to two facts: (i) a Dedekind domain with finitely many prime ideals is a PID.  (ii) with notation as above, the map $\operatorname{Spec S} \rightarrow \operatorname{Spec R}$ is surjective and at most $[L:K]$-to-one, so $R$ has infinitely many prime ideals iff $S$ has infinitely many prime ideals.)</p>

<p>Corollary: There are infinitely many primes.</p>

<p>Proof: Applying the Proposition with $R = \mathbb{Z}$, if there were only finitely many primes, then for every number field $K$, the ring $\mathbb{Z}_K$ of integers in $K$ would be a PID, hence a UFD.  But for instance this fails for $K = \mathbb{Q}(\sqrt{-5})$, as $2 \cdot 3 = (1+\sqrt{-5})(1-\sqrt{-5})$ is a nonunique factorization into ireducible elements (since there are no elements of norm $2$ or $3$) in $\mathbb{Z}_K = \mathbb{Z}[\sqrt{-5}]$.  </p>

==============================
===============================
Question: <p>Does math require a concept of infinity?</p>

<p>For instance if I wanted to take the limit of $f(x)$ as $x \rightarrow \infty$, I could use the substitution $x=1/y$ and take the limit as $y\rightarrow 0^+$.</p>

<p>Is there a statement that can be stated without the use of any concept of infinity but which unavoidably requires it to be proved?</p>

 
Answer: <p>Surprisingly, infinity proves necessary even for finite combinatorial mathematics.  For a nice explanation as to why there cannot be any such as 
thing as a comprehensive, self-contained discipline of finite 
combinatorial mathematics see Stephen G. Simpson's writeup of his expository talk <a href="http://groups.google.com/forum/#!original/sci.math/KQ4Weqk4TmE/LE_Wfsk00H4J">Unprovable Theorems and Fast-Growing Functions, Contemporary Math. 65 1987, 359-394.</a> </p>

<p>Simpson gives a detailed discussion of three theorems about finite objects whose
proofs necessarily require the use of infinite sets. The three theorems discussed are about colorings of finite sets (modified finite Ramsey theorem),
embeddings of finite trees (Friedman's finite form of Kruskal's theorem) 
 and iterated exponential notation for integers (Goodstein's theorem).</p>

<p>Below is an excerpt from the introduction.</p>

<blockquote>
  <p>$\quad$The purpose of the talk is to exposit some recent results (1977 and 
  later) in which mathematical logic has impinged upon finite combinatorics. 
  Like most good research in mathematical logic, the results which I am 
  going to discuss had their origin in philosophical problems concerning the 
  foundations of mathematics.  Specifically, the results discussed here were 
  inspired by the following philosophical question.  Could there be such a 
  thing as a comprehensive, self-contained discipline of finite 
  combinatorial mathematics?<br>
  $\quad$    It is well known that a great deal of reasoning about finite 
  combinatorial structures can be carried out in a self-contained finitary 
  way, i.e. with no reference whatsoever to infinite sets or structures.  I 
  have in mind whole branches of mathematics such as finite graph theory, 
  finite lattice theory, finite geometries, block designs, large parts of 
  finite group theory (excluding character theory, in which use is made of 
  the field of complex numbers), and large parts of number theory (including 
  the elementary parts but excluding analytical techniques such as contour 
  integrals).  One could easily imagine comprehensive textbooks of these 
  subjects in which infinite sets are never mentioned, even tangentially. 
  All of the reasoning in such textbooks would be concerned exclusively with 
  finite sets and structures.<br>
  $\quad$  Consequently, there is a strong naive impression that the answer to 
  our above-mentioned philosophical question is "yes."<br>
  $\quad$ However, naive impressions can be misleading.  I am going to discuss 
  three recent results from mathematical logic which point to an answer of 
  "no."  Namely, I shall present three examples of combinatorial theorems 
  which are finitistic in their statements but not in their proofs.  Each of 
  the three theorems is simple and elegant and refers only to finite 
  structures.  Each of the three theorems has a simple and elegant proof. 
  The only trouble is that each of the proofs uses an infinite set at some 
  crucial point.  Moreover, deep logical investigations have shown that the 
  infinite sets are in fact indispensable.  Any proof of one of these finite 
  combinatorial theorems must involve a detour through the infinite.  Thus, 
  in a strong relative sense, the three theorems are "unprovable" -- they 
  cannot be proved by means of the finite combinatorial considerations in 
  terms of which they are stated. </p>
</blockquote>

==============================
===============================
Question: <p>Little Picard's theorem is the following:  Suppose $f:\mathbb{C}\rightarrow \mathbb{C}$ is entire.  Then either </p>

<p>1)  $f$ is constant</p>

<p>2)  $f$ is surjective or</p>

<p>3)  $f$ is onto $\mathbb{C}-\{p\}$ for some point $p\in \mathbb{C}$.</p>

<p>Said another way, an entire function which misses 2 points in the codomain is actually constant.</p>

<p>The exponential function $f(z) = e^z$, which is never $0$, shows that in general all 3 cases can arise.</p>

<p>As someone who knows a bit of differential geometry and algebraic topology, the proof I like (indeed, the only one I remember) goes as follows:  Consider $X= \mathbb{C}-\{p,q\}$ where $p$ and $q$ are distinct complex numbers.  Then an entire map $f:\mathbb{C}\rightarrow X$ lifts to the universal cover $\mathbb{D}(0,1)$ (the unit disc around $0$ in $\mathbb{C}$) of $X$.  The lift of $f$ is an entire bounded function, and hence, by Liouville's theorem, is constant.  This easily implies $f$ itself is constant.  $\square$</p>

<p>The part that's hazy, to me, is the justification that the universal cover of $X$ is (biholomorphic to) the unit disc.  Of course, by uniformization, the universal cover is biholomorphic to either $\mathbb{C}$, $\mathbb{D}(0,1)$, or $S^2$.  Since $S^2$ is compact and $X$ is not, it cannot be $S^2$.  Interestingly, if we remove only a single point from $\mathbb{C}$ (which we assume wlog is $0$), then $e^z$ is a covering map from $\mathbb{C}$ to $\mathbb{C}-\{0\}$.  In other words, the universal cover a once punctured plane is $\mathbb{C}$ but the universal cover of a twice or more punctured plane is the unit disc.</p>

<blockquote>
  <p>Is there good intuition as to why 2 is the crucial number of punctures for which the universal cover is no longer biholomorphic to $\mathbb{C}$?</p>
</blockquote>

<p>Relatedly (and nicer since it would allow me to avoid using uniformization, which I feel is way overkill for this),</p>

<blockquote>
  <p>Is the universal covering map $\pi:\mathbb{D}(0,1)\rightarrow X$ easy, or even possible, to explicitly write down?</p>
</blockquote>

<p>By translating, rotating, and scaling, one can obviously assume that $\{p,q\} = \{0,1\}$</p>

<p>A quick google search shows the answer to the second question should be "yes", and that $\pi$ can be expressed in terms of modular functions.  Sadly, I don't know anything at all about modular functions, but I couldn't find anyting that tells <em>how</em> to express $\pi$ with modular functions.</p>

 
Answer: <p>$\mathbb{C} - \{ 0, 1 \}$ can be thought of as the <a href="http://en.wikipedia.org/wiki/Modular_curve">modular curve</a> $Y(2) \cong \mathbb{H}/\Gamma(2)$ parameterizing elliptic curves together with a basis for their $2$-torsion. This parameterization takes a point $\lambda \in \mathbb{C} - \{ 0, 1 \}$ to the elliptic curve $y^2 = x(x - 1)(x - \lambda)$ together with the ordered basis $(0, 0), (1, 0)$ (say) for the $2$-torsion. Explicit formulas for the covering map can be found, for example, in Dolgachev's <a href="http://www.math.lsa.umich.edu/~idolga/modular.pdf">Lectures on Modular Forms</a>, Lecture 9. </p>

<p>As for intuition, I suppose one could say the following: generically we should expect a hyperbolic structure. $\mathbb{C}$ is not generic as it has a group structure, and $\mathbb{C} - \{ 0 \}$ is also not generic as it also has a group structure, but $\mathbb{C} - \{ 0, 1 \}$ has no obvious group structure so we can expect generic behavior.</p>

==============================
===============================
Question: <p>I've been reading Hatcher's Algebraic Topology, specifically the paragraph about reduced homology $\tilde{H}_*$ (for singular homology of topological spaces). Can someone please provide reasons why reduced homology is defined and studied?</p>

<p>I understand the following facts, which are all found in Hatcher's book :</p>

<p>$-$ The reduced homology of a point is $0$.</p>

<p>$-$ The reduced homology is the same in all degrees $*$ as the usual singular homology for pairs of spaces $(X,A)$ with $A\neq \emptyset$ : $\tilde{H}_*(X,A)= H_*(X,A)$, and in positive degrees $(*=n&gt;0)$ for single spaces $X$ (that is when $A=\emptyset$). There is the same long exact sequence in reduced homology for a pair of spaces as in standard homology.</p>

<p>$-$ In degree $0$, one has $\tilde{H}_*(X)\oplus\mathbb{Z}\approx H_*(X)$ (here coefficients for homology are in $\mathbb{Z}$) (EDIT : it should read $\tilde{H}_0(X)\oplus\mathbb{Z}\approx H_0(X)$)</p>

<p>$-$ For any space $X$, and any point $\mathrm{pt}\in X$, there is an isomorphism $\tilde{H}_*(X)\approx H_*(X,\lbrace \mathrm{pt}\rbrace)$</p>

<p>$-$ This in turn implies that when $A\subset  U\subset X$ is such that $A$ is closed, $U$ is open, and $A$ is a strong deformation retract of $U$, then there is an exact sequence in reduced homology (that stems from an exact sequence for standard singular homology)</p>

<p>$$\cdots\rightarrow\tilde{H}_*(A)\rightarrow\tilde{H}_*(X)\rightarrow\tilde{H}_*(X/A)\rightarrow\cdots$$</p>

<p>All of this is straightforward to prove, but it doesn't tell me why reduced homology is defined and when it is used. Can someone please shed some light on this matter?</p>

 
Answer: <p>Reduced homology is used, mostly, to simplify statements.</p>

<p>For example, it is not true that the homology of a wedge of two spaces $X\vee Y$ is the direct sum of the homologies of $X$ and of $Y$, but the <em>only</em> problem is actually in degree $0$. It is true, on the other hand, that the <em>reduced</em> homology of $X\vee Y$ is the direct sum of the reduced homologies of $X$ and of $Y$. This happens in various other contexts.</p>

<p><strong>N.B.:</strong> You should be careful with those isomorphisms you mention, for they are generally not natural.</p>

==============================
===============================
Question: <p>It is quite easy to show that for every prime $p$ and $0&lt;i&lt;p$ we have that $p$ divides the binomial coefficient $\large p\choose i$; one simply notes that in $\large \frac{p!}{i!(p-i)!}$ the numerator is divisible by $p$ whereas the denominator is not (since it is a product of numbers smaller than $p$ and $p$ is prime).</p>

<p>My problem is with generalizing this argument for $q=p^n$. I'm looking for the most elegant and simple way to prove that $p$ still divides $\large q\choose i$.</p>

 
Answer: <p>Let $v_p(n)$ denotes the exponent of the largest power of $p$ which divides $n$. We'll show that $v_p\left({p^n \choose i}\right) = n-v_p(i)$. In particular, this is positive unless $i=0$ or $i=p^n$.</p>

<p>It's easy to see that for any $n$, $$v_p(n!)=\sum_{k=1}^\infty \left\lfloor \frac{n}{p^k}\right\rfloor.$$</p>

<p>We need an expression for $v_p(q!)-v_p(i!)-v_p((q-i)!)$, where $q=p^n$.</p>

<p>Notice that $v_p(q!) = \frac{p^n-1}{p-1}$ by the above formula (which just becomes a geometric series with finitely many terms).</p>

<p>Notice also that for any $x \in \mathbb{R}$, $\lfloor -x \rfloor + \lfloor x \rfloor =\begin{cases} 0 &amp;&amp; \text{if } x \in \mathbb{Z} \\ -1 &amp;&amp; \text{otherwise.}\end{cases}$</p>

<p>Therefore,</p>

<p>$$\begin{align}v_p((q-i)!)+v_p(i!) &amp;= \sum_{k=1}^n \left\lfloor\frac{p^n-i}{p^k}\right\rfloor + \left\lfloor\frac{i}{p^k}\right\rfloor \\ &amp;=\sum_{k=1}^n \left(p^{n-k} + \left\lfloor\frac{-i}{p^k}\right\rfloor + \left\lfloor\frac{i}{p^k}\right\rfloor\right) \\&amp;=\frac{p^n-1}{p-1}-(n-v_p(i)).\end{align}$$</p>

<p>Hence we have $v_p\left({p^n \choose i}\right) = n-v_p(i)$.</p>

<p><strong>Edit (Dec. 6 2011):</strong> for fun, yesterday I asked myself how badly the equality $v_p\left({n \choose m}\right) = v_p(n)-v_p(m)$ fails for general $n$ and $m$. So I used Mathematica to create the following image. The triangle consists of the first 256 rows of Pascal's triangle, colored using the following rule: the greener a points is, the bigger the difference $v_2\left({n \choose m}\right) - v_2(n) +v_2(m)$. A little experimentation shows that any other choice of prime generates a similar image.</p>

<p><img src="https://i.stack.imgur.com/A99Nm.jpg" alt="the triangle"></p>

<p>To create this image, I used the <a href="http://library.wolfram.com/infocenter/MathSource/556/">p-adic arithmetic package</a> and the following code:</p>

<p><code>p = 2; 
until = 256; t = Table[Table[{RGBColor[0, PadicOrder[Binomial[n, m]/(n/m), p]/Log[p, until], 0], Rectangle[{until/2 - 1/2 - n/2 + m, n}]}, {m, 1, n}], {n, 1, until}];
Graphics[t]</code></p>

==============================
===============================
Question: <p>One of the joys of high-school mathematics is summing a complicated series to get a “closed-form” expression. And of course many of us have tried summing the harmonic series $H_n =\sum \limits_{k \leq n} \frac{1}{k}$, and failed. But should we necessarily fail? </p>

<blockquote>
  <p>More precisely, is it known that $H_n$ <em>cannot</em> be written in terms of the elementary functions, say, the rational functions, $\exp(x)$ and $\ln x$? If so, how is such a theorem proved? </p>
</blockquote>

<p><strong>Note</strong>. When I started writing the question, I was going to ask if it is known that the harmonic function cannot be represented simply as a rational function? But this is easy to see, since $H_n$ grows like $\ln n+O(1)$, whereas no rational function grows logarithmically.</p>

<p><strong>Added note:</strong> This <a href="https://math.stackexchange.com/questions/155/">earlier question</a> asks a similar question for “elementary integration”. I guess I am asking if there is an analogous theory of “elementary summation”. </p>

 
Answer: <p>There is a theory of elementary summation; the phrase generally used is "summation in finite terms." An important reference is Michael Karr, Summation in finite terms, <em>Journal of the Association for Computing Machinery</em> <strong>28</strong> (1981) 305-350, DOI: <a href="http://dx.doi.org/10.1145/322248.322255">10.1145/322248.322255</a>. Quoting, </p>

<blockquote>
  <p>This paper describes techniques which greatly broaden the scope of what is meant by 'finite terms'...these methods will show that the following sums have no formula as a rational function of $n$:
  $$\sum_{i=1}^n{1\over i},\quad \sum_{i=1}^n{1\over i^2},\quad \sum_{i=1}^n{2^i\over i},\quad \sum_{i=1}^ni!$$</p>
</blockquote>

<p>Undoubtedly the particular problem of $H_n$ goes back well before 1981. The references in Karr's paper may be of some help here. </p>

==============================
===============================
Question: <p>I'm not sure I've got this right. When proving $a^n \mid b^n \Rightarrow a \mid b$, can we do this indirectly? In short,</p>

<p>"Suppose $a$ does not divide $b$, this implies that $a^n$ does not divide $b^n$. But $a^n \mid b^n$, hence $a$ divides $b$."</p>

<p>How about $n^n \mid m^m \Rightarrow n \mid m$? Can we do this the same way?</p>

 
Answer: <p>This is false: $4^4$ divides $10^{10}$ but $4$ does not divide $10$.</p>

==============================
===============================
Question: <p>I just bought a copy of J&uuml;rgen Neukirch's book Algebraic Number Theory. While browsing through it I found a section titled &sect;&nbsp;14. <strong>Function Fields</strong> in chapter I. In it the author describes some aspects of an analogy between <a href="http://en.wikipedia.org/wiki/Function_field_of_an_algebraic_variety">function fields</a> and <a href="http://en.wikipedia.org/wiki/Algebraic_number_field">algebraic number fields</a>.</p>

<p>This led me to google for a while and I ended up reading the Wikipedia entry for <a href="http://en.wikipedia.org/wiki/Global_field">Global Field</a>. And this is where my question comes from. In the last sentence of that entry there's the following passage, which I find really interesting:</p>

<blockquote>
  <blockquote>
    <p>It is usually easier to work in the function field case and then try to develop parallel techniques on the number field side. The development of <strong>Arakelov theory</strong> and its exploitation by Gerd Faltings in his proof of the <strong>Mordell conjecture</strong> is a dramatic example.</p>
  </blockquote>
</blockquote>

<p>Unfortunately, being as dramatic as it is, the example mentioned does not tell me anything because not even the Wikipedia entry on <a href="http://en.wikipedia.org/wiki/Arakelov_theory">Arakelov Theory</a> is somehow close to give even a small hint as to what it is about.</p>

<blockquote>
  <blockquote>
    <p>So I would like to ask for some <strong>insight</strong> and/or <strong>examples</strong> that illustrate why it is said to be easier to work with <strong>function fields</strong> than with <strong>algebraic number fields</strong> and then try to develop parallel techniques for the number field case.</p>
  </blockquote>
</blockquote>

<p>Thank you very much for any help.</p>

 
Answer: <p>One answer is that we can take formal derivatives. For example, Fermat's last theorem is rather difficult but the function field version is a straightforward consequence of the <a href="http://planetmath.org/encyclopedia/MasonStothersTheorem.html">Mason-Stothers theorem</a>, whose <a href="http://topologicalmusings.wordpress.com/2008/03/03/mason-stothers-theorem-and-the-abc-conjecture/">elementary proof</a> crucially relies on the ability to take formal derivatives of polynomials. </p>

<p>There is no obvious way to extend this construction to integers in a way that preserves its good properties. If there were, then the <a href="http://en.wikipedia.org/wiki/Abc_conjecture">abc conjecture</a> (of which Mason-Stothers is the function field version) would be trivial, which it's not. There is a thing called the <a href="http://en.wikipedia.org/wiki/Arithmetic_derivative">arithmetic derivative</a>, but it is of course not linear, and it doesn't seem to me to be very easy to prove anything with it. </p>

<p>The problem is that if we want to think of $\mathbb{Z}$ as being analogous to a function field, then the "field" that it's a function field over is the <a href="http://en.wikipedia.org/wiki/Field_with_one_element">field with one element</a>, so if a reasonable notion of formal derivative exists here it needs not to be $\mathbb{Z}$-linear, but to be $\mathbb{F}_1$-linear, whatever that means... if we understood what that meant, perhaps we could construct the "correct" version of the arithmetic derivative and presumably prove the abc conjecture. </p>

<hr>

<p>Arakelov theory addresses another difference between function fields and number fields, which is the existence of <a href="http://en.wikipedia.org/wiki/Algebraic_number_field#Places">Archimedean places</a>. Over a function field all places are non-Archimedean and I understand this makes various things easier, but I don't know much about this so someone else should chime in here.</p>

==============================
===============================
Question: <p>We have $N$ urns forming a circle and $M&lt;N$ balls (for example, $N=9,M=6$ in the diagram). In each step we visit, sequentially, clockwise, an urn. If it's occupied by a ball, we say a $hit$ has ocurred. Elsewhere (<em>miss</em>), we pick randomly one of the  $M$ balls and move it to the current urn. The goal is to compute the average hit rate, for arbitrary $N,M$, in the long run.</p>

<p><img src="https://i.stack.imgur.com/vSOOc.png" alt="enter image description here"></p>

<p>I was confronted with this problem some years ago, for some concrete application (some cache model). It's not terribly difficult, but not as simple as it might seem. It's also interesting to contrast with the intuition (on which side would you bet in this example?).</p>

<p>I have a solution, (<s>with two different proofs - I'll post them soon</s> posted in answer below) but I'd like to hear about other attempts - or perhaps some reference - this should probably have been studied somewhere.</p>

<p>A few (exact) results: </p>

<pre><code> N  M   p
------------
 3  2  1/3
 4  2  1/7
 5  3  7/25
</code></pre>

<p><em>Edited:</em> as found out semi-empirically in an answer below, the hit rate is given by $$p= \frac{S(N-1,M-1)}{S(N,M)}$$
where $S(N,M)$ are <a href="http://en.wikipedia.org/wiki/Stirling_numbers_of_the_second_kind" rel="noreferrer">Stirling numbers of the second kind</a>. </p>

 
Answer: <p><i>I had devised two derivations, one using a Markov chain (here the Stirling numbers appear through their combinatorial meaning), other using a recursion for the probabilities distributions for different $N,M$ (this leads to a recursion like that of eBusiness' answer). I post here the first one, because it's simpler and the later is more difficult to justify. At the end, some asympotics.</i></p>

<hr>

<p>Let number the urns relatively to the current position, so that
urn $1$ is the next one to be visited, urn $N$ is the most recently visited one.</p>

<p>The key to get a solvable Markov chain is to define the states in an seemingly
"inflated" way: instead of the natural state, with $M$ components, (for each ball, list its position), the state will be a vector of $N$ components, taking values in $1 \cdots M$. <strong>The state vector lists, for each urn, the last ball placed there</strong> (assume that all urns have already been visited at least once). </p>

<p>Notice that all ball numbers must appear in the list. Some will repeat; but we can spot in which urn a ball currently is: it's the righmost (largest index=most recent) one.
Then, we will have a hit if the first component is not repeated. And the state transition rule is : if <em>hit</em>, shift and rotate the elements to left; if <em>miss</em>, shift to the left and place in the last position a random number (the selected ball).</p>

<p>For example, for the position in the diagram (N=9, M=6; we assumed some arbitrary past for the currently empty urns), assuming we are about to visit the top urn, we could have this state sequence (the asterisks correspond the empty urns; they are just those numbers having some repetition to the right). </p>

<pre>
S(t)   = [ 3  4* 5  2* 4  2  6* 1  6 ]
                                       hit
S(t+1) = [ 4* 5  2* 4  2  6* 1  6  3 ]   
                                       miss; ball '6' was randomly chosen
S(t+2) = [ 5  2* 4  2  6* 1  6* 3  6 ]   
</pre>

<p>Notice that:</p>

<ul>
<li>A valid state corresponds to a <strong>surjective mapping</strong> from $\{1 \cdots N\}$ to $\{1 \cdots M\}$ (all ball numbers must appear). </li>
<li>All valid states are reachable from any other.</li>
<li>A state can have either one outgoing transition with probability 1 (hit state), or $M$ transitions equally probable. Hence the transition matrix have only $1$ and $1/M$ as non zero entries.</li>
<li>In-going transitions: (this is the key) each state has either one in-going transition with probability 1 or M with $1/M$; in the example above: we can tell that state $S(t+1)$ is <em>post-hit</em> with only one possible previous state); and that state $S(t+2)$ is <em>post-miss</em>, with $M$ possible previous states. Hence both the rows and the columns of the  transition matrix sum up to one: it's <strong>doubly stochastic</strong>.</li>
</ul>

<p>But an irreducible [<em>edited</em>: actually also ergodic, as noted in the comments] and doubly-stochastic Markov chain, in steady state, has <strong>equiprobable states</strong>. </p>

<p>Now, the total number of states (number of mappings) is equivalent to the number of ways of placing $N$ objects in $M$ bins, with no empty bin; this is given by Stirling Number of second Kind (multiplied by $M!$ to account for distinguishable balls): $\#S= M! \; S(N,M)$</p>

<p>To count the hit states $S_h$: the first component must be unique, so 
 $\#S_h = M (M-1)! \; S(N-1,M-1) = M! \; S(N-1,M-1)$</p>

<p>The probability of hit, then, is just the number of hit states over the total number of states. </p>

<p>$$p = \frac{\#S_h}{\#S} = \frac{S(N-1,M-1)}{S(N,M)}$$</p>

<p>Some values:</p>

<pre>
       M    2        3        4          5        6         7        8  
     N  
     3   0.33333
     4   0.14286  0.50000
     5   0.06666  0.28000  0.60000
     6   0.03226  0.16666  0.38462   0.66667
     7   0.01587  0.10299  0.25714   0.46429   0.71429
     8   0.00787  0.06522  0.17695   0.33333   0.52632   0.75000
     9   0.00392  0.04198  0.12432   0.24471   0.39683   0.57576  0.77778
</pre>

<p>BTW, for the example diagram (9,6), the hit rate is about 40%.</p>

<hr>

<p><strong>Asymptotics</strong>: For large $N,M$, the Stirling numbers of second kind grow quickly and its asympotics are rather tricky. Here goes very simple probabilistic approach.</p>

<p>Suppose we have just visited the top urn; it must be occupied. 
We can estimate the probability that  the ball survives in that position after a full round
as the probability that in $N-1$ tries it never happen the event "miss and my ball was selected".
This survival corresponds to a hit event. Then, asumming independence:</p>

<p>$$p \approx (1 - \frac{1-p}{M})^{N-1} \approx e^{-r(1-p)}$$</p>

<p>with $N,M \to \infty$ and $r = N/M$. The implicit $p(r)$ could be explicitly expressed using the  Lambert function (see <a href="https://math.stackexchange.com/questions/5842/implicit-function-y-ey-1-x">here</a>).</p>

<p>The independence assumption is not exact, but the error is asympotically negligible.
I have another (better) probabilistic argument, which leads to the same expression,
I'll spare you that (in case someone is interested, send me a message).</p>

<p><img src="https://i.stack.imgur.com/0OjCH.png" alt="enter image description here"></p>

==============================
===============================
Question: <p>Inspired by Pascal, I put on some shackles and a thorny belt. Inspiration came pouring in, and I thought of the following triangle:</p>

<p>$$
\begin{array}{rcccccccccc}
&amp;    &amp;    &amp;    &amp;    &amp;  1\\\
&amp;    &amp;    &amp;    &amp;  1 &amp;    &amp;  1\\\
&amp;    &amp;    &amp;  1 &amp;    &amp;  \frac{1}{2} &amp;    &amp;  1\\\
&amp;    &amp;  1 &amp;    &amp;  \frac{2}{3} &amp;    &amp;  \frac{2}{3} &amp;    &amp;  1\\\
&amp;  1 &amp;    &amp;  \frac{3}{5} &amp;    &amp;  \frac{3}{4} &amp;    &amp;  \frac{3}{5} &amp;    &amp;  1\\\
1 &amp; &amp;  \frac{5}{8} &amp;    &amp;  \frac{20}{27} &amp;    &amp;  \frac{20}{27} &amp;    &amp;  \frac{5}{8} &amp;    &amp;  1\\\
&amp; ... &amp; &amp; &amp; &amp;... &amp; &amp; &amp; &amp; ... &amp;
\end{array}
$$</p>

<p>Let's call the corresponding entry ${n \choose k}$ because there is clearly no danger of confusion. The construction rule is very simple. Instead of having 
$${n+1 \choose k} = {n \choose k-1} + {n \choose k},$$
as usual, we have
$${n+1 \choose k} = \frac{1}{{n \choose k-1} + {n \choose k}}.$$</p>

<p>It's easy to see by induction that all entries of the triangle lie between $1/2$ and $1$. Also, for fixed $k$, ${n \choose k}$ converges to a limit $C_k$. For example, $C_1=1/\phi$, where $\phi$ is the golden ratio (this should be obvious! think of Fibonacci numbers...). We can determine easily $C_{k+1}$ in terms of $C_k$ by taking the limit in the construction rule, which yields $C_k=(C_{k-1}+C_k)^{-1}$. In particular, all of the $C_k$'s are algebraic numbers.</p>

<p>I would like to know if anybody here can prove interesting properties of this triangle, or of the numbers $C_k$.</p>

<p>Enjoy! I'm going to take off the shackles and belt now. </p>

 
Answer: <p>The sequence $C_k$ is not monotonic as @JohnM originally claimed. Here's a quick but not so elegant proof of convergence of $C_k$. As a side effect, we'll also know that the sequence goes alternately above and below its limit, namely $1/\sqrt{2}$. </p>

<p>Solving for $C_{k+1}$ in terms of $C_k$, we get $C_{k+1} = \frac{\sqrt{C_k^2 + 4} - C_k}{2}$. I'll directly show that the difference sequence $|C_{k}-\frac{1}{\sqrt{2}}|$ is decreasing exponentially fast, which establishes the required convergence. I'll abbreviate $C_k$ by $c$ for convenience. We have:
$$
\frac{C_{k+1} - \frac{1}{\sqrt{2}}}{C_{k} - \frac{1}{\sqrt{2}}} = \frac{\sqrt{c^2+4} - (c + \sqrt{2})}{2 (c - \frac{1}{\sqrt{2}})}
= \frac{-\sqrt{2}}{\sqrt{c^2+4} + c + \sqrt{2}},
$$
after some straightforward rearrangement. (Notice the minus sign.) Finally, notice that the denominator is at least $2+\sqrt{2} \geq 2\sqrt{2}$ for $c \geq 0$. Hence the ratio is at most $1/2$ in magnitude. In particular, we have $|C_k - \frac{1}{\sqrt{2}}| \leq A 2^{-k}$ for some constant $A$, and we are done. The negative sign shows that the sequence is alternately above and below the limit. $\Box$  </p>

==============================
===============================
Question: <p>The Wikipedia article on <a href="http://en.wikipedia.org/wiki/Banach_algebra#Properties">Banach algebras</a> claims, without a proof or reference, that there does not exist a (unital) Banach algebra $B$ and elements $x, y \in B$ such that $xy - yx = 1$. This is surprising to me, but maybe the proof is straightforward; anyone have a proof and/or a reference? </p>

<p>More generally, I would have naively thought that I could embed any ring into a Banach algebra. I guess there are actually serious restrictions to doing this; are these issues discussed anywhere? </p>

 
Answer: <p>Here's a sketch of a proof.  Let $\sigma(x)$ denote the spectrum of $x$.  Then $\sigma(xy)\cup\{0\} = \sigma(yx)\cup\{0\}$.  On the other hand, $\sigma(1+yx)=1+\sigma(yx)$.  If $xy=1+yx$, then the previous two sentences, along with the fact that the spectrum of each element of a Banach algebra is nonempty, imply that $\sigma(xy)$ is unbounded.  But every element of a Banach algebra has bounded spectrum.  </p>

<p>(I don't remember where I first learned this proof, nor do I have a reference for it off-hand, but I did not come up with it myself.)</p>

<p>The proof that $\sigma(xy)\cup\{0\}=\sigma(yx)\cup\{0\}$ reduces to showing that $1-xy$ is invertible if and only if $1-yx$ is invertible, a problem that was the subject of <a href="https://mathoverflow.net/questions/31595/how-would-you-solve-this-tantalizing-halmos-problem">a MathOverflow question</a>. </p>

<hr>

<p>There's a proof using derivations in section 2.2 of <a href="http://books.google.com/books/about/Operator_Algebras_in_Dynamical_Systems.html?id=fgYPJyqBBwUC" rel="nofollow noreferrer">Sakai's book, <em>Operator algebras in dynamical systems: the theory of unbounded derivations in $C^*$-algebras</em></a>. A bounded derivation on a Banach algebra $A$ is a bounded linear map $\delta$ on $A$ such that $\delta(ab)=\delta(a)b+a\delta(b)$ for all $a$ and $b$ in $A$.  <a href="http://books.google.com/books?id=fgYPJyqBBwUC&amp;lpg=PP1&amp;pg=PA18#v=onepage&amp;q&amp;f=false" rel="nofollow noreferrer">Theorem 2.2.1 on page 18</a> shows that if $\delta$ is a bounded derivation on $A$, and if $a$ is an element of $A$ such that $\delta^2(a)=0$, then $\lim\limits_{n\to\infty}\|\delta(a)^n\|^{1/n}=0$.  The proof uses induction with a neat computation to show that $\delta^2(a)=0$ implies that $n!\delta(a)^n=\delta^n(a^n)$, and then the result follows from boundedness of $\delta$ and the fact that $\lim\limits_{n\to\infty}\frac{1}{\sqrt[n]{n!}}=0$.  </p>

<p>Corollary 2.2.2 concludes that the identity is not a commutator.  If $ab-ba=1$, then the bounded derivation $\delta_a:A\to A$ defined by $\delta_a(x)=ax-xa$ satisfies $\delta_a^2(b)=\delta_a(1)=0$.  By the preceding theorem, this implies that $1=\lim\limits_{n\to\infty}\|1^n\|^{1/n}=\lim\limits_{n\to\infty}\|\delta_a(b)^n\|^{1/n}=0$.</p>

<p>(Completeness is not used in this approach.  An element $x$ of  $A$ satisfies $\lim\limits_{n\to\infty}\|x^n\|^{1/n}=0$ if and only if $\sigma(x)=\{0\}$, and such an $x$ is called a <em>generalized nilpotent</em>.  Incidentally, this also gives an approach to answering the example problem in the MathOverflow question <a href="https://mathoverflow.net/questions/15050/linear-algebra-problems">Linear Algebra Problems?</a>  The remainder of Section 2.2 has a number of interesting results on bounded derivations and commutators of bounded operators.)</p>

==============================
===============================
Question: <p>As I understand it, sheaf cohomology is now an indispensable tool in algebraic geometry, but was originally developed to solve problems in algebraic <em>topology</em>. I have two questions about the matter.</p>

<p><strong>Question 1.</strong> What <em>is</em> sheaf cohomology? I have a vague idea that it has something to do with right derived functors, but this seems rather far removed from the (admittedly very little) cohomology of (co)chain complexes I do know. I would also like to know why sheaf cohomology appears to be so much more fundamental in algebraic geometry than algebraic topology—for instance, I will be taking second courses in algebraic geometry and topology this coming autumn, but sheaf cohomology only appears in the former, suggesting that perhaps sheaf cohomology is not as relevant in basic algebraic topology. (For example, is there an ‘intuitive’ reason why de Rham cohomology cannot be made to work for algebraic varieties?)</p>

<p><strong>Question 2.</strong> Are there any good introductions to sheaf cohomology <em>in a general context</em>? I have tried reading Chapter III of Hartshorne, but very little is getting through, perhaps because I'm not yet comfortable with schemes. A different take—perhaps with an emphasis on manifolds, say—may prove more accessible to me, but since I also need to learn it in the context of algebraic geometry, it would be nice if there were a single text which introduces the theory with applications in both subjects.</p>

 
Answer: <p>Sheaf cohomology is the right derived functor of the global section functor, regarded as a left-exact functor from abelian sheaves on a topological space (more generally, on a site) to the category of abelian groups.  In fact, one can regard this functor as $\mathcal{F} \mapsto \hom_{\mathrm{sheaves}}(\ast, \mathcal{F})$ where $\ast$ is the constant sheaf with one element (the terminal object in the category of all -- not necessarily abelian -- sheaves, so sheaf cohomology can be recovered from the full category of sheaves, or the "topos:" it is a fairly natural functor.</p>

<p>de Rham cohomology <em>can</em> be made to work for arbitrary algebraic varieties: there is something called algebraic de Rham cohomology (which is the hyper-sheaf cohomology of the analog of the usual de Rham complex with algebraic coefficients) and it is a theorem of Grothendieck that this gives the usual singular cohomology over the complex numbers. Incidentally, sheaf cohomology provides a very simple proof that de Rham cohomology agrees with ordinary cohomology (at least when you agree that ordinary cohomology is cohomology of the constant sheaf, here $\mathbb{R}$) because the de Rham resolution is a soft resolution of the constant sheaf $\mathbb{R}$, and you can thus use it to compute cohomology.</p>

<p>Sheaf cohomology is quite natural if you want to consider questions like the following: say you have a surjection of vector bundles $M_1 \to M_2$: then when does a global section of $M_2$ lift to one of $M_1$? The obstruction is in $H^1$ of the kernel. So, for instance, this means that on an <em>affine</em>, there is no obstruction. On a <em>projective</em> scheme, there is no obstruction after you make a large Serre twist (because it is a theorem that twisting a lot gets rid of cohomology). Sheaf cohomology arises when you want to show that something that can be done <em>locally</em> (i.e., lifting a section under a surjection of sheaves) can be done globally. </p>

<p>$H^1$ is also particularly useful because it classifies torsors over a group: for instance, $H^1$ of a Lie group on a manifold  $G$ classifies principal $G$-bundles, $H^1$ of $GL_n$ classifies principal $GL_n$-bundles (which are the same thing as $n$-dimensional vector bundles), etc.</p>

<p>Also, sheaf cohomology does show up in algebraic topology. In fact, the singular cohomology of a space with coefficients in a fixed group is just sheaf cohomology with coefficients in the appropriate constant sheaf (for nice spaces, anyway, say locally contractible ones; this includes the CW complexes algebraic topologists tend to care about).  For instance, Poincare duality in algebraic topology can be phrased in terms of sheaves. Recall that this gives an isomorphism
$H^p(X; k) \simeq H^{n-p}(X; k)$ for a field $k$ and an oriented $n$-dimensional manifold $X$, say compact. This does not look very sheaf-ish, but in fact, since these cohomologies are really $\mathrm{Ext}$ groups of sheaves (sheaf cohomology is a special case of $\mathrm{Ext}$), so we get a perfect pairing
$$ \mathrm{Ext}^p(k, k) \times \mathrm{Ext}^{n-p}(k, k)\to \mathrm{Ext}^n(k,k)$$
where the $\mathrm{Ext}$ groups are in the category of $k$-sheaves. This can be <a href="http://en.wikipedia.org/wiki/Verdier_duality">generalized to singular spaces</a>, but to do so <em>requires</em> sheaf cohomology (and derived categories): the reason, I think, that for manifolds those ideas don't enter is that the "dualizing complex" that arises in this theory is very simple for  a manifold. You might find useful these <a href="http://people.fas.harvard.edu/~amathew/verd.pdf">notes</a> on Verdier duality, which explains the connection (and which mostly follow the book by Iversen).</p>

==============================
===============================
Question: <p>I'm wondering if it's possible for a function to be an $L^p$ space for only one value of $p \in [1,\infty)$ (on either a bounded domain or an unbounded domain).</p>

<p>One can use interpolation to show that if a function is in two $L^p$ spaces, (e.g. $p_1$ and $p_2$,with $p_1 \leq p_2$ then it is in all $p_1\leq p \leq p_2$). </p>

<p>Moreover, if we're on a bounded domain, we also have the relatively standard result that if $f \in L^{p_1}$ for some $p_1 \in [1,\infty)$, then it is in $L^p$ for every $p\leq p_1$ (which can be shown using H&ouml;lder's inequality).</p>

<p>Thus, I think that the question can be reduced to unbounded domains if we consider the question for any $p&gt;1$. </p>

<p>Intuitively, a function on an unbounded domain is inside an $L^p$ space if it decrease quickly enough toward infinity. This makes it seem like we might be able to multiply the function by a slightly larger exponent. At the same time, doing this might cause the function to blow up near zero. That's not precise/rigorous at all though.   </p>

<p>So I'm wondering if it is possible to either construct an example or prove that this can't be true.</p>

 
Answer: <p>Robert's and joriki's examples are of course nice and explicit, but you can get examples on any subset of $\mathbb{R}^n$ with infinite measure. Here's how:</p>

<p>Take a function $f$ that is in $L^p$ but not in $L^q$ for $q \gt p$ (on the unit ball $B$ around zero, say). Now take a sequence $x = (x_n)$ that is in $\ell^p$ but not in $\ell^q$ for $q \lt p$ (there are standard examples for both of these things). Now take disjoint balls $B_n$ of volume $1$ (disjoint from $B$) and consider $g = f + \sum x_n \cdot [B_n]$ where $[B_n]$ denotes the characteristic function of $B_n$. Obviously, $\|g\|_{q}^q = \|f\|_{q}^q + \|x\|_{q}^{q}$ is in $L^q$ if and only if $q = p$. If $q \lt p$ then $\|x\|_q = \infty$ and if $q \gt p$ then $\|f\|_{q}^q = \infty$.</p>

<p>I leave it to you to make that explicit and to modify it when your domain is not all of $\mathbb{R}^n$.</p>

==============================
===============================
Question: <p>In short, my question is:</p>

<blockquote>
  <p>Was Grothendieck familiar with Stone's work on Boolean algebras?</p>
</blockquote>

<p><strong>Background:</strong></p>

<p>In an answer to Pierre-Yves Gaillard's question <em><a href="https://math.stackexchange.com/q/55259/">Did Zariski really define the Zariski topology on the prime spectrum of a ring?</a></em> I let myself get carried away and explained a result of Grothendieck that (for me) implies that Grothendieck certainly was familiar with Stone's work on spectra and even proved theorems with it. Qiaochu suggested that I ask a question and answer myself (apparently <a href="http://blog.stackoverflow.com/2011/07/its-ok-to-ask-and-answer-your-own-questions/">officially encouraged</a>, see his remark), so I'm doing that in order to avoid an off-topic answer to Pierre-Yves's question. </p>

<p>Qiaochu's accepted answer quotes excerpts from Johnstone's <em><a href="http://books.google.com/books?id=CiWwoLNbpykC" rel="nofollow noreferrer">Stone spaces</a></em> that seem to imply that Grothendieck never quoted Stone. Precisely I'm having the following passage in mind:</p>

<blockquote>
  <p>But again, one will not find any reference to Stone in the work of Grothendieck, even though his use of the word 'spectrum' is an obvious echo of <a href="http://www.ams.org/mathscinet-getitem?mr=2023" rel="nofollow noreferrer">[Stone 1940]</a>, and Grothendieck, with his background in functional analysis, must have been familiar with Stone's work in that field.</p>
</blockquote>

<p>I did <em>not</em> seriously try to verify or falsify the first part of the sentence (and please do provide references if you happen to know of them). My own long answer addresses the second part of the sentence and tries to make a point that <em>must have been</em> should be replaced by <em>was</em>.</p>

<p>Now fire away and complain about this being a nitpick, but I'm trying to explain a nice and interesting piece of mathematics and both Jonas Meyer and Qiaochu Yuan said I should post this answer, so: that's what I'm doing here.</p>

 
Answer: <blockquote>
  <p>[...] Grothendieck, with his background in functional analysis, must have been familiar with Stone's work in that field.</p>
</blockquote>

<p>cited by Qiaochu reveals a gap in the knowledge of Grothendieck's work (which is of course nothing to be blamed for, given its vastness and ramifications in so many fields) but it also misses a link to one of Grothendieck's beautiful theorems in functional analysis. I'd like to make the point that</p>

<blockquote>
  <p>not only was Grothendieck well aware of that work, he even exploited it!</p>
</blockquote>

<p>The crucial reference is his article <em><a href="http://dx.doi.org/10.4153/CJM-1955-060-6" rel="noreferrer">Une caract&eacute;risation vectorielle&ndash;m&eacute;trique des espaces $L^{1}$.</a></em> While Grothendieck does <em>not</em> cite Stone, he relies crucially on Nachbin's paper <em><a href="http://dx.doi.org/10.1090/S0002-9947-1950-0032932-3" rel="noreferrer">A theorem of the Hahn&ndash;Banach type for linear transformations</a></em>, improves on that paper and exploits the main results in a serious way. This <em>is</em> only possible if you understand these results profoundly. Nachbin in turn cites three works of Stone, see references 4,5,6 below.</p>

<p>To prevent a possible criticism of that argument, let me note that Nachbin and Grothendieck knew each other well. Grothendieck spent some time in Brazil and  even planned to write a book on topological vector spaces with Nachbin:</p>

<blockquote>
  <p>Grothendieck planned to write a book on topological vector spaces with Leopoldo Nachbin, who was in Rio de Janeiro, but the book never materialized. However, Grothendieck taught a course in S&atilde;o Paulo on topological vector spaces and wrote up the notes, which were subsequently published by the university.</p>
</blockquote>

<p>see Allyn Jackson's <a href="http://www.ams.org/notices/200409" rel="noreferrer">Notices article on Grothendieck, part&nbsp;1, p.1044</a>. It <em>could</em> seem conceivable that the results were orally transmitted and that Grothendieck never looked at that paper. However, to such an objection I'd respond: you have to take into account that Grothendieck asserted the main results of that work earlier but he later discovered that his arguments had a serious gap. Given that he had to work rather hard to fix it, it seems quite implausible to me that he never took a closer look at Nachbin's work and missed the work of Stone cited in there entirely.</p>

<p>Secondly Grothendieck refers to two works of Kakutani (references 8 and 9) below, which in turn refer to Stones works&nbsp;4 and&nbsp;5 and rely on it, too.</p>

<p>In conclusion I think it is safe to say that Grothendieck not only "must have been" but actually "was" aware of Stone's work (<strong>Edit:</strong> As Didier Piau pointed out in a comment this is still inconclusive, but please see the update at the end of this post).</p>

<p>I'm now parting from the historical ramblings and make an attempt at a description of Grothendieck's result in a way that I hope is appealing to algebraists. For the actual work, please consult the <a href="http://www.ams.org/mathscinet-getitem?mr=76301" rel="noreferrer">MathSciNet review</a> and the <a href="http://dx.doi.org/10.4153/CJM-1955-060-6" rel="noreferrer">paper itself</a>.</p>

<p><strong>Further References:</strong> It don't know of many self-contained expositions of the results I mention below. The classification of "injective" Banach spaces (called $P_1$-spaces in the classical literature) can be found in Day's booklet <em><a href="http://www.ams.org/mathscinet-getitem?mr=344849" rel="noreferrer">Normed Linear Spaces</a></em> as well as in H.&nbsp;Elton Lacey's <em><a href="http://www.ams.org/mathscinet-getitem?mr=493279" rel="noreferrer">The isometric theory of classical Banach spaces.</a></em> For a categorical view on Banach spaces please consult the Book <em><a href="http://www.ams.org/mathscinet-getitem?mr=533819" rel="noreferrer">Banach modules and functors on categories of Banach spaces</a></em> by Cigler&ndash;Losert&ndash;Michor. I take the liberty and refer to Part&nbsp;2 (Chapter&nbsp;IV) of <a href="http://dx.doi.org/10.3929/ethz-a-005561107" rel="noreferrer">my thesis</a> for further facts, references and details.</p>

<hr>

<p>Recall that Grothendieck's thesis was called <em><a href="http://www.ams.org/mathscinet-getitem?mr=75539" rel="noreferrer">Produits tensoriels topologiques et espaces nucl&eacute;aires</a></em> which is a masterpiece of its own and even mentioning its ramifications to the theory of distributions would lead us too far astray&mdash;the first line of the MathSciNet review reads: <em>Le grand nombre de r&eacute;sultats importants contenus dans ce m&eacute;moire (Th&egrave;se), rend difficile d'en mettre en &eacute;vidence les lignes essentielles, m&ecirc;me si l'on a recours au r&eacute;sum&eacute; des r&eacute;sultats publi&eacute; auparavant&nbsp;[...].</em> Incidentally, one characteristic of that work is that quite often the statement of theorems span more than a page while the proofs only take a couple of lines or are dismissed with a mere "Preuve: &eacute;vidente."</p>

<p>The simplest instance of a topological tensor product is due to Murray (and von Neumann)'s student <a href="http://dx.doi.org/10.1090/S0002-9947-1943-0007568-7" rel="noreferrer">Schatten</a> and is called the <em>projective</em> tensor product $\otimes$ of Banach spaces (usually denoted $\hat{\otimes}$ or $\hat{\otimes}_{\pi}$). Given two Banach spaces, the space of bounded linear operators equipped with the operator norm yields an (internal) Hom-bifunctor and by design the projective tensor product is its left adjoint. From that point of view this is the most algebraically sane tensor product of Banach spaces to look at. (Yes, it is part of a monoidal closed structure etc etc)</p>

<p>Let us call a Banach space <em>flat</em> if $F \otimes {-}$ preserves short exact sequences of Banach spaces (here short exact means isometric inclusion of subspace + corresponding quotient map&mdash;we're working in the category of Banach spaces and linear contractions).</p>

<p>A Banach space $I$ will be called <em>injective</em> if every contractive map $E \to I$ from a subspace $E \leq F$ extends to a contractive map $F \to I$.</p>

<p>Note: The scalar field is of course flat (it is the tensor unit) and it is injective (that's equivalent to Hahn&ndash;Banach).</p>

<p>Using this language we have:</p>

<blockquote>
  <p><strong>Theorem (Grothendieck).</strong> A Banach space $F$ is flat if and only if  $F$ is isomorphic to a space $L^1(\Omega)$ where $\Omega$ is some measure space.</p>
</blockquote>

<p>Now how does Grothendieck prove that? In his thesis he observed that $L^1(\Omega)$ <em>is</em> flat. This is not very hard to prove, as from an analytic perspective the projective tensor product $L^1(\Omega) \otimes E$ really is the space of Bochner integrable functions $L^1(\Omega, E)$ and from that identification (due to Grothendieck as well, as far as I know) the exactness of $L^1(\Omega) \otimes {-}$ <em>is</em> rather obvious .</p>

<p>The other direction needed much more insight. I won't elaborate on precisely <em>what</em> Grothendieck did, but here's what it comes down to morally, from the skewed perspective I adopted in this part of the answer so far:</p>

<ol>
<li>"Lambek's theorem": A Banach space is flat if and only if its dual space $F^{\ast}$ is injective (rather trivial, see see also <a href="http://www.ams.org/mathscinet-getitem?mr=1653294" rel="noreferrer">Lam</a> Theorem&nbsp;4.9, p.125).</li>
<li>A Banach space is injective if and only if it is isomorphic to a space of the form $C(K)$ with $K$ <em>Stonean</em> (compact Hausdorff and <a href="http://en.wikipedia.org/wiki/Extremally_disconnected_space" rel="noreferrer">extremally disconnected</a>).</li>
<li>Grothendieck's theorem can now be phrased as: An injective Banach space is a dual space if and only if it is of the form $L^{\infty}(\Omega)$; its pre-dual  $L^1(\Omega)$ is unique (contrary to general Banach spaces).</li>
</ol>

<p>The theorem in 2. (due to various efforts by Akilov-Goodner-Kelley-Nachbin) is seriously deep. A feeling for this can be obtained by noting that the easiest example of an infinite Stonean space is $K = \beta \mathbb{N}$, the Stone&ndash;&#268;ech compactification of the natural numbers. Suffice it to say that the space $K$ arises from the geometry of the unit ball of an injective Banach space, which is strongly related to lattice theory and Boolean algebras, hence the link. Note also that Stonean spaces are called thus because they arose from Stones study of spectra of Boolean algebras.</p>

<p>Note that by the Riesz-Kakutani representation theorem the space $C(K)^\ast$ is the space of measures on $K$. Now given a flat Banach space $F$ it embeds into $F^{\ast\ast} = C(K)^{\ast}$ and Grothendieck needed to recover it from the fact that he knew only that $C(K)$ is a dual space. He did that by identifying the space $F$ with the <em>normal</em> measures on $K$ and this <em>does</em> involve a deep understanding of the Stonean spaces.</p>

<hr>

<p><strong>Added:</strong> I forgot to mention one further punchline: Grothendieck also proves and makes use of the fact that a $C(K)$ space which is a dual space can be realized as a von Neumann algebra (in the spatial definition, of course). In remarque&nbsp;3 he states: </p>

<blockquote>
  <p>On peut se demander si le th&eacute;or&egrave;me&nbsp;2 se g&eacute;n&eacute;ralise &agrave; toute $C^{\ast}$-alg&egrave;bre (non n&eacute;cessairement ab&eacute;lienne comme dans notre &eacute;nonc&eacute;): Si une telle alg&egrave;bre $C$ est isomorphe (avec sa norme) au dual d'un sous-espace $L$ de $C$, est-il vrai que $C$ est isomorphe &agrave; une alg&egrave;bre de von Neumann, et que $L$ est exactement l'ensemble des formes normales sur $C$? [...] La seule difficult&eacute; est dans la question si $L$ est engendr&eacute; par sa partie positive, le raisonnement donn&eacute; dans le cas commutatif ne vaut pas tel quel. Il semble probable cependant que la technique des $C^{\ast}$-alg&egrave;bres jointe au th&eacute;or&egrave;me de Banach-Dieudonn&eacute; doive permettre de donner une r&eacute;ponse affirmative &agrave; notre question.</p>
</blockquote>

<p>Of course, this is nothing but giving the outline of the proof of the celebrated Sakai theorem that characterizes von Neumann algebras as precisely those $C^{\ast}$-algebras which are dual spaces as a Banach space. Those acquainted with <a href="http://projecteuclid.org/euclid.pjm/1103043801" rel="noreferrer">Sakai's theorem</a> will of course recognize that this is exactly how Sakai proceeded and indeed the <em>"seule difficult&eacute;"</em> in the proof... but I digressed enough. Let me stop by remarking that Sakai's paper was submitted while Grothendieck proofread his paper and I'll finish by quoting him:</p>

<blockquote>
  <p><em>Ajout&eacute; pendant la correction des &eacute;preuves.</em> Monsieur Lowdenslager m'a fait observer les faits suivants. La g&eacute;n&eacute;ralisation du th&eacute;or&egrave;me&nbsp;2 conjectur&eacute;e dans la remarque&nbsp;3 a &eacute;t&eacute; prouv&eacute;e r&eacute;cemment par Sakai, dans un papier qui sera publi&eacute; dans le Pacific Journal of Mathematics. Le th&eacute;or&egrave;me de Nachbin cit&eacute; au d&eacute;but de ce travail a &eacute;t&eacute; prouv&eacute; ind&eacute;pendamment par D.&nbsp;B.&nbsp;Goodner; la plus jolie preuve connue semble &ecirc;tre celle de Kelley (Banach spaces with the extension property, Trans. Amer. Math. Soc, 72 (1952), 323-326), qui ne suppose pas que la boule unit&eacute; admette un point extremal.</p>
</blockquote>

<hr>

<p><strong>References:</strong></p>

<ol>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=75539" rel="noreferrer">MR0075539</a>:
Grothendieck, Alexandre, 
<em>Produits tensoriels topologiques et espaces nucl&eacute;aires</em>.
Mem. Amer. Math. Soc. (1955), no.&nbsp;16, 140&nbsp;pp.</li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=76301" rel="noreferrer">MR0076301</a>:
Grothendieck, A.
<em><a href="http://dx.doi.org/10.4153/CJM-1955-060-6" rel="noreferrer">Une caractérisation vectorielle-métrique des espaces $L^1$.</a></em>
Canad. J. Math.<strong>7</strong>&nbsp;(1955),&nbsp;552&ndash;561. </li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=0032932" rel="noreferrer">MR0032932</a>: Leopoldo Nachbin, <em><a href="http://dx.doi.org/10.1090/S0002-9947-1950-0032932-3" rel="noreferrer">A theorem of the Hahn-Banach type for linear transformations</a></em>, Trans. Amer. Math. Soc.&nbsp;<strong>68</strong>&nbsp;(1950), 28-46. </li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=1501905" rel="noreferrer">MR1501905</a>: Stone, M. H.,
<em><a href="http://dx.doi.org/10.1090/S0002-9947-1937-1501905-7" rel="noreferrer">Applications of the theory of Boolean rings to general topology</a>.</em> 
Trans. Amer. Math. Soc. 41 (1937), no. 3, 375–481. </li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=2023" rel="noreferrer">MR2023</a>: Stone, M. H., <em>A general theory of spectra. I.</em>, 
Proc. Nat. Acad. Sci. U. S. A. 26, (1940). 280–283.</li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=4092" rel="noreferrer">MR4092</a>: Stone, M. H., <em>A general theory of spectra. II.</em> 
Proc. Nat. Acad. Sci. U. S. A. 27, (1941). 83–87. </li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=29091" rel="noreferrer">MR29091</a>: M. H. Stone, <em>Boundedness properties in function-lattices</em>, Canadian Journal of Mathematics vol. 1 (1949) pp. 176-186.</li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=4095" rel="noreferrer">MR0004095</a>: Kakutani, Shizuo. <em>Concrete representation of abstract $(L)$-spaces and the mean ergodic theorem.</em>
Ann. of Math. (2) 42, (1941). 523--537.</li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=5778" rel="noreferrer">MR0005778</a>: Kakutani, Shizuo. <em>Concrete representation of abstract (M)-spaces. (A characterization of the space of continuous functions.)</em>
Ann. of Math. (2) 42, (1941). 994--1024.</li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=0084115" rel="noreferrer">MR0084115</a>: Sakai, Sh&ocirc;ichir&ocirc;,
<em><a href="http://projecteuclid.org/euclid.pjm/1103043801" rel="noreferrer">A characterization of $W^{\ast}$-algebras.</a></em> Pacific J. Math.&nbsp;6&nbsp;(1956), 763&ndash;773. </li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=0007568" rel="noreferrer">MR0007568</a>: Robert Schatten, <em><a href="http://dx.doi.org/10.1090/S0002-9947-1943-0007568-7" rel="noreferrer">On the direct product of Banach spaces</a>,</em> Trans. Amer. Math. Soc.&nbsp;<strong>53</strong> (1943), 195-217.</li>
<li>T. B&uuml;hler, <em><a href="http://dx.doi.org/10.1090/S0065-9266-2011-00618-0" rel="noreferrer">On the algebraic foundation of bounded cohomology</a></em>, Mem. Amer. Math. Soc., posted on March&nbsp;11, 2011,
PII S&nbsp;0065-9266(2011)00618-0  (to appear in print). Also available <a href="http://dx.doi.org/10.3929/ethz-a-005561107" rel="noreferrer">here</a>.</li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=533819" rel="noreferrer">MR533819</a>: Cigler, Johann; Losert, Viktor; Michor, Peter
<em>Banach modules and functors on categories of Banach spaces.</em> 
Lecture Notes in Pure and Applied Mathematics,&nbsp;46. Marcel Dekker, Inc., New York, 1979. xv+282 pp.</li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=344849" rel="noreferrer">MR0344849</a>: Day, Mahlon M. <em>Normed linear spaces.</em> 
Third edition. Ergebnisse der Mathematik und ihrer Grenzgebiete, Band&nbsp;21. Springer-Verlag, New York-Heidelberg, 1973. viii+211&nbsp;pp. </li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=493279" rel="noreferrer">MR0493279</a>:
Lacey, H. Elton. <em>The isometric theory of classical Banach spaces.</em>
Die Grundlehren der mathematischen Wissenschaften, Band&nbsp;208. Springer-Verlag, New York-Heidelberg, 1974. x+270&nbsp;pp.</li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=1653294" rel="noreferrer">MR1653294</a>: T.&nbsp;Y.&nbsp;Lam, <em>Lectures on modules and rings</em>, Graduate Texts in Mathematics, vol.&nbsp;189, Springer-Verlag, New York,&nbsp;1999. </li>
<li><a href="http://www.ams.org/mathscinet-getitem?mr=58866" rel="noreferrer">MR58866</a>: A. Grothendieck, <em><a href="http://dx.doi.org/10.4153/CJM-1953-017-4" rel="noreferrer">Sur les applications lin&eacute;aires faiblement compactes d'espaces du type $C(K)$.</a></em>, Canadian J. Math.<strong>5</strong>,(1953). 129–173. </li>
</ol>

<hr>

<p><strong>Update:</strong></p>

<p>In the paper <em><a href="http://dx.doi.org/10.4153/CJM-1953-017-4" rel="noreferrer">Sur les applications lin&eacute;aires faiblement compactes d'espaces du type $C(K)$</a></em> we find Stone's paper <em><a href="http://dx.doi.org/10.1090/S0002-9947-1937-1501905-7" rel="noreferrer">Applications of the theory of Boolean rings to general topology</a></em> listed as reference&nbsp;14. It is mentioned only once as a mere reference for the Stone&ndash;&#268;ech compactification at the very end of the proof of Proposition&nbsp;6&nbsp;(b): </p>

<p><img src="https://i.stack.imgur.com/6xGH0.png" alt="Grothendieck: Citation of Stone"></p>

<p>Here's the bibliography of that paper:</p>

<p><img src="https://i.stack.imgur.com/zZQEF.png" alt="Grothendieck: Reference list"></p>

<p>I'd like to emphasize that my intention of this post was by no means to debunk anything Johnstone writes (and as a matter of fact: I didn't!): the excerpt provided by Qiaochu explicitly speaks of Grothendieck's work on <em>Algebraic Geometry</em> a bit before. I merely wanted to point out that there <em>was</em> an interesting link that may not be as widely known as it deserves to be.</p>

<p>For me the above settles the matter whether Grothendieck was <em>aware</em> of Stone's work. Whether he was <em>familiar</em> with it, particularly with the aspect of spectra, it is probably something he alone could answer, unless a more specific reference is provided. However, I hope I have succeeded in making the point that he was familiar enough with the <em>contents</em> that he could prove a beautiful theorem with it.</p>

==============================
===============================
Question: <p>In other word, how to prove:</p>

<blockquote>
  <p>For all real constants $a$ and $b$ such that $a &gt; 1$,</p>
  
  <p>$$\lim_{n\rightarrow\infty}\frac{n^b}{a^n} = 0$$</p>
</blockquote>

<p>I know the definition of limit but I feel that it's not enough to prove this theorem.</p>

 
Answer: <p>We could prove this by induction on integers $k$:  </p>

<p>$$
\lim_{n \to \infty} \frac{n^k}{a^n} = 0.
$$</p>

<p>The case $k = 0$ is straightforward.  I will leave the induction step to you.  To see how this implies the statement for all real $b$, just note that every real number is less than some integer.  In particular, $b \leq \lceil b \rceil$.  Thus,</p>

<p>$$
0 \leq \lim_{n \to \infty} \frac{n^b}{a^n} \leq \lim_{n \to \infty} \frac{n^{\lceil b \rceil}}{a^n} = 0.
$$</p>

<p>The first inequality follows since all the terms are positive.  The last equality follows from the induction we established previously.</p>

==============================
===============================
Question: <p>Is there a way to prove the following result using connectedness?</p>

<p><strong>Result</strong>:</p>

<p>Let $J=\mathbb{R} \setminus \mathbb{Q}$ denote the set of irrational numbers. There is no continuous map $f: \mathbb{R} \rightarrow \mathbb{R}$ such that $f(\mathbb{Q}) \subseteq J$ and $f(J) \subseteq \mathbb{Q}$.</p>

<p><a href="http://planetmath.org/encyclopedia/ThereIsNoContinuousFunctionThatSwitchesTheRationalNumbersWithTheIrrationalNumbers.html">http://planetmath.org/encyclopedia/ThereIsNoContinuousFunctionThatSwitchesTheRationalNumbersWithTheIrrationalNumbers.html</a></p>

 
Answer: <p>Here's a way to use connectedness, really amounting to using the intermediate value theorem.</p>

<p>If $f(\mathbb{Q})\subseteq \mathbb R\setminus\mathbb Q$ and $f(\mathbb R\setminus \mathbb Q)\subseteq\mathbb  Q$, then $f(0)\neq f(\sqrt 2)$.  Because intervals are connected in $\mathbb R$ and $f$ is continuous, $f[0,\sqrt 2]$ is connected.  Because connected subsets of $\mathbb R$ are intervals, $f[0,\sqrt 2]$ contains the interval $\left[\min\{f(0),f(\sqrt 2)\},\max\{f(0),f(\sqrt 2)\}\right]$.  The set of irrational numbers in this interval is uncountable, yet contained in the countable set $f(\mathbb Q)$, a contradiction.</p>

<p>A slightly briefer outline: The hypothesis implies that $f$ is nonconstant with range contained in the countable set $\mathbb Q\cup f(\mathbb Q)$, whereas the intermediate value theorem and uncountability of $\mathbb R$ imply that a nonconstant continuous function $f:\mathbb R\to\mathbb R$ has uncountable range.</p>

==============================
===============================
Question: <p>It is known that if $f_n = \sum\limits_{i=0}^{n} g_i \binom{n}{i}$ for all $0 \le n \le m$, then $g_n = \sum_{i=0}^{n} (-1)^{i+n} f_i \binom{n}{i}$ for $0 \le n \le m$. This sort of inversion is called <em>binomial inversion</em>, for obvious reasons.</p>

<p>Many nice elegant proofs exist (my favorite uses exponential generating functions of $f_n$ and $g_n$), and also many applications (such as proving that if polynomial $f$ of degree $n$ assumes integers values on $0,1,\cdots,n$, then $f(i) \in \mathbb{Z}$ for all integers $i$).</p>

<p>What I'm interested is the following:</p>

<ol>
<li>A nice inclusion-exclusion proof - similar to interpreting Möbius inversion as inclusion-exclusion.</li>
<li>If $f_0 = g_0 = 0$ and $i | f_i$ for $i&gt;1$, we get, by the Binomial Inversion, that $i | g_i$ (reason: $i\binom{n}{i} = n\binom{n-1}{i-1}$). Is there a nice combinatorial interpretation of this phenomena? Nice applications?</li>
<li>Are there any more famous/cool inversions (I know of Möbius inversion, binomial inversion, and the discrete derivative inversion $a_i \to a_{i+1}-a_{i})$?</li>
</ol>

 
Answer: <p>These kinds of inverse relations are equivalent to orthogonal relations between sets of numbers.</p>

<p>Suppose you have two triangular sets of numbers $a_{n,k}$ and $b_{n,k}$, each defined for $k = 0, 1, \ldots, n$, such that $$\sum_{k=m}^n b_{n,k} a_{k,m} = \delta_{nm}.$$  Then $a_{n,k}$ and $b_{n,k}$ are orthogonal, and they have the inverse property you are asking for in (3); i.e., if $f_n = \sum_{k=0}^n a_{n,k} g_k$ then $g_n = \sum_{k=0}^n b_{n,k} f_k$, and vice versa.</p>

<p><em>Proof</em>:  $$\sum_{k=0}^n b_{n,k} f_k = \sum_{k=0}^n b_{n,k} \sum_{m=0}^k a_{k,m} g_m = \sum_{m=0}^n \left(\sum_{k=m}^n b_{n,k} a_{k,m}\right) g_m = g_n.$$ </p>

<p>Thus binomial inversion follows from the "<a href="https://math.stackexchange.com/questions/4175/beautiful-identity-sum-k-mn-1k-m-binomkm-binomnk-delta">beautiful identity</a>" $$\sum_{k=m}^n (-1)^{k+m} \binom{n}{k} \binom{k}{m}  = \delta_{nm}.$$</p>

<p>Since the orthogonal relation and the inverse relation are equivalent, perhaps the <a href="https://math.stackexchange.com/questions/4175/beautiful-identity-sum-k-mn-1k-m-binomkm-binomnk-delta/4187#4187">proof of this identity given by Aryabhata</a>  or <a href="https://math.stackexchange.com/questions/4175/beautiful-identity-sum-k-mn-1k-m-binomkm-binomnk-delta/4189#4189">the proof by Yuval Filmus</a> can be considered a combinatorial proof of the inverse relation you describe for binomial coefficients.</p>

<p><HR></p>

<p><strong>Other examples</strong></p>

<p>The <a href="http://en.wikipedia.org/wiki/Lah_number" rel="nofollow noreferrer">Lah numbers</a> $L(n,k)$ satisfy $$\sum_{k=m}^n (-1)^{k+m} L(n,k) L(k,m) = \delta_{nm},$$ and so, like the binomial coefficients, are (up to sign) self-orthogonal and have the inverse relation
$$f_n = \sum_{k=0}^n L(n,k) g_k \Leftrightarrow g_n = \sum_{k=0}^n (-1)^{k+n} L(n,k) f_k.$$</p>

<p>The two kinds of <a href="http://en.wikipedia.org/wiki/Stirling_number" rel="nofollow noreferrer">Stirling numbers</a>, $\left[ n \atop k \right]$ and $\left\{ n \atop k \right\}$, are orthogonal, satisfying 
$$\sum_{k=m}^n (-1)^{k+m} \left[ n \atop k \right] \left\{ k \atop m \right\} = \delta_{nm}$$
and
$$\sum_{k=m}^n (-1)^{k+m} \left\{ n \atop k \right\} \left[ k \atop m \right] = \delta_{nm}.$$
Thus they satisfy the inverse relation
$$f_n = \sum_{k=0}^n \left[ n \atop k \right] g_k \Leftrightarrow g_n = \sum_{k=0}^n (-1)^{k+n} \left\{ n \atop k \right\} f_k.$$</p>

<p>John Riordan wrote a paper "Inverse Relations and Combinatorial Identities" (<em>American Mathematical Monthly</em> 71 (5), May 1964, pp. 485--498) and devoted two of the six chapters of his text <em>Combinatorial Identities</em> to these kinds of inverse relations.  For example, he shows how inverse relations can be derived from <a href="http://en.wikipedia.org/wiki/Chebyshev_polynomials" rel="nofollow noreferrer">Chebyshev polynomials</a> (since they are orthogonal) and <a href="http://en.wikipedia.org/wiki/Legendre_polynomials" rel="nofollow noreferrer">Legendre polynomials</a> (since they are also orthogonal).  See the article or the book for many more examples.  </p>

<p><HR></p>

<p><strong>Additional comments and consequences</strong></p>

<p>The proof using the orthogonal relation can also be applied with respect to the upper index to obtain inverse relations based on the upper index rather than the lower.  Thus, for example, we also have (provided, of course, that the sums converge) $$f_n = \sum_{k=n}^\infty \binom{k}{n} g_k \Leftrightarrow g_n = \sum_{k=n}^\infty (-1)^{k+n} \binom{k}{n} f_k,$$
as well as the same kind of thing for the Lah numbers, Stirling numbers, and the other examples.</p>

<p>In addition, these orthogonal relations mean that matrices consisting of orthogonal numbers are inverses.  Thus, for example, if $A$ and $B$ are $n \times n$ matrices such that $A_{ij} = \binom{i}{j}$ and $B_{ij} = (-1)^{i+j} \binom{i}{j}$ then the orthogonal relationship implies that $AB = I$.  This, of course, means that $BA = I$ as well, and so every orthogonal relationship goes both ways; i.e., $$\sum_{k=m}^n b_{n,k} a_{k,m} = \delta_{nm} \Leftrightarrow \sum_{k=m}^n a_{n,k} b_{k,m} = \delta_{nm}.$$
For more on inverse matrices consisting of combinatorial numbers, see <a href="https://math.stackexchange.com/questions/42018/stirling-numbers-and-inverse-matrices/49496#49496">my answer</a> to the question "Stirling numbers and inverse matrices."</p>

==============================
===============================
Question: <p>(I give a lengthy introduction to a concise question -- scroll down if you want to jump straight up to the question).</p>

<p>Recall that abelian group theory consists of two primitive symbols: $\cdot$ which is a binary function symbol, and $e$ which is a constant. The axioms are:</p>

<blockquote>
  <p>($G_1$) $\forall x \forall y \forall z \ \ x\cdot (y\cdot z)=(x\cdot y)\cdot z$</p>
  
  <p>($G_2$) $\forall x \ \ x\cdot e=x$</p>
  
  <p>($G_3$) $\forall x \exists y \ \ x\cdot y=e$</p>
  
  <p>($G_4$) $\forall x \forall y \ \ x\cdot y =y \cdot x$</p>
</blockquote>

<p>A set of axioms $\Phi$ is <em>independent</em> if for every $\varphi\in \Phi$ there exists an interpretation $\mathcal{I}$ such that $\mathcal{I} \models \Phi\setminus \{\varphi\}$ and $\mathcal{I}\not\models \varphi$.</p>

<p>In non-formal logic language, $\mathcal{I}\models \Phi$ means: exhibit a set $G$ with a binary operation $\cdot$ and an element $e\in G$ such that all axioms in $\Phi$ are satisfied (taking the variables as belonging to $G$).</p>

<p>So, to prove that the above axioms are independent is to exhibit, for every $i=1,\dots,4$, a set $G$ with a binary operation $\cdot$ and an element $e\in G$ such that $(G_j)$ holds for every $j\not=i$, and $(G_i)$ does not hold. Thusly you prove that you can't prove $(G_i)$ from $\{(G_j), j\not=i\}$.</p>

<p>A cute and fun problem in Ebbinghaus, Mathematical Logic (exercise 4.14, p. 39) asks us to prove that the <em>group theory</em> axioms, i.e. $\{(G_1), (G_2), (G_3)\}$ is an independent set of axioms. This is fun to do.</p>

<p>But then the natural follow-up question that occurred to me is: is $\{(G_1), (G_2), (G_3) ,(G_4)\}$ an independent set of axioms?</p>

<p>For $i=2,3,4$ it is easy to prove that there are models of $\{(G_j):j\not=i\}$ where $(G_i)$ does not hold. (In fact, for $i=2,3$, the ones I have thought for the exercise in Ebbinghaus were all commutative, and thus worked; for $i=4$ it's just the existence of non-abelian groups).</p>

<p>But for $i=1$ I'm having a really hard time. I tried a lot of examples, neither of which works. To sum up, I'm trying to prove that:</p>

<blockquote>
  <p>There exists a set $G$ with a binary operation $\cdot$ such that: $\cdot$ is not associative, $\cdot$ is commutative, there is an identity element $e$, and every element has an inverse with respect to $e$.</p>
</blockquote>

<p>The best I could do was the following. Take $G=\mathbb{R}^2$, with $(a,b)\cdot (c,d)=(ac+bd,0)$. It is commutative, not associative, the inverse with respect to $(0,0)$ is $(b,-a)$, but $(a,b)\cdot (0,0)=(0,0)$, not $(a,b)$, whence $(0,0)$ is not an identity element.</p>

<p>Or perhaps I'm just wrong and $(G_2), (G_3), (G_4)$ imply $(G_1)$, which would come off as a surprise.</p>

 
Answer: <p>Consider the non-negative integers $\mathbb{Z}_{\ge 0}$ with the binary operation $|x - y|$. This is obviously commutative. The identity is $0$ and every element is its own inverse, but $||1 - 1| - 2| = 2 \neq |1 - |1 - 2|| = 0$. </p>

==============================
===============================
Question: <p>To end a proof, I often write "as was to be shown" or "q.e.d". Both of these terms make sense to me as a reader. On the other hand, I feel a little strange to put down $\square$ although I  saw it many times here and there. In fact, I learned $\square$ notation here. I wonder if anyone could give me a brief explanation of $\square$ notation in mathematics. Where does it come from? More importantly, how does it logically mean "end" of a proof? Thank you.</p>

 
Answer: <p>It just means the same thing as <em>q.e.d.</em> Its introduction is usually attributed to Paul Halmos:</p>

<blockquote>
  <p>"The symbol is definitely not my invention — it appeared in popular magazines (not mathematical ones) before I adopted it, but, once again, I seem to have introduced it into mathematics. It is the symbol that sometimes looks like ▯, and is used to indicate an end, usually the end of a proof. It is most frequently called the 'tombstone', but at least one generous author referred to it as the 'halmos'.", Paul R. Halmos, I Want to Be a Mathematician: An Automathography, 1985, p. 403.</p>
</blockquote>

<p>(This is quoted in Wikipedia)</p>

==============================
===============================
Question: <p>This question has been in my mind since high school.</p>

<p>We can get multiplication of natural numbers by repeated addition; equivalently, if we define $f$ recursively by $f(1)=m$ and $f(n+1)=f(n)+m$, then $f(n) = m \times n$.  Likewise, we get exponentiation by repeated multiplication. If $g(1)=m$ and $g(n+1)=mg(n)$, then $g(n) = m^n$.  In my high school mind it was natural to imagine a new function defined by repeated exponentiation: $h(1)=m$ and $h(n+1)=m^{h(n)}$.</p>

<p>These definitions only make sense for $n$ a natural number, but of course there are standard very mathematically satisfying ways to define multiplication and exponentiation by any real number. My question is this:</p>

<p><strong>Can the function $h$ defined above also be extended in a natural way to $\mathbb{R}^{&gt;0}$?</strong></p>

<p>The question is in the spirit of seeking an extension of $f(n)=n!$ to $\mathbb{R}$ and arriving at $\Gamma(x)$.</p>

<p>Let me focus the question, and attempt to make precise what I mean by "in a natural way." Take $h(1)=2$ and $h(n+1)=2^{h(n)}$. $h$ is now defined on $\mathbb{N}$, and $h(2)=4$, $h(3)=16$, $h(4)=2^{16}=65,536$ etc. Is it possible to extend the domain of definition of $h$ to all positive reals in such a way that</p>

<p>a) The functional equation $h(x+1)=2^{h(x)}$ continues to be satisfied for all $x$ in the domain.</p>

<p>b) $h$ is $C^\infty$. (Analytic would be even better but this seems maybe too much to hope for?)</p>

<p>c) All $h$'s derivatives are monotone.</p>

<p>These requirements are my attempt to codify what would count as "natural." I am open to suggestions about what would be a better list of requirements.</p>

<p>If such a function exists, I would like to know how to construct it; if it doesn't, I would like to know why (i.e. outline of proof), and if relaxing some of the requirements (e.g. just the first derivative monotone) would make it possible.</p>

<p>(If the function exists, I am also interested in the questions, "is it unique?" "Could we add some natural requirements to make it unique?" But my main query is about existence.)</p>

 
Answer: <p>What you're after is called <a href="http://en.wikipedia.org/wiki/Tetration" rel="noreferrer">tetration</a> (the example you computed is given <a href="http://en.wikipedia.org/wiki/Tetration#Iterated_powers" rel="noreferrer">here</a>), and it has an active community of people who are interested in it (though my sense is that it is not quite in the mainstream of mathematics research at the moment, for whatever reason). The Wikipedia page <a href="http://en.wikipedia.org/wiki/Tetration#Extension_to_real_heights" rel="noreferrer">indicates</a> that the problem of extending tetration to arbitrary real powers in a sufficiently <strong>regular</strong>/<strong>smooth</strong> way is still not satisfactorily solved, so I'm afraid I don't know the answer to your question about the existence of such a function $h(x)$.</p>

<p>Tetration is further generalized by <a href="http://en.wikipedia.org/wiki/Knuth%27s_up-arrow_notation" rel="noreferrer">Knuth's up-arrow notation</a>, and then generalized even more by <a href="http://en.wikipedia.org/wiki/Conway_chained_arrow_notation" rel="noreferrer">Conway's chained arrow notation</a>.</p>

==============================
===============================
Question: <p>Assume that $A$ is an $n\times n$ <a href="http://en.wikipedia.org/wiki/Skew-symmetric_matrix">skew-symmetric</a> real matrix, i.e.
$$A^T=-A.$$</p>

<p>Since $\det(A-\lambda I)=\det(A^T-\lambda I)$, $A$ and $A^T$ have the same eigenvalues. On the other hand, $A^T$ and $-A$ also have the same eigenvalues. Thus if $\lambda$ is an eigenvalue of $A$, so is $-\lambda$. If $n$ is odd, $\lambda = 0 $ is an eigenvalue.</p>

<p>A curious search in Google returns <a href="http://en.wikipedia.org/wiki/Skew-symmetric_matrix#Spectral_theory">that</a> the nonzero eigenvalues of $A$ are all pure imaginary and thus are of the form $iλ_1, −iλ_1, iλ_2, −iλ_2,$ … where each of the $λ_k$ are real. </p>

<p>Here is my <strong>question</strong>:</p>

<blockquote>
  <p>How can I prove the fact that "the nonzero eigenvalues of $A$ are all pure imaginary"?</p>
</blockquote>

 
Answer: <p>Consider $A$ as a matrix over $\mathbb{C}$. Then we have that for all $\mathbf{x},\mathbf{y}\in\mathbb{C}^n$,
$$\langle A\mathbf{x},\mathbf{y} \rangle = \langle \mathbf{x},A^*\mathbf{y}\rangle,$$
where $\langle-,-\rangle$ is the standard complex inner product, and $A^*$ is the adjoint (which relative to the standard complex inner product is given by the conjugate transpose of $A$). Since $A$ is a real matrix, the adjoint is equal to the transpose, so for every $\mathbf{x},\mathbf{y}\in\mathbb{C}^n$, you have
$$\langle A\mathbf{x},\mathbf{y}\rangle = \langle \mathbf{x},A^T\mathbf{y}\rangle = \langle \mathbf{x},-A\mathbf{y}\rangle = -\langle \mathbf{x},A\mathbf{y}\rangle.$$</p>

<p>Now suppose that $\mathbf{x}$ is an eigenvector with eigenvalue $\lambda$. Setting $\mathbf{y}=\mathbf{x}$, we have
$$\langle A\mathbf{x},\mathbf{x}\rangle = \langle \lambda\mathbf{x},\mathbf{x}\rangle = \lambda \lVert\mathbf{x}\rVert^2.$$
On the other hand,
$$-\langle \mathbf{x},A\mathbf{x}\rangle = -\langle\mathbf{x},\lambda\mathbf{x}\rangle = -\overline{\lambda}\langle\mathbf{x},\mathbf{x}\rangle = -\overline{\lambda}\lVert\mathbf{x}\rVert^2.$$
These two are equal, and since $\mathbf{x}$ is an eigenvector, then $\lVert\mathbf{x}\rVert\neq 0$. Therefore, we have that $\lambda=-\overline{\lambda}$, and hence $\lambda$ is either $0$ or a pure imaginary number. </p>

==============================
===============================
Question: <blockquote>
  <p>Consider a square of side equal to $1$. Prove that we can place inside the square a finite number of disjoint circles, with different radii of the form $1/k$ with $k$ a positive integer, such that the area of the remaining region is at most $0.0001$.</p>
</blockquote>

<p>If we consider all the circles of this form, their total area is $\sum_{k \geq 1}\displaystyle \pi \frac{1}{k^2} - \pi=\frac{\pi^3}{6}-\pi\simeq 2.02$ which is greater than the area of the square. (I subtracted $\pi$ because we cannot place a disk of radius $1$ inside the square).</p>

<p>So the circles of this form can cover the square very well, but how can I prove that there is a disjoint family which leaves out a small portion of the area?</p>

 
Answer: <p>I don't think this is possible for general $\epsilon$, and I doubt it's possible for remainder $0.0001$.</p>

<p>Below are some solutions with remainder less than $0.01$. I produced them by randomized search from two different initial configurations. In the first one, I only placed the circle with curvature $2$ in the centre and tried placing the remaining circles randomly, beginning with curvature $12$; in the second one, I prepositioned pairs of circles that fit in the corners and did a deterministic search for the rest.</p>

<p>The data structure I used was a list of interstices, each in turn consisting of a list of circles forming the interstice (where the lines forming the boundary of the square are treated as circles with zero curvature). I went through the circles in order of curvature and for each circle tried placing it snugly in each of the cusps where two circles touch in random order. If a circle didn't fit anywhere, I discarded it; if that decreased the remaining area below what was needed to get up to the target value (in this case $0.99$), I backtracked to the last decision.</p>

<p>I also did this without using the circle with curvature $2$. For that case I did a complete search and found no configurations with remainder less than $0.01$. Thus, if there is a better solution in that case, it must involve placing the circles in a different order. (We can always transform any solution to one where each circle is placed snugly in a cusp formed by two other circles, so testing only such positions is not a restriction; however, circles with lower curvature might sit in the cusps of circles with higher curvature, and I wouldn't have found such solutions.)</p>

<p>For the case including the circle with curvature $2$, the search wasn't complete (I don't think it can be done completely in this manner, without introducing further ideas), so I can't exclude that there's are significantly better configurations (even ones with in-order placement), but I'll try to describe how I came to doubt that there's much room for improvement beyond $0.01$, and particularly that this can be done for arbitrary $\epsilon$.</p>

<p>The reasons are both theoretical and numerical. Numerically, I found that this seems to be a typical combinatorial optimization problem: There are many local minima, and the best ones are quite close to each other. It's easy to get to $0.02$; it's relatively easy to get to $0.011$; it takes quite a bit more optimization to get to $0.01$; and beyond that practically all the solutions I found were within $0.0002$ or so of $0.01$. So a solution with $0.0001$ would have to be of a completely different kind from everything that I found.</p>

<p>Now of course <em>a priori</em> there might be some systematic solution that's hard to find by this sort of search but can be proved to exist. That might conceivably be the case for $0.0001$, but I'm pretty sure it's not the case for general $\epsilon$. To prove that it's possible to leave a remainder less than $\epsilon$ for any $\epsilon\gt0$, one might try to argue that after some initial phase it will always be possible to fit the remaining circles into the remaining space. The problem is that such an argument can't work, because we're trying to fill the rational area $1$ by discarding rational multiples of $\pi$ from the total area $\pi^3/6$, so we can't do it by discarding a finite number of circles, since $\pi$ is transcendental.</p>

<p>Thus we can never reach a stage where we could prove that the remaining circles will exactly fit, and hence every proof that proves we can beat an arbitrary $\epsilon$ would have to somehow show that the remaining circles can be divided into two infinite subsets, with one of them exactly fitting into the remaining gaps. Of course this, too, is possible in principle, but it seems rather unlikely; the problem strikes me as a typical messy combinatorial optimization problem with little regularity.</p>

<p>A related reason not to expect a clean solution is that in an <a href="http://en.wikipedia.org/wiki/Apollonian_gasket" rel="nofollow noreferrer">Apollonian gasket</a> with integer curvatures, some integers typically occur more than once. For instance, one might try to make use of the fact that the curvatures $0$, $2$, $18$ and $32$ form a quadruple that would allow us to fill an entire half-corner with a gasket of circles of integer curvature; however, in that gasket, many curvatures, for instance $98$, occur more than once, so we'd have to make exceptions for those since we're not allowed to reuse those circles. Also, if you look at the gaskets produced by $0$, $2$ and the numbers from $12$ to $23$ (which are the candidates to be placed in the corners), you'll find that the fourth number increases more rapidly than the third; that is, $0$, $2$ and $18$ lead to $32$, whereas $0$ $2$ and $19$ already lead to $(\sqrt2+\sqrt{19})^2\approx33.3$; so not only can you not place all the numbers from $12$ to $23$ into the corners (since only two of them fit together and there are only four corners), but then if you start over with $24$ (which is the next number in the gasket started by $12$), you can't even continue with the same progression, since the spacing has increased. The difference would have to be compensated by the remaining space in the corners that's not part of the gaskets with the big $2$-circle, but that's too small to pick up the slack, which makes it hard to avoid dropping several of the circles in the medium range around the thirties. </p>

<p>My impression from the optimization process is that we're forced to discard too much area quite early on; that is, we can't wait for some initial irregularities to settle down into some regular pattern that we can exploit. For instance, the first solution below uses all curvatures except for the following: 3 4 5 6 7 8 9 10 11 16 17 20 22 25 30 31 33 38 46 48 49 52 53 55 56 57 59 79 81 94 96 101 106 107 108 113 125 132. Already at 49 the remaining area becomes less than would be needed to fill the square. Other solutions I found differed in the details of which circles they managed to squeeze in where, but the total area always dropped below $1$ early on. Thus, it appears that it's the irregular constraints at the beginning that limit what can be achieved, and this can't be made up for by some nifty scheme extending to infinity. It might even be possible to prove by an exhaustive search that some initial set of circles can't be placed without discarding too much area. To be rigorous, this would have to take a lot more possibilities into account than my search did (since the circles could be placed in any order), but I don't see why allowing the bigger circles to be placed later on should make such a huge difference, since there's precious little wiggle room for their placement to begin with if we want to fit in most of the ones between $12$ and $23$.</p>

<p>So here are the solutions I found with remainder less than $0.01$. The configurations shown are both filled up to an area $\gtrsim0.99$ and have a tail of tiny circles left worth about another $0.0002$. For the first one, I checked with integer arithmetic that none of the circles overlap. (In fact I placed the circles with integer arithmetic, using floating-point arithmetic to find an approximation of the position and a single iteration of Newton's method in integer arithmetic to correct it.)</p>

<p>The first configuration has $10783$ circles and was found using repeated randomized search starting with only the circle of curvature $2$ placed; I think I ran something like $100$ separate trials to find this one, and something like $1$ in $50$ of them found a solution with remainder below $0.01$; each trial took a couple of seconds on a MacBook Pro.</p>

<p><img src="https://i.stack.imgur.com/K1MNc.png" alt="randomized"></p>

<p>The second configuration has $17182$ circles and was found by initially placing pairs of circles with curvatures $(12,23)$, $(13,21)$, $(14,19)$ and $(15,18)$ touching each other in the corners and tweaking their exact positions by hand; the tweaking brought a gain of something like $0.0005$, which brought the remainder down below $0.01$. The search for the remaining circles was carried out deterministically, in that I always tried first to place a circle into the cusps formed by the smaller circles and the boundary lines; this was to keep as much contiguous space as possible available in the cusps between the big circle and the boundary lines.</p>

<p><img src="https://i.stack.imgur.com/5zUI0.png" alt="pre-placed"></p>

<p>I also tried placing pairs of circles with curvatures $(13,21)$, $(14,19)$, $(15,18)$ and $(16,17)$ in the corners, but only got up to $0.9896$ with that.</p>

<p>Here are high-resolution version of the images; they're scaled down in this column, but you can open them in a new tab/window (where you might have to click on them to toggle the browser's autoscale feature) to get the full resolution.</p>

<p>Randomized search:</p>

<p><img src="https://i.stack.imgur.com/JWiwd.png" alt="randomized hi-res"></p>

<p>With pre-placed circles:</p>

<p><img src="https://i.stack.imgur.com/aFFfN.png" alt="enter image description here"></p>

==============================
===============================
Question: <p>The following is a well-known result in functional analysis:</p>

<blockquote>
  <p>If the vector space $X$ is finite dimensional, all norms are equivalent.  </p>
</blockquote>

<p>Here is the standard proof in one textbook. First, pick a norm for $X$, say 
$$\|x\|_1=\sum_{i=1}^n|\alpha_i|$$
where $x=\sum_{i=1}^n\alpha_ix_i$, and $(x_i)_{i=1}^n$ is a basis for $X$. Then show that every norm for $X$ is equivalent to $\|\cdot\|_1$, i.e., 
$$c\|x\|\leq\|x\|_1\leq C\|x\|.$$
For the first inequality, one can easily get $c$ by triangle inequality for the norm. For the second inequality, instead of constructing $C$, the <a href="http://en.wikipedia.org/wiki/Bolzano%E2%80%93Weierstrass_theorem" rel="noreferrer">Bolzano-Weierstrass theorem</a> is applied to construct a contradiction. </p>

<p>The strategies for proving these two inequalities are so different. Here is my <strong>question</strong>, </p>

<blockquote>
  <p>Can one prove this theorem without Bolzano-Weierstrass theorem?</p>
</blockquote>

<p><strong>UPDATE:</strong></p>

<blockquote>
  <p>Is the converse of the theorem true? In other words, if all norms for a vector space $X$ are equivalent, then can one conclude that $X$ is of finite dimension?</p>
</blockquote>

 
Answer: <p>To answer the question in the update:</p>

<p>If $(X,\|\cdot\|)$ is a normed space of infinite dimension, we can produce a non-continuous linear functional: Choose an algebraic basis $\{e_{i}\}_{i \in I}$ which we may assume to be normalized, i.e., $\|e_{i}\| = 1$ for all $i$. Every vector $x \in X$ has a unique representation $x = \sum_{i \in I} x_i \, e_i$ with only finitely many nonzero entries (by definition of a basis).</p>

<p>Now choose a countable subset $i_1,i_2, \ldots$ of $I$. Then $\phi(x) = \sum_{k=1}^{\infty} k \cdot x_{i_k}$ defines a linear functional on $x$. Note that $\phi$ is not continuous, as $\frac{1}{\sqrt{k}} e_{i_k} \to 0$ while $\phi(\frac{1}{\sqrt{k}}e_{i_k}) = \sqrt{k} \to \infty$.</p>

<p>There can't be a $C \gt 0$ such that the norm $\|x\|_{\phi} = \|x\| + |\phi(x)|$ satisfies $\|x\|_\phi \leq C \|x\|$ since otherwise $\|\frac{1}{\sqrt{k}}e_k\| \to 0$ would imply $|\phi(\frac{1}{\sqrt{k}}e_k)| \to 0$ contrary to the previous paragraph.</p>

<p>This shows that on an infinite-dimensional normed space there are always inequivalent norms. In other words, the converse you ask about is true.</p>

==============================
===============================
Question: <p>I was wondering the following. And I probably know the answer already: NO.</p>

<p>Is there another number with similar properties as $e$? So that the derivative of $\exp(x)$ is the same as the function itself.</p>

<p>I can guess that it's probably not, because otherwise $e$ wouldn't be that special, but is there a proof of it?</p>

 
Answer: <p>Of course $C e^x$ has the same property for any $C$ (including $C = 0$). But these are the only ones.</p>

<p><strong>Proposition:</strong> Let $f : \mathbb{R} \to \mathbb{R}$ be a differentiable function such that $f(0) = 1$ and $f&#39;(x) = f(x)$. Then it must be the case that $f = e^x$.</p>

<p><em>Proof.</em> Let $g(x) = f(x) e^{-x}$. Then </p>

<p>$$g&#39;(x) = -f(x) e^{-x} + f&#39;(x) e^{-x} = (f&#39;(x) - f(x)) e^{-x} = 0$$</p>

<p>by assumption, so $g$ is constant. But $g(0) = 1$, so $g(x) = 1$ identically. </p>

<p><strong>N.B.</strong> Note that it is also true that $e^{x+c}$ has the same property for any $c$. Thus there exists a function $g(c)$ such that $e^{x+c} = g(c) e^x = e^c g(x)$, and setting $c = 0$, then $x = 0$, we conclude that $g(c) = e^c$, hence $e^{x+c} = e^x e^c$. </p>

<p>This observation generalizes to any differential equation with translation symmetry. Apply it to the differential equation $f&#39;&#39;(x) + f(x) = 0$ and you get the angle addition formulas for sine and cosine. </p>

==============================
===============================
Question: <ol>
<li><p>How to prove that $\quad\displaystyle\frac{4^{n}}{\sqrt{4n}}&lt;\binom{2n}{n}&lt;\frac{4^{n}}{\sqrt{3n+1}}\quad$ for all $n$ > 1 ?</p></li>
<li><p>Does anyone know any better elementary estimates?</p></li>
</ol>

 
Answer: <p>Here are some crude bounds:</p>

<p>$${1\over 2\sqrt{n}}\leq {2n\choose n}{1\over 2^{2n}}\leq{3\over4\sqrt{n+1}},\quad n\geq1.$$</p>

<hr>

<p>We begin with the product representations
$${2n\choose n}{1\over 2^{2n}}={1\over 2n}\prod_{j=1}^{n-1}\left(1+{1\over 2j}\right)=\prod_{j=1}^n\left(1-{1\over2j}\right),\quad n\geq1.$$</p>

<p>From
$$ \prod_{j=1}^{n-1}\left(1+{1\over 2j}\right)^{\!\!2}=\prod_{j=1}^{n-1}\left(1+{1\over j}+{1\over 4j^2}\right)\geq \prod_{j=1}^{n-1}\left(1+{1\over j}\right)=n,$$
we see that
$$\left({2n\choose n}{1\over 2^{2n}} \right)^{2} = {1\over (2n)^2}\, \prod_{j=1}^{n-1}\left(1+{1\over 2j}\right)^{\!\!2}
\geq {1\over 4n^2}\, n ={1\over 4n},\quad n\geq1.$$
 so by taking square roots, ${2n\choose n}{1\over 2^{2n}}\geq \displaystyle{1\over 2\sqrt{n}}.$</p>

<p>On the other hand, $$ \prod_{j=1}^{n}\left(1+{1\over 2j}\right)  \left(1-{1\over 2j}\right)
= \prod_{j=1}^{n}\left(1-{1\over 4j^2}\right)\leq {3\over 4},$$
so that (using the lower bound above), we have
$$ {2n\choose n}{1\over 2^{2n}}=\prod_{j=1}^n\left(1-{1\over2j}\right)\leq{3\over4\sqrt{n+1}}.$$</p>

<p>Alternatively, multiplying the different representations we get
 $$n\left[{2n\choose n}{1\over 2^{2n}}\right]^2={1\over 2}\prod_{j=1}^{n-1}\left(1-{1\over4j^2}\right) \,\left(1-{1\over 2n}\right).$$
It's not hard to show that the right hand side increases from $1/4$ to $1/\pi$ for $n\geq 1$.</p>

<hr>

<p><strong>Edit:</strong> You can get better bounds if you know Wallis's formula:</p>

<p>$$2n\left[{2n\choose n}{1\over 4^n}\right]^2={1\over 2}{3\over 2}{3\over 4}{5\over 4}\cdots
{2n-1\over 2n-2}{2n-1\over 2n}={1\over 2}\prod_{j=2}^n\left(1+{1\over 4j(j-1)}\right)$$</p>

<p>$$(2n+1)\left[{2n\choose n}{1\over 4^n}\right]^2={1\over 2}{3\over 2}{3\over 4}{5\over 4}\cdots
{2n-1\over 2n-2}{2n-1\over 2n}{2n+1\over 2n}=\prod_{j=1}^n\left(1-{1\over 4j^2}\right)$$</p>

<p>By Wallis's formula, both middle expressions converge to ${2\over \pi}$.
The right hand side of the first equation is increasing, while the right hand
side of the second equation is decreasing. We conclude that </p>

<p>$${1\over\sqrt{\pi(n+1/2)}}\leq {2n\choose n}{1\over 4^n}\leq {1\over\sqrt{\pi n}}.$$</p>

==============================
===============================
Question: <p>Given an $n\times n$-matrix $A$ with integer entries, I would like to decide whether there is some $m\in\mathbb N$ such that $A^m$ is the identity matrix.</p>

<p>I can solve this by regarding $A$ as a complex matrix and computing its Jordan normal form; equivalently, I can compute the eigenvalues and check whether they are roots of $1$ and whether their geometric and algebraic multiplicities coincide.</p>

<p>Are there other ways to solve this problem, perhaps exploiting the fact that $A$ has integer entries? <strong>Edit:</strong> I am interested in conditions which are easy to verify for families of matrices in a proof.</p>

<p><strong>Edit:</strong> Thanks to everyone for this wealth of answers. It will take me some time to read all of them carefully.</p>

 
Answer: <p>The following conditions on an $n$ by $n$ integer matrix $A$ are equivalent: </p>

<p>(1) $A$ is invertible and of finite order. </p>

<p>(2) The minimal polynomial of $A$ is a product of distinct cyclotomic polynomials. </p>

<p>(3) The elementary divisors of $A$ are cyclotomic polynomials. </p>

==============================
===============================
Question: <p>I’m not saying that it ought to be. I was just wondering whether it has. What I have in mind is that it would have been of material help in proving, say, the Hahn-Banach Theorem, or some such. If it has, what is the most important/impressive instance of this?</p>

 
Answer: <p>Speaking as someone who is basically an algebraist, I think of algebra as using structure to help understand or simplify a mathematical situation.  The common algebraic objects (groups, rings, Lie algebras, etc.) reflect common structures that appear in many different contexts.</p>

<p>Now analysis often seems to have a certain slipperiness that makes it hard to pin down precise structures that meaningfully persist across different problems and contexts, and hence seems to have been somewhat resistant to methods of algebra in general.  (This is an outsider's impression, and shouldn't be taken too seriously.  But it does honestly reflect my impression ... .)</p>

<p>On the other hand, there do seem to be places where algebra can sneak in and play a role.  One is mentioned by Qiaochu: Wiener proved that if $f$ is a nonwhere zero periodic function with absolutely convergent Fourier series, then $1/f$ again has an absolutely convergent Fourier series.  Wiener's proof was <em>by hand</em> harmonic analysis, but a conceptually simpler proof (in a much more general setting) was supplied by Gelfand (I believe) using the theory of Banach algebras, which hinges on algebraic concepts such as maximal ideals and radicals.   Wiener proved his result as a step along the way to proving his general <a href="http://en.wikipedia.org/wiki/Wiener%27s_tauberian_theorem">Tauberian theorem</a>, and this result again admits a conceptually simpler proof, and generalization, via 
Banach algebra methods.</p>

<p>Another, more recent, example is the work of Green and Tao on asymptotics for the Hardy--Littlewood problem of solving linear equations in primes.  Here they introduced algebraic ideas related to nilpotent Lie groups, which play a key role in understanding and analyzing the complexity and solubility of such equations.  </p>

==============================
===============================
Question: <p>I got stuck with a problem that pop up in my mind while learning limits. I am still a high school student. </p>

<p>Define $P(m)$ to be the statement: $\quad \lim\limits_{n\to\infty}(\underbrace{\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}}_{m})=0$</p>

<p>The statement holds for $m = 1$: $\quad \lim\limits_{n\to\infty}\frac{1}{n}=0$.</p>

<p>Assume that $P(k)$ holds for some $k$. So put $m = k$: $\quad \lim\limits_{n\to\infty}(\underbrace{\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}}_{k})=0$.</p>

<p>We prove $P(k + 1)$: $\quad \lim\limits_{n\to\infty}(\underbrace{\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}}_{k+1}) =\lim\limits_{n\to\infty}(\underbrace{\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}}_{k}+\frac{1}{n})$</p>

<p>$=\lim\limits_{n\to\infty}(\underbrace{\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}}_{k}) +\lim\limits_{n\to\infty}\frac{1}{n}$</p>

<p>$=0+0=0$.</p>

<p>It has now been proved by mathematical induction that statement holds for all natural m.</p>

<p>If we let $m=n$, then $\lim\limits_{n\to\infty}(\underbrace{\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}}_{n})=0 \tag{*}$.</p>

<p>However, $\underbrace{\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}}_{n}=1 \implies \lim\limits_{n\to\infty}(\underbrace{\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}}_{n})=1 \tag{$\dagger$}$.</p>

<p>Then $(*) \, \&amp; \, (\dagger)$ yield $1=0$?</p>

<p>Can anybody explain this? thanks.</p>

 
Answer: <p>$n$ is a <a href="http://en.wikipedia.org/wiki/Free_variables_and_bound_variables">free variable</a> of the term $n$ that <a href="http://en.wikipedia.org/wiki/First-order_logic#Rules_of_inference">becomes bound during the substitution</a> $m=n$ into</p>

<p>$\lim\limits_{n\to\infty}(\underbrace{\frac{1}{n}+\frac{1}{n}+\cdots+\frac{1}{n}}_{m})=0$</p>

<p>so the substitution is not logically valid.</p>

==============================
===============================
Question: <p>In "The New Book of Prime Number Records", Ribenboim reviews the known results on the degree and number of variables of prime-representing polynomials (those are polynomials such that the set of positive values they obtain for nonnegative integral values of the variables coincides with the set of primes). For example, it is known that there is such a polynomial with 42 variables and degree 5, as well as one with 10 variables and astronomical degree.</p>

<p>Ribenboim mentions that it's an open problem to determine the least number of variables possible for such a polynomial, and remarks "it cannot be 2". It's a fairly simple exercise to show that it cannot be 1, but why can't it be 2?</p>

<p>EDIT: here's the relevant excerpt from Ribenboim's book. Given that nobody seems to be familiar with such a proof, I'm inclined to assume that this is a typo and he just meant "it cannot be 1". </p>

<p><img src="https://i.stack.imgur.com/R1Hcw.png" alt="Excerpt from &quot;The New Book of Prime Number Records&quot;"></p>

 
Answer: <p>I <a href="https://mathoverflow.net/questions/75637/is-there-a-two-variable-prime-representing-polynomial-in-the-sense-of-jones-sato">asked the same question at MathOverflow</a> (linking here) where I noted that, at least as of 1982, the problem was still open because even universal Diophantine equations were not known to be impossible with two variables.</p>

<p>On further searching I found a FOM posting (see link above) which shows that the universal Diophantine equation problem is still open, so it looks like Ribenboim's book is in error (probably a typo, as Alon suggests).</p>

==============================
===============================
Question: <p>I have a question:</p>

<blockquote>
  <p>Suppose $f$ is continuous and even on $[-a,a]$, $a&gt;0$ then prove that
  $$\int\limits_{-a}^a \frac{f(x)}{1+e^{x}} \mathrm dx = \int\limits_0^a f(x) \mathrm dx$$</p>
</blockquote>

<p>How can I do this? Don't know how to start.</p>

 
Answer: <p>You have</p>

<p>\begin{align*}
I &amp;=\int\limits_{-a}^{a}\frac{f(x)}{1+e^{x}} \ dx \qquad\qquad \cdots (1)\\\ I &amp;= \int\limits_{-a}^{a} \frac{f(x)}{1+e^{-x}} \ dx \qquad\qquad \Bigl[ \small\because \int\limits_{a}^{b}f(x) = \int\limits_{a}^{b}f(a+b-x) \ \Bigr] \quad \cdots (2) \\\ \Longrightarrow 2I &amp;= \int\limits_{-a}^{a} \biggl[ \frac{f(x)}{1+e^{x}} + \frac{e^{x}\cdot f(x)}{1+e^{x}} \biggr] \ dx  \quad\qquad \cdots (1) + (2)\\\  &amp;=\int\limits_{-a}^{a} f(x) \ dx = 2 \int\limits_{0}^{a} f(x) \ dx \qquad \Bigl[ \small  \text{since}\ f \  \text{is even so} \ \int\limits_{-a}^{a} f(x) = 2\int\limits_{0}^{a} f(x) \Bigr]
\end{align*}</p>

<hr>

<p>$\textbf{Note.}$ A similar problem, which uses result $(2)$ can be found here:</p>

<ul>
<li><a href="https://math.stackexchange.com/questions/57557/integration-of-a-trigonometric-function/57561#57561">Integration of a trigonometric function</a></li>
</ul>

==============================
===============================
Question: <p>I'm a first year Undergraduate student from India. Our professor is going to start a Real Analysis course in September and I was preparing for the initials. I tried and solved many problems, but this one has me confused. Probably the main reason for the confusion is that my book has cited it as Hardy's problem.</p>

<blockquote>
  <p>If $\dfrac {m}{n}$ is a good approximation to $\sqrt{2}$, prove that $\dfrac{m+2n}{m+n}$ is a better one, and that the errors in the two cases are in opposite direction. Apply this result to show that the limit of the sequence $\dfrac{1}{1}$, $\dfrac{3}{2}$,$\dfrac{7}{5}$,$\dfrac{17}{12}$,$\dfrac{41}{29}$,.... is $ \sqrt{2}$.</p>
</blockquote>

<p>I need help regarding the first part of the problem, since the second part is obvious. The simpler the language, the better it is for me.</p>

 
Answer: <p>Suppose $\frac{m}{n} $ is slightly bigger than $\sqrt{2}$, so that we can write $\frac{m}{n}= \sqrt{2}(1+\epsilon)$ where $\epsilon &gt;0$ is small. </p>

<p>Then $$\frac{m+2n}{m+n} = \frac{ \frac{m}{n} +2}{\frac{m}{n} +1} = \frac{ \sqrt{2}(1+\epsilon)+2}{\sqrt{2}(1+\epsilon)  + 1} = \sqrt{2} \left(1- \left(\frac{\sqrt{2}-1}{\sqrt{2}+1+\sqrt{2}\epsilon}\right)\epsilon \right)$$</p>

<p>Note that $\sqrt{2}+1+\sqrt{2}\epsilon&gt; \sqrt{2}+1 $. Also, since $1&lt;\sqrt{2}&lt; \frac{3}{2}$,  we have $\frac{\sqrt{2}-1}{\sqrt{2}+1} &lt; \frac{1}{4}$ so ,$$\frac{\sqrt{2}-1}{\sqrt{2}+1+\sqrt{2}\epsilon}&lt;\frac{1}{4}.$$</p>

<p>Thus, $\frac{m+2n}{m+n}$ is slightly smaller than $\sqrt{2}$ and it's difference from $\sqrt{2}$ is smaller in magnitude than the previous estimate, and decreases by at least a factor of $4$ with each iteration. </p>

<p>In a similar manner you can show the other case.</p>

<p>EDIT: I strengthened the estimates to address the rate of convergence issues Andres Caicedo brought up in a comment above. </p>

==============================
===============================
Question: <p>Can any one give a generalization of the following properties in a single proof? I have checked the results, which I have given below by trial and error method. I am looking for a general proof, which will cover the all my results below:</p>

<ol>
<li>Every third Fibonacci number is even.</li>
<li>3 divides every 4th Fibonacci number.</li>
<li>5 divides every 5th Fibonacci number.</li>
<li>4 divides every 6th Fibonacci number.</li>
<li>13 divides every 7th Fibonacci number.</li>
<li>7 divides every 8th Fibonacci number.</li>
<li>17 divides every 9th Fibonacci number.</li>
<li>11 divides every 10th Fibonacci number.</li>
<li>6, 9, 12 and 16 divides every 12th Fibonacci number.</li>
<li>29 divides every 14th Fibonacci number.</li>
<li>10 and 61 divides every 15th Fibonacci number.</li>
<li>15 divides every 20th Fibonacci number.</li>
</ol>

 
Answer: <p>Most of the divisibility properties of Fibonacci numbers follow from the fact that they comprise a <a href="http://en.wikipedia.org/wiki/Divisibility_sequence" rel="nofollow noreferrer">divisibility sequence,</a> i.e. $\rm\,m\,|\,n\ \Rightarrow\ F_m\,|\,F_n.\,$  <em>All</em> of your statements above are special cases of this, e.g. $\rm\,F_{15} = 610,\,$ so $\rm\,15\,|\,n\ \Rightarrow\ F_{15}\,|\,F_n\,\Rightarrow\,610\,|\,F_n,\,$ which is precisely your statement $11,\,$ that $10$ and $61$ divide every $15\,$'th Fibonacci number.</p>

<p>In fact $\rm\,F_n\,$ is <a href="http://en.wikipedia.org/wiki/Divisibility_sequence" rel="nofollow noreferrer"><em>strong</em> divisibility sequence,</a> i.e. $\rm\,(F_m,F_n) = F_{(m,n)},\,$ i.e. $\rm\,gcd(F_m,F_n) = F_{\gcd(m,n)}.\,$ This <em>stronger</em> property specializes to the above property if $\rm\,m\mid n\,\ (\!\!\iff \gcd(m,n) = m\,\!).\,$ The proof is not  difficult. Here is a straightforward way to proceed. Recall the <a href="https://math.stackexchange.com/questions/11477/11482#11482">Fibonacci addition law</a> $\rm\,F_{n+m} =F_{n+1}\,F_m + F_n\,F_{m-1}.\,$ Applying the shift $\rm\,n\to n-m\ $ this addition law becomes $\rm\,F_n  = F_{n-m+1}\,F_m  + F_{n-m}\,F_{m-1}\!\equiv F_{n-m}\,F_{m-1}\pmod{F_m}.\,$ So for $\rm\,k=m-1\,$ we may invoke the Theorem below to conclude that $\rm\,f_n  = F_n\,$ is a strong divisibility sequence. </p>

<p><strong>Theorem</strong> $\ $  Let $\rm\ f_n\, $ be an integer sequence such that $\rm\ f_{\,0} =\, 0,\ f_1 = 1\ $ and such that for all $\rm\,n &gt; m\,$ holds  $\rm\ \, \color{#c00}{f_n\equiv\, f_{\,k}\ f_{n-m}}\,\ (mod\ f_m)\ $ for some $\rm\,k &lt; n,\ (k,m)\, =\, 1.\, $  Then $\rm\ (f_n,f_m)\, =\ f_{\,(n,\,m)} $</p>

<p><strong>Proof</strong> $\ $ By induction on  $\rm\,n + m\,$. The theorem is trivially true if $\rm\ n = m\ $ or $\rm\ n = 0\ $ or $\rm\, m = 0.\,$ Assume wlog $\rm\,n &gt; m &gt; 0.\,$  Since $\rm\,k\!+\!m &lt; n\!+\!m,\,$ by induction $\rm\,(f_{\,k},f_m)=f_{\,(k,\,m)}\!=\,f_1 = 1.\,$  Thus $\rm\ (\color{#c00}{f_n},\,f_m)\, =\, (\color{#c00}{f_{\,k}\,f_{n-m}},\,f_m)\, =\, (f_{n-m},\,f_m)\, =\, f_{\,(n-m,\,m)} =\, f_{\,(n,\,m)} $ follows by induction  (which applies here since $\rm\,(n-m)+m\,  &lt;\, n+m\,\!),\,$ and by employing  well-known gcd laws, namely <a href="https://math.stackexchange.com/questions/59147/need-help-understanding-euclids-algorithm-to-find-greatest-common-divisor/59200#">$\rm\,(a,b) = (a',\,b)\ \ if\ \ a\equiv a'\pmod{b}\ $</a> and <a href="https://math.stackexchange.com/questions/20889/prove-that-if-gcd-a-b-1-then-gcd-ac-b-gcd-c-b/20904#20904">$\rm\,(c\,a,b) = (a,b)\,$ if $\rm\,(c,b) = 1.\quad$</a> <strong>QED</strong></p>

<p>You may find it insightful to simultaneously examine other strong divisibility sequences, e.g. see my <a href="https://math.stackexchange.com/questions/24529/factoring-a10a51/28762#28762">post here</a> on $\rm\,f_n = (x^n-1)/(x-1).\,$ In this case $\rm\, \gcd(f_m,f_n)\, =\, f_{\,\gcd(m,n)}\,$ may be interpreted as a $\rm\,q$-analog of the integer Bezout identity, for example
$$\rm\displaystyle\ 3\ =\ (15,21)\ \ \leadsto\ \ \frac{x^3-1}{x-1}\ =\ (x^{15} + x^9 + 1)\ \frac{x^{15}-1}{x-1}\ -\ (x^9+x^3)\ \frac{x^{21}-1}{x-1}$$</p>

==============================
===============================
Question: <p>I came across the following problem, known as <a href="http://mathworld.wolfram.com/KnuthsSeries.html">Knuth's Series</a> which originally was an American Mathematical Monthly problem.</p>

<blockquote>
  <p>Prove that $$\sum_{n=1}^\infty \left(\frac{n^n}{n!e^n}-\frac{1}{\sqrt{2\pi n}}\right)=-\frac{2}{3}-\frac{\zeta\left(\frac{1}{2}\right)}{\sqrt{2\pi}}.$$</p>
</blockquote>

<p>It seems interesting. We are trying to compute a particular sum of the error term in Stirlings approximation.  The immediate simple approaches don't seem to work.  </p>

<p><strong>Attempt: Why $\zeta\left(\frac{1}{2}\right)$:</strong>  By partial summation we know that $$\sum_{n=1}^M \frac{1}{n^s}= \frac{M^{1-s}}{1-s}+\zeta(s)+O\left(M^{-s}\right)$$ for $s&gt;0$, $s\neq 1$.  This tells us where the $\frac{\zeta\left(\frac{1}{2}\right)}{\sqrt{2\pi}}$ comes from since</p>

<p>$$\sum_{n=1}^M \frac{1}{\sqrt{2\pi n}}=\sqrt{\frac{2M}{\pi}}+\frac{\zeta\left(\frac{1}{2}\right)}{\sqrt{2\pi}}+o(1).$$</p>

<p>Now all that remains is to prove that $$\sum_{n=1}^M  \frac{n^n}{n!e^n}=\sqrt{\frac{2M}{\pi}} -\frac{2}{3}+o(1).$$</p>

<p>I am kinda stuck here, as this series seems strange to deal with. 
Thanks!</p>

 
Answer: <p>Here is a series of hints to summarise the approach that appeared in the American Math Monthly. I have divided them by horizontal bars so hopefully it can ensure you only read one at a time. Unfortunately, this particular solution does not appear to be very general.</p>

<hr>

<p>Prove the following separately first: 
$$ \sum_{k=1}^{\infty} \biggl( \frac{k^k}{k!e^k} - \frac{ (1/2)_{k-1} }{\sqrt{2} (k-1)!} \biggr) = \frac{-2}{3} $$ $$ \sum_{k=1}^{\infty} \biggl( \frac{1}{\sqrt{2\pi k}} - \frac{ (1/2)_{k-1} }{\sqrt{2} (k-1)!} \biggr) = \frac{ \zeta (1/2) }{\sqrt{2\pi}} $$ where the rising factorial is defined: $ (a)_0 = 1 \mbox{  and  } (a)_m = a(a+1)(a+2) \cdots (a+m-1) $</p>

<hr>

<p>Abel's theorem comes in handy: If $\sum_{k=0}^{\infty} a_k $ converges, then $$\sum_{k=0}^{\infty} a_k = \lim_{x\to 1^{-} } \sum_{k=0}^{\infty} a_k x^k $$</p>

<hr>

<p>Some power series (both for $ |z| &lt; 1 $) : $$ \mathrm{W}(z) = \sum_{k=1}^{\infty} \frac{k^{k-1} z^k}{k!e^k} $$ $$ \sum_{k=1}^{\infty} \frac{ (1/2)_{k-1} }{(k-1)!} z^{k-1} = \frac{1}{\sqrt{1-z}} $$ where $\mathrm{W}(z) $ satisfies $ \mathrm{W} \exp(-\mathrm{W}) = z/e $ (See <a href="http://en.wikipedia.org/wiki/Lambert_W_function">Lambert W Function</a>), and the second series comes from Newton's Binomial Expansion.</p>

==============================
===============================
Question: <p>In my answer to the recent question <a href="https://math.stackexchange.com/questions/61012/nested-square-roots">Nested Square Roots</a>, @GEdgar correctly raised the issue that the proof is incomplete unless I show that the intermediate expressions do converge to a (finite) limit. One such quantity was the nested radical 
$$
\sqrt{1 + \sqrt{1+\sqrt{1 + \sqrt{1 + \cdots}}}} \tag{1}
$$</p>

<p>To assign a value $Y$ to such an expression, I proposed the following definition. Define the sequence $\{ y_n \}$ by: 
$$
y_1 = \sqrt{1}, y_{n+1} = \sqrt{1+y_n}.
$$
Then we say that this expression evaluates to $Y$ if the sequence $y_n$ converges to $Y$. </p>

<p>For the expression (1), I could show that the $y_n$ converges to $\phi = (\sqrt{5}+1)/2$. (To give more details, I showed, by induction, that $y_n$ increases monotonically and is bounded by $\phi$, so that it has a limit $Y &lt; \infty$. Furthermore, this limit must satisfy $Y = \sqrt{1+Y}$.) Hence we could safely say (1) evaluates to $\phi$, and all seems to be good.</p>

<p><strong>My trouble.</strong> Let us now test my proposed idea with a more general expression of the form
$$\sqrt{a_1 + \sqrt{a_2 + \sqrt{a_3 + \sqrt{a_4+\cdots}}}} \tag{2}$$
 (Note that the linked question involves one such expression, with $a_n = 5^{2^n}$.) How do we decide if this expression converges? Mimicking the above definition, we can write:
$$
y_1 = \sqrt{a_1}, y_{n+1} = \sqrt{a_{n+1}+y_n}.
$$
However, unrolling this definition, one get the sequence
$$
\sqrt{a_1}, \sqrt{a_{2}+ \sqrt{a_1}}, \sqrt{a_3 + \sqrt{a_2 + \sqrt{a_1}}}, \sqrt{a_4+\sqrt{a_3 + \sqrt{a_2 + \sqrt{a_1}}}}, \ldots
$$
but this seems little to do with the expression (2) that we started with. </p>

<p>I could not come up with any satisfactory ways to resolve the issue. So, my question is:</p>

<blockquote>
  <p>How do I rigorously define when an expression of the form (2) converges, and also assign a value to it when it does converge?</p>
</blockquote>

<p>Thanks.</p>

 
Answer: <p>I would understand it by analogy with continued fractions and look for a limit of $\sqrt{a_1}$, $\sqrt{a_1+\sqrt{a_2}}$, $\sqrt{a_1+\sqrt{a_2+\sqrt{a_3}}}$, ..., $\sqrt{a_1+\sqrt{a_2 \cdots + \sqrt{a_n}}}$, ...</p>

<p>Each of these is not simply derivable from the previous one, but neither are continued fraction approximants.</p>

==============================
===============================
Question: <p>I was just thinking about this recently, and I thought of a possible bijection between the natural numbers and the real numbers.  First, take the numbers between zero and one, exclusive.  The following sequence of real numbers is suggested so that we have bijection.  </p>

<p>0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.01, 0.02, ... , 0.09, 0.10, 0.11, ... , 0.99, 0.001, 0.002, ... , 0.999, 0.0001, etc.</p>

<p>Obviously, this includes repeats, but this set is countable.  Therefore, the set of all numbers between zero and one is a subset of the above countable set, and is thus countable.  Then we simply extend this to all real numbers and all the whole numbers themselves, and since the real numbers, as demonstrated above, between any two whole numbers is countable, the real numbers are the union of countably many countable sets, and thus the real numbers are countable.  </p>

<p>Please help me with this.  I understand the diagonalization argument by Cantor, but I am curious specifically about this proof which I thought of and its strengths and flaws.</p>

<p>Thanks.</p>

 
Answer: <p>Your function ignores all the real numbers whose decimal representations are not finite, such as </p>

<p>$\dfrac13=0.3333\ldots$</p>

<p>The subset of real numbers that do have finite decimal representations is indeed countable (also because they are all rational and $\mathbb Q$ is countable).</p>

==============================
===============================
Question: <p>I recently proved that</p>

<p>$$\sum_{k=1}^n k^3 = \left(\sum_{k=1}^n k \right)^2$$</p>

<p>using mathematical induction.  I'm interested if there's an intuitive explanation, or even a combinatorial interpretation of this property. I would also like to see any other proofs.</p>

 
Answer: <p>Stare at the following image, taken from this <a href="https://mathoverflow.net/questions/8846/proofs-without-words/24828#24828">MO answer</a>, long enough:</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Nicomachus_theorem_3D.svg/1024px-Nicomachus_theorem_3D.svg.png" alt="Proof that the sum of the cubes is the square of the sum"></p>

==============================
===============================
Question: <p>How can I prove the Theorem of Frullani? I did not even know all the hypothesis that $f$ must satisfy, but I think that this are</p>

<p>Let $\,f:\left[ {0,\infty } \right) \to \mathbb R$ be a a continuously differentiable function such that $$
\mathop {\lim }\limits_{x \to \infty } f\left( x \right) = 0,
$$
and let $
a,b \in \left( {0,\infty } \right)$.
Prove that $$
\int\limits_0^{\infty}  {\frac{{f\left( {ax} \right) - f\left( {bx} \right)}}
{x}}dx  = f\left( 0 \right)\left[ {\ln \frac{b}
{a}} \right]
$$
 If you know a more general version please give it to me )= I can´t prove it.</p>

 
Answer: <p>We will assume $a&lt;b$.
Let $x,y&gt;0$. We have:
\begin{align*}
\int_x^y\dfrac{f(at)-f(bt)}{t}dt&amp;=\int_x^y\dfrac{f(at)}{t}dt-
\int_x^y\dfrac{f(bt)}{t}dt\\
&amp;=\int_{ax}^{ay}\dfrac{f(u)}{\frac ua}\frac{du}a-
\int_{bx}^{by}\dfrac{f(u)}{\frac ub}\frac{du}b\\
&amp;=\int_{ax}^{ay}\dfrac{f(u)}udu-\int_{bx}^{by}\dfrac{f(u)}udu\\
&amp;=\int_{ax}^{bx}\dfrac{f(u)}udu+\int_{bx}^{ay}\dfrac{f(u)}udu
-\int_{bx}^{ay}\dfrac{f(u)}udu-\int_{ay}^{by}\dfrac{f(u)}udu\\
&amp;=\int_{ax}^{bx}\dfrac{f(u)}udu-\int_{ay}^{by}\dfrac{f(u)}udu.
\end{align*}
Since $\displaystyle\int_0^{+\infty}\dfrac{f(at)-f(bt)}tdt=\lim_{y\to +\infty}\lim_{x\to 0}
\int_x^y\dfrac{f(at)-f(bt)}{t}dt$ if these limits exist, we only have to show that the 
limits $\displaystyle\lim_{x\to 0}\int_{ax}^{bx}\dfrac{f(u)}udu$ and $\displaystyle\lim_{y\to +\infty}\int_{ay}^{by}\dfrac{f(u)}udu$ exists, by computing them. </p>

<p>For the first, we denote $\displaystyle m(x):=\min_{t\in\left[ax,bx\right]}f(t)$ and 
$\displaystyle M(x):=\max_{t\in\left[ax,bx\right]}f(t)$. We have for $x&gt;0$:
$$m(x)\ln\left(\dfrac ba\right)\leq \int_{ax}^{bx}\dfrac{f(u)}udu\leq 
M(x)\ln\left(\dfrac ba\right) $$ and we get $\displaystyle\lim_{x\to 0}\,m(x)=\lim_{x\to 0}\, M(x)=f(0)$ thanks to the continuity of $f$. </p>

<p>For the second, fix $\varepsilon&gt;0$. We can find $x_0$ such that if $u\geq x_0$ then
$|f(u)|\leq \varepsilon$.
For $y\geq \frac{x_0}a$, we get $\displaystyle\left|\int_{ay}^{by}\frac{f(u)}udu\right|
\leq \varepsilon\ln\left(\dfrac ba\right) $. 
We notice that we didn't need the differentiability of $f$.</p>

<p><strong>Added later, thanks to Didier's remark:</strong> if $f$ has a limit $l$ at $+\infty$, then $g\colon
x\mapsto f(x)-l$ is still continuous and has a limit $0$  at $+\infty$. Then 
$$\int_0^{+\infty}\dfrac{f(at)-f(tb)}tdt =
\int_0^{+\infty}\dfrac{g(at)-g(tb)}tdt =g(0)\ln\left(\dfrac ba\right) =
\left(f(0)-l\right)\ln\left(\dfrac ba\right).$$</p>

==============================
===============================
Question: <p>I am horribly confused about Jordan's Curve Theorem (henceforth JCT). Could you give me some reason why should the validity of this theorem be in doubt? I mean for anyone who trusts the eye theorem is obvious. Therefore answers like "do not trust the eye" is not going to help me.</p>

<p>I am looking for answers along the following lines. If the JCT were true for the "obvious" reason, then it might lead to some contradiction someplace else. To be more concrete, I can give an analogy with another theorem for which I had similar feelings -- namely the unique factorization theorem for natural numbers which subsided when I learnt about Kummer Primes.</p>

<p>In case you think that I am being too demanding when I ask this question, here is another direction you could help me with. In that case, I would just like one or two quick sentences about your personal experience with Jordan's curve theorem -- kind of like when you had your aha moment with this theorem. Something like, "I see, now I know (or can guess) why proving it was such a big deal". Please reply when you get time -- I am horribly confused.</p>

<p>Thanks for your patience,</p>

 
Answer: <p>There is exactly one way in which one can convince oneself that a statement is not obvious: try to prove it and look at your attempts <em>very, very critically</em>.</p>

<p>If you think you can come up with a proof of the curve theorem, edit it into the answer and we can help you dissect it :)</p>

<p><strong>Later.</strong> Asaf observes that it may be the case that you are refering to "intuitively obviousness". Well... I tend to think that when someone says something is intuitively obvious without having a specific proof in mind, he is just waving hands in words. But there are two observations one can make which are independent of that. </p>

<p>First, the full Jordan curve theorem deals with <em>arbitrary</em> closed curves, and here ẗhe word "arbitrary" includes things that one usually does not think about, curves so complicated that one cannot make accurate pictures of them, so it is rather unlikely one has any intuition about them at all (at least, when encountering the theorem for the first time) This is a situation that comes all the time: one thinks a statement is intuitively true only because one is not familiar with the cases where it is not clearly true at all. One's intuition is built upon our experience, and since our experience is, by definition, limited, our intuition is limited, too.</p>

<p>In any case, I would suggest you try to prove the version of the Jordan curve theorem which deals with piecewise linear curves, that is, with polygonal closed curves (with finitely many segments). In this more restricted situation, we have eliminated all the wildness continuous arcs can have and are left with a geometrically sensible situation. But! It is nonetheless quite not obvious how to prove the theorem in this simple situation either, as you will find out when you try. (This version can be proved without the machinery used to prove the general theorem, though)</p>

==============================
===============================
Question: <p>How can I prove that</p>

<blockquote>
  <p>$$1^3+ 2^3 + \cdots + n^3 = \left(\frac{n(n+1)}{2}\right)^2$$ </p>
</blockquote>

<p>for all $n \in \mathbb{N}$? I am looking for a proof using mathematical induction.</p>

<p>Thanks</p>

 
Answer: <p>You are trying to prove something of the form, $$A=B.$$ Well, both $A$ and $B$ depend on $n$, so I should write, $$A(n)=B(n).$$ First step is to verify that $$A(1)=B(1).$$ Can you do that? OK, then you want to deduce $$A(n+1)=B(n+1)$$ from $A(n)=B(n)$, so write out $A(n+1)=B(n+1)$. Now you're trying to get there from $A(n)=B(n)$, so what do you have to do to $A(n)$ to turn it into $A(n+1)$, that is (in this case) what do you have to add to $A(n)$ to get $A(n+1)$? OK, well, you can add anything you like to one side of an equation, so long as you add the same thing to the other side of the equation. So now on the right side of the equation, you have $B(n)+{\rm something}$, and what you want to have on the right side is $B(n+1)$. Can you show that $B(n)+{\rm something}$ is $B(n+1)$?</p>

==============================
===============================
Question: <p>Most questions usually just relate to what these can be used for, that's fairly obvious to me since I've been programming 3D games/simulations for a while, but I've never really understood the inner workings of them... I could get the cross product equation as a determinant of a carefully-constructed matrix, </p>

<p>but what I want to ask is... How did the dot and cross product come to be? When were they "invented"? Some detailed proofs? Did someone say: "Hey, wouldn't it be nice if we could construct a way to calculate a vector that is perpendicular to two given operands?"</p>

<p>Basically, how/why do they work?</p>

<p>I would appreciate explanations, links to other explanations, other web resources... I've been searching the Internet lately for explanations, but most of them are on how to use it and nothing that really gives substance to it.</p>

 
Answer: <p>A little bit more of the 'how and why': the dot product comes about as a natural answer to the question: 'what functions do we have that take two vectors and produce a number?'  Keep in mind that we have a natural additive function (vector or componentwise addition) that takes two vectors and produces another vector, and another natural multiplicative function (scalar multiplication) that takes a vector and a number and produces a vector.  (We might also want another function that takes two vectors and produces another vector, something more multiplicative than additive &mdash; but hold that thought!)  For now we'll call this function $D$, and specifically use the notation $D({\bf v},{\bf w})$ for it as a function of the two vectors ${\bf v}$ and ${\bf w}$.</p>

<p>So what kind of properties would we want this hypothetical function to have?  Well, it seems natural to start by not distinguishing the two things it's operating on; let's make $D$ symmetric, with $D({\bf v},{\bf w})=D({\bf w},{\bf v})$.  Since we have convenient addition and multiplication functions it would be nice if it 'played nice' with them. Specifically, we'd love it to respect our addition for each variable, so that $D({\bf v}_1+{\bf v}_2,{\bf w}) = D({\bf v}_1,{\bf w})+D({\bf v}_2,{\bf w})$ and $D({\bf v},{\bf w}_1+{\bf w}_2) = D({\bf v},{\bf w}_1)+D({\bf v},{\bf w}_2)$; and we'd like it to commute with scalar multiplication similarly, so that $D(a{\bf v}, {\bf w}) = aD({\bf v}, {\bf w})$ and $D({\bf v}, a{\bf w}) = aD({\bf v}, {\bf w})$ &mdash; these two conditions together are called <em>linearity</em> (more accurately, 'bilinearity': it's linear in each of its arguments).  What's more, we may have some 'natural' basis for our vectors (for instance, 'North/East/up', at least locally), but we'd rather it weren't tied to any particular basis; $D({\bf v},{\bf w})$ shouldn't depend on what basis ${\bf v}$ and ${\bf w}$ are expressed in (it should be <em>rotationally invariant</em>).  Furthermore, since any multiple of our function $D$ will satisfy the same equations as $D$ itself, we may as well choose a normalization of $D$. Since $D(a{\bf v},a{\bf v}) = aD({\bf v},a{\bf v}) = a^2D({\bf v},{\bf v})$ it seems that $D$ should have dimensions of (length$^2$), so let's go ahead and set $D({\bf v},{\bf v})$ equal to the squared length of ${\bf v}$, $|{\bf v}|^2$ (or equivalently, set $D({\bf v},{\bf v})$ to $1$ for any unit vector ${\bf v}$; since we chose $D$ to be basis-invariant, any unit vector is as good as any other).</p>

<p>But these properties are enough to define the dot product!  Since $$\begin{align}
|{\bf v}+{\bf w}|^2 &amp;= D({\bf v}+{\bf w},{\bf v}+{\bf w}) \\
&amp;= D({\bf v}+{\bf w},{\bf v})+D({\bf v}+{\bf w},{\bf w}) \\
&amp;= D({\bf v},{\bf v})+D({\bf w},{\bf v})+D({\bf v},{\bf w})+D({\bf w},{\bf w})\\
&amp;= D({\bf v},{\bf v})+2D({\bf v},{\bf w})+D({\bf w},{\bf w}) \\
&amp;= |{\bf v}|^2+|{\bf w}|^2+2D({\bf v},{\bf w})
\end{align}$$
then we can simply set $D({\bf v},{\bf w}) = {1\over2} \bigl(|{\bf v}+{\bf w}|^2-|{\bf v}|^2-|{\bf w}|^2\bigr)$.  A little arithmetic should convince you that this gives the usual formula for the dot product.</p>

<p>While the specific properties for the cross product aren't precisely the same, the core concept is: it's the only function that satisfies a fairly natural set of conditions.  But there's one broad catch with the cross-product &mdash; two, actually, though they're related.  One is that the fact that the cross product takes two vectors and produces a third is an artifact of $3$-dimensional space; in general the operation that the cross-product represents (orthogonality) can be formalized in $n$ dimensions either as a function from $(n-1)$ vectors to a single result or as a function from $2$ vectors that produces a <em>2-form</em>, essentially a $n(n-1)/2$-dimensional object; coincidentally when $n=3$ this means that the cross-product has the 'vector$\times$vector$\rightarrow$vector' nature that we were looking for.  (Note that in $2$ dimensions the natural 'orthogonality' operation is essentially a function from one vector to one vector &mdash; it takes the vector $(x,y)$ to the vector $(y,-x)$!)  The other catch is lurking in the description of the cross product as a 2-form; it turns out that this isn't <em>quite</em> the same thing as a vector!  Instead it's essentially a <em>covector</em> - that is, a linear function from vectors to numbers (note that if you 'curry' the dot-product function $D$ above and consider the function $D_{\bf w}$ such that $D_{\bf w}({\bf v}) = D({\bf v},{\bf w})$, then the resulting object $D_{\bf w}$ is a covector).  For most purposes we can treat covectors as just vectors, but not uniformly; the most important consequence of this is one that computer graphics developers have long been familiar with: normals don't transform the same way vectors do! In other words, if we have ${\bf u} = {\bf v}\times{\bf w}$, then for a transform $Q$ it's not (necessarily) the case that the cross product of transformed vectors $(Q{\bf v})\times(Q{\bf w})$ is the transformed result $Q{\bf u}$; instead it's the result ${\bf u}$ transformed by the so-called <em>adjoint</em> of $Q$ (roughly, the inverse of $Q$, with a few caveats).  For more background on the details of this, I'd suggest looking into exterior algebra, geometric algebra, and in general the theory of linear forms.</p>

<p><strong>ADDED:</strong> Having spent some more time thinking about this over lunch, I think the most natural approach to understanding where the cross product 'comes from' is through the so-called <em>volume form</em>: a function $V({\bf u}, {\bf v}, {\bf w})$ from three vectors to a number that returns the (signed) volume of the rhomboid spanned by ${\bf u}$, ${\bf v}$, and ${\bf w}$.  (This is also the determinant of the matrix with ${\bf u}$, ${\bf v}$, and ${\bf w}$ as its columns, but that's a whole different story...)  Specifically, there are two key facts:</p>

<ol>
<li>Given a basis and given some linear function $f({\bf v})$ from vectors to numbers (remember that linear means that $f({\bf v}+{\bf w}) = f({\bf v})+f({\bf w})$ and $f(a{\bf v}) = af({\bf v})$, we can write down a vector ${\bf u}$ such that $f()$ is the same as the covector $D_{\bf u}$ (that is, we have $f({\bf v}) = D({\bf u}, {\bf v})$ for all ${\bf v}$).  To see this, let the basis be $(\vec{e}_{\bf x}, \vec{e}_{\bf y}, \vec{e}_{\bf z})$; now let $u_{\bf x} = f(\vec{e}_{\bf x})$, and similarly for $u_{\bf y}$ and $u_{\bf z}$, and define ${\bf u} = (u_{\bf x},u_{\bf y},u_{\bf z})$ (in the basis we were provided).  Obviously $f()$ and $D_{\bf u}$ agree on the three basis vectors, and so by linearity (remember, we explicitly said that $f$ was linear, and $D_{\bf u}$ is linear because the dot product is) they agree everywhere.</li>
<li>The volume form $V({\bf u}, {\bf v}, {\bf w})$ is linear in all its arguments - that is, $V({\bf s}+{\bf t}, {\bf v}, {\bf w}) = V({\bf s}, {\bf v}, {\bf w})+V({\bf t}, {\bf v}, {\bf w})$.  It's obvious that the form is 'basis-invariant' &mdash; it exists regardless of what particular basis is used to write its vector arguments &mdash; and fairly obvious that it satisfies the scalar-multiplication property that $V(a{\bf u}, {\bf v}, {\bf w}) = aV({\bf u}, {\bf v}, {\bf w})$ (note that this is why we had to define it as a signed volume - $a$ could be negative!).  The linearity under addition is a little bit trickier to see; it's probably easiest to think of the analogous area form $A({\bf v}, {\bf w})$ in two dimensions: imagine stacking the parallelograms spanned by $({\bf u}, {\bf w})$ and $({\bf v}, {\bf w})$ on top of each other to form a sort of chevron, and then moving the triangle formed by ${\bf u}$, ${\bf v}$ and ${\bf u}+{\bf v}$ from one side of the chevron to the other to get the parallelogram $({\bf u}+{\bf v}, {\bf w})$ with the same area.  The same concept works in three dimensions by stacking rhomboids, but the fact that the two 'chunks' are the same shape is trickier to see.  This linearity, incidentally, explains why the form changes signs when you swap arguments (that is, why $V({\bf u}, {\bf v}, {\bf w}) = -V({\bf v}, {\bf u}, {\bf w})$) : from the definition $V({\bf u}, {\bf u}, {\bf w}) = 0$ for any ${\bf u}$ (it represents the volume of a degenerate 2-dimensional rhomboid spanned by ${\bf u}$ and ${\bf w}$), and using linearity to break down $0 = V({\bf u}+{\bf v}, {\bf u}+{\bf v}, {\bf w})$ shows that $V({\bf u}, {\bf v}, {\bf w}) + V({\bf v}, {\bf u}, {\bf w}) = 0$.</li>
</ol>

<p>Now, the fact that the volume form $V({\bf u}, {\bf v}, {\bf w})$ is linear means that we can do the same sort of 'currying' that we talked about above and, for any two vectors ${\bf v}$ and ${\bf w}$, consider the function $C_{\bf vw}$ from vectors ${\bf u}$ to numbers defined by $C_{\bf vw}({\bf u}) = V({\bf u}, {\bf v}, {\bf w})$.  Since this is a linear function (because $V$ is linear, by point 2), we know that we have some vector ${\bf c}$ such that $C_{\bf vw} = D_{\bf c}$ (by point 1).  And finally, we <em>define</em> the cross product of the two vectors ${\bf v}$ and ${\bf w}$ as this 'vector' ${\bf c}$.  This explains why the cross product is linear in both of its arguments (because the volume form $V$ was linear in all three of its arguments) and it explains why ${\bf u}\times{\bf v} = -{\bf v}\times{\bf u}$ (because $V$ changes sign on swapping two parameters).  It also explains why the cross product isn't <em>exactly</em> a vector: instead it's really the linear function $C_{\bf vw}$ disguising itself as a vector (by the one-to-one correspondence through $D_{\bf c}$).  I hope this helps explain things better!</p>

==============================
===============================
Question: <p>Mariano mentioned somewhere that everyone should prove once in their life that every matrix is conjugate to its transpose.</p>

<p>I spent quite a bit of time on it now, and still could not prove it. At the risk of devaluing myself, might I ask someone else to show me a proof?</p>

 
Answer: <p>I had in mind an argument using the Jordan form, which reduces the question to single Jordan blocks, which can then be handled using Ted's method ---in the comments.</p>

<p>There is one subtle point: the matrix which conjugates a matrix $A\in M_n(k)$ to its transpose can be taken with coefficients in $k$, no matter what the field is. On the other hand, the Jordan canonical form exists only for algebraically closed fields (or, rather, fields which split the characteristic polynomial)</p>

<p>If $K$ is an algebraic closure of $k$, then we can use the above argument to find an invertible matrix $C\in M_n(K)$ such that $CA=A^tC$. Now, consider the equation $$XA=A^tX$$ in a matrix $X=(x_{ij})$ of unknowns; this is a linear equation, and <em>over $K$</em> it has non-zero solutions. Since the equation has coefficients in $k$, it follows that there are also non-zero solutions with coefficients in $k$. This solutions show $A$ and $A^t$ are conjugated, except for a detail: can you see how to assure that one of this non-zero solutions has non-zero determinant?</p>

==============================
===============================
Question: <p>The <a href="http://en.wikipedia.org/wiki/Pigeonhole_principle">pigeonhole principle</a> states that if $n$ items are put into $m$ "pigeonholes" with $n &gt; m$, then at least one pigeonhole must contain more than one item.</p>

<p>I'd like to see your favorite application of the pigeonhole principle, to prove some surprising theorem, or some interesting/amusing result that one can show students in an undergraduate class. Graduate level applications would be fine as well, but I am mostly interested in examples that I can use in my undergrad classes.</p>

<p>There are some examples in the Wikipedia page for the <a href="http://en.wikipedia.org/wiki/Pigeonhole_principle">pigeonhole principle</a>. The hair-counting example is one that I like... let's see some other good ones!</p>

<p>Thanks!</p>

 
Answer: <p>As the wikipedia article describes, <a href="http://en.wikipedia.org/wiki/Dirichlet&#39;s_approximation_theorem" rel="nofollow noreferrer">Dirichlet's approximation theorem</a> is a foundational result in diophantine approximation. For a real number $x$, let $\|x\|$ denote the distance from $x$ to its closest integer. Then the theorem states that for any <em>irrational</em> number $\alpha$, there exists infinitely many $q \gt 0$ such that 
$$
\| q\alpha \| \leqslant \frac{1}{q}.
$$
This theorem is a simple consequence of the pigeonhole principle, and I was very surprised on seeing the proof. You can find the proof in robjohn's answer to the question: <a href="https://math.stackexchange.com/questions/56045/approximation-of-irrationals-by-fractions/56054#56054">Approximation of irrationals by fractions</a>. </p>

<p>In words, this theorem says that we can <strong>approximate the irrationals as closely as we want</strong> (in the sense of $\| q \alpha \|$) if we are allowed to pick a large enough $q$. This may not sound that surprising at first, but it becomes striking when one compares it to rational case. </p>

<p>Suppose $\alpha = a/b$ where $a$ and $b$ are integers and $b \geqslant 1$. We want to know how well $\alpha$ can be approximated using <em>other</em> rationals, since otherwise the problem is trivial. So fix $p/q \neq \alpha = a/b$.
Rearranging, $qa - pb$ is nonzero; since it is also an integer, $|qa - pb|$ must be at least $1$. Thus,
$$
|q\alpha - p| = \frac{|qa - pb|}{b} \geqslant \frac{1}{b}.
$$
In particular, if $q \alpha$ is not an integer, then $\| q \alpha \| \geqslant \frac{1}{b}$, which is bounded away from zero, irrespective of $q$. </p>

<p>Thus, in a precise sense, the irrational numbers can be better approximated using rationals than the rational numbers themselves! (Of course, as stated previously, in the rational case, we do not count "approximating" the number by itself.)</p>

==============================
===============================
Question: <p>My book says 
\begin{equation}
\(a,b\)=\\{\\{a\\},\\{a,b\\}\\}
\end{equation}</p>

<p>I have been staring at this for a bit and it is not making since to me. I have read several others posts on this, but none made any sense to me.</p>

<p>For example, <a href="https://math.stackexchange.com/questions/25791/definition-of-an-ordered-pair">Definition of an Ordered Pair</a></p>

<p>Based on how my ignorant brain is viewing this, I don't see why the definition could not be.</p>

<p>\begin{equation}
\(a,b\)=\\{\\{a\\},\\{b\\},\\{a,b\\}\\}
\end{equation}</p>

<p>aka the power set. What is the significance of the {a} in that definition? Please keep things simple if possible. Normally definitions have a valid and clear reason for being defined that way.</p>

<hr>

<p><strong>Clarification</strong></p>

<p>First, I understand what an ordered pair is. I just don't see how the set notation says that. </p>

<p>Second, 
\begin{equation}
(a,b) = \\{\\{a\\},\\{a,b\\}\\}=\\{\\{a,b\\},\\{a\\}\\}
\end{equation}
Sets don't preserve order, but ordered pairs do. How does the third part of the equality apply to the definition?</p>

<p>Third, another issue with the notation that I have starts with the <em>Product Property of Sets</em></p>

<p>\begin{equation}
\text{Let $X$ and $Y$ be sets} :\ X=\\{a,b,c\\}\text{ and }Y=\\{a,d,e\\}.
\end{equation}
\begin{equation}
\text{Then }X \times Y = \\{(a,a),(a,d),(a,e),(b,a),(b,d),(b,e),\dots,(c,e)\\}
\end{equation}
If we look at the first ordered pair and our given definition we have</p>

<p>\begin{equation}
(a,a)=\\{\\{a\\},\\{a,a\\}\\}
\end{equation} </p>

<p>How can this be so, you can't have duplicates in sets? I guess what I am looking for in an answer, is not a proof or a definition of ordered pairs, but rather something like, "This notation says what it says because...". Except for the second to last point I get the terminology, I just don't get the connection between the two different uses of notation.</p>

 
Answer: <p>Whatever it is we define "$(a,b)$" to <em>be</em> as a set, what we <em>really</em> want is the following "defining property":</p>

<blockquote>
  <p>$(a,b) = (c,d)$ if and only if $a=c$ and $b=d$.</p>
</blockquote>

<p>There are many ways to achieve this, but this is what we really want to achieve; once we achieve this via some definition, we want to avoid using the actual "guts" of the definition and stick exclusively to that defining property. (Similar to the points made <a href="https://math.stackexchange.com/questions/62852/in-set-theory-how-are-real-numbers-represented-as-sets/62859#62859">in this answer and comment</a> about how to represent the real numbers as sets). </p>

<p>One way to achieve this "defining property" is via the Kuratowski definition, by defining
$$(a,b) = \Bigl\{ \{a\},\{a,b\}\Bigr\}.$$
We can prove that this is a set, and that this set <em>has</em> the property we want.</p>

<p>There are other ways of achieving the same result; for example, Wiener proposed
$$(a,b) = \Bigl\{ \bigl\{ \{a\},\emptyset\bigr\}, \bigl\{\{b\}\bigr\}\Bigr\},$$
which also has the "defining property". </p>

<p>The problem with your proposal is that it does <em>not</em> have the defining property we want for ordered pairs: for example, $\emptyset\neq\{\emptyset\}$, so we want $(\emptyset,\{\emptyset\}) \neq (\{\emptyset\},\emptyset)$. But in your proposal, we have:
$$\begin{align*}
(\emptyset,\{\emptyset\}) &amp;= \Bigl\{ \{\emptyset\}, \bigl\{\{\emptyset\}\bigr\}, \bigl\{ \emptyset, \{\emptyset\}\bigr\}\Bigr\},\\
(\{\emptyset\},\emptyset) &amp;= \Bigl\{ \bigl\{ \{\emptyset\}\bigr\}, \{\emptyset\}, \bigl\{ \{\emptyset\},\emptyset\bigr\}\Bigr\};
\end{align*}$$
so that $(\emptyset,\{\emptyset\}) = (\{\emptyset\},\emptyset)$. </p>

<p>So the proposal, while a perfectly fine definition of <em>a</em> set, does not achieve the ultimate purpose of defining the ordered pair, and so it should not be the definition of "ordered pair". </p>

<hr/>

<p><strong>Proof that the Kuratowski definition has the "defining property".</strong></p>

<p>If $a=c$ and $b=d$, then 
$$(a,b) = \Bigl\{ \{a\}, \{a,b\}\Bigr\} = \Bigl\{ \{c\},\{c,d\}\Bigr\} = (c,d).$$
Assume conversely that $(a,b)=(c,d)$. Then
$\bigcap(a,b) = \bigcap(c,d)$. Since
$$\bigcap(a,b) = \bigcap\Bigl\{ \{a\},\{a,b\}\Bigr\} = \{a\}\cap\{a,b\} = \{a\}$$
and
$$\bigcap(c,d) = \bigcap\Bigr\{ \{c\}, \{c,d\}\Bigr\} = \{c\}\cap\{c,d\} = \{c\},$$
we conclude that $a=c$.</p>

<p>If $b=a$, then $(a,b) = \{\{a\}\} = (c,d) = \{\{c\},\{c,d\}\}$. Therefore, $\{c,d\} \in\{\;\{a\}\;\}$, so $d\in\{a\}$, hence $d=a=b$ and we conclude $d=b$, as desired. Symmetrically, if $c=d$, then $\{a,b\}\in(a,b)=(c,d) = \{\;\{c\}\;\}$, so $\{a,b\}=\{c\}$, hence $b=c=d$ and we again conclude $d=b$ as desired.</p>

<p>If $b\neq a$ and $c\neq d$, then $\bigcup(a,b)-\bigcap(a,b) = \bigcup(c,d)-\bigcap(c,d)$. Since
$$\bigcup(a,b)-\bigcap(a,b) = \bigcup\Bigl\{\{a\},\{a,b\}\Bigr\} - \{a\} = \Bigl( \{a\}\cup \{a,b\}\Bigr)-\{a\} = \{a,b\}-\{a\} = \{b\}$$
and
$$\bigcup(c,d)-\bigcap(c,d) = \bigcup\Bigl\{\{c\},\{c,d\}\Bigr\} - \{c\} = \Bigl(\{c\}\cup \{c,d\}\Bigr)-\{c\} = \{c,d\}-\{c\} = \{d\}$$
(where we've used that $a\neq b$ to conclude that $\{a,b\}-\{a\}=\{b\}$ and we've used $c\neq d$ to conclude $\{c,d\}-\{c\}=\{d\}$), then we have $\{b\}=\{d\}$, hence $b=d$, again as desired.</p>

<p>Thus, if $(a,b)=(c,d)$, then $a=c$ and $b=d$. </p>

<hr/>

<p>Addressing the comments added to the question.</p>

<p>This definition is part of a way to try to define a lot of the things that we use in mathematics on the basis of an axiomatic theory; in this case, we start with Axiomatic Set Theory, where the only notions we have (if we are working in <a href="http://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory" rel="nofollow noreferrer">Zermelo-Fraenkel Set Theory</a>) are "set" and "is and element of", together with the axioms that tells us properties of sets and things we can do with sets. </p>

<p>We want to have something that works like what we know as "the ordered pair"; but all we have to work with are sets. So we need to find a way of constructing a set that has the properties we want for the ordered pair. </p>

<p>For a metaphor: the ordered pair is like a car; we know how to drive. But in order to actually <em>have</em> a car, there needs to be an engine and gasoline, and the engine has to work. We are trying to <em>construct</em> that engine so that we can later drive it.</p>

<p>So this is not <strong>notation</strong>, this is a <strong>definition</strong> of what the ordered pair <em>is</em> in set theory. We are <strong>defining</strong> an object, which we call "$(a,b)$", to be the given set. It's not merely how we are writing the ordered pair, is what the ordered pair <em>is</em> if you are interested in actually seeing the engine of the car working. We know what we want "ordered pair" to behave like, but we have to actually <em>construct</em> an object that behaves that way. This is a way of <em>defining</em> an object that does behave that way.</p>

<p>There aren't "two notations" here. We <strong>define</strong> "the ordered pair with first component $a$ and second component $b$" to be the set
$$\bigl\{ \{a\}, \{a,b\}\bigr\},$$
(which one can prove is indeed a set using the Axioms of Set Theory, if $a$ and $b$ are already in the theory).</p>

<p>Then we prove that "the ordered pair with first component $a$ and second component $b$" is equal to "the ordered pair with first component $c$ and second component $d$" if and only if $a=c$ and $b=d$. </p>

<p><strong>Then</strong> we abbreviate "the ordered pair with first component $a$ and second component $b$" by writing "$(a,b)$" (or sometimes "$\langle a,b\rangle$"). </p>

<p>"$(a,b)"$ <em>is</em> notation. The other side is the <em>definition</em> of this set.</p>

<p>The definition is the way it is because <em>it works</em>; that's really all we care about. In fact, we forget about the definition pretty much as soon as we can, and simply use the $(a,b)$ and the "defining property." We can do that, because we know that "under the hood" there actually is an engine that does what we need it to do, even if we don't see it working while we are driving the car.</p>

<p>So, there is only <em>one</em> bit of notation, and it's "$(a,b)$". The other side is the <em>definition</em> of what that notation actually is.</p>

<hr/>

<ol>
<li><p>The "set notation" doesn't "say" the ordered pair is what you think it is. What we are doing is <strong>defining</strong> what an ordered pair is, in a theory where the only thing we have are sets and the axioms of set theory. <em>Because</em> sets don't respect order, we cannot rely on simply how we <em>write</em> something; in order to be able to define an ordered pair we need to give a purely set-theoretic definition that actually achieves the purpose we want. Kuratowski's <em>definition</em> of an ordered pair $(a,b)$ to be the set given by $\bigl\{\{a\},\{a,b\}\bigr\}$ achieves this objective, in that the defined object has precisely the property we want an "ordered-pair-whatever-it-may-<em>actually</em>-be" to have. Since this set has that property, we <em>define</em> that set to be what the ordered pair "really is". But we don't actually care about what an ordered pair "really is", we just care about its desired "defining property". </p>

<p>In order for your car to work, there has to be an engine somewhere; but once there is an engine and your car works, you don't need to <em>see</em> the engine working in order to drive the car. The same with the ordered pair: for us to have an "ordered pair" in set theory, we need to be able to construct it somehow using sets. Once we have managed to do that, we don't need to see the actual set, we can just use the fact that there is a set that achieves our desired goal.</p></li>
<li><p>Yes, two sets are equal if and only if they have the same elements. So $\bigl\{\{a\},\{a,b\}\bigr\} = \bigl\{ \{a,b\}, \{a\}\bigr\}$. <em>This does not matter.</em> What matters is that $\bigl\{ \{a\}, \{a,b\}\bigr\} = \bigl\{ \{c\},\{c,d\}\bigr\}$ if and only if $a=c$ and $b=d$, because <em>that's</em> what we are going for. The definition of ordered pair by Kuratowski is <em>specifically</em> designed so that the end result "encodes" an order and distinguishes between the "first component" and the "second component" of $(a,b)$. The definition <em>actually</em> achieves this, as I proved above.</p></li>
<li><p>There is no problem with "duplicate elements". It's just that the set $\bigl\{\{a\},\{a\}\bigr\}$ is equal to the set $\bigl\{\{a\}\bigr\}$ by the Axiom of Extension, which says that two sets $A$ and $B$ are equal if and only if for every $x$, $x\in A\leftrightarrow x\in B$. The ordered pair $(a,a)$, <em>as a set</em>, is a set which can be written as
$$\bigl\{ \{a\},\{a,a\}\bigr\} \text{ or as }\bigl\{\{a\},\{a\}\bigr\}\text{ or as }\bigl\{ \{a\}\bigr\}.$$
There is no problem with this, because <em>that</em> set has the property that $(c,d)$ is equal to $\bigl\{ \{a\}\bigr\}$ if and only if $c=d=a$, which is <em>exactly what we want</em>. </p></li>
</ol>

<p>Again: the whole point of this definition is only that it satisfies the property</p>

<blockquote>
  <p>$\bigl\{ \{a\},\{a,b\}\bigr\} = \bigl\{ \{c\},\{c,d\}\bigr\}$ if and only if $a=c$ and $b=d$.</p>
</blockquote>

<p>Once we have this property, we abbreviate the set $\bigl\{\{a\},\{a,b\}\bigr\}$ as $(a,b)$, and simply <em>use</em> the property listed above. </p>

<hr/>

==============================
===============================
Question: <p>I was trying to work out a problem I found online. Here is the problem statement:</p>

<blockquote>
  <p>Let $f(x)$ be continuously differentiable on $(0, \infty)$ and suppose $\lim\limits_{x \to \infty} f&#39;(x) = 0$. Prove that $\lim\limits_{x \to \infty} \frac{f(x)}{x} = 0$. </p>
</blockquote>

<p>(source: <a href="http://www.math.vt.edu/people/plinnell/Vtregional/E79/index.html">http://www.math.vt.edu/people/plinnell/Vtregional/E79/index.html</a>)</p>

<p>The first idea that came to my mind was to show that for all $\epsilon &gt; 0$, we have $|f(x)| &lt; \epsilon|x|$ for sufficiently large $x$. (And I believe I could do this using the fact that $f&#39;(x) \to 0$ as $x \to \infty$.)</p>

<p>However, I was wondering if there was a different (and nicer or cleverer) way. Here's an idea I had in mind:</p>

<p>If $f$ is bounded, then $\frac{f(x)}{x}$ clearly goes to zero. If $\lim\limits_{x \to \infty} f(x)$ is either $+\infty$ or $-\infty$, then we can apply l'Hôpital's rule (to get $\lim\limits_{x \to \infty} \frac{f(x)}{x} = \lim\limits_{x \to \infty} \frac{f'(x)}{1} = 0$). </p>

<p>However, I'm not sure what I could do in the remaining case (when $f$ is unbounded but oscillates like crazy). Is there a way to finish the proof from here? </p>

<p>Also, are there other ways of proving the given statement?</p>

 
Answer: <p>This is an immediate consequence of L'Hopital's rule. For example, below is said L'Hospital's rule, from Rudin's $\:$ <em>Principles of Mathematical Analysis,</em> $\:$  1976. Note that it requires only that the denominator $\to\infty\:,\:$ not also the numerator. For more see the Monthly papers <a href="https://math.stackexchange.com/questions/11236/another-limit-task-x-over-ln-x-lhopital-wont-do-it/11252#11252">cited here.</a></p>

<p><strong>REMARK</strong> $\ $ L'Hospital's rule (LHR) is essentially a form of the <em>Mean value Theorem</em> (MVT) repacked into a form convenient for limit calculations. One can of course "unpackage" the MVT and apply it directly without any mention of LHR.  It's worth emphasizing that doing so does <em>not</em> really avoid L'Hopital's Rule (LHR) since it is precisely the proof of LHR, only specialized to a specfic function. Further, the proof of most special cases isn't much simpler than the proof of the general case of LHR. The raison d'être of the LHR abstraction is that it encapulates such applications of the Mean Value Theorem into a conveniently applicable form, so that one can easily reuse the proof by simply invoking the rule by name, not by value, i.e. not by repeating the whole proof ("inlining" it) every time one applies it!</p>

<p><img src="https://i.stack.imgur.com/IhUhD.jpg" alt="enter image description here"></p>

==============================
===============================
Question: <p>Gödel's incompleteness theorem says "Any effectively generated theory capable of expressing elementary arithmetic cannot be both consistent and complete. In particular, for any consistent, effectively generated formal theory that proves certain basic arithmetic truths, there is an arithmetical statement that is true,[1] but not provable in the theory."</p>

<p>I liked the theorem, but had a hard time finding an example. Here, I am proposing an example for Gödel's theorem. Please tell me if it is correct or point out the flaws.</p>

<p>Consider an axiomatic system where all the regular axioms regarding real valued functions hold. In particular, this system is concerned with integrals. One additional constraint is that existence of any integral is 'provable' if the indefinite integral can be expressed in terms of elementary functions. Now, given the fact that the integral for error function converges i.e. existence is true, but can't be expressed in terms of elementary functions i.e. not provable, can I say that this is an example wherein a statement is known to be true, but not provable?</p>

 
Answer: <p>Yes, your example does give an example of an incomplete system. This is because you took an intentionally weak axiom system but a strong semantics.  Another way to get an example is just to take any semantics and throw away <em>all</em> the inference rules. Then nothing is provable.  </p>

<p>The reason that the incompleteness theorems are more interesting than this is that they apply to every effective set of inference rules for arithmetic, no matter how strong we try to make the rules.  </p>

<hr>

<p>Here is how to make you question more precise. In general, a formal system consists of:</p>

<ul>
<li><p>A formal language $L$ (set of sentences)</p></li>
<li><p>A set of inference rules (and axioms, which are a type of inference rule for this purpose)</p></li>
<li><p>A semantics, which provides a set of models, or at least a set of valuation functions from $L$ to $\{T,F\}$</p></li>
</ul>

<p><em>Completeness</em> of the system says that if a sentence is sent to $T$ by every valuation function in the semantics, then that sentence is provable from the inference rules.</p>

<p>In the incompleteness theorem, when it says "true", it means "true in a particular, distinguished, standard model". It doesn't mean "true in every model" because every first-order theory is complete in that sense, with its usual inference rules and semantics. </p>

<p>In your framework, you could take $L$ to be the language of ZFC enhanced with an extra unary predicate $I$. For the inference rules, you take the axioms of ZFC, an axiom that says $I$ can only hold of a function $\mathbb{R}\to\mathbb{R}$, axioms that let you prove that every elementary function is integrable, and the usual inference rules for first-order logic. For the distinguished model (valuation function) you take the standard model of ZFC and make $I$ hold of all integrable functions.  </p>

<p>In that set-up, there are many functions $f$ for which $I(f)$ is true, and such that you can express $I(f)$ in the language at hand, but where your inference rules can't prove that $I(f)$ holds. For example, $\sin(x)$ is definable in ZFC, so you could let $f = \sin(x)$.  You just have to be able to express $I(f)$ without $f$ in the language of ZFC with the extra symbol $I$. </p>

<p>The next problem is that you might wonder about making the inference rules stronger, in an attempt to prove more functions are integrable. In the context of set theory, this will lead you to some more interesting things, like the distinction between extensional and intensional definitions. </p>

==============================
===============================
Question: <p>Do you have some reference to a proof of the so-called Borel theorem, i.e. every power series is the Taylor series of some $C^{\infty}$ function?</p>

 
Answer: <p>Borel's theorem states that given a sequence of real numbers $(a_n)_{n\in \mathbb N}$ there exists a $C^\infty$ function $f\in C^\infty(\mathbb R)$ such that 
$\frac {f^{(n)}(0)}{n!}=a_n $ ,  i.e. the Taylor series associated to $f$ is $\Sigma a_nX^n$.<br>
The function $f$ is never unique: you can always add to it a flat function, one all of whose derivatives at zero are zero, like the well-known Cauchy function $e^{-1/x^2}$  .</p>

<p>There is a huge <em>caveat</em> however: you can't go from the series to the function $f$ .<br>
Firstly,  the series might not be convergent at any $x\neq 0\in \mathbb R $ ! An example is $\Sigma a_n X^n=\Sigma n^n X^n$ whose radius of convergence is zero.<br>
Secondly, even if it does converge it might converge to the wrong function! For example if you start with Cauchy's function you get the zero Taylor series. It converges to zero, of course, but that is definitely not the Cauchy function you started with. So we should not read too much in Borel's theorem: it cannot force a non-analytic function to become analytic!</p>

<p>Borel's theorem is also valid in several variables. Given a sequence of $k$-tuples $(a_I)_{I\in \mathbb N^k}$ of real numbers $a_I \in\mathbb R$, there exists a function $f\in C^\infty(\mathbb R^k)$, again highly non-unique,  whose derivatives satisfy
$\frac {\partial^I f(0)}{I!}=a_I  $. [I have used multiindex notation with $I=(i_1,\ldots,i_k)$,  $I!=i_1!\ldots i_k!  \;etc.$]</p>

<p>There is a vast generalization due to Whitney of Borel's theorem. You can consider a closed subset $Z\subset \mathbb R^k$ and continuous functions $\phi_I\in C(Z) \; $ . Whitney gives necessary and sufficient growth and compatibility conditions on the $\phi_I $ 's which will guarantee that there exists a $C^\infty$ function $f\in C^\infty (U)$ defined on an open neighbourhood  $U \supset Z$ of $Z$ such that $\frac {\partial^I f(0)}{I!}=\phi_I \; $.  Borel' s theorem is then  the case $Z=\{0\}$ .</p>

<p><strong>Bibliography:</strong> Borel's theorem in several variables is proved in R.Narasimhan's book <em>Analysis on Real and complex Manifolds</em>, which also contains the precise statement of Whitney's theorem.</p>

==============================
===============================
Question: <p>Continuing my work through Dummit &amp; Foote's "Abstract Algebra", 3.1.36 asks the following (which is exactly the same as exercise 5 in <a href="https://math.stackexchange.com/questions/44995/are-cyclic-groups-always-abelian-commutative/45042#45042">this related MSE answer</a>):</p>

<blockquote>
  <p>Prove that if $G/Z(G)$ is cyclic, then $G$ is abelian. [If $G/Z(G)$ is cyclic with generator $xZ(G)$, show that every element of $G$ can be written in the form $x^az$ for some $a \in \mathbb{Z}$ and some element $z \in Z(G)$]
  <br></p>
</blockquote>

<p>The hint is actually the hardest part for me, as the quotient groups are somewhat abstract. But once I have the hint, I can write:
<br>
$g, h \in G$ implies that $g = x^{a_1}z_1$ and $h = x^{a_2}z_2$, so
\begin{align*}gh &amp;= (x^{a_1}z_1)(x^{a_2}z_2)\\\
 &amp;= x^{a_1}x^{a_2}z_1z_2\\\
&amp; = x^{a_1 + a_2}z_2z_1\\\
&amp;= \ldots = (x^{a_2}z_2)(x^{a_1}z_1) = hg.
\end{align*}
Therefore, $G$ is abelian. <br>
1) Is this right so far? <br>
2) How can I prove the "hint"?</p>

 
Answer: <p>We have that $G/Z(G)$ is cyclic, and so there is an element $x\in G$ such that $G/Z(G)=\langle xZ(G)\rangle$, where $xZ(G)$ is the coset with representative $x$. Now let $g\in G$. We know that $gZ(G)=(xZ(G))^m$ for some $m$, and by definition $(xZ(G))^m=x^mZ(G)$. Now, in general, if $H\leq G$, we have by definition too that $aH=bH$ if and only if $b^{-1}a\in H$. In our case, we have that $gZ(G)=x^mZ(G)$, and this happens if and only if $(x^m)^{-1}g\in Z(G)$. There then exists a $z\in Z(G)$ such that $(x^{m})^{-1}g=z$, and so $g=x^mz$. The hint is then proved, and the rest is identical to the work you did.  </p>

==============================
===============================
Question: <p>It's commonly stated that the roots of a polynomial are a continuous function of the coefficients.  How is this statement formalized?  I would assume it's by restricting to polynomials of a fixed degree n (maybe monic? seems like that shouldn't matter), and considering the collection of roots as a a point in $F^n/\sim$ where F is the field and $\sim$ is permutation of coordinates, but is there something I'm missing?  More to the point, where would I find a proof?</p>

<p>At least, I've seen this stated for <strong>C</strong> (and hence <strong>R</strong>); is this even true in general -- say, for an algebraically closed valued field (and hence complete non-Archimedean field because those extend uniquely)?  I've seen it implied that it's not always true in the non-Archimedean case; is this correct?  What's a counterexample?  (If this is wrong and it is true in this generality, is it true in any greater generality?)</p>

 
Answer: <p>Here is a version of continuity of the roots.<br>
Consider the monic complex polynomial $f(z)=z^n+c_1z^{n-1}+...+c_n\in \mathbb C[z]$ and factor it as $$f(z)=(z-a_1)...(z-a_n) \quad (a_k\in \mathbb C)$$ 
where the roots $a_k$ are arranged in some order, and of course needn't be distinct.<br>
Then for every $\epsilon \gt 0$, there exists $\delta \gt 0$ such that every polynomial $ g(z) =z^n+d_1z^{n-1}+...+d_n\in \mathbb C[z]$ satisfying $|d_k-c_k|\lt \delta \quad (k=1,...,n)$ can be written 
$$g(z)=(z-b_1)...(z-b_n) \quad (b_k\in \mathbb C)$$<br>
with $|b_k-a_k|\lt \epsilon \quad (k=1,...,n)$.</p>

<p>A more geometric version is to consider  the Viète map $v:\mathbb C^n \to \mathbb C^n $ sending, in the notation above,   $(a_1,...,a_n)$  to $(c_1,...,c_n)$ (identified with  $z^n+c_1z^{n-1}+...+c_n=(z-a_1)...(z-a_n)$             ).<br>
It is a polynomial map (and so certainly continuous!) since $c_k=(-1)^{k} s_k(  a_1,...,a_n)$, where $s_k$ is the $k$-th symmetric polynomial in $n$ variables.<br>
There is an obvious action of the symmetric group $S_n$ on $\mathbb C^n$ and the theorem of continuity of the roots states that the Viète map descends to a homeomorphism  $w: \mathbb C^n / S_n \to \mathbb C^n$. It is trivial (by the definition of quotient topology) that $w$ is a bijective continuous mapping, but continuity of the inverse is the difficult part.<br>
The difficulty is concentrated at those points   $(c_1,...,c_n)$ corresponding to polynomials $z^n+c_1z^{n-1}+...+c_n$ having multiple roots.</p>

<p>This, and much more, is proved in Whitney's <em>Complex Analytic Varieties</em> (see App. V.4, pp. 363 ff). </p>

<p><strong>Algebraic geometry point of view</strong> Since you are interested in general algebraically closed fields $k$, here is an interpretation  for that case.<br>
 The symmetric group $S_n$ acts on $\mathbb A_k^n$ and the problem is whether the quotient set $\mathbb A_k^n /S_n$ has a reasonable algebraic structure. The answer is yes and the Viète map again descends to an isomorphism <em>of algebraic varieties</em> $\mathbb A_k^n /S_n \stackrel {\sim }{\to} \mathbb A_k^n $.<br>
This is the geometric interpretation of the fundamental theorem on symmetric polynomials.<br>
The crucial point is that the symmetric polynomials are a finitely generated $k$-algebra.</p>

<p>Hilbert's 14th problem was whether more generally the invariants of a polynomial ring under the action of a linear group form a finitely generated algebra. Emmy Noether proved in 1926 that the answer is yes for a finite group (in any characteristic), as illustrated by $S_n$.<br>
However  Nagata anounced  counterexamples (in all characteristics) to Hilbert's 14th problem at the International Congress of Mathematicians in 1958 and published them in 1959.</p>

==============================
===============================
Question: <p>I was going through the fundamental theorem in Number Theory where any non zero integer n can be represented as a product of distinct primes. A related problem with this theorem is to prove that for every such number, there exists a prime $p$ such that $p&lt; \sqrt n$.<br>
I was wondering if there is any mathematical proof that no prime $p$ exists for the number $n$ such that $p&gt; \sqrt n$.</p>

 
Answer: <p>No.  Consider that the square root of $14$ is about $3.74$ but $14$ has $7$ as a prime factor.  Also consider that any prime number such as $2$ is its own (only) prime factor, and any number greater than $1$ is greater than its square root.  The theorem you have stated is incorrect: $25$ has no prime factor less than $5$, and $3$ has no prime factor less than $1.732$; however, it is true that every <em>composite</em> number has a prime factor less than or <em>equal</em> to its square root.</p>

==============================
===============================
Question: <p>Picard's little theorem says that</p>

<blockquote>
  <p>If there exist two complex numbers $a,b$ such that $f: \Bbb{C} \to \Bbb{C}\setminus \{a,b\}$ is holomorphic then $f$ is constant.</p>
</blockquote>

<p>I am interested in proofs for this theorem. Until now I found at least two, one in W. Rudin's <em>Real and Complex Analysis</em> and another one in S. Krantz, <em>Geometric Function Theory</em>. Both of them need some preparation before someone not very advanced in Complex Analysis could understand them, especially the one in S. Krantz's book. </p>

<p>My questions are</p>

<blockquote>
  <ol>
  <li><p>How many proofs are there for Picard's little theorem? (references if possible)</p></li>
  <li><p>Is there a "simple" proof for Picard's little theorem? Simple means that it could be presented to an audience which had a one semester course in complex analysis.</p></li>
  </ol>
</blockquote>

<p>Thank you.</p>

 
Answer: <p>There is an essentially elementary proof that <em>can</em> be presented to an audience having only little background in complex analysis. Apart from miraculous trickery and some simple estimates, the only ingredients are Cauchy's integral formula and the existence of holomorphic logarithms on simply connected domains.</p>

<p>A much more complete exposition can be found in Remmert, <em><a href="http://books.google.com/books?id=BHc2b0iCoy8C&amp;pg=PA226" rel="nofollow noreferrer">Classical Topics in Complex Function Theory</a></em>, Springer GTM&nbsp;172, chapter 10. Let me emphasize: the following is only a distillate of the parts from Remmert's chapter&nbsp;10 needed for a proof of Picard's little theorem. Said chapter contains a lot more: extensive historical remarks and references, variants of the proofs and further developments, improvements of the results, some nice <a href="https://math.stackexchange.com/questions/29935/f3-g3-1-for-two-meromorphic-functions/29936#29936">applications of Picard's theorem</a> and it culminates in a proof of Picard's great theorem.</p>

<p>I once presented this argument to a group of talented students in a two hours &ldquo;Christmas special lecture&rdquo; and I think it worked quite well, but admittedly it <em>is</em> ambitious and the argument is flabbergasting at various points.</p>

<p>The main ingredient in the proof is the amazing:</p>

<blockquote>
  <p><strong>Theorem (Bloch).</strong> If $f$ is holomorphic in a neighborhood of the closed unit disk $\overline{\mathbb D}$ and $f'(0) = 1$ then $f(\mathbb{D})$ contains a disk of radius $\frac{3}{2} - \sqrt 2 \gt 0$. </p>
</blockquote>

<p>Remmert prefaces the section containing this result by a statement of J.E. Littlewood:</p>

<blockquote>
  <p>One of the queerest things in mathematics, ... the proof itself is crazy.</p>
</blockquote>

<p>I'll give a proof at the end of this answer.</p>

<p>The way this is applied is:</p>

<blockquote>
  <p><strong>Exercise.</strong> If $f: \mathbb{C} \to \mathbb{C}$ is holomorphic and non-constant then $f(\mathbb{C})$ contains disks of arbitrary radius.</p>
  
  <p><em>Hint:</em> If $f'(0) \neq 0$ then $g(z) = \frac{f(rz)}{r |f'(0)|}$ satisfies the hypothesis of Bloch's theorem.</p>
</blockquote>

<hr>

<p>There's a second tricky ingredient, due to Landau and refined by K&ouml;nig:</p>

<blockquote>
  <p>Let $G \subset \mathbb{C}$ be a <em>simply connected</em> domain and let $f: G \to \mathbb{C}$ be holomorphic. If $f(G)$ does not contain $0$ and $1$ then there is a holomorphic $g: G \to \mathbb{C}$ such that $$f = \frac{1}{2}\big(1+ \cos{(\pi\cos{(\pi g)})}\big).$$
  Moreover, if $g$ is any such function then $g(G)$ does <em>not</em> contain a disk of radius one.</p>
</blockquote>

<p>Simple connectedness is used in guise of <a href="http://books.google.com/books?id=uP8SF4jf7GEC&amp;pg=PA278" rel="nofollow noreferrer">existence of roots and logarithms of holomorphic functions omitting the value $0$</a>. Let us show first that for a function $h$ on a simply connected domain $G$ such that $\pm 1 \notin h(G)$ there is a holomorphic $H:G \to \mathbb{C}$ such that $h = \cos{H}$: The trick is that $1-h^2$ has no zero, hence there exists $k$ such that $k^2 = 1-h^2$, so $1 = h^2 + k^2 = (h+ik)(h-ik)$. But this means that $h+ik$ doesn't have a zero either, hence it has a logarithm: $h+ik = e^{iH}$ and thus $h = \frac{1}{2}(e^{iH}+e^{-iH})$. Applying this to $h = 2f-1$ (which leaves out the values $\pm 1$ by hypothesis) we get an $F$ such that $h=\cos{(\pi F)}$, but $F$ must leave out all integer values in its range, hence $F = \cos{(\pi g)}$ and unwinding the construction gives us the desired $f=\frac{1}{2}\big(1+ \cos{(\pi\cos{(\pi g)})}\big)$.</p>

<p>The &ldquo;moreover&rdquo; part follows from the observation that $g(G)$ must not hit the set $$A = \left\{m \pm \frac{i}{\pi} \log{\big(n+\sqrt{n^2 - 1}\big)},\;m\in\mathbb{Z},\;n \in \mathbb{N}\smallsetminus\{0\}\right\}$$
since for $a \in A$ we have $\cos{(\pi a)} = (-1)^m \cdot n$ by a short calculation. Thus $\cos{(\pi\cos{(\pi a)})} = \pm 1$ and if there were $z \in G$ such that $g(z) \in A$ we would have $f(z) \in \{0,1\}$ contradicting the assumptions. It is not hard to convince oneself that every point $w \in \mathbb{C}$ is within distance $\lt 1$ of some point of $A$ (a picture would help!), hence $g(G)$ can't contain a disk of radius $1$.</p>

<hr>

<p>Armed with these two ingredients the proof of Picard's little theorem is immediate:</p>

<blockquote>
  <p><strong>Picard's little theorem.</strong> If there exist two complex numbers $a,b$ such that $f: \mathbb{C} \to \mathbb{C}\smallsetminus \{a,b\}$ is holomorphic then $f$ is constant.</p>
</blockquote>

<p><em>Proof.</em> We may assume $\{a,b\} = \{0,1\}$. By the Landau&ndash;K&ouml;nig theorem we have $f(z) = \frac{1}{2}\big(1+ \cos{(\pi\cos{(\pi g)})}\big)$ for some $g$ whose image does not contain a disk of radius $1$ and by the exercise to Bloch's theorem $g$ must be constant.</p>

<hr>

<p>Now for the proof of Bloch's theorem:</p>

<blockquote>
  <p><strong>Lemma.</strong> Let $f$ be holomorphic in a neighborhood of the closure of the disk $D = B_r(a)$ and assume that $|f'(z)| \lt 2|f'(a)|$ for $z \in D$. Put $\rho = (3-2\sqrt{2})\cdot r \cdot |f'(a)|$ then $B_{\rho}(f(a)) \subset f(D)$.</p>
</blockquote>

<p><em>Proof.</em> Assume $a = f(a) = 0$ for simplicity of notation and write $C = \sup\limits_{z \in D}{\,|f'(z)|}$.</p>

<p>Put $A(z) = f(z) - f'(0)\cdot z$. Then $A(z) = \int_{0}^{z} (f'(w) - f'(0))\,dw$, so
$$|A(z)| \leq \int_{0}^{1} |f'(zt) - f'(0)|\,|z|\,dt.$$
For $d \in D$ we have by Cauchy's integral formula
$$f'(d) - f'(0) = \frac{d}{2\pi i} \int_{|w|= r} \frac{f'(w)}{w(w-d)} \,dw,$$
hence
$$|f'(d) - f(0)| \leq \frac{|d|}{r - |d|} C$$
and thus
$$|A(z)| \leq \int_{0}^{1} \left(\frac{|zt|}{r - |zt|}C\right)|z|\,dt \leq \frac{1}{2} \frac{|z|^2}{r - |z|} C.$$
Let $x = |z| \in (0,r)$ and observe that $|f(z) - f'(0)z| \geq |f'(0)| x - |f(z)|$. The last inequality together with the hypothesis $C \leq 2 |f'(0)|$ gives
$$|f(z)| \geq \underbrace{\left(x - \frac{x^2}{r- x}\right)}_{h(x)} |f'(0)|.$$
Now $h(x)$ assumes its maximum $(3 - 2\sqrt{2})r$ at the point $\tilde{x} = (1-\frac{\sqrt{2}}{2})r$. Thus we have shown that for $|z| = \tilde{x}$ we have
$$|f(z)| \geq (3 - 2\sqrt{2})\cdot r \cdot |f'(0)| = \rho.$$
But this implies that $B_{\rho}(f(0)) \supset f(B_{\tilde{x}}(0))$. Why? This is because $B_{\tilde{x}}(0)$ is a domain whose boundary is mapped outside the ball $B_{\rho}(f(0))$ by $f$, as $f(0) = 0$, see <a href="http://books.google.com/books?id=BHc2b0iCoy8C&amp;pg=PA226" rel="nofollow noreferrer">here</a> (1) at the bottom of the page for more details.</p>

<p><em>Proof of Bloch's theorem.</em> Assume that $f$ is holomorphic in a neighborhood of the closed unit disk and assume that $f'(0) = 1$. Consider the function $z \mapsto |f'(z)|(1-|z|)$. It takes on its maximum at some point $p \in \mathbb{D}$. Putting $t = \frac{1}{2}(1-|p|)$ we have $B_{t}(p) \subset \mathbb{D}$ and $1-|z| \geq t$ for all $z \in B_{t}(p)$. Therefore $|f'(z)|(1-|z|) \leq 2t|f'(p)|$ and hence $|f'(z)| \leq 2|f'(p)|$ for all $z \in B_t(p)$. Hence the lemma gives us $B_{\rho}(f(p)) \subset f(\mathbb{D})$ for $\rho = (3-2\sqrt{2}) \frac{1}{2} t |f'(p)| \geq \frac{3}{2} - \sqrt{2}$.</p>

==============================
===============================
Question: <p>Let $H_n$ denote the $n$th harmonic number; i.e., $H_n = \sum\limits_{i=1}^n \frac{1}{i}$.  I've got a couple of proofs of the following limiting expression, which I don't think is that well-known: $$\lim_{n \to \infty} \left(H_n - \frac{1}{2^n} \sum_{k=1}^n \binom{n}{k} H_k \right) = \log 2.$$
I'm curious about other ways to prove this expression, and so I thought I would ask here to see if anybody knows any or can think of any.  I would particularly like to see a combinatorial proof, but that might be difficult given that we're taking a limit and we have a transcendental number on one side.  I'd like to see any proofs, though.  I'll hold off from posting my own for a day or two to give others a chance to respond first.</p>

<p>(The probability tag is included because the expression whose limit is being taken can also be interpreted probabilistically.)</p>

<p><HR></p>

<p>(<strong>Added</strong>: I've accepted Srivatsan's first answer, and I've posted my two proofs for those who are interested in seeing them.  </p>

<p>Also, the sort of inverse question may be of interest.  Suppose we have a function $f(n)$ such that  $$\lim_{n \to \infty} \left(f(n) - \frac{1}{2^n} \sum_{k=0}^n \binom{n}{k} f(k) \right) = L,$$ where $L$ is finite and nonzero.  What can we say about $f(n)$?  <a href="https://math.stackexchange.com/questions/8415/asymptotic-difference-between-a-function-and-its-binomial-average">This question was asked</a> and <a href="https://math.stackexchange.com/questions/8415/asymptotic-difference-between-a-function-and-its-binomial-average/22582#22582">answered a while back</a>; it turns out that $f(n)$ must be $\Theta (\log n)$.  More specifically, we must have $\frac{f(n)}{\log_2 n} \to L$ as $n \to \infty$.) </p>

 
Answer: <p>I made an quick estimate in my comment. The basic idea is that the binomial distribution $2^{−n} \binom{n}{k}$ is concentrated around $k= \frac{n}{2}$. Simply plugging this value  in the limit expression, we get $H_n−H_{n/2} \sim \ln 2$ for large $n$. Fortunately, formalizing the intuition isn't that hard. </p>

<p>Call the giant sum $S$. Notice that $S$ can be written as $\newcommand{\E}{\mathbf{E}}$
$$
\sum_{k=0}^{\infty} \frac{1}{2^{n}} \binom{n}{k} (H(n) - H(k)) = \sum_{k=0}^{\infty} \Pr[X = k](H(n) - H(k)) = \E \left[ H(n) - H(X) \right],
$$
where $X$ is distributed according to the binomial distribution $\mathrm{Bin}(n, \frac12)$. We need the following two facts about $X$: </p>

<ul>
<li>With probability $1$,  $0 \leqslant H(n) - H(X) \leqslant H(n) = O(\ln n)$.</li>
<li>From the <a href="http://en.wikipedia.org/wiki/Bernstein_inequalities_%28probability_theory%29" rel="noreferrer">Bernstein inequality</a>, for any $\varepsilon \gt 0$, we know that $X$ lies in the range $\frac{1}{2}n (1\pm \varepsilon)$, except with probability at most $e^{- \Omega(n \varepsilon^2) }$. </li>
</ul>

<p>Since the function $x \mapsto H(n) - H(x)$ is monotone decreasing, we have
$$
S \leqslant \color{Red}{H(n)} \color{Blue}{-H\left( \frac{n(1-\varepsilon)}{2} \right)} + \color{Green}{\exp (-\Omega(n \varepsilon^2)) \cdot O(\ln n)}.
$$
Plugging in the standard estimate $H(n) = \ln n + \gamma + O\Big(\frac1n \Big)$ for the harmonic sum, we get:
$$
\begin{align*}
S 
&amp;\leqslant \color{Red}{\ln n + \gamma + O \Big(\frac1n \Big)} \color{Blue}{- \ln \left(\frac{n(1-\varepsilon)}{2} \right) - \gamma + O \Big(\frac1n \Big)} +\color{Green}{\exp (-\Omega(n \varepsilon^2)) \cdot O(\ln n)}
\\ &amp;\leqslant \ln 2 - \ln (1- \varepsilon) + o_{n \to \infty}(1) 
\leqslant \ln 2 + O(\varepsilon) + o_{n \to \infty}(1).  \tag{1}
\end{align*}
$$</p>

<p>An analogous argument gets the lower bound
$$
S \geqslant \ln 2 - \ln (1+\varepsilon) - o_{n \to \infty}(1) \geqslant \ln 2 - O(\varepsilon) - o_{n \to \infty}(1). \tag{2}
$$
Since the estimates $(1)$ and $(2)$ hold for all $\varepsilon &gt; 0$, it follows that $S \to \ln 2$ as $n \to \infty$. </p>

==============================
===============================
Question: <p>I've read the proof for why $\int_0^\infty P(X &gt;x)dx=E[X]$ for nonnegative random variables (located <a href="http://en.wikipedia.org/wiki/Expected_value#Formulas_for_special_cases">here</a>) and understand its mechanics, but I'm having trouble understanding the intuition behind this formula or why it should be the case at all. Does anyone have any insight on this? I bet I'm missing something obvious.</p>

<p>Thanks!</p>

 
Answer: <p>For the discrete case, and if $X$ is nonnegative, $E[X] = \sum_{x=0}^\infty x P(X = x)$.  That means we're adding up $P(X = 0)$ zero times, $P(X = 1)$ once, $P(X = 2)$ twice, etc.  This can be represented in array form, where we're adding column-by-column:</p>

<p>$$\begin{matrix} P(X=1) &amp; P(X = 2) &amp; P(X = 3) &amp; P(X = 4) &amp; P(X = 5) &amp; \cdots \\ &amp; P(X = 2) &amp; P(X = 3) &amp; P(X = 4) &amp; P(X = 5) &amp; \cdots \\ &amp; &amp; P(X = 3) &amp; P(X = 4) &amp; P(X = 5) &amp; \cdots \\ &amp; &amp; &amp; P(X = 4) &amp; P(X = 5) &amp; \cdots \\ &amp; &amp;  &amp;  &amp; P(X = 5) &amp; \cdots\end{matrix}.$$</p>

<p>We could also add up these numbers row-by-row, though, and get the same result.  The first row has everything but $P(X = 0)$ and so sums to $P(X &gt; 0)$.  The second row has everything but $P(X =0)$ and $P(X = 1)$ and so sums to $P(X &gt; 1)$.  In general, the sum of row $x+1$ is $P(X &gt; x)$, and so adding the numbers row-by-row gives us $\sum_{x = 0}^{\infty} P(X &gt; x)$, which thus must also be equal to $\sum_{x=0}^\infty x P(X = x) = E[X].$</p>

<p>The continuous case is analogous.</p>

<p>In general, switching the order of summation (as in the proof the OP links to) can always be interpreted as adding row-by-row vs. column-by-column.</p>

==============================
===============================
Question: <p>How could we prove that this inequality holds </p>

<blockquote>
  <p>$$ \left(1+\frac{1}{n+1}\right)^{n+1} \gt \left(1+\frac{1}{n} \right)^{n} $$</p>
</blockquote>

<p>where $n \in \mathbb{N}$, I think we could use the AM-GM inequality for this but not getting how? </p>

 
Answer: <p>This is one of the cutest applications of AM-GM I have learned. Unfortunately, I do not remember the source. </p>

<p>Define the numbers $x_0, x_1, x_2, \ldots, x_n$ by:
$$
x_i =
\begin{cases}
1, &amp;i = 0,
\\\\ 1+\frac{1}{n}, &amp;1 \leqslant i \leqslant n. 
\end{cases}
$$
The claim follows by applying AM-GM:
$$
\left( \frac{x_0 + x_1 + \ldots + x_n}{n+1} \right)^{n+1} \gt \ \prod_{i=0}^n \, x_i .
$$
Plugging in the above values, we get 
$$
\left( \frac{1+n \Big(1+\frac{1}{n} \Big)}{n+1} \right)^{n+1} \gt \  1 \cdot \left( 1+\frac{1}{n} \right)^n ,
$$
which simplifies to 
$$
\left( 1+ \frac{1}{n+1} \right)^{n+1} \gt \left( 1 + \frac{1}{n} \right)^n.
$$</p>

==============================
===============================
Question: <p>I made up this question, but unable to solve it: </p>

<blockquote>
  <p>Let $f : \mathbb R \to \mathbb R$ be a continuous function such that $f(x) &gt; 0$ for all $x \in \mathbb Q$. Is it necessary that $f(x) &gt; 0$ almost everywhere?</p>
</blockquote>

<p>This is my attempt. </p>

<ol>
<li><p>It is easy to show that $f(x) \geq 0$ everywhere, so the real question is whether $f$ can be zero at <strike>an</strike> "almost all" <em>irrational</em> points. </p></li>
<li><p>The function can become $0$ at isolated points, e.g., $f(x) = (x - \sqrt{2})^2$. In particular, the qualification "almost" is necessary for the question to be nontrivial. </p></li>
<li><p>Every rational point has an open neighborhood where $f$ is positive. Hence at least know that the set $\{ x \,:\, f(x) &gt; 0 \}$ is not a measure-zero set. </p></li>
<li><p>I first mistakenly assumed that <a href="http://en.wikipedia.org/wiki/Thomae%27s_function">Thomae's function</a> provides a counter-example to this. Indeed, it is positive at all rationals and zero at all irrationals, but the function is continuous at only the irrationals, not everywhere. </p></li>
</ol>

<p>Then I tried to prove that the question has an affirmative answer, but do not have much progress there. Please suggest some hints!  </p>

 
Answer: <p>Here's a hint: If you can think of closed set $C \subset \mathbb{R}$ of positive measure containing no rationals, then the function sending $x$ to its distance from $C$ is an example.</p>

<p>(I changed this because I just realized you were looking for a hint)</p>

==============================
===============================
Question: <p>I understand how to find a limit. 
I understand the concept of the $\epsilon$-$\delta$ definition of a limit. 
Can you walk me through what we're doing in this worked example? </p>

<p>It is from my student solutions manual to my textbook. I need help understanding what we're saying here, and why. I understand the math expressions, but I do not understand why we chose the ones we did, and why and how they prove anything. Can you help?</p>

<blockquote>
  <p>Find the limit $$ \lim\limits_{x \to 1} \ (x+4) ,$$ and prove it exists using the $\epsilon$-$\delta$ definition of limit. </p>
</blockquote>

<p>By direct substitution, the limit is $5$. Understood. Now, here's where I start to get confused...</p>

<p>Let $\epsilon &gt; 0$ be given. </p>

<p>Choose $\delta = \epsilon$.</p>

<p>$$ 0 &lt; | x-1 | &lt; \delta = \epsilon .$$</p>

<p>$$ | (x+4) - 5 | &lt; \epsilon $$</p>

<p>$$ | f(x) - L | &lt; \epsilon $$</p>

<p>Proved.</p>

<p>Uh, okay, if you say so... Now, what's going on here line by line and term by term?</p>

 
Answer: <p>You want to prove that $\lim\limits_{x\to 1}(x+4) = 5$ using $\epsilon$-$\delta$. </p>

<p>Let $\epsilon\gt 0$. We need to prove that there exists a $\delta\gt 0$ such that</p>

<blockquote>
  <p>If $0\lt |x-1|\lt \delta$ then $|f(x)-5|\lt \epsilon$.</p>
</blockquote>

<p>Now, we want to think a bit: how will the size of $|x-1|$ affect the size of $|f(x)-5|$? Since $f(x)=x+4$,  we  notice  that $|f(x)-5| = |(x+4)-5| = |x-1|$; that is, the size of $|f(x)-5|$ is <em>equal</em> to the size of $|x-1|$. So in order to make sure that $|f(x)-5|\lt \epsilon$, it is enough to require that $|x-1|\lt\epsilon$. </p>

<p>Thus, we can select $\delta=\epsilon$. Then $\delta\gt 0$, and if $0\lt |x-1|\lt\delta$, then it will follow that $|f(x)-5|\lt\epsilon$. </p>

<p>Thus, for all $\epsilon\gt 0$ there exists a $\delta\gt 0$ (namely, $\delta=\epsilon$) with the property that if $0\lt |x-1|\lt \delta$, then $|f(x)-5|\lt \epsilon$. This proves that $\lim\limits_{x\to 1}f(x) = 5$, as desired. $\Box$</p>

<p>That's what you have, only with lots of words thrown in in-between...</p>

==============================
===============================
Question: <p>I am really sure that if two sets have the same power set, then they are the same set. I just am wondering how does one exactly go about proving/showing this?</p>

<p>I'm usually wrong, so if anyone can show me an example where this fails, I'd like that too.</p>

<p>The homework just asks for true/false, but I'm wanting to show it if possible. My thoughts are that since the power set is by definition the set of all subsets of a set, if each of the two power sets are identical, we have an identity map between each set, thus it's indistinguishable which power set is a given set's power set. I hope that wasn't verbose. Since a set has only one power set, we can conclude they are in fact the same set.</p>

 
Answer: <p>Suppose $A \neq B$. Without loss of geneality, there exists $x \in A$ such that $x \notin B$. Then $\{x\} \in \mathscr{P}(A)$ wherease $\{x\} \notin \mathscr{P}(B)$. Thus $\mathscr{P}(A) \neq \mathscr{P}(B)$. </p>

<p>Conversely, if $\mathscr{P}(A) = \mathscr{P}(B)$, then all their singleton's are the same. Thus $A = B$. </p>

<p>$A = B$ if and only if $\mathscr{P}(A) = \mathscr{P}(B)$. </p>

==============================
===============================
Question: <p>I am sure the answer to this is (kind of) well known. I've searched the web and the site for a proof and found nothing, and if this is a duplicate, I'm sorry.</p>

<p>The following question was given in a contest I took part. I had an approach but it didn't solve the problem.</p>

<blockquote>
  <p>Consider $V$ <strong>a</strong> linear subspace of the real vector space $\mathcal{M}_n(\Bbb{R})$ ($n\times n$ real entries matrices) such that $V$ contains only singular matrices (i.e matrices with determinant equal to $0$). What is the maximal dimension of $V$?</p>
</blockquote>

<p>A quick guess would be $n^2-n$ since if we consider $W$ the set of $n\times n$ real matrices with last line equal to $0$ then this space has dimension $n^2-n$ and it is a linear space of singular matrices.</p>

<p>Now the only thing there is to prove is that if $V$ is a subspace of $\mathcal{M}_n(\Bbb{R})$ of dimension $k &gt; n^2-n$ then $V$ contains a non-singular matrix. The official proof was unsatisfactory for me, because it was a combinatorial one, and seemed to have few things in common with linear algebra. I was hoping for a pure linear algebra proof.</p>

<p>My approach was to search for a permutation matrix in $V$, but I used some 'false theorem' in between, which I am ashamed to post here. </p>

 
Answer: <p>We can show more generally that if $\mathcal M$ is a linear subspace of $\mathcal M_n(\mathbb R)$ such that all its element have a rank less than or equal to $p$, where $1\leq p&lt;n$, then the dimension of $\mathcal M$ is less than or equal to $np$. To see that, consider the subspace $\mathcal E:=\left\{\begin{pmatrix}0&amp;B\\^tB&amp;A\end{pmatrix}, A\in\mathcal M_{n-p}(\mathbb R),B\in\mathcal M_{p,n-p}(\mathbb R) \right\}$. Its dimension is $p(n-p)+(n-p)^2=(n-p)(p+n-p)=n(n-p)$. Let $\mathcal M$ a linear subspace of $\mathcal M_n(\mathbb R)$ such that $\displaystyle\max_{M\in\mathcal M}\operatorname{rank}(M)=p$. We can assume that this space contains the matrix $J:=\begin{pmatrix}I_p&amp;0\\0&amp;0\end{pmatrix}\in\mathcal M_n(\mathbb R)$. Indeed, if $M_0\in\mathcal M$ is such that $\operatorname{rank}M_0=p$, we can find $P,Q\in\mathcal M_n(\mathbb R)$ invertible matrices such that $J=PM_0Q$, and the map $\varphi\colon \mathcal M\to\varphi(\mathcal M)$ defined by $\varphi(M)=PMQ$ is an isomorphism.</p>

<p>If we take $M\in\mathcal M\cap \mathcal E$, then we can show, considering $M+\lambda J\in\mathcal M$, that $M=0$. Therefore, since
$$\dim (\mathcal M+\mathcal E)=\dim(\mathcal M)+\dim(\mathcal E)\leq \dim(\mathcal M_n(\mathbb R))=n^2, $$<br>
we have 
$$\dim (\mathcal M)\leq n^2-n(n-p)=np.$$</p>

==============================
===============================
Question: <p>How do I prove group of order 15 is abelian?</p>

<p>Is there any general strategy to prove that a group of particular order(composite order) is abelian?</p>

 
Answer: <p>Let $G$ be a group of order 15.  We know $G$ has subgroups of order 3 and order 5, say $P_3$ and $P_5$ from Sylow theory.  These must be cyclic (why?) so write $P_3 = \langle a \rangle$, $P_5 = \langle b \rangle$.</p>

<p>Using the lemma below, show $G = P_3P_5$.  Prove the lemma if it's not something you already know.</p>

<p><strong>Lemma.</strong> For subgroups $H$ and $K$ of a finite group $G$, $|HK| = |H||K|/ |H \cap K|$, where $HK = \{hk \mid h \in H, k \in K\}$.</p>

<p>Using Sylow theory, show $P_3$ is normal.</p>

<p>Then $bab^{-1} \in \langle a \rangle$.  If $bab^{-1} = a$, we have $ba = ab$, so $G$ is abelian.  Observe $bab^{-1} \neq 1$ (why?).  The only "bad" possibility now is that $bab^{-1} = a^2$.</p>

<p>Suppose, to get a contradiction, that $bab^{-1} = a^2$.  Then $ba = a^2b$.  Using this identity repeatedly to fill in the $ \cdots $, show $a = b^5a = \cdots = a^2b^5 = a^2$.  But $a \neq a^2$, so this is a contradiction.</p>

<p>PS - Since $P_3$ and $P_5$ are both normal, you could instead argue that $G = P_3P_5$ implies $G \simeq P_3 \times P_5$.  In general, you can adapt this argument to show for primes $p,q$ with $p &gt; q$ and $q \nmid p - 1$, every group of order $pq$ is abelian.</p>

==============================
===============================
Question: <p>Could anyone explain to me why maximal ideals are prime?</p>

<p>I'm approaching it like this, let $R$ be a commutative ring with $1$ and $A$ be a maximal ideal. Let $a,b\in R:ab\in A$</p>

<p>I'm trying to construct a ideal $B$ such that $A\subset B \neq A$ As this would be a contradiction. An alternative idea I had was to prove that $R/A$ is an integral domain, but this reduces to the same problem.</p>

<p>EDIT: Ergh.. just realized that I've learnt a theorem that states is $A$ is a maximal ideal then $R/A$ is a field</p>

 
Answer: <p>Let $A$ be a maximal ideal. Then $R/A$ contains no proper ideals, by the correspondence theorem. Indeed, $R/A$ is a field (assuming that $R$ contains an identity).</p>

<p>Theorem: R/A is a field.</p>

<p>Proof: Let $i+A\in R/A$ such that $i+A\neq 0+A$. We want to prove that $i+A$ is a unit. Then set $B=A+Ri=\{a+ri: a\in A, r\in R\}$.     </p>

<p>Now, you (yourself!) need to prove that $B$ is an ideal, and that $A\subset B$ properly. So, since $A$ is maximal this means that $B=R$.</p>

<p>As $B=R$ we have that $1\in B$, so $(1+ri)+A=ri+A=(r+A)(i+A)$, and so $i+A$ is a unit, as required.</p>

==============================
===============================
Question: <p>I read a section of a book and it made mention of the set of rationals not being a $G_\delta$. However, it gave no proof. I read on <a href="http://en.wikipedia.org/wiki/G%CE%B4_set#Examples">wikipedia</a> about using contradiction, but it made use of the Baire category theorem, which is unfamiliar to me.<br>
I was wondering if anyone could offer me a different proof; perhaps using the fact that the complement of $G_\delta$ is $F_\sigma$.</p>

<p>Thanks.</p>

 
Answer: <p>I suspect that just about any proof that doesn’t directly use the Baire category theorem either uses a consequence of it or proves a special case of it. I’ve chosen the second course.</p>

<p>Suppose that $\mathbb{Q} = \bigcap\limits_{k\in\omega}V_k$, where each $V_k$ is open in the usual topology on $\mathbb{R}$. Clearly each $V_k$ is dense in $\mathbb{R}$. Let $\mathbb{Q}=\{q_k:k\in\omega\}$ be an enumeration of the rationals, and for each $k\in\omega$ let $W_k=V_k\setminus \{q_k\}$; clearly each $W_k$ is dense and open in $\mathbb{R}$, and $\bigcap\limits_{k\in\omega}W_k = \varnothing$.</p>

<p>Let $(a_0,b_0)$ be any non-empty open interval such that $[a_0,b_0]\subseteq W_0$. Given a non-empty open interval $(a_k,b_k)$, let $r_k=\frac14(b_k-a_k)$; clearly $a_k&lt;a_k+r_k&lt;b_k-r_k&lt;b_k$. Since $W_{k+1}$ is dense and open, there is a non-empty open interval $(a_{k+1},b_{k+1})$ such that $$(a_{k+1},b_{k+1}) \subseteq [a_{k+1},b_{k+1}] \subseteq W_{k+1}\cap (a_k+r_k,b_k-r_k),$$ and the construction can continue.</p>

<p>For $k\in\omega$ let $J_k = [a_k,b_k] \subseteq W_k$. For each $k \in \omega$ we have $J_k \supseteq J_{k+1}$, so $\{J_k:k\in\omega\}$ is a decreasing nest of non-empty closed intervals. Let $J = \bigcap\limits_{k\in\omega}J_k$; $J\subseteq J_k \subseteq W_k$ for each $k\in\omega$, so $J \subseteq \bigcap\limits_{k\in\omega}W_k = \varnothing$. But the <a href="http://en.wikipedia.org/wiki/Nested_intervals">nested intervals theorem</a> guarantees that $J \ne \varnothing$, so we have a contradiction. Thus, $\mathbb{Q}$ cannot be a $G_\delta$-set in $\mathbb{R}$.</p>

==============================
===============================
Question: <p>For financial reasons, I dropped out my senior year of college as a piano performance major. I will be returning to college to dual major in mathematics and computer science. I've taught myself to program out of SICP and would like to develop my mathematical chops. I got a 5 on the Calc BC test my junior year of high school and have always considered myself decent at math.</p>

<p>I have a preference for learning from rigorous material, so based on what I read, Spivak's Calculus seemed to be a logical choice. I made it through the reading in the first chapter, easily enough. Subsequently, I was blindsided by the difficulty of the problem set accompanying the first chapter. </p>

<p>So, after solving a few problems, I put Spivak aside and picked up "How to Prove it" to brush up on my proof writing skills. I'm a ways away from finishing that, but was wondering if anyone else recommends any prerequisite material for Spivak?</p>

<p>I remember feeling similarly overwhelmed when starting "Structure and Interpretation of Computer Programs" however, there's a lot of supplementary information available for that book and I now feel I have a mastery of that material. "Helper" material for Spivak seems sparse (excepting the solutions manual.) If anyone knows of any video lectures that cover Spivak, that would be especially helpful...</p>

<p>I should add that to my uninformed mind, Spivak seemed like a good way to "brush up" on Calculus while improving my general math skills. Obviously, I horribly underestimated the difficulty of the text.</p>

 
Answer: <p>I have read through the first few chapters of Spivak, however my personal preference is for Apostol's Calculus. It's also a very rigorous approach, and a very well respected book, however it starts more gently than Spivak's. With Spivak's book, the problems start out extremely hard, and get easier as the book goes on (mostly by getting used to his style, not objectively). With Apostol I was able to understand and answer all the questions in the first few chapters much more easily, and then I saw the difficulty increase a bit; however it increases progressively throughout the book. Many of the problems in the introduction of Apostol are exactly the same as those in Spivak, however the order and context that they are presented in leads you to the correct method for proving them, whereas Spivak's are more isolated.</p>

<p>There are many great discussions about calculus books on other forums, such as here:
<a href="http://www.physicsforums.com/showthread.php?t=122924">http://www.physicsforums.com/showthread.php?t=122924</a></p>

<p>I agree wholeheartedly with mathwonk's statement that, although the books are difficult, reading different approaches and going over them multiple times is really what gives you a deeper understanding of calculus. Mathwonk also mentions that most students find Apostol very dry and scholarly, where Spivak is more fun, however I have not found this to be the case. I have worked through every problem in Apostol's Calculus through chapter 10 so far, and it has been a joy (most times). As an added bonus, Apostol's Calculus covers linear algebra as well, and the second volume covers multivariable calculus. Spivak's analogous book, "Calculus on Manifolds", is known as an extremely difficult text, and is commonly used as an introduction to differential geometry (indeed, his comprehensive volumes on differential geometry mention Calculus on Manifolds as a prerequisite).</p>

<p>The choice of book should also reflect your future interests. I am a computer programmer currently, and am looking to go into mathematics exclusively. It sounds like you are still melding the two. I would say that Apostol's book might serve you a little better in this respect as well, as it is slightly tilted towards analysis, whereas Spivak's is tilted towards differential geometry. For instance, Apostol introduces "little-o" notation, a cousin of "big-O" notation which is <a href="http://www.google.com/url?sa=t&amp;source=web&amp;cd=1&amp;ved=0CB0QFjAA&amp;url=http%3A%2F%2Fmicromath.wordpress.com%2F2008%2F04%2F14%2Fdonald-knuth-calculus-via-o-notation%2F&amp;ei=HcWRTvy-IMff0QHAg-Aa&amp;usg=AFQjCNFThBHBMVgoL9KOPaMPgPQjNE4xFA&amp;sig2=b5QK16LgjeNzQrApype16Q">used extensively in computer science</a>. That being said, Spivak has been described by some as a deep real-analysis text more than a calculus book, so you would still deeply cover all the fundamentals.</p>

<p>Another set of calculus books which I own and are held in high regard are Courant's. My brief skim of them, as well as other's comments, suggest that they are more focused on applications perhaps than some of the other books. Apostol's is still, in my opinion, very well peppered throughout with applications; many chapters contain a specific "applications of ..." section which links the theoretical concepts you just learned with the applied use of those concepts.</p>

<p>My only exposure to Courant's expository style comes from his excellent book <em>What is Mathematics</em>. This is a book I would strongly recommend reading regardless of what calculus book you choose. I cannot praise Courant's lucid writing highly enough, and look forward to working though his Calculus texts in the future.</p>

<p>I think that you would find Apostol's book sufficiently rigorous, as well as extremely intuitive. I also am a musician, and coupled with my computer programming experience it seems that perhaps we think alike. Whatever book you choose, recognize before you start it that you are running a marathon, not a sprint. </p>

==============================
===============================
Question: <p>A number is an "algebraic integer" if it is the root to a <em>monic</em> polynomial with integer coefficients. Artin says (Algebra, p. 411):</p>

<blockquote>
  <p>The concept of algebraic integer was one of the most important discoveries of number theory. It is not easy to explain quickly why it is the right definition to use, but roughly speaking, we can think of the leading coefficient of the primitive irreducible polynomials $f(x)$ as a "denominator." If $\alpha$ is the root of an integer polynomial $f(x)=dx^n+a_{n-1}x^{n-1}...$ then $d\alpha$ is an algebraic integer, because it is a root of the monic integer polynomial $x^n + a_{n-1}x^{n-1} + ... + d^{n-1}a_0$. </p>
  
  <p>Thus we can "clear the denominator" in any algebraic number by multiplying it with a suitable integer to get an algebraic integer.</p>
</blockquote>

<p>When I first learned of algebraic integers, I looked online and saw some hints that maybe they were used to prove the Abel-Ruffini theorem. So I put off questioning their usage for a while; I now think I understand one proof of this theorem (the one at the end of Artin's Algebra) and it has nothing to do with algebraic integers (that I can tell).</p>

<p>So basically: why is it important if a number is an algebraic integer? I think I understand what he's saying about the relationship between roots of integer polynomials and algebraic integers, but I fail to see why this is "one of the most important discoveries of number theory."</p>

 
Answer: <p>Suppose that we desire to consider as "integers" some subring $\:\mathbb I\:$ of the field of all algebraic numbers. To be a purely <em>algebraic</em> notion, it cannot distinguish between conjugate roots, so if $\rm\:\alpha,\alpha&#39;$ are roots of the same polynomial irreducible over $\rm\:\mathbb Q\:,\:$ then $\rm\:\alpha\in\mathbb I\iff \alpha&#39;\in\mathbb I\:.\:$ Also we desire $\rm\:\mathbb I\cap \mathbb Q = \mathbb Z\ $ so that our notion of algebraic integer is a <em>faithful</em> extension of the notion of a rational integer. Now suppose that $\rm\:f(x)\:$ is the monic minimal polynomial over $\rm\:\mathbb Q\:$ of an algebraic "integer" $\rm\:\alpha\in \mathbb I\:.\:$ Then $\rm\:f(x) = (x-\alpha)\:(x-\alpha&#39;)\:(x-\alpha&#39;&#39;)\:\cdots\:$ has coefficients in $\rm\:\mathbb I\cap \mathbb Q = \mathbb Z\:.\:$ Therefore the monic minimal polynomial of elements $\in\mathbb I\:$ must have coefficients $\in\mathbb Z\:.\:$ Conversely, one easily shows that the set of all such algebraic numbers contains $1$ and is closed under both difference and multiplication, so it forms a <em>ring</em>. Moreover, as Artin's quote shows, the quotient field of $\rm\:\mathbb I\:$ is the field of all algebraic numbers. Hence a few natural hypotheses on the notion of an algebraic integer imply the standard criterion in terms of minimal polynomials.</p>

<p>Because this notion of integer <em>faithfully</em> extends the notion of rational integers, we can employ algebraic integers to deduce results about rational integers. This often results in great simplifications because many diophantine equations become simpler - being "linearized" - when one factors them in algebraic extension fields. For example, see proofs about Pythagorean triples using Gaussian integers, or classical proofs of FLT for small exponents employing algebraic integers.</p>

==============================
===============================
Question: <p><strong>Update</strong>: Pending independent verification, the answer to the title question is "<strong>no</strong>", according to a computation of $q(10) = 11609679812$ (which is <em>even</em>). </p>

<p>Let $q(n)$ be the number of ones in the binary expression for $10^{10^{n}}$ (which is the same as for $5^{10^{n}}$ of course), for positive integer $n$. The first nine $q(n)$ values — the most I can compute — are all odd: $11, 105, 1163, 11683, 115979, 1161413, 11606847, 116093517, 1160951533$. Is this just a quirk (with even values showing up eventually), or is $q(n)$ odd for all positive integer $n$? Equivalently, letting $t(0),t(1),t(2)...$ be the <a href="http://en.wikipedia.org/wiki/Thue%E2%80%93Morse_sequence">Thue-Morse sequence</a>, is $t(10^{10^{n}}) = 1$ for all positive integer $n$? </p>

<p>It may not be surprising that <em>about</em> half of the binary digits of $5^{10^{n}}$ are ones, i.e., $q(n) \sim \displaystyle\frac{1}{2} \log_2(5^{10^{n}}) \approx \ 1.16096404744 \cdot 10^{n}$ (thus explaining the leading digits of sufficiently large terms), but why should all the terms be odd (if indeed they are)?</p>

<p>Note: My motivation for posting is the expectation that a proposition like "$q(10^{10})$ is even" provides a problem of the kind that Solomon Feferman (<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.156.6181">"Are there absolutely unsolvable problems?"</a>, p. 16), calls "absolutely unsolvable from the standpoint of practice". Obviously, this expectation is wrong if it can be proved that $q(n)$ is odd for all positive integer $n$. I strongly suspect, however, that there are infinitely many $q(n)$ values of each parity.</p>

 
Answer: <p>The answer to the title question is "<strong>no</strong>" according to the following computation in a <a href="http://sagemath.org/" rel="nofollow">Sage notebook</a>:</p>

<pre><code>%time
for n in [1..10]: print n, (5^10^n).popcount()

 1 11
 2 105
 3 1163
 4 11683
 5 115979
 6 1161413
 7 11606847
 8 116093517
 9 1160951533
10 11609679812

CPU time: 487.60 s,  Wall time: 1935.41 s
</code></pre>

<p>EDIT: In Sage, the popcount() method -- which returns the number of ones in the binary representation -- is built-in for objects of type 'Integer' (but <em>not</em> for type 'long', which I had been forcing), making it unnecessary to import gmpy, etc., as done previously.</p>

==============================
===============================
Question: <p>How to prove
$$ \prod_{k=1}^{n-1} \sin\left(\frac{k\pi}{n}\right) = \frac{n}{2^{n-1}}$$
and
$$ \prod_{k=1}^{n-1} \cos\left(\frac{k\pi}{n}\right) = \frac{\sin(\pi n/2)}{2^{n-1}}$$</p>

 
Answer: <p>For the first:
$$
\lim_{z=1}\frac{z^n-1}{z-1}=n\tag{1a}
$$
$$
\frac{z^n-1}{z-1}=\prod_{k=1}^{n-1}(z-e^{2\pi ik/n})\tag{1b}
$$
$$
|1-e^{i2k\pi/n}|=|2\sin(k\pi/n)|\tag{1c}
$$
Combining $(1a)$, $(1b)$, and $(1c)$, we get
$$
2^{n-1}\prod_{k=1}^{n-1}\sin(k\pi/n)=n
$$
since everything is positive.
<hr/>
For the second:</p>

<p>If $n$ is even, then $\cos(\frac{\pi}{2})=0$ appears in the product (when $k=n/2$) and $\sin(\frac{n\pi}{2})=0$.</p>

<p>If $n$ is odd, then combining
$$
\lim_{z=1}\frac{z^n+1}{z+1}=1\tag{2a}
$$
$$
\frac{z^n+1}{z+1}=\prod_{k=1}^{n-1}(z+e^{2\pi ik/n})\tag{2b}
$$
$$
1+e^{i2k\pi/n}=2\cos(k\pi/n)e^{ik\pi/n}\tag{2c}
$$
and noting that $\displaystyle\sum_{k=1}^{n-1}k=\frac{n(n-1)}{2}$ so that $\displaystyle\prod_{k=1}^{n-1}e^{ik\pi/n}=(-1)^{(n-1)/2}$ which matches the sign of $\sin(\pi n/2)$, yields
$$
2^{n-1}\prod_{k=1}^{n-1}\cos(k\pi/n)=(-1)^{(n-1)/2}=\sin(\pi n/2)
$$</p>

==============================
===============================
Question: <p>My friend was asked the following problem in an interview a while back, and it has a nice answer, leading me to believe that there is an equally nice solution.</p>

<blockquote>
  <p>Suppose that there are 42 bags, labeled $0$ though $41$.  Bag $i$ contains $i$ red balls and $42-(i+1)$ blue balls.  Suppose that you pick a bag, then pull out three balls without replacement.  What is the probability that all 3 balls are the same color?</p>
</blockquote>

<p>The problem can be solved easily by using some basic identities with binomial coefficients, and the answer is $1/2$.  Moreover, if $42$ is replaced by $n$, the answer does not change, assuming $n&gt;3$.  However, this computational approach obscures any hidden structure there might be.  Ideally, I would like a simple and direct proof that the probability of getting RRR is the same as the probability of getting RBB.</p>

<p>So, is there a nice solution to the problem, one that could be explained fully to someone without the use of paper?  Or is there no good way to explain this beyond computational coincidence?</p>

 
Answer: <p>The game can be reformulated in the following way: There is one urn with 42 balls numbered 0 through 41. You start by drawing and keeping one ball (this corresponds to picking a bag in your version). The urn is then taken away while an assistant paints all balls with a <em>lower</em> number than your first draw red and the rest of them blue. Then you draw three more balls and see whether they have the same color.</p>

<p>Now, this is equivalent to first drawing <em>four</em> of the numbered balls, then among those four pick a random one to be the "bag" ball and coloring the other three according to that choice. But doing it that way, we can see that the initial drawing of four balls is entirely superfluous -- only the order relation between them matters, and any ordered set of four balls have the same structure. So we might as well forgo the initial draw and just start out with four balls numbered 1, 2, 3, and 4. Then you win if the one you pick in the second draw is either 1 or 4, and the probability of that is, naturally, 1/2.</p>

==============================
===============================
Question: <p>It seems it's well known that if a sigma algebra is generated by countably many sets, then the cardinality of it is either finite or $c$ (the cardinality of continuum). But it seems hard to prove it, and actually hard to find a proof of it. Can anyone help me out?</p>

 
Answer: <p>Let's say the $\sigma$-algebra on $X$ is generated by the sets $A_i \subseteq X$.  For each subset $I$ of the natural numbers, consider the set $B_I = \bigcap_{i \in I} A_i \cap \bigcap_{i \notin I} (X \setminus A_i)$.  For distinct sets $I$ and $J$, the corresponding sets $B_I$ and $B_J$ are disjoint.  Now take cases: either only finitely many of the $B_I$ are nonempty, or infinitely many are.  This will show that the $\sigma$-algebra is either finite or has cardinality at least that of the continuum.</p>

<p>To show that the $\sigma$-algebra cannot have cardinality strictly above that of the continuum is a bit more involved.  I can't come up with an approach avoiding transfinite induction up the Borel hierarchy.  Here's a sketch of what I have in mind:</p>

<p>We build an increasing family $S_\alpha$ of subsets of the power set of $X$, as $\alpha$ ranges over the countable ordinals.  In the end, $\bigcup_{\alpha &lt; \omega_1} S_\alpha$ will be a $\sigma$-algebra of size at most continuum containing our countably many generators (in fact, it will be the $\sigma$-algebra they generate, but that's just an added bonus).  We start by setting $S_0$ to equal the (countable) set of generators.  Given $S_\alpha$, we let $S_{\alpha+1}$ be the collection of subsets which can be written as countable unions of the form $\bigcup_i A_i \cup \bigcup_j (X \setminus B_j)$, where $A_i$ and $B_j$ are chosen from $S_\alpha$.  Note that if $|S_\alpha| \leq 2^{\aleph_0}$, then $|S_{\alpha+1}| \leq 2^{\aleph_0}$ as well (since there are only continuum many choices of ways to write the union: this is essentially the cardinal equality $(2^{\aleph_0})^{\aleph_0} = 2^{\aleph_0}$).  For limit ordinals $\lambda$, let $S_\lambda = \bigcup_{\alpha &lt; \lambda} S_\alpha$.  This will again satisfy $|S_\lambda| \leq 2^{\aleph_0}$ provided each $S_\alpha$ in the union does.</p>

<p>Finally, we see $\bigcup_{\alpha&lt;\omega_1} S_\alpha$ has cardinality at most that of the continuum, since $\aleph_1 \cdot 2^{\aleph_0} = 2^{\aleph_0}$.  Moreover, it is closed under the $\sigma$-algebra operations since any countable sequence of elements is accounted for in some $S_\alpha$ (with $\alpha &lt; \omega_1$).</p>

==============================
===============================
Question: <p>I would like to teach myself measure theory. Unfortunately most of the books that I've come across are very difficult and are quick to get into Lemmas and proofs. Can someone please recommend a layman's guide to measure theory? Something that reads a bit like this <a href="http://blog.echen.me/2011/03/14/laymans-introduction-to-measure-theory/">blog post</a>, starts out very gently and places much emphasis on the intuition behind the subject and the many lemmas.</p>

 
Answer: <p><a href="http://books.google.com/books?id=_OjSIphIrH0C&amp;lpg=PP1&amp;pg=PP1#v=onepage&amp;q&amp;f=false">Measures, Integrals and Martingales by René L. Schilling</a> is a very gentle (mathematically rigorous, but that should be the case if you want to learn measure theory) introduction to measure theory. All the solutions to the exercises are available on the website of the author. Another advantage is that it is quite inexpensive.</p>

<p>However, I'd also suggest <a href="http://books.google.com/books?id=5mskCf1wKPkC&amp;lpg=PP1&amp;dq=bauer%20measure&amp;pg=PP1#v=onepage&amp;q&amp;f=false">Measure and Integration Theory by Heinz Bauer</a>. This is one of the best introductions to this subject I have ever seen (and my professor and some others seem to agree). One drawback is that it has a few typos but that keeps you sharp ;-). It is a translation of the author's original book in German where only the relevant topics are kept.</p>

<p>Here (TU Delft) they first used the first book which I mentioned and this year they use Bauer.</p>

<p>Both books are an excellent basis if you want to go in the direction of analysis or probability theory. Both fields require at least what is in these books.</p>

<p>A companion to Bauer's measure theory book if your goal is to learn probability theory is his <a href="http://books.google.com/books?id=w76IHsPHybcC&amp;lpg=PP1&amp;dq=bauer%20probability%20theory&amp;pg=PP1#v=onepage&amp;q&amp;f=false">probability theory book</a>.</p>

<p>Another thing I would like to note is that you should have a reasonable knowledge of the foundations of real analysis before you embark on this. Measure theory is a "true" analytic topic and should not be treated like many calculus courses.</p>

==============================
===============================
Question: <p>In this image given below, there is an actor's (famous south Indian actor Rajinikanth) image which can be seen only if you shake your head ! I had lifted this from Facebook.</p>

<p><img src="https://i.stack.imgur.com/yj0pa.jpg" alt="enter image description here"></p>

<p>I am just curious to know if there is any mathematical explanation for it. Is there any way to know how this image was created in the first place.</p>

<p>PS : If this question (although interesting) is inappropriate here, it is still okay and i hope it could be migrated to some stackexchange site.</p>

<p><strong>ADDED</strong></p>

<p>(...experiment to prove that it is a physical phenomenon)</p>

<p>After some comments expressing doubt as to whether this is a physical phenomenon, I have done a small experiment using a simple camera. I have have shot photos of the picture displayed on a LCD monitor in two different cases. In case-1, the camera was still and in case-2 the camera was shaking in a circular arc (in to and fro) about and axis in the vertical plane passing through the centre of the camera. (just as like we shake our head). I did it with hand just as we shake our head.
I have given the photos below.</p>

<p><strong>Case-1</strong> (still camera)</p>

<p><img src="https://i.stack.imgur.com/Nynvi.jpg" alt="**Case-1** (still camera)"></p>

<p><strong>Case-2</strong> (shaking camera)</p>

<p><img src="https://i.stack.imgur.com/M8UEc.jpg" alt="**Case-2** (shaking camera)"></p>

<p>It can be observed that the face of Rajini is more clearly visible in Case-2 (shaking camera) than in the Case-1 (still camera) where the face is not clearly visible.</p>

<p>PS : Now there is really no need to shake our head.</p>

<p><strong>Added 2</strong></p>

<p>after a recommendation by Willie, <a href="http://meta.math.stackexchange.com/q/3088/2987">here</a>, I have added Case-3 where the camera is shaking vertically (parallel to the stripes in the picture).</p>

<p>It can be observed that not much of an effect there when camera is shaking parallel to the stripes.</p>

<p>Case-3 (shaking camera vertically)</p>

<p><img src="https://i.stack.imgur.com/fdPA1.jpg" alt="**Case-3** (shaking camera vertically)"></p>

 
Answer: <p>What you are seeing is a physical manifestation of the mathematical operation known as the <a href="http://en.wikipedia.org/wiki/Convolution" rel="noreferrer">convolution</a>.</p>

<p>First let me show you some pictures; we'll get into the mathematics afterwards. We start with the original </p>

<p><img src="https://i.stack.imgur.com/owO0B.png" alt="enter image description here"></p>

<p>I take the image, desaturated the colours, and duplicated another layer, and pixel-wise added the layers after some translation. With a horizontal translation that is half the "wavelength" of the black bars, we get</p>

<p><img src="https://i.stack.imgur.com/nXFRN.png" alt="enter image description here"></p>

<p>With a translation of the same number of pixels, but vertically, we get</p>

<p><img src="https://i.stack.imgur.com/LX50L.png" alt="enter image description here"></p>

<p>and finally, a diagonal translation at -45 degrees. </p>

<p><img src="https://i.stack.imgur.com/4xNJD.png" alt="enter image description here"></p>

<hr>

<p>So what is going on? Why did I say that this is a manifestation of convolution?</p>

<p>Recall that the convolution of two functions defined on (say) the real line $\mathbb{R}$ is defined to be </p>

<p>$$ f * g (x) = \int_{\mathbb{R}} f(y) g(x-y) dy $$</p>

<p>In a course in Fourier analysis, one is taught to emphasize that this is the dual operation of multiplication. That is, convolution in physical space corresponds to (point-wise) multiplication in Fourier space. This immediately gives the following interpretation of a convolution in signal processing:</p>

<blockquote>
  <p>Convolving a signal $f$ by a function $\psi$ is the same as applying a frequency dependent filter $\hat{\psi}$ to the signal $f$. </p>
</blockquote>

<p>Another way of looking at the convolution, however, after staring at the above definition for a bit, is that</p>

<blockquote>
  <p>A convolution is a way of taking weighted average of a signal with its translates. The weight depends on the amount of translation. </p>
</blockquote>

<p>It is in this second sense that we will first look at the phenomenon you asked above. In the second image of this post, I averaged the signal with its translation horizontally by half the wavelength of the black bars. Hence this is a convolution. Similarly, in the third/fourth image of this post, I averaged the original with a vertical/diagonal translation. They are also convolutions. And you see that this reproduces the observation you made that the direction in which you shake your head/camera produces an effect on the image seen/captured. </p>

<p>So how is the process of shaking your head of shaking a camera a process of convolution? The idea is that the image you see with your eyes and you capture with a camera do not come from photons all emitted at the same instant in time (special relativity notwithstanding). In your vision, there is the well-known phenomenon of <a href="http://en.wikipedia.org/wiki/Persistence_of_vision" rel="noreferrer">persistence of vision</a> which posits that the perceived image is actually made up of photons arriving in a 40 millisecond interval. Similarly, the shutter-speed of a camera determines how long a camera registers light, and so a camera set on 1/25 for the shutter-speed will "open its eye" for 40 milliseconds, and the image registered on the CCD or on film will be photons arriving in that window. </p>

<p>Now, if you shake your head or camera so that the retina or the CCD or the film moves significantly during that 40 milliseconds, each of your retina cell, each of the photoelements on the CCD, or each of the dye pigments on the film will be exposed to photons originating from different spatial positions. (I am grossly simplifying here, but that's the moral of the story.) </p>

<p>To summarise: your eyes and cameras already take convolution of the incoming signal <strong>in time</strong> when they compose the image. By shaking the apparati you convert the <em>temporal</em> convolution to a <em>spatial</em> convolution. Which means that you are taking a weighted average of the image and its spatial translations, which is why what you see and capture on camera can be analogously described by digitally manipulating the image via an averaging/convolution procedure. </p>

<p>Note that this corresponds somewhat with Henning's comment to your question. The "eye's edge detection" he mentions is, roughly speaking, a description of how the eye is sensitive to different <em>spatial</em> frequencies of a signal (not to be confused with the actual electromagnetic frequencies with determines the colour). By shaking your head you apply a convolution operator, which in frequency space introduces a cut-off for high spatial frequency components. Buy reducing the high spatial frequency components, your eye is forced to get its information from the lower-frequency components in which the image of the Indian Actor hide. (There's some technical inaccuracies in this paragraph about how human physiology works and how it interacts with the shaking of the head, but I think this simpler picture illustrates the idea better.) </p>

<hr>

<p>At this point I should mention that the idea of taking spatial convolutions of images and the exchange between temporal and spatial convolutions with the motion of the camera is not only useful for optical illusions. <a href="http://www.cs.columbia.edu/CAVE/projects/motion_deblur/" rel="noreferrer">It actually has industry application in automatic image deblurring</a>. </p>

==============================
===============================
Question: <p>In Royden (4th edition), it says one can prove the General Lebesgue Dominated Convergence Theorem by simply replacing $g-f_n$ and $g+f_n$ with $g_n-f_n$ and $g_n+f_n$.  I proceeded to do this, but I feel like the proof is incorrect.</p>

<p>So here is the statement:</p>

<blockquote>
  <p>Let $\{f_n\}_{n=1}^\infty$ be a sequence of measurable functions on $E$ that converge pointwise a.e. on $E$ to $f$.  Suppose there is a sequence $\{g_n\}$ of integrable functions on $E$ that converge pointwise a.e. on $E$ to $g$ such that $|f_n| \leq g_n$ for all $n \in \mathbb{N}$.  If $\lim\limits_{n \rightarrow \infty}$ $\int_E$ $g_n$ = $\int_E$ $g$, then $\lim\limits_{n \rightarrow \infty}$ $\int_E$ $f_n$ = $\int_E$ $f$.</p>
</blockquote>

<p><strong>Proof:</strong><br>
$$\int_E (g-f) =  \liminf \int_E g_n-f_n.$$</p>

<p>By the linearity of the integral: </p>

<p>$$\int_E g - \int_E f = \int_E g-f \leq \liminf \int_E g_n -f_n = \int_E g - \liminf \int_E f_n.$$</p>

<p>So,</p>

<p>$$\limsup \int_E f_n \leq \int_E f.$$</p>

<p>Similarly for the other one.</p>

<p>Am I missing a step or is it really a simple case of replacing.</p>

 
Answer: <p>Since $|f_n| \leq g_n$ for all $n$ and $f_n$ ($g_n$ respectively) converge pointwise a.e. on $E$ to $f$ ($g$ respectively), we have $|f|\leq g$ pointwise a.e. on $E$. Therefore, for all $n$ we have
$$|f_n-f|\leq g_n+g$$
pointwise a.e. on $E$. Now apply <a href="http://mathworld.wolfram.com/FatousLemma.html">Fatou Lemma</a> to the nonegative function $g_n+g-|f_n-f|$, we have
$$\liminf_{n\rightarrow\infty}\int_E(g_n+g-|f_n-f|)\geq\int_E\liminf_{n\rightarrow\infty}(g_n+g-|f_n-f|).$$
The right hand side is equal to 
$$\int_E\liminf_{n\rightarrow\infty}(g_n+g-|f_n-f|)=2\int_Eg,$$
since $f_n$ ($g_n$ respectively) converge pointwise a.e. on $E$ to $f$ ($g$ respectively). On the other hand, the left  hand side is equal to 
$$\liminf_{n\rightarrow\infty}\int_E(g_n+g-|f_n-f|)=2\int_Eg-\limsup_{n\rightarrow\infty}\int_E|f_n-f|$$
since $\displaystyle\lim_{n \rightarrow \infty}\int_Eg_n=\int_Eg$ by assumption. Now putting all these together, we obtain
$$0\geq\limsup_{n\rightarrow\infty}\int_E|f_n-f|.$$
Since $\displaystyle\int_E|f_n-f|\geq\Big|\int_Ef_n-f\Big|$, by the above inequality we have
$$0\geq\limsup_{n\rightarrow\infty}\Big|\int_E(f_n-f)\Big|\geq\liminf_{n\rightarrow\infty}\Big|\int_Ef_n-f\Big|\geq 0.$$
By the above equality, $\displaystyle\limsup_{n\rightarrow\infty}\Big|\int_E(f_n-f)\Big|=\liminf_{n\rightarrow\infty}\Big|\int_E(f_n-f)\Big|$, i.e. $\displaystyle\lim_{n\rightarrow\infty}\Big|\int_E(f_n-f)\Big|$ exists. Moreover, by the above equality again, $\displaystyle\lim_{n\rightarrow\infty}\Big|\int_E(f_n-f)\Big|=0$, which implies 
$$\lim_{n\rightarrow\infty}\int_Ef_n=\int_Ef,$$
as required.</p>

==============================
===============================
Question: <p>I've just started to learn about the tensor product and I want to show: $$(\mathbb{Z}/m\mathbb{Z}) \otimes_\mathbb{Z} (\mathbb{Z} / n \mathbb{Z}) \cong \mathbb{Z}/ \gcd(m,n)\mathbb{Z}.$$</p>

<p>Can you tell me if my proof is right:</p>

<p>$\mathbb{Z}/m\mathbb{Z}$ and $\mathbb{Z} / n \mathbb{Z}$ are both finite free $\mathbb{Z}$-modules with the basis consisting of one single element $\{ 1 \}$. So $(\mathbb{Z}/m\mathbb{Z}) \otimes_\mathbb{Z} (\mathbb{Z} / n \mathbb{Z})$ has the basis $\{ 1 \otimes 1 \}$.</p>

<p>Therefore, any element in $(\mathbb{Z}/m\mathbb{Z}) \otimes_\mathbb{Z} (\mathbb{Z} / n \mathbb{Z})$  is of the form $(ab) 1 \otimes 1$ and any element in $\mathbb{Z}/ \gcd(m,n)\mathbb{Z}$ is of the form $k 1 = k$ where $k \in \{ 0, \dots , \gcd(n,m) \}$.</p>

<p>I would like to construct an isomorphism that maps $ab$ to some $k$. Let this map be $ab (1 \otimes 1) \mapsto ab \bmod \gcd(n,m)$.</p>

<p>This is a homomorphism between modules: it maps $0$ to $0$ because it maps the empty sum to the empty sum. It also fulfills $f(a + b) = f(a) + f(b)$ because there is only one element, $a = 1$. </p>

<p>It is surjective. So all I need to show is that it is injective. But that is clear too because if $ab \equiv 0 \bmod \gcd(m,n)$  then both $a \equiv 0 \bmod n$ and $b \equiv 0 \bmod m$ so the kernel is trivial.</p>

<p>Many thanks for your help!!</p>

 
Answer: <p>The part that is missing is pretty much the essence of the following (incomplete) alternative proof.</p>

<p>Determine the kernel of
$$
  \begin{array}{rlrl}
    g: &amp; \mathbb{Z} &amp; \rightarrow &amp; (\mathbb{Z}/m\mathbb{Z}) \otimes_\mathbb{Z} (\mathbb{Z} / n \mathbb{Z})
    \\
       &amp; z          &amp; \to         &amp; z (1 \otimes 1)
  \end{array}
$$
That is: When is it true that $z (1 \otimes 1)$ is null? Since it is true for $n \in m\mathbb{Z} \cup n\mathbb{Z}$, then you know that it is true for the ideal generated by it: $\langle \mathrm{gcd}(m,n)\rangle \subset \mathrm{ker}(g)$.</p>

<p>You know that the map is surjective because $1 \otimes 1$ is a generator. If you show that $\mathrm{ker}(g) \subset \langle \mathrm{gcd}(m,n) \rangle$, you will have the isomorphism you claim. This is the part you are missing. It is equivalent to showing that your $f$ is well-defined.</p>

<p>So, the conclusion is that it is not right.</p>

==============================
===============================
Question: <p>Under what circumstances is there at least one non-constant continuous function from a topological space $X$ to a topological space $Y$? Assume that $X$ and $Y$ each have at least two points. If $X$ is disconnected, separated by $A$ and $B$, then any function with one value on $A$ and another on $B$ is continuous.  If $X$ is connected, then the image of $X$ under a continuous function must lie within a connected component of $Y$. Therefore, to avoid triviality, assume that $X$ and $Y$ are both connected.</p>

<p>The only theorem I've encountered of this nature is Urysohn's lemma, which proves such a function exists if $X$ is a $T_4$ space and $Y$ has a path-connected component with more than one point. This is of course a rather strong condition.</p>

<p>It's obvious that if $X$ is convex in $\mathbb{R}$ and $Y$ is totally path disconnected, then there is no such function.</p>

<p>Otherwise, I haven't a clue. I'm particularly curious about what happens if $X$ and/or $Y$ is required to be homogeneous or bihomogeneous, and/or if $Y$ is required to be uniform.</p>

 
Answer: <p>This paper might be of interest:</p>

<ul>
<li>Horst Herrlich: <a href="http://dx.doi.org/10.1007/BF01112240">Wann sind alle stetigen Abbildungen in Y konstant?</a> Mathematische Zeitschrift, Volume 90, Number 2, 152-154
Also freely available at <a href="http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN266833020_0090&amp;DMDID=dmdlog25">GDZ</a>; <a href="http://www.ams.org/mathscinet-getitem?mr=MR32:3029">MR32:3029</a>, <a href="http://www.zentralblatt-math.org/zmath/en/search/?q=an:0131.20402&amp;format=complete">Zbl 0131.20402</a>.</li>
</ul>

<p>The content of the paper:</p>

<blockquote>
  <p>Urysohn [5] asked whether for every regular space $X$ (having
  at least two points) there is a non-constant continuous map from $X$ do the space
  $Y$ of real numbers. This question was negatively answered by Hewitt [2], Novak [2]
  and Van Est-Freudenthal [1]. The methods used by these authors (which go back to Tychonoff [4])
  let us show relatively easy the following result:</p>
  
  <p><strong>Theorem</strong> Let $Y$ be a topological space. The following conditions are equivalent:<br>
  (a) $Y$ is a $T_1$-space,<br>
  (b) there exists a regular space $X$ (having at least two points), such that every continuous map from $X$ to $Y$ is constant.</p>
</blockquote>

<p>Sketch of the construction in the proof of this theorem: (I have omitted many details and also the proofs that these space do have the required properties.)</p>

<p><em>Definition of a space $Q$.</em> First we start with some given space $Y$.</p>

<ul>
<li>The spaces $R_i$ for $i=1,2$ and points $r_i\in R_i$ are constructed in such way that every continuous map from $R_i$ to $Y$ is constant on some neighborhood of $R_i$.</li>
<li>A space $T=R_1\times R_2\setminus \{(r_1,r_2)\}$. This space has the property, that for every continuous map $f$ from $T$ to $Y$ there exist neighborhoods $U_i$ of $r_i$ such that $f$ is constant on $U_1\times U_2 - \{(r_1; r_2)\}$.</li>
<li>We take countably many homeomorphic copies $T\times\{n\}$ of the space $T$. We add two new points $a$, $b$ with local neighborhood bases $\{\bigcup T_m; m\ge n\}\cup \{a\}\subseteq B$ and $\{\bigcup T_m; m\ge n\}\cup \{b\}\subseteq B$.</li>
<li>In this space we identify $(x,r_2,n)$ and $(x,r_2,n+1)$ for any $x\in R_1\setminus\{r_1\}$ and any even $n$. We also identify $(r_1,x,n)$ and $(r_1,x,n+1)$ for every odd $n$ and every $x\in R_2\setminus\{r_2\}$.</li>
</ul>

<p>Let us call the resulting space $Q$. </p>

<p>Now for any space $Z$ we define a space $Q(Z)$ on the set $Z\times Q$ where a subset $B$ of $Z\times Q$ is open in $Z\times Q$ if and only if the following holds:</p>

<ul>
<li>If $(z;x)$ is an element of $B$, then there is a neighborhood $U$ of $x$ in $Q$ with $\{z\}\times U\subset B$.</li>
<li>If $(z;a)$ is an element of $B$, then there is a neighborhood $U$ of $z$ in $Z$ with $U\times\{a\}\subset B$.</li>
</ul>

<p>If we identify in the above space $Z\times Q$ all points of the set $Z\times\{b\}$, then we obtain a space $Q(Z)$.</p>

<p><em>Definition of $Q(Z)$.</em> The space $Q(Z)$ contains a homeomorphic copy of $Z$. If $f$ is a continuous map from $Q(Z)$ to $Y$, then $f$ is constant on $Z$.</p>

<p><em>Definition of $X$.</em> Let $X_0$ be a singleton. By induction we define $X_{n+1}=Q(X_n)$. Then $X_0\subset X_1\subset X_2\subset \dots $ are regular spaces. Let a subset of $X=\bigcup\{X_n; n=0,1,\dots\}$ be open if and only if $B\cap X_n$ is open for every $n$. The space $X$ is a regular space. Every continuous map from $X$ to $Y$ is constant.</p>

<blockquote>
  <p>Remark. The above results has a trivial analogue:<br>
  Let $X$ be a topological space. The following conditions are equivalent:<br>
  (a) $X$ is connected,<br>
  (b) there is a regular space $Y$ (having at least 2 points), such that every continuous map from $X$ to $Y$ is constant.</p>
</blockquote>

<p><strong>EDIT:</strong> I have put my attempt to translate the article <a href="http://msleziak.com/texty/translat/">here</a> (let me know if you find any typos or mistranslations).</p>

==============================
===============================
Question: <p>Let $F$ be a finite field.
.How do I prove that the order of $F$ is always of order $p^n$ where $p$ is prime?</p>

 
Answer: <ol>
<li><p>Prove that the smallest multiple $m$ of 1 that gives zero has to be a prime. (Otherwise there are divisors of $m$ which are then divisors of zero.)</p></li>
<li><p>Prove that a field is a vector space over a subfield.</p></li>
<li><p>Count the elements of the field if the dimension of this vector space is $n$.</p></li>
</ol>

==============================
===============================
Question: <p>I am having trouble proving the statement:</p>

<p>Let $S = \{m + n\sqrt 2 : m, n \in\mathbb Z\}$. Prove for every $\epsilon &gt; 0$, The intersection of $S$ and $(0, \epsilon)$ is nonempty.</p>

 
Answer: <p>Hint: $|\sqrt2 -1|&lt;1/2$, so as $n\to\infty$ we have that $(\sqrt2-1)^n\to ?$ In addition to that use the fact that the set $S$ is a ring, i.e. closed under multiplication <strong>and</strong> addition.</p>

==============================
===============================
Question: <p>The other day I and my friend were having an argument. He was saying that there is no real life application of Topology at all whatsoever. I want to disprove him, so posting the question here.</p>

<p>What are the various real life applications of topology?</p>

 
Answer: <p>See "Topological Insulators", an invention that takes
electronics to a new phase.</p>

<p><a href="http://en.wikipedia.org/wiki/Topological_insulator">http://en.wikipedia.org/wiki/Topological_insulator</a></p>

==============================
===============================
Question: <p>Suppose we have two short exact sequences in an abelian category
$$0 \to A \mathrel{\overset{f}{\to}} B \mathrel{\overset{g}{\to}} C \to 0 $$
$$0 \to A&#39; \mathrel{\overset{f&#39;}{\to}} B&#39; \mathrel{\overset{g&#39;}{\to}} C&#39; \to 0 $$
and morphisms $a : A \to A&#39;, b : B \to B&#39;, c : C \to C&#39;$ making the obvious diagram commute. The snake lemma states that there is then an exact sequence
$$0 \to \ker a \to \ker b \to \ker c \to \operatorname{coker} a \to \operatorname{coker} b \to \operatorname{coker} c \to 0$$
where the morphisms between the kernels are induced by $f$ and $g$ while the maps between the cokernels are induced by $f&#39;$ and $g&#39;$.</p>

<p>It is not hard to show that the morphisms induced by $f, g, f&#39;, g&#39;$ exist, are unique, and that the sequence is exact at $\ker a, \ker b, \operatorname{coker} b, \operatorname{coker} c$. With the use of a somewhat large diagram shown <a href="http://unapologetic.wordpress.com/2007/10/02/the-snake-lemma/">here</a>, we can even construct the connecting morphism $d : \ker c \to \operatorname{coker} a$. However, I'm stuck showing exactness at $\ker c$ and $\operatorname{coker} a$. I thought Freyd might have had an element-free proof in his book, but it turns out he proves it by diagram chasing and invoking the Mitchell embedding theorem [pp. 98–99]. Is there a direct proof?</p>

 
Answer: <p>You can always "diagram chase" in any abelian category, without invoking any embedding theorem, using arguments with subobjects, as in MacLane's book.  </p>

<p>In any case, you can also construct the boundary map as follows:</p>

<p>We are given a map $b: B \to B&#39;$.  Let $B&#39;&#39; \hookrightarrow B$ denote
the preimage in $B$ of $\ker c$.  (If you want to desribe this in more categorical
terms, it is the kernel of the composite $B \to C \to C&#39;$.)</p>

<p>Then the map $B&#39;&#39;\hookrightarrow B \rightarrow B&#39;$ factors through the monomorphism $A&#39; \hookrightarrow B&#39;$
(using the fact that $A' =\ker(B' \to C')\, \, $).
This then induces a map on quotients $ B''/A \to A'/\operatorname{im}A$,
which is precisely the desired map $\ker c \to\operatorname{coker}a.$</p>

<p>Checking the various exactness claims is just a matter of using all the relevant universal properties of kernels, cokernels, quotients, etc. </p>

==============================
===============================
Question: <p>How can one prove the statement
$$\lim_{x\to 0}\frac{\sin x}x=1$$
without using the Taylor series of $\sin$, $\cos$ and $\tan$? Best would be a geometrical solution.</p>

<p>This is <em>homework</em>. In my math class, we are about to prove that $\sin$ is continuous. We found out, that proving the above statement is enough for proving the continuity of $\sin$, but I can't find out how. Any help is appreciated.</p>

 
Answer: <p><img src="https://i.stack.imgur.com/UdlyK.gif" alt="sinc and tanc at 0"></p>

<p>The area of $\triangle ABC$ is $\frac{1}{2}\sin(x)$.  The area of the colored wedge is $\frac{1}{2}x$, and the area of $\triangle ABD$ is $\frac{1}{2}\tan(x)$.  By inclusion, we get
$$
\frac{1}{2}\tan(x)\ge\frac{1}{2}x\ge\frac{1}{2}\sin(x)\tag{1}
$$
Dividing $(1)$ by $\frac{1}{2}\sin(x)$ and taking reciprocals, we get
$$
\cos(x)\le\frac{\sin(x)}{x}\le1\tag{2}
$$
Since $\frac{\sin(x)}{x}$ and $\cos(x)$ are even functions, $(2)$ is valid for any non-zero $x$ between $-\frac{\pi}{2}$ and $\frac{\pi}{2}$.  Furthermore, since $\cos(x)$ is continuous near $0$ and $\cos(0) = 1$, we get that
$$
\lim_{x\to0}\frac{\sin(x)}{x}=1\tag{3}
$$
Also, dividing $(2)$ by $\cos(x)$, we get that
$$
1\le\frac{\tan(x)}{x}\le\sec(x)\tag{4}
$$
Since $\sec(x)$ is continuous near $0$ and $\sec(0) = 1$, we get that
$$
\lim_{x\to0}\frac{\tan(x)}{x}=1\tag{5}
$$</p>

==============================
===============================
Question: <p>A problem on my (last week's) real analysis homework boiled down to proving that, for $a&gt;-1$,
$$\sum_{n=1}^\infty\frac{(n-1)!}{n\prod\limits_{i=1}^n(a+i)}=\sum_{k=1}^\infty \frac{1}{(a+k)^2}.$$ Mathematica confirms this is true, but I couldn't even prove the convergence of the original series (the one on the left), much less demonstrate that it equaled this other sum; the ratio test is inconclusive, and the root test and others seem hopeless. It was (and is) quite a  frustrating problem. Can someone explain how to go about tackling this?</p>

 
Answer: <p>This uses a reliable trick with the Beta function.  I say reliable because you can use the beta function and switching of the integral and sum to solve many series very quickly.</p>

<p>First notice that $$\prod_{i=1}^{n}(a+i)=\frac{\Gamma(n+a+1)}{\Gamma(a+1)}.$$ Then</p>

<p>$$\frac{(n-1)!}{\prod_{i=1}^{n}(a+i)}=\frac{\Gamma(n)\Gamma(a+1)}{\Gamma(n+a+1)}=\text{B}(n,a+1)=\int_{0}^{1}(1-x)^{n-1}x{}^{a}dx.$$ Hence, upon switching the order we have that $$\sum_{n=1}^{\infty}\frac{(n-1)!}{n\prod_{i=1}^{n}(a+i)}=\int_{0}^{1}x^{a}\left(\sum_{n=1}^{\infty}\frac{(1-x)^{n-1}}{n}\right)dx.$$ Recognizing the power series, this is  $$\int_{0}^{1}x^{a}\frac{-\log x}{1-x}dx.$$ Now, expand the power series for $\frac{1}{1-x}$  to get $$\sum_{m=0}^{\infty}-\int_{0}^{1}x^{a+m}\log xdx.$$ It is not difficult to see that $$-\int_{0}^{1}x^{a+m}\log xdx=\frac{1}{(a+m+1)^{2}},$$ so we conclude that $$\sum_{n=1}^{\infty}\frac{(n-1)!}{n\prod_{i=1}^{n}(a+i)}=\sum_{m=1}^{\infty}\frac{1}{(a+m)^{2}}.$$ </p>

<p>Hope that helps,</p>

<p><strong>Remark:</strong>  To evaluate the earlier integral, notice that $$-\int_{0}^{1}x^{r}\log xdx=\int_{1}^{\infty}x^{-(r+2)}\log xdx=\int_{0}^{\infty}e^{-u(r+1)}udu=\frac{1}{(r+1)^{2}}\int_{0}^{\infty}e^{-u}udu. $$  Alternatively, as Joriki pointed out, you can just use integration by parts.</p>

==============================
===============================
Question: <p><strong>Question.</strong> Let $R$ be a ring, $\mathfrak{p}$ a prime, $M$ a finitely-generated $R$-module, and $N$ any $R$-module. Is the natural map
$$\textrm{Hom}_R(M, N)_\mathfrak{p} \to \textrm{Hom}_{R_\mathfrak{p}}(M_\mathfrak{p}, N_\mathfrak{p})$$
an isomorphism (of $R_\mathfrak{p}$-modules)?</p>

<p>I can prove this in the case when $M$ is finitely <em>presented</em>: indeed, let $S$ be any flat $R$-algebra, and let
$$R^m \to R^n \to M \to 0$$
be a right-exact sequence; tensoring with $S$ gives another right-exact sequence
$$S^m \to S^n \to M \mathbin{\otimes_R} S \to 0$$
and applying hom functors, we get left-exact sequences
$$0 \to \textrm{Hom}_R(M, N) \to N^n \to N^m$$
$$0 \to \textrm{Hom}_S(M \mathbin{\otimes_R} S, N \mathbin{\otimes_R} S) \to (N \mathbin{\otimes_R} S)^n \to (N \mathbin{\otimes_R} S)^m$$
and $S$ is flat, so tensoring the first sequence yields
$$0 \to \textrm{Hom}_R(M, N) \mathbin{\otimes_R} S \to (N \mathbin{\otimes_R} S)^n \to (N \mathbin{\otimes_R} S)^m$$
but extending the sequences by $0$ to the left, and putting in vertical maps between the last two, we conclude that $\textrm{Hom}_R(M, N) \mathbin{\otimes_R} S \cong \textrm{Hom}_S(M \mathbin{\otimes_R} S, N \mathbin{\otimes_R} S)$ by the five lemma (modulo checking commutativity of diagrams). This is essentially the proof Eisenbud gives [<em>Commutative Algebra</em>, Prop. 2.10].</p>

<p>The trouble with extending it to a proof for finitely-<em>generated</em> modules is that we have to replace $R^m$ with a potentially arbitrary submodule $K$ of $R^n$, and that may not be free or even finitely-generated without some additional assumptions on $R$. I can't see an abstract nonsense proof of the claim, but I admit I haven't tried a bare-hands proof. However, is the claim even true?</p>

 
Answer: <p>Let me try a counterexample. I will take $N=R$. Consider $\phi : R^2\to R$ the linear map $(x,y)\mapsto x+y$, $\rho : R\to R_P$ the localization map at some prime ideal $P$, $K=\phi^{-1}(\ker(\rho))$ and $M=R^2/K$. Then, as in the first part of your question, one can see that 
$$\mathrm{Hom}(M, R)_P\to \mathrm{Hom}(M_P, R_P)$$ 
is surjective if and only if 
$$ \mathrm{Hom}(K, R)_P\to \mathrm{Hom}(K_P, R_P)$$
is injective when restricted to the image of   $\mathrm{Hom}(R^2, R)_P\to \mathrm{Hom}(K, R)_P$. Let $\psi=\phi|_K$. Then the image of $\psi_P$ in $\mathrm{Hom}(K_P, R_P)$ is zero by the construction of $K$. Now let us see under which condition $\psi_P=0$. This is equivalent to $\exists s\in R\setminus P$ such that $s\psi=0$. Or $s\mathrm{Im}(\psi)=0$. As $\phi$ is surjective, $\mathrm{Im}(\psi)=\ker\rho$. So 
$$ \psi_P=0 \Longleftrightarrow \exists s\in R\setminus P, \ s\ker\rho=0.$$
So to have a counterexample, it is enough to find $R, P$ such that the kernel of $R\to R_P$ is not killed by any $s\notin P$. </p>

<p>Consider $R$ the product of  infinitely many copies of $\mathbb F_2$ (say indexed by $\mathbb N$). All prime ideals are maximal and correspond to ultrafilters (see <a href="http://en.wikipedia.org/wiki/Ultrafilter">http://en.wikipedia.org/wiki/Ultrafilter</a>) of $\mathbb N$. Some of them are obivous: those with $0$ in a fixed component. They correspond to principal ultrafilters. Let $P$ be a maximal ideal corresponding to a non-principal ultrafilter (it is known that such ultrafilters exist). The kernel of $R\to R_P=\mathbb F_2$ is $P$. If $P$ was killed by a single $s\notin P$, $s=(a_0, a_1,....)$, then $P$ is killed by some $t=(0,...,a_r,0,..)$ with $a_r\ne 0$. So $P\subseteq \mathrm{Ann}(t)$. But the latter is a maximal ideal corresponding to a principal ultrafilter. Contradiction.</p>

==============================
===============================
Question: <p>What is the proof of the following:
$$\int_{0}^{1} \left(\frac{\ln t}{1-t}\right)^2 \,\mathrm{d}t=\frac{\pi^2}{3} \&gt;?$$</p>

 
Answer: <p>$$\int_0^1\frac{\log t}{1-t}dt=\int_0^1\log(1-u)\frac{du}{u}=\int_0^\infty \log(1-e^{-v})dv =-\frac{\pi^2}{6}.$$
For the last part see <a href="https://math.stackexchange.com/questions/60478/evaluating-the-integral-int-0-infty-ln-left1-e-x-right-mathrm/60479#60479">an answer of mine here</a>.</p>

<hr>

<p>For the revised question, substitute $u=1-t$ and expand into a product of Taylor series, then use some of partial fraction decomposition, sum splitting, reindexing, and telescoping properties:
$$\int_0^1\left(\frac{\log t}{1-t}\right)^2dt=\int_0^1\left(\frac{\log(1-u)}{u}\right)^2du=\sum_{n=1}^\infty\sum_{m=1}^\infty\frac{1}{nm}\int_0^1 u^{n+m-2}du$$
$$=\sum_{n=1}^\infty\sum_{m=1}^\infty\frac{1}{nm(n+m-1)}=\sum_{m=1}^\infty \frac{1}{m^2}+\sum_{n=2}^\infty\frac{1}{n}\frac{1}{n-1}\sum_{m=1}^\infty\left(\frac{1}{m}-\frac{1}{n+m-1}\right)$$
$$=\frac{\pi^2}{6}+\sum_{n=1}^\infty \left(\frac{1}{n}-\frac{1}{n+1}\right)\sum_{m=1}^n\frac{1}{m}=\frac{\pi^2}{6}+\sum_{n=1}^\infty\frac{1}{n^2}=\frac{\pi^2}{3}. $$</p>

==============================
===============================
Question: <blockquote>
  <p>What is the millionth decimal digit of the $10^{10^{10^{10}}}$th prime?</p>
</blockquote>

<p>(This prime, with more than $10^{10^{10}}$ decimal digits, is far larger than <a href="http://primes.utm.edu/largest.html#biggest">the largest "known" prime</a>.) The answer should include a proof of correctness. I'm posting this question in the spirit of <a href="http://blog.stackoverflow.com/2011/07/its-ok-to-ask-and-answer-your-own-questions/">this advice</a>, and will eventually post an answer (with proof of a more general result) if no one else does so.</p>

<p><strong>NB</strong>: The notation $10^{10^{10^{10}}}$ means the same as $10^{(10^{(10^{10})})}$, and the "millionth digit" means the millionth digit from the left, as usually written (i.e., the most significant digit is leftmost and is called the 1st digit).</p>

<p><strong>Afterthought</strong>: It might have been more impressive to have asked for the $10^{10}$th digit of, say, the $10^{10^{10^{10^{10}}}}$th prime (that digit being $8$), since perhaps no one has ever before computed the ten-billionth digit of a particular prime.</p>

 
Answer: <p>The following bound on the $n$-th prime ($p_n$) is known: for $n &gt; 6$,
$$
n\left(\log{n} + \log\log{n} - 1\right) &lt; p_n &lt; n\left(\log{n} + \log\log{n}\right).
$$
For $n=10^{10^{10^{10}}}$, we have $$\log{n} = 10^{10^{10}}\log{10},$$ a number with ten billion and one digits before the decimal point, and $$\log\log{n} = 10^{10}\log{10} + \log\log{10} \approx 23 025 850 931,$$ a number with eleven digits before the decimal point.  Since the latter number is about ten billion digits shorter than the former, the millionth digit of $p_n$ is the same as the millionth digit of $n\log{n}$; that is, we can ignore the $n\log\log{n}$ correction$^{\dagger}$.  But
$$
n\log{n} = 10^{10^{10^{10}}}\cdot 10^{10^{10}}\log{10} = 10^{\left(10^{10^{10}} + 10^{10}\right)}\log{10}
$$
is a large power of ten multiplied by $\log{10}$, and so its millionth digit is the same as the millionth digit of $\log{10}$ (i.e., the 999999-th digit after the decimal).  This digit can be found in a number of places (e.g., at <a href="http://www.numberworld.org/digits/Log%2810%29/">[numberworld.org]</a>), and is equal to $5$.</p>

<hr>

<p>$^\dagger$ This relies on our knowing that the digits <em>after</em> the millionth digit of $n\log{n}$ are not an enormous string of $9$'s.  In fact, the next digit is $0$ (since that is the millionth digit of $\log{10}$ after the decimal), justifying this step.</p>

==============================
===============================
Question: <p>How to find $\displaystyle\lim_{n\rightarrow\infty}\left({2\sqrt n}-\sum_{k=1}^n\frac{1}{\sqrt k}\right)$ ?</p>

<p>And generally does the limit of the integral of f(x) minus the sum of f(x) exist?
How to prove that and find the limit?</p>

 
Answer: <p>Use $\sqrt{n} = \sum_{k=1}^n \left( \sqrt{k} - \sqrt{k-1} \right)$, then
$$
\begin{eqnarray}
  2 \sqrt{n} - \sum_{k=1}^n \frac{1}{\sqrt{k}} &amp;=&amp; \sum_{k=1}^n \left( 2 \sqrt{k} - 2 \sqrt{k-1} - \frac{1}{\sqrt{k}} \right) = \sum_{k=1}^n \frac{1}{\sqrt{k}}  \left( \sqrt{k}-\sqrt{k-1} \right)^2\\
 &amp;=&amp; \sum_{k=1}^n \frac{1}{\sqrt{k}} \left( \frac{(\sqrt{k}-\sqrt{k-1})(\sqrt{k}+\sqrt{k-1})}{(\sqrt{k}+\sqrt{k-1})} \right)^2 \\
  &amp;=&amp; \sum_{k=1}^n \frac{1}{\sqrt{k} \left(\sqrt{k}+\sqrt{k-1}\right)^2} 
\end{eqnarray}
$$</p>

<p>This shows the limit does exist and $\lim_{n \to \infty} \left( 2 \sqrt{n} - \sum_{k=1}^n \frac{1}{\sqrt{k}} \right) = \sum_{k=1}^\infty  \frac{1}{\sqrt{k} \left(\sqrt{k}+\sqrt{k-1}\right)^2}$.</p>

<p>The value of this sums equals $-\zeta\left(\frac{1}{2} \right) \approx 1.4603545$. This value is found by other means, though:
$$
  2 \sqrt{n} - \sum_{k=1}^n \frac{1}{\sqrt{k}} = 2 \sqrt{n} - \left( \zeta\left(\frac{1}{2}\right) - \zeta\left(\frac{1}{2}, n+1\right)\right) \sim -\zeta\left(\frac{1}{2}\right) - \frac{1}{2\sqrt{n}} + o\left( \frac{1}{n} \right) 
$$ </p>

==============================
===============================
Question: <p>Consider a $2 \times 1$ rectangle split by a diagonal.  Then the two angles
at a corner are ArcTan(2) and ArcTan(1/2), which are about $63.4^\circ$ and $26.6^\circ$.
Of course the sum of these angles is $90^\circ = \pi/2$.</p>

<p>I would like to know if these angles are rational multiples of $\pi$.
It doesn't appear that they are, e.g., $(\tan^{-1} 2 )/\pi$ is computed as</p>

<blockquote>
  <p>0.35241638234956672582459892377525947404886547611308210540007768713728\
  85232139736632682857010522101960</p>
</blockquote>

<p>to 100 decimal places by Mathematica.  But is there a theorem that could be applied here to
prove that these angles are irrational multiples of $\pi$?  Thanks for ideas and/or pointers!</p>

<p>(This question arose thinking about Dehn invariants.)</p>

 
Answer: <p><strong>Lemma:</strong> If $x$ is a rational multiple of $\pi$ then $2 \cos(x)$ is an algebraic integer.</p>

<p><strong>Proof</strong></p>

<p>$$\cos(n+1)x+ \cos(n-1)x= 2\cos(nx)\cos(x) \,.$$</p>

<p>Thus</p>

<p>$$2\cos(n+1)x+ 2\cos(n-1)x= 2\cos(nx)2\cos(x) \,.$$</p>

<p>It follows from here that $2 \cos(nx)= P_n (2\cos(x))$, where $P_n$ is a monic polynomial of degree $n$ with integer coefficients.</p>

<p>Actually $P_{n+1}=XP_n-P_{n-1}$ with $P_1(x)=X$ and $P_0(x)=1$.</p>

<p>Then, if $x$ is a rational multiple of $\pi$ we have $nx =2k \pi$ for some $n$ and thus, $P_n(2 \cos(x))=1$.</p>

<hr>

<p>Now, coming back to the problem. If $\tan(x)=2$ then $\cos(x) =\frac{1}{\sqrt{5}}$. Suppose now by contradiction that $x$ is a rational multiple of $\pi$. Then  $2\cos(x) =\frac{2}{\sqrt{5}}$ is an algebraic integer, and so is its square $\frac{4}{5}$. But this number is algebraic integer and rational, thus integer, contradiction....</p>

<p><strong>P.S.</strong> If $\tan(x)$ is rational, and $x$ is a rational multiple of $\pi$, it follows exactly the same way that $\cos^2(x)$ is rational, thus $4 \cos^2(x)$ is  algebraic integer and rational. This shows that $2 \cos(x) \in \{ 0, \pm 1, \pm 2 \}$.....</p>

==============================
===============================
Question: <p>Let $X$ be a topological space, and $x \in X$ be a point. There are two prevalent conventions on how to define a neighborhood of $x$:</p>

<blockquote>
  <p><strong>Alternative Definitions (Neighborhood):</strong>  </p>
  
  <p>1) A <em>neighborhood</em> of $x$ is any open subset $W \subset X$ such that $x \in W$.<br>
  (This convention is used in Munkres's book for example.)</p>
  
  <p>2) A <em>neighborhood</em> of $x$ is a subset $W \subset X$ such that there exists an open set $A$ such that $x \in A \subset W$.<br>
  (For example this is the definition in Bourbaki's or Willard's "General Topology")</p>
</blockquote>

<p>Thus, every neighborhood in the sense of (1) is a neighborhood in the sense of (2), but not vice-versa.</p>

<p>One often needs to show that a neighborhood of a point $x$ in the sense of (2) is actually open, and often this is a non-trivial verification from the given context. An <strong><em>example</em></strong> that I can come up with now (and this example was a motivation for asking this question) is the following:</p>

<blockquote>
  <p>Let $G$ be a topological abelian group, and $H$ a subgroup of $G$ which is also a neighborhood of $0 \in G$ in the sense of 2). Then one can show that $H$ is in fact an open set.</p>
  
  <p><em>[The trick is to observe that for a given $g \in G$, the map $\phi_{g} :G \rightarrow G$ given by for $x \in G, \phi_{g}(x) = g + x$ is a homeomorphism, and so any neighborhood of a point $g \in G$ is of the form $g + U$, where $U$ is a neighborhood of $0$. Thus, for an $h \in H$, $h + H$ is a neighborhood of $h$, and moreover, $h + H \subset H$ because $H$ is a subgroup.]</em></p>
</blockquote>

<p>The above proof shows that sometimes proving that a neighborhood in the sense of (2) is open is not completely trivial, while a neighborhood in the sense of (1) is always open. At times like these, I wonder why the second definition of a neighborhood is used at all. But I have learned topology primarily from Munkres, and so I might be ignorant of the advantages of definition (2).</p>

<p>So, what do you think are some of the advantages of using (2) as a definition for a neighborhood of a point $x \in X$, where $X$ is a topological space?</p>

<p>(This might be a duplicate question. But I searched a little bit and could not find a question that was exactly similar to this one. So, excuse me if I have asked something that was already asked.)</p>

 
Answer: <p>I don't follow your argument; if anything, it strikes me as an argument for definition 2). You're saying that it may be non-trivial to show that a neighbourhood in the sense of 2) is a neighbourhood in the sense of 1). But why is the definition that contains more non-trivial properties the better one? It's easier to add the non-trivial properties when they're there than to subtract them out when they're not. If we use definition 2), we can easily express both concepts by speaking of "neighbourhoods" and "open neighbourhoods". If we use definition 1), we have to speak of "sets containing neighbourhoods" and "neighbourhoods" -- that's slightly more complicated.</p>

<p>Also, one often doesn't care whether the neighbourhood is open. For example, if a function is constant on a neighbourhood of $x\in\mathbb R$, its derivative at $x$ is zero. If you formulate this in terms of open neighbourhoods and for some reason you have that a function is constant on some closed interval, you have to insert the rather artificial step of specifying an open interval within that closed interval on which the function is constant. Or you could say that if a function is constant on a set containing a neighbourhood of $x\in\mathbb R$, its derivative at $x$ is zero, but that involves the complication with "sets containing neighbourhoods" again.</p>

==============================
===============================
Question: <p>I am a big fan of the oldschool games and I once noticed that there is a sort parity associated to one and only one Tetris piece, the $\color{purple}{\text{T}}$ piece.  This parity is found with no other piece in the game.</p>

<p><strong>Background:</strong> The Tetris playing field has width $10$.  Rotation is allowed, so there are then exactly $7$ unique pieces, each of which is composed of $4$ blocks.</p>

<p>For convenience, we can name each piece by a letter.  See this <a href="http://en.wikipedia.org/wiki/Tetris#Colors_of_Tetriminos">Wikipedia page for the Image</a> ($\color{cyan}{\text{I}}$ is for the stick piece, $\color{goldenrod}{\text{O}}$ for the square, and $\color{green}{\text{S}},\color{purple}{\text{T}},\color{red}{\text{Z}},\color{orange}{\text{L}},\color{blue}{\text{J}}$ are the others)</p>

<p>There are $2$ sets of $2$ pieces which are mirrors of each other, namely $\color{orange}{\text{L}}, \color{blue}{\text{J}}$ and $\color{green}{\text{S}},\color{red}{\text{Z}}$ whereas the other three are symmetric $\color{cyan}{\text{I}},\color{goldenrod}{\text{O}}, \color{purple}{\text{T}}$</p>

<p><strong>Language:</strong> If a row is completely full, that row disappears.  We call it a <strong>perfect clear</strong> if no blocks remain in the playing field.  Since the blocks are size 4, and the playing field has width $10$, the number of blocks for a perfect clear must always be a multiple of $5$.</p>

<p><strong>My Question:</strong>  I noticed while playing that the $\color{purple}{\text{T}}$ piece is particularly special.  It seems that it has some sort of parity which no other piece has.  Specifically:</p>

<blockquote>
  <p><strong>Conjecture</strong>:  If we have played some number of pieces, and we have a perfect clear, then the number of $\color{purple}{\text{T}}$ pieces used must be even.  Moreover, the $\color{purple}{\text{T}}$ piece is the only piece with this property.</p>
</blockquote>

<p>I have verified the second part; all of the other pieces can give a perfect clear with either an odd or an even number used.  However, I am not sure how to prove the first part.  I think that assigning some kind of invariant to the pieces must be the right way to go, but I am not sure.</p>

<p>Thank you,</p>

 
Answer: <p>My colleague, Ido Segev, pointed out that there is a problem with most of the elegant proofs here - Tetris is not just a problem of tiling a rectangle.</p>

<p>Below is his proof that the conjecture is, in fact, false.</p>

<p><img src="https://i.stack.imgur.com/p7MOS.png" alt="Counter proof"></p>

==============================
===============================
Question: <p>In <a href="https://math.stackexchange.com/questions/80092/how-can-i-express-sum-k-0n-binom-1-2k-1k-binom-1-2n-k-without-u/80101#80101">my answer here</a> I prove, using generating functions, a statement equivalent to 
$$\sum_{k=0}^n \binom{2k}{k} \binom{2n-2k}{n-k} (-1)^k = 2^n \binom{n}{n/2}$$
when $n$ is even.  (Clearly the sum is $0$ when $n$ is odd.)  The nice expression on the right-hand side indicates that there should be a pretty combinatorial proof of this statement.  The proof should start by associating objects with even parity and objects with odd parity counted by the left-hand side.  The number of leftover (unassociated) objects should have even parity and should "obviously" be $2^n \binom{n}{n/2}$.  I'm having trouble finding such a proof, though.  So, my question is</p>

<blockquote>
  <p>Can someone produce a combinatorial proof that, for even $n$, $$\sum_{k=0}^n \binom{2k}{k} \binom{2n-2k}{n-k} (-1)^k = 2^n \binom{n}{n/2}?$$</p>
</blockquote>

<p><em>Some thoughts so far:</em> </p>

<p>Combinatorial proofs for $\sum_{k=0}^n \binom{2k}{k} \binom{2n-2k}{n-k}  = 4^n$ are given by <a href="https://math.stackexchange.com/questions/37971/identity-involving-binomial-coefficients/37984#37984">Phira here</a> and by <a href="https://math.stackexchange.com/questions/72367/proof-of-a-combinatorial-identity-sum-i-0n-2i-choose-i2n-i-choose-n/72661#72661">Brian M. Scott here</a>.  The proofs are basically equivalent.  In Phira's argument, both sides count the number of paths of length $2n$ starting from $(0,0)$ using steps of $(1,1)$ and $(1,-1)$.  By conditioning on the largest value of $2k$ for which a particular path returns to the horizontal axis at $(2k,0)$ and using the facts that there are $\binom{2k}{k}$ paths from $(0,0)$ to $(2k,0)$ and $\binom{2n-2k}{n-k}$ paths of length $2n-2k$ that start at the horizontal axis but never return to the axis we obtain the left-hand side.</p>

<p>With these interpretations of the central binomial coefficients $2^n \binom{n}{n/2}$ could count (1) paths that do not return to the horizontal axis by the path's halfway point of $(n,0)$, or (2) paths that touch the point $(n,0)$.  But I haven't been able to construct the association that makes these the leftover paths (nor do all of these paths have even parity anyway).  So perhaps there's some other interpretation of $2^n \binom{n}{n/2}$ as the number of leftover paths.</p>

<p><HR></p>

<p><strong>Update.</strong> <em>Some more thoughts</em>:</p>

<p>There's another way to view the identity $\sum_{k=0}^n \binom{2k}{k} \binom{2n-2k}{n-k}  = 4^n$.  Both sides count the number of lattice paths of length $n$ when north, south, east, and west steps are allowed.  The right side is obvious. The left side has a similar interpretation as before: $\binom{2k}{k}$ counts the number of NSEW lattice paths of length $k$ that end on the line $y=0$, and $\binom{2n-2k}{n-k}$ counts the number of NSEW lattice paths of length $n-k$ that never return to the line $y =0$.  So far, this isn't much different as before.  However, $2^n \binom{n}{n/2}$ has an intriguing interpretation: It counts the number of NSEW lattice paths that end on the diagonal $y = x$ (or, equivalently, $y = -x$).  So maybe there's an involution that leaves these as the leftover paths.  (Proofs of all of these claims can be found on <a href="http://mikespivey.wordpress.com/2012/01/04/morelatticestat/" rel="noreferrer">this blog post</a>, for those who are interested.)</p>

 
Answer: <p>Divide by $4^n$ so that the identity reads (again, for $n$ even)</p>

<p>$$ \sum_{k=0}^n \binom{2k}{k} \binom{2n-2k}{n-k} \frac{1}{4^n} (-1)^k = \frac{1}{2^n} \binom{n}{n/2}. \tag{1}$$</p>

<p><strong>Claim 1</strong>: Select a permutation $\sigma$ of $[n]$ uniformly at random.  For each cycle $w$ of $\sigma$, color $w$ red with probability $1/2$; otherwise, color it blue.  This creates a colored permutation $\sigma_C$.  Then $$\binom{2k}{k} \binom{2n-2k}{n-k} \frac{1}{4^n}$$ is the probability that exactly $k$ of the $n$ elements of a randomly-chosen permutation $\sigma$ are colored red.  (See proof of Claim 1 below.)</p>

<p><strong>Claim 2</strong>: Select a permutation $\sigma$ of $[n]$ uniformly at random.  Then, if $n$ is even, $$\frac{1}{2^n} \binom{n}{n/2}$$ is the probability that $\sigma$ contains only cycles of even length.  (See proof of Claim 2 below.)</p>

<p><strong>Combinatorial proof of $(1)$, given Claims 1 and 2</strong>: For any colored permutation $\sigma_C$, find the smallest element of $[n]$ contained in an odd-length cycle $w$ of $\sigma_C$.  Let $f(\sigma_C)$ be the colored permutation for which the color of $w$ is flipped.  Then $f(f(\sigma_C)) = \sigma_C$, and $\sigma_C$ and $f(\sigma_C)$ have different parities for the number of red elements but the same probability of occurring.  Thus $f$ is a sign-reversing involution on the colored permutations for which $f$ is defined.  The only colored permutations $\sigma_C$ for which $f$ is not defined are those that have only even-length cycles.  However, any permutation with an odd number of red elements must have at least one odd-length cycle, so the only colored permutations for which $f$ is not defined have an even number of red elements.  Thus the left-hand side of $(1)$ must equal the probability of choosing a colored permutation that contains only even-length cycles.  The probability of selecting one of the several colored variants of a given uncolored permutation $\sigma$, though, is that of choosing an uncolored permutation uniformly at random and obtaining $\sigma$, so the left-hand side of $(1)$ must equal the probability of selecting a permutation of $[n]$ uniformly at random and obtaining one containing only cycles of even length.  Therefore,
 $$\sum_{k=0}^n \binom{2k}{k} \binom{2n-2k}{n-k} \frac{1}{4^n} (-1)^k = \frac{1}{2^n} \binom{n}{n/2}.$$</p>

<p>(Clearly, $$\sum_{k=0}^n \binom{2k}{k} \binom{2n-2k}{n-k} \frac{1}{4^n} = 1,$$
which gives another combinatorial proof of the unsigned version of $(1)$ mentioned in the question.)</p>

<p><HR></p>

<p><strong>Proof of Claim 1</strong>: There are $\binom{n}{k}$ ways to choose which $k$ elements of a given permutation will be red and which $n-k$ elements will be blue. Given $k$ particular elements of $[n]$, the number of ways those $k$ elements can be expressed as the product of $i$ disjoint cycles is $\left[ {k \atop i} \right]$, an unsigned <a href="http://en.wikipedia.org/wiki/Stirling_numbers_of_the_first_kind">Stirling number of the first kind</a>.  Thus the probability of choosing a permutation $\sigma$ that has those $k$ elements as the product of $i$ disjoint cycles and the remaining $n-k$ elements as the product of $j$ disjoint cycles is $\left[ {k \atop i} \right] \left[ {n-k \atop j}\right] /n!$, and the probability that the $i$ cycles are colored red and the $j$ cycles are colored blue as well is $\left[ {k \atop i} \right] \left[ {n-k \atop j}\right]/(2^i 2^j n!).$  Summing up, the probability that exactly $k$ of the $n$ elements in a randomly chosen permutation are colored red is
\begin{align}
\frac{\binom{n}{k}}{n!}  \sum_{i=1}^k \sum_{j=1}^{n-k} \frac{\left[ {k \atop i} \right] \left[ n-k \atop j \right]}{2^i 2^j} = \frac{\binom{n}{k}}{n!}  \sum_{i=1}^k  \frac{\left[ {k \atop i} \right]}{2^i} \sum_{j=1}^{n-k} \frac{\left[ {n-k \atop j} \right]}{2^j}.
\end{align}
The two sums are basically the same, so we'll just do the first one.
$$\sum_{i=1}^k  \frac{\left[ {k \atop i} \right]}{2^i} = \left( \frac{1}{2} \right)^{\overline{k}} = \prod_{i=0}^{k-1} \left(\frac{1}{2} + i\right) = \frac{1 (3) (5) \cdots (2k-1)}{2^k} = \frac{1 (2) (3) \cdots (2k-1)(2k)}{2^k 2^k k!} =  \frac{(2k)!}{4^k k!}.$$ 
(The first equality is the well-known property that Stirling numbers of the first kind are used to convert rising factorial powers to ordinary powers.  This property can be proved combinatorially.  For example, Vol. 1 of Richard Stanley's <em><a href="http://www-math.mit.edu/~rstan/ec/ec1/">Enumerative Combinatorics</a></em>, 2nd ed., pp. 34-35 contains two such combinatorial proofs.)</p>

<p>Thus the probability that exactly $k$ of the $n$ elements of a randomly chosen permutation are colored red is $$\frac{\binom{n}{k}}{n!} \frac{(2k)!}{4^k k! } \frac{(2n-2k)!}{4^{n-k} (n-k)!} = \binom{2k}{k} \binom{2n-2k}{n-k} \frac{1}{4^n}.$$</p>

<p><HR></p>

<p><strong>Proof of Claim 2</strong>: Since there can be no odd cycles, $\sigma(1) \neq 1$.  Thus there are $n-1$ choices for $\sigma(1)$.  We have already chosen the element that maps to $\sigma(1)$, but otherwise there are no restrictions on the value of $\sigma(\sigma(1))$, and so we have $n-1$ choices for $\sigma(\sigma(1))$ as well.  </p>

<p>Now $n-2$ elements are unassigned. If $\sigma(\sigma(1)) \neq 1$, then we have an open cycle.  We can't assign $\sigma^3(1) = 1$, as that would close the current cycle at an odd number of elements.  Also, $\sigma(1)$ and $\sigma^2(1)$ are already taken.  Thus there are $n-3$ choices for the value of $\sigma^3(1)$.  If $\sigma(\sigma(1)) = 1$, then we have just closed an even cycle.  Selecting any unassigned element in $[n]$, say $j$, we cannot have $\sigma(j) = j$, as that would create an odd cycle, and $1$ and $\sigma(1)$ are already taken.  Thus we have $n-3$ choices for $\sigma(j)$ as well.</p>

<p>In general, if there are $i$ elements unassigned and $i$ is even, there is either one even-length open cycle or no open cycles.  If there is an open cycle, we cannot close it, and so we have $i-1$ choices for the next element in the cycle.  If there is not an open cycle, we select the smallest unassigned element $j$.  Since we cannot have $\sigma(j) = j$, there are $i-1$ choices for $\sigma(j)$.  Either way, we have $i-1$ choices.  If there are $i$ elements unassigned and $i$ is odd, though, there must always be an odd-length open cycle.  Since we can close it, there are $i$ choices for the next element in the cycle. </p>

<p>All together, then, if $n$ is even then the number of permutations of $[n]$ that contain only cycles of even length is $$(n-1)^2 (n-3)^2 \cdots (1)^2 = \left(\frac{n!}{2^{n/2} (n/2)!}\right)^2 = \frac{n!}{2^n} \binom{n}{n/2}.$$  Thus the probability of choosing a permutation uniformly at random and obtaining one that contains only cycles of even length is $$\frac{1}{2^n} \binom{n}{n/2}.$$ </p>

<p><HR></p>

<p>(I've been thinking about this problem off and on for the two months since I first posted it.  What finally broke it open for me was discovering the interpretation of the unsigned version of the identity mentioned as #60 on Richard Stanley's "<a href="http://www-math.mit.edu/~rstan/bij.pdf">Bijective Proof Problems</a>" document.)</p>

==============================
===============================
Question: <p>I have heard anecdotally that Euclid's Elements was an unsatisfactory development of geometry, because it was not rigorous, and that this spurred other people (including Hilbert) to create their own sets of axioms.</p>

<p>I have two related questions:</p>

<p>1) What is the modern axiomatization of plane geometry? For example, when mathematicians speak of a point, a line, or a triangle, what does this mean formally?</p>

<p>My guess would be that one could simply put everything in terms of coordinates in R^2, but then it seems to be hard to carry out usual similarity and congruence arguments. For example, the proof of SAS congruence would be quite messy. Euclid's arguments are all "synthetic", and it seems hard to carry such arguments out in an analytic framework. </p>

<p>2) What problems exist with Euclid's elements? Why are the axioms unsatisfactory? Where does Euclid commit errors in his reasoning? I've read that the logical gaps in the Elements are so large one could drive a truck through them, but I cannot see such gaps myself.</p>

 
Answer: <p>I can recommend an article <em>Old and New Results in the Foundations of Elementary Plane Euclidean and Non-Euclidean Geometries</em> by Marvin Jay Greenberg, The American Mathematical Monthly, Volume 117, Number 3, March 2010, pages 198-219. One of the great strengths of the article is that I am in it. Marvin promotes what he calls Aristotle's axiom, which rules out planes over arbitrary non-Archimedean fields without leaving the synthetic framework. If you email me I can send you a pdf. </p>

<p>EDIT: Alright, Marvin won an award for the article, which can be downloaded from the award announcement page <a href="http://mathdl.maa.org/mathDL/22/?pa=content&amp;sa=viewDocument&amp;nodeId=3729&amp;pf=1">GREENBERG</a>. The award page, by itself, gives a pretty good response to the original question about the status of Euclid in the modern world. </p>

<p>As far as book length, there are the fourth edition of Marvin's book, <em>Euclidean and Non-Euclidean Geometries,</em> also <em>Geometry: Euclid and Beyond</em> by Robin Hartshorne. Hartshorne, in particular, takes a synthetic approach throughout, has a separate index showing where each proposition of Euclid appears, and so on. </p>

<p>Hilbert's book is available in English, <em>Foundations of Geometry</em>. He laid out a system but left it to others to fill in the details, notably Bachmann and Pejas. The high point of Hilbert is the "field of ends" in non-Euclidean geometry, wherein a hyperbolic plane gives rise to an ordered field $F$ defined purely by the axioms, and in turn the plane is isomorphic to, say, a Poincare disk model or upper half plane model in $F^{\; 2}.$  Perhaps this will be persuasive: from Hartshorne, </p>

<blockquote>
  <p>Recall that an <em>end</em> is an equivalence class of limiting parallel rays</p>
</blockquote>

<p>Addition and multiplication of ends are defined entirely by geometric constructions; no animals are harmed and no numbers are used. In what amounts to an upper half plane model, what becomes the horizontal axis is isomorphic to the field of ends. This accords with our experience in the ordinary upper half plane, where geodesics are either vertical lines or semicircles with center on the horizontal axis. In particular, infinitely many geodesics "meet" at any given  point on the horizontal axis.</p>

==============================
===============================
Question: <p>I am taking a course next term in homological algebra (using Weibel's classic text) and am having a hard time seeing some of the big picture of the idea behind homological algebra. </p>

<p>Now, this sort of question has been asked many times on forums such as mathoverflow (viz. <a href="https://mathoverflow.net/questions/640/what-is-cohomology-and-how-does-a-beginner-gain-intuition-about-it">here</a>
and <a href="https://mathoverflow.net/questions/10879/intuition-for-group-cohomology" title="here">here</a>) so, let me try to make more specific what I'd like to understand, which isn't covered in either of the responses to these  questions. I have a (with no small amount of help from the first link I posted) a fairly good intuition for the uses of homology in topology, what I am more interested in is the intuition for the use of homological algebra in "pure algebra". I want to understand better why studying what we study in homological algebra gives us valuable information about the ring over which we are concerned--what information does it exactly give us? Of course, for commutative rings the question is answered definitively by <a href="http://en.wikipedia.org/wiki/Morita_equivalence#Formal_definition" rel="nofollow noreferrer" title="Morita&#39;s theorem">Morita's theorem</a> which tells us that $R\text{-}\mathbf{Mod}$ is categorially equivalent to $S\text{-}\mathbf{Mod}$ implies that $R$ and $S$ are isomorphic as rings. Fine, I can see why this obviously gives us motivation to study some of the things we study in homological algebra, but the only problem is I have no intuition for why Morita's theorem should be true. Can anyone elucidate this, in the most simple terms possible?</p>

<p>While this very well may be equivalent to what I have asked in the above paragraph (if so, feel free to concatenate answers) I was wondering if someone could more fully explain Eisenbud's analogy that homological algebra is to ring theory as representation theory is to group theory (in your own opinion, I know you don't know what he was thinking).</p>

<p>Lastly, for me, to get a basic motivation/intuition it is necessary for me to see how powerful a subject $X$ can be, in the sense that it can answer questions which (ostensibly!) have nothing to do with subject $X$. The classic example being that <a href="http://en.wikipedia.org/wiki/Burnside_theorem" rel="nofollow noreferrer" title="Burnside&#39;s theorem">Burnside's theorem</a> has nothing directly to do with representation theory (there is no use of character theoretic language in its statement) yet the only "simple" proof uses character theory. Unfortunately, in the realm of pure algebra I have been able to find very few examples of such uses of homological algebra--the only exception being the <a href="http://en.wikipedia.org/wiki/Schur%E2%80%93Zassenhaus_theorem" rel="nofollow noreferrer" title="Scur">Schur-Zassenhaus theorem</a>. So, any (as elementary possible) applications of homological algebra to problems in more elementary algebra (group theory, module theory, ring theory, and to some extent [but preferably less so] commutative algebra) where the statements would seem to suggest that the proof could be self-contained, yet realistically requires homological algebra would be great.</p>

<p>Thank you very much friends, help with any of these questions would go a LONG way to helping a very excited, and eager learner of homological algebra.</p>

 
Answer: <p>I certainly won't try to give a general philosophical answer to your question, but I'll mention a success story that persuaded specialists that homological algebra was an amazingly powerful tool in commutative algebra.  </p>

<p>Auslander, Buchsbaum and Serre proved that a local noetherian ring is regular if and only if it has finite global dimension.<br>
From this it is easy to deduce that the localization at a prime ideal of a regular local ring is still regular.<br>
The statement of that result has nothing to do with homological algebra but since nobody had managed to prove it before, without homological algebra,  this duly impressed algebraists.</p>

<p><strong>Optional technicalities</strong><br>
Let me give some relevant definitions here.<br>
A noetherian local ring $(R,\mathfrak m)$ is called regular if its maximal ideal can be generated by $dim (A)$ (=Krull dimension of $A$) elements.<br>
This definition, due to Zariski, is a purely algebraic way of ensuring that an algebraic variety has no singularities.<br>
The global dimension of the ring $A$ is  the supremum of the projective dimensions $pd_AM$ of its modules $M$.<br>
And $pd_AM$ is the infimum of the lengths of resolutions $0\to P_n\to...\to P_0\to M\to0$ of $M$ by projective $A$-modules $P_i$.</p>

==============================
===============================
Question: <blockquote>
  <p>Let $p$ be a prime. How do I prove that $x^p-x+a$ is irreducible in a field with $p$ elements when $a\neq 0$?</p>
</blockquote>

<p>Right now I'm able to prove that it has no roots and that it is separable, but I have not a clue as to how to prove it is irreducible. Any ideas?</p>

 
Answer: <p>Greg Martin and zyx have given you IMHO very good answers, but they rely on a few basic facts from Galois theory and/or group actions. Here is a more elementary but also a longer approach. </p>

<p>Because we are in a field with $p$ elements, we know that $p$ is the characteristic of our field. Hence, the polynomial $g(x)=x^p-x$ has the property $$g(x_1+x_2)=g(x_1)+g(x_2)$$ whenever $x_1$ and $x_2$ are two elements of an extension field of $\mathbb{F}_p$. By little Fermat we know that $g(k)=k^p-k=0$ for all $k\in \Bbb{F}_p$. Therefore, if $r$ is one of the roots of $f(x)=x^p-x+a$, then $$f(r+k)=g(r+k)+a=g(r)+g(k)+a=f(r)+g(k)=0,$$ so all the elements $r+k$ with $k \in \Bbb{F}_p$ are roots of $f(x)$, and as there are $p$ of them, they must be all the roots. It sounds like you have already shown that $r$ cannot be an element of $\Bbb{F}_p$.</p>

<p>Now assume that $f(x)=f_1(x)f_2(x)$, where both factors $f_1(x),f_2(x)\in \Bbb{F}_p[x]$. From the above consideration we can deduce that
$$
f_1(x)=\prod_{k\in S}(x-(r+k)),
$$
where $S$ is some subset of the field $\Bbb{F}_p$. Write $\ell=|S|=\deg f_1(x)$. Expanding the product we see that
$$
f_1(x)=x^\ell-x^{\ell-1}\sum_{k\in S}(r+k)+\text{lower degree terms}.
$$
This polynomial was assumed to have coefficients in the field $\Bbb{F}_p$. From the above expansion we read that the coefficient of degree $\ell-1$ is $|S|\cdot r+\sum_{k\in S}k$. This is an element of $\Bbb{F}_p$, if and only if the term $|S|\cdot r\in\Bbb{F}_p$. Because $r\notin \Bbb{F}_p$, this can only happen if $|S|\cdot1_{\Bbb{F}_p}=0_{\Bbb{F}_p}$. In other words $f_1(x)$ must be either of degree zero or of degree $p$.</p>

==============================
===============================
Question: <blockquote>
  <p>Let
  $A\stackrel{\alpha}{\rightarrow}B\stackrel{\beta}{\rightarrow}C\rightarrow 0$ a exact sequence of left $R$-modules and $M$ a left $R$-module ($R$
  any ring).</p>
  
  <p>I am trying to prove that the induced sequence $$A\otimes_R M\xrightarrow{\alpha\otimes Id}B\otimes_R M\xrightarrow{\beta\otimes Id}C\otimes_R M\rightarrow 0$$ is
  exact.</p>
</blockquote>

<p>The part I have trouble with is that $\ker{\beta\otimes Id}\subset\text{im }{\alpha\otimes Id}$. </p>

<p>If we had $$\beta(b)\otimes m=0 \text{ if and only if } \beta(b)=0\text{ or }m=0,$$
we could easily conclude using the exactness of the original sequence. However, it is false, right ? (I think of $C_3\otimes \mathbb{Z}/2\mathbb{Z}$, we have $g^2\otimes 1=g\otimes 2=g\otimes 0=0$, where $g$ is a generator of $C_3$.)</p>

<p>I can't see how to proceed then... When a tensor $c\otimes m$ is zero, what can we say on $c$ and $m$ in general ?</p>

 
Answer: <p>The proof mentioned by Frederik and Loronegro is great because it provides a first example of how it can be useful to know that two functors are <a href="http://en.wikipedia.org/wiki/Adjoint_functors">adjoint</a>: left adjoints are right exact. However, you can also argue as follows. Let $D$ be the image of $\alpha \otimes \operatorname{id}$. You get an induced map $(B \otimes M)/D \to C \otimes M$. Let's try to define an inverse: if $(c, m) \in C \times M$ then choose a $b \in B$ such that $\beta(b) = c$, and send $(c, m)$ to $b \otimes m \bmod D$. You can check that this is well defined using the exactness of the original sequence.</p>

==============================
===============================
Question: <p>Can someone point me to a paper, or show here, why symmetric matrices have orthogonal eigenvectors? In particular, I'd like to see proof that for a symmetric matrix $A$ there exists decomposition $A = Q\Lambda Q^{-1} = Q\Lambda Q^{T}$ where $\Lambda$ is diagonal.</p>

 
Answer: <p>For any real matrix $A$ and any vectors $\mathbf{x}$ and $\mathbf{y}$, we have
$$\langle A\mathbf{x},\mathbf{y}\rangle = \langle\mathbf{x},A^T\mathbf{y}\rangle.$$
Now assume that $A$ is symmetric, and $\mathbf{x}$ and $\mathbf{y}$ are eigenvectors of $A$ corresponding to distinct eigenvalues $\lambda$ and $\mu$. Then
$$\lambda\langle\mathbf{x},\mathbf{y}\rangle = \langle\lambda\mathbf{x},\mathbf{y}\rangle = \langle A\mathbf{x},\mathbf{y}\rangle = \langle\mathbf{x},A^T\mathbf{y}\rangle = \langle\mathbf{x},A\mathbf{y}\rangle = \langle\mathbf{x},\mu\mathbf{y}\rangle = \mu\langle\mathbf{x},\mathbf{y}\rangle.$$
Therefore, $(\lambda-\mu)\langle\mathbf{x},\mathbf{y}\rangle = 0$. Since $\lambda-\mu\neq 0$, then $\langle\mathbf{x},\mathbf{y}\rangle = 0$, i.e., $\mathbf{x}\perp\mathbf{y}$.</p>

<p>Now find an orthonormal basis for each eigenspace; since the eigenspaces are mutually orthogonal, these vectors together give an orthonormal subset of $\mathbb{R}^n$. Finally, since symmetric matrices are diagonalizable, this set will be a basis (just count dimensions). The result you want now follows.</p>

==============================
===============================
Question: <p>I recently solved a <a href="http://www.spoj.pl/problems/ONEZERO/" rel="noreferrer">problem</a>, which says that,</p>

<blockquote>
  <p>A positive integer can be multiplied with another integer resulting in
  a positive integer that is composed only of one and zero as digits.</p>
</blockquote>

<p>How can I prove that this is true(currently I assume that it is). Also, is it possible to establish an upper bound on the length(number of digits) of the number generated?</p>

 
Answer: <p>Not only is it possible to find a multiple of $n$ whose decimal expansion consists solely of $0$s and $1$s, it is possible to arrange for all the $1$s to come before all the $0$s.</p>

<p>Suppose first that $n$ is coprime to $10$. Then by Fermat–Euler, $10^{\varphi (9n)} \equiv 1 \pmod{9n}$. Thus $(10^{\varphi (9n)} -1)/9 \equiv 0 \pmod{n}$, and so there is a multiple of $n$ which consists solely of $1$s, namely $(10^{\varphi (9n)} -1)/9$.</p>

<p>Now consider the opposite case that $n=2^a 5^b$ for some natural $a, b$. Then some multiple of $n$ is a power of $10$: either $2^{b-a}n$ or $5^{a-b}n$, depending on whether $a$ or $b$ is greater.</p>

<p>Thus for general $n$, we can express $n$ as $2^a 5^b m$, where $m$ is coprime to $10$. Then we can find a multiple of $m$ which is a string of $1$s and a multiple of $2^a 5^b$ which is a power of $10$, and hence a multiple of $n$ which is a string of $1$s followed by a string of $0$s. Specifically, there are $\varphi (9m)$ $1$s and $\max(a,b)$ $0$s, so $\varphi (9m)+\max(a,b)$ gives an upper bound on the number of digits needed.</p>

==============================
===============================
Question: <p>The title of the question already says it all but I would like to add that I would really like the book to be more about geometric algebra than its applications : it should contain theorems' proofs. Just adding that I have never taken a course on geometric algebra. I'm a 2nd year engineering student, so a "beginner" book style will be very good!!! Also mentioning what would be the prerequisites for mastering the branch is appreciated. Thanks.</p>

 
Answer: <p>The classic reference is David Hestenes' <a href="http://rads.stackoverflow.com/amzn/click/0792355148">New Foundations for Classical Mechanics</a> which is by one of the early developers of geometric algebra.</p>

<p>You may find it easier to learn geometric algebra from <a href="http://assets.cambridge.org/052148/0221/sample/0521480221WS.pdf">Geometric Algebra for Physicists</a> by Doran and Lasenby though (I certainly did). The link is to a sample version of chapter 1.</p>

<p>A reference that I've never looked at is <a href="http://geometricalgebra.org/downloads/ga4cs_toc.pdf">Geometric Algebra for Computer Science</a> which details the geometric algebra approach to computer graphics, robotics and computer vision.</p>

<p>As for prerequisites - certainly some familiarity with linear algebra. For the 'geometric calculus' component a first course in multivariable calculus would be sufficient. Since the big developments in geometric algebra in the 1980s were by physicists, many of the examples tend to be physically motivated (spacetime algebras, relativistic electrodynamics etc) and a passing familiarity with (special) relativity, rigid body dynamics and electromagnetism would be useful (though certainly not essential).</p>

==============================
===============================
Question: <p>I would like to prove the following:  </p>

<blockquote>
  <p>Let $g$ be a monotone increasing function on $[0,1]$. Then the set of points where $g$ is not continuous is at most countable.  </p>
</blockquote>

<p><strong>My attempt:</strong>  </p>

<p>Let $g(x^-)~,g(x^+)$ denote the left and right hand limits of $g$ respectively. Let $A$ be the set of points where $g$ is not continuous. Then for any $x\in A$, there is a rational, say, $f(x)$ such that $g(x^-)\lt f(x)\lt g(x^+)$. For $x_1\lt x_2$, we have that $g(x_1^+)\leq g(x_2^-)$. Thus $f(x_1)\neq f(x_2)$ if $x_1\neq x_2$. This shows an injection between $A$ and a subset of the rationals. Since the rationals are countable, $A$ is countable, being a subset of a countable set.  </p>

<p>Is my work okay? Are there better/cleaner ways of approaching it?  </p>

 
Answer: <p>This looks beautiful to me: or, more truthfully, it looks like exactly what I would write.</p>

<p>If anything else can be asked of this argument, maybe it is a justification that monotone functions have discontinuities as you have described.  I happen to have recently written this up in lecture notes for a "Spivak calculus" course: see $\S 3$ <a href="http://math.uga.edu/~pete/2400LUBS.pdf">here</a>.  Although the fact is quite well known, many texts do not treat it explicitly.  I think this may be a mistake: in the the same section of my notes, I explain how this can be used to give a quick proof of the Continuous Inverse Function Theorem.</p>

==============================
===============================
Question: <p>Wikipedia claims this but only cites an offline proof:</p>

<p>$$\lim_{n\to\infty} 2^n \sqrt{2-\sqrt{2+\cdots+ \sqrt 2}} = \pi$$</p>

<p>for $n$ square roots and one minus sign. The formula is not the "usual" one, like Taylor series or something like that, so I can't easily prove it. I wrote a little script to calculate it and it's clearly visible, but that's not a proof.</p>

 
Answer: <p>It's the sequence of approximations obtained when you approximate the perimeter of the  circle of diameter $1$ with inscribed regular $n$-gons for $n$ a power of $2$.</p>

<p>As I happen to have this TeXed' up, I'll offer:</p>

<p>Suppose regular $2^n$-gons are inscribed in a circle of radius $r$.</p>

<p>Suppose the side length(the length of one "face") $a_n$ of a the inscribed $2^{n}$-gon is known (so, $a_2$ is the side length of the square).
To find the side length of the $2^{n+1}$-gon, one may  apply the Pythagorean Theorem twice to obtain
$$
\tag{1}a_{n+1} = r\sqrt{2-\sqrt{4-{a_n^2\over r^2}}} 
$$</p>

<p>Now, starting with a square,  $$a_2=\sqrt 2 r.$$
Using the recursion formula (1) repeatedly gives: 
$$
a_3%= r\sqrt{2-\sqrt{4-{2r^2\over r^2}}} 
=  r\sqrt{2-\sqrt2}, 
$$
$$
a_4%= r\sqrt{2-\sqrt{4-{ ( r\sqrt{2-\sqrt2})^2       \over r^2}}}  = r\sqrt{2-\sqrt{4-{ ({2-\sqrt2} )    }}} 
= r\sqrt{2-\sqrt{{ {2+\sqrt2}     }}},
$$
and
$$
a_5%=  r\sqrt{2-\sqrt{4-{     (      r\sqrt{2-\sqrt{{ {2+\sqrt2}     }}}            )^2\over r^2}}}   
= 
 r\sqrt{2-\sqrt{ 2+\sqrt{{ {2+\sqrt2}     }}}            }. 
$$ 
$$\vdots$$</p>

<p>Let $b_n=2^n a_n$. Let $P_n=r\cdot b_n$ be the perimeter of the $2^n$-gon.  Let $P$ be the perimeter of the circle.
Then $$
 \lim_{ n\rightarrow \infty} P_n = P.
$$
Note that from the above identity,  it follows that the ratio of the perimeter of a circle to its diameter must be a constant, namely $\lim\limits_{n \rightarrow \infty} b_n$. We call this number $\pi$.</p>

<p><hr>
Below are some particular calculations when the radius of the circle is $1/2$:
$$</p>

<p>\eqalign{
 P_2&amp;=2^1\cdot\sqrt 2 \approx 2.82842712\cr 
 P_3&amp;=2^2\cdot\sqrt{2-\sqrt2}\approx 3.06146746\cr
 P_4&amp;=2^3\cdot\sqrt{2-\sqrt{2+\sqrt2}}\approx3.12144515 \cr
 P_5&amp;=2^4\cdot\sqrt{2-\sqrt{2+\sqrt{2+\sqrt2}}}\approx 3.13654849\cr
 P_6&amp;=2^5\cdot\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\sqrt2}}}}\approx 3.14033116\cr
 P_7&amp;=2^6\cdot\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt2}}}}}\approx 3.14127725\cr
 P_8&amp;=2^7\cdot\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt2}}}}}}\approx 3.1415138 \cr
 P_9&amp;=2^8\cdot\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt{2+\sqrt2}}}}}}}\approx  3.14157294 \cr
}
$$</p>

<p><hr>
For completedness:</p>

<p><b>Remark 1:</b>
Here is the proof that the recursion formula (1) holds:</p>

<p>Let $a_n$ be the side length of the $2^n$-gon.  </p>

<p>To obtain the $2^{n+1}$-gon: take the "outer end point" of the radii of the circle that  bisect the faces of the $2^n$-gon to form the new vertices of the $2^{n+1}$-gon.</p>

<p>We  then have, for $a_{n+1}$, the scenario shown in the following diagram (not to scale):</p>

<p><img src="https://i.stack.imgur.com/tIuPF.png" alt="enter image description here"></p>

<p>Now $$
b^2=r^2-{a_n^2\over4};
$$
whence
$$\eqalign{
a_{n+1}^2={a_n^2\over4} + \Biggl((r-\sqrt{ r^2-{a_n^2\over4}}\ \Biggr)^2
&amp;={a_n^2\over4}+  r^2-2r\sqrt{r^2-{a_n^2\over4}}+r^2 -{a_n^2\over4}\cr
&amp;= 2r^2-2r\sqrt{r^2-{a_n^2\over4}}\cr
&amp;= 2r^2-r^2\sqrt{4-{a_n^2\over r^2}}\cr
&amp;= r^2 \Biggl(2-\sqrt{4-{a_n^2\over r^2}}\ \Biggr).}$$
And, thus
$$
a_{n+1}= r \sqrt{2-\sqrt{4-{a_n^2\over r^2}}}.
$$ </p>

<p><br>
<b>Remark 2:</b> To explain why limit $\lim\limits_{n\rightarrow\infty} P_n=P\ $ holds, I can do no better than refer you to Eric Naslund's comment in his answer.</p>

<p>See also, <a href="http://jsxgraph.uni-bayreuth.de/wiki/index.php/Circle_approximation" rel="nofollow noreferrer">here</a>.</p>

==============================
===============================
Question: <blockquote>
  <p>Can every group be represented by a group of matrices?</p>
</blockquote>

<p>Or are there any counterexamples? Is it possible to prove this from the group axioms?</p>

 
Answer: <p>Every finite group is isomorphic to a matrix group.  This is a consequence of <strong>Cayley's theorem</strong>: <em>every</em> group is isomorphic to a subgroup of its symmetry group.  Since the symmetric group $S_n$ has a natural faithful permutation representation as the group of $n\times n$ 0-1 matrices with exactly one 1 in each row and column, it follows that every finite group is a matrix group.</p>

<p>However, there are infinite groups which are not matrix groups, for example, the symmetric group on an infinite set or the <a href="http://en.wikipedia.org/wiki/Metaplectic_group">metaplectic group</a>.</p>

<hr>

<p>Note that every group can be represented <em>non-faithfully</em> by a group of matrices: just take the trivial representation.  My answer above is for the question of whether every group has a faithful matrix representation.</p>

==============================
===============================
Question: <p>In 1847 <a href="http://en.wikipedia.org/wiki/Gabriel_Lam%C3%A9">Lamé</a> had announced that he had proven Fermat's Last Theorem.  This "proof" was based on the unique factorization in $\mathbb{Z}[e^{2\pi i/p}]$.  However, <a href="http://en.wikipedia.org/wiki/Ernst_Kummer">Kummer</a>, proved that when $p=23$ we do not have unique factorization, and in fact Kummer proved this 3 years earlier in 1844.</p>

<p>My question is:  how can you prove that $\mathbb{Z}[\zeta_p]$ does not have unique factorization when $p = 23$, but does for $p &lt; 23$?</p>

 
Answer: <p>Two remarks.</p>

<ol>
<li><p>Class field theory can be eliminated from Paul's answer: if the degree $(L:K)$ of an extension of number fields is coprime to the class number $h_K$ of $K$, the $h_K \mid h_L$.
The proof follows by observing that the transfer of ideal classes $j: Cl(K) \longrightarrow Cl(L)$ composed with the relative norm is just raising to the $(L:K)$-th power in the class group of $K$. Since the relative degree in the example at hand is $11$, this remark applies here.</p></li>
<li><p>Showing that the class number is $1$ for $p &lt; 23$ is difficult. Kummer proved that the ring of integers inside the 5th roots of unity is Euclidean, but this method becomes impossible to use for $p &gt; 7$. Kummer showed that the class number is the product of two factors $h^-$ and $h^+$, and gave a simple formula for $h^-$. Using this result it is easy to show that $h^- = 1$ for $p &lt; 23$. Showing that the factor $h^+$ is trivial is much more difficult. You can get an idea of the difficulty by consulting Schoof's calculations in the appendix of the 2nd edition of Washington's book.</p></li>
</ol>

==============================
===============================
Question: <p>This is a question from Stromberg related to Steinhaus' Theorem:</p>

<blockquote>
  <p>If $A$ is a set of positive Lebesgue measure, show that $A + A$ contains an interval.</p>
</blockquote>

<p>I can't quite see how to modify the Steinhaus proof though.</p>

 
Answer: <p>I don't know what proof of Steinhaus theorem is used, but we can show the following result:</p>

<blockquote>
  <p>If $A$ and $B$ have a positive Lebesgue measure, then $A+B$ contains an interval.</p>
</blockquote>

<p>We can assume that $A$ and $B$ have finite measure. Indeed, if $\lambda(A)$ is infinite, $A=\bigcup_{n\in\mathbb N}A\cap\left[-n,n\right]$ and we only have to pick $n_0$ such that $\lambda(A\cap \left[-n_0,n_0\right])&gt;0$. If $n_1$ is such that $\lambda(B\cap \left[-n_1,n_1\right])&gt;0$, and we have shown the result for $A$ and $B$ of finite measure, then $A+B\supset (A\cap \left[-n_0,n_0\right])+(B\cap \left[-n_1,n_1\right])\supset I$ and we are done.</p>

<p>Thank to the fact the indicator functions are in $L^2$ and the density of the continuous functions with compact support in $L^2(\mathbb R)$
$$f\colon x\mapsto \mathbf{1}_A*\mathbf{1}_B(x)=\int_{\mathbb R}\mathbf{1}_A(x-t)\mathbf {1}_B(t)d\lambda(t)$$
is continuous .
 Hence the set $O:=\left\{x\in\mathbb R,f(x)&gt;0\right\}$ is open. Since 
$\int_{\mathbb R}f(x)d\lambda(x)=\lambda(A)\cdot\lambda(B)&gt;0$, $O$ is non-empty and therefore contains an open non-empty interval $I$. If $x\notin A+B$, $A\cap(-B+x)=\emptyset$. Indeed, if $y\in A\cap(-B+x)$ then $y=a$ for some $a\in A$, and $y=-b+x$ for some $b\in B$, hence $x=a+b$. So if $x\notin A+B$, $f(x)=0$, and taking the complement, if $f(x)\neq 0$ then $x\in A+B$, hence we got 
$$I\subset O\subset A+B.$$</p>

==============================
===============================
Question: <p>I would like your help with proving that for every  $0 \leq k \leq n$, </p>

<blockquote>
  <p>$$\binom{n}{k}^{-1}=(n+1)\int_{0}^{1}x^{k}(1-x)^{n-k}dx
 . $$</p>
</blockquote>

<p>I tried to integration by parts and to get a pattern or to use the binomial formula somehow, but it didn't go well.</p>

<p>Thanks a lot!</p>

 
Answer: <p>Use induction on $k$. For $k=0$, we have $$(n+1)\int_{0}^{1}(1-x)^{n}dx=-(1-x)^{n+1}\Big|_0^1=1=\binom{n}{0}^{-1}.$$
Now assume that it's true for all $k\leq n-1$ (if $k=n$ we are done), i.e. 
$$\binom{n}{k}^{-1}=(n+1)\int_{0}^{1}x^{k}(1-x)^{n-k}dx.$$
Consider $(n+1)\int_{0}^{1}x^{k+1}(1-x)^{n-k-1}dx$. By integration by parts,
$$(n+1)\int_{0}^{1}x^{k+1}(1-x)^{n-k-1}dx=-\frac{(n+1)}{n-k}\int_{0}^{1}x^{k+1}d((1-x)^{n-k})$$
$$=-\frac{(n+1)}{n-k}\Big[x^{k+1}(1-x)^{n-k}\Big|_0^1-\int_{0}^{1}(1-x)^{n-k}d(x^{k+1})\Big]=\frac{(n+1)(k+1)}{n-k}\int_{0}^{1}x^{k}(1-x)^{n-k}dx.$$
Hence, by the induction assumption (the above equality), 
$$(n+1)\int_{0}^{1}x^{k+1}(1-x)^{n-k-1}dx=\frac{k+1}{n-k}\binom{n}{k}^{-1}=\binom{n}{k+1}^{-1},$$
as required.</p>

==============================
===============================
Question: <p>I'm following the book <em>Measure and Integral</em> of Richard L. Wheeden and Antoni Zygmund. This is the problem 4 of chapter 8.</p>

<p>Consider $E\subseteq \mathbb{R}^n$ a measurable set. In the following all the integrals are taken over $E$, $1/p + 1/q=1$, with $1\lt p\lt \infty$.</p>

<p>I'm trying to prove that $$\int \vert fg\vert =\Vert f \Vert_p\Vert g \Vert_q$$ if and only if $\vert f \vert^p$ is multiple of $\vert g \vert^q$ almost everywhere.</p>

<p>To do this, I want to consider the following cases: if $\Vert f \Vert_p=0$ or $\Vert g \Vert_q=0$, we are done. Then suppose that $\Vert f \Vert_p\ne 0$ and $\Vert g \Vert_q\ne 0$. If $\Vert f \Vert_p=\infty$ or $\Vert g \Vert_q=\infty$, we are done (I hope). If $0\lt\Vert f \Vert_p\lt\infty$ and $0\lt\Vert g \Vert_q\lt\infty$, proceed as follows.</p>

<p>When we are proving the Hölder's inequality, we use that for $a,b\geq 0$
$$ab\leq \frac{a^p}{p}+\frac{b^q}{q},$$
where the equality holds if and only if $b=a^{p/q}$. Explicitly
$$\int\vert fg \vert\leq \Vert f \Vert_p \Vert g \Vert_q \int\left( \frac{\vert f \vert^p}{p\Vert f \Vert_p^p} + \frac{\vert g \vert^q}{q\Vert g \Vert_q^q}\right)=\Vert f \Vert_p \Vert g \Vert_q.$$
From here, we see that the equality in Hölder's inequalty holds iff
$$\frac{\vert fg \vert}{\Vert f \Vert_p \Vert g \Vert_q}=\frac{\vert f \vert^p}{p\Vert f \Vert_p^p} + \frac{\vert g \vert^q}{q\Vert g \Vert_q^q}, \text{ a.e.}$$
iff
$$\frac{\vert g \vert}{\Vert g \Vert_q}=\left( \frac{\vert f \vert}{\Vert f \Vert_p} \right)^{p/q},\text{ a.e.}$$
iff
$$\vert g \vert^q\cdot \Vert f \Vert_p^p=\vert f \vert^p \cdot \Vert g \Vert_q^q,\text{ a.e.}$$
Q.E.D. But, assuming that $\Vert f \Vert_p\ne 0$ and $\Vert g \Vert_q\ne 0$, what about when $\Vert f \Vert_p=\infty$ or $\Vert g \Vert_q=\infty$? How can I deal with it?</p>

<p>In the case of Minkowski inequality, suppose that the equality holds and that $g\not \equiv 0$ (and then $\left( \int \vert f+g \vert^p\right)\ne 0$). I need to prove that $\Vert f \Vert_p$ is multiple of $\Vert g \Vert_q$ almost everywhere. I can reduce to the "Hölder's equality case". I can get
$$\vert f \vert^p=\left( \int \vert f+g \vert^p\right)^{-1}\Vert f \Vert_p^p\vert f+g \vert^p$$
$$\vert g \vert^p=\left( \int \vert f+g \vert^p\right)^{-1}\Vert g \Vert_p^p\vert f+g \vert^p$$
almost everywhere, but again, using the finiteness and nonzeroness of $\Vert f \Vert_p$ and $\Vert g \Vert_p$. </p>

 
Answer: <p>On leo's request I'm posting my comment as an answer.</p>

<p>Your treatment of the equality cases of H&ouml;lder's and Minkowski's inequalities are perfectly fine and clean. There's a small typo when you write that $\int|fg| = \|f\|_p\|g\|_q$ if and only if $|f|^p$ is a constant times of $|g|^q$ almost everywhere (you write the $p$-norm of $f$ and the $q$-norm of $g$ instead).</p>

<hr>

<p>The case where either one $\|f\|_p$ or $\|g\|_q$ (or both) are infinite isn't part of this exercise and simply wrong. You can trisect $E = F \cup G \cup H$ into disjoint measurable sets of positive measure, take $f$ not $p$-integrable on $F$ and zero on $G$, take $g$ not $q$-integrable on $G$ and zero on $F$ and choose $fg$ non-integrable on $H$. Then certainly no power of $|f|$ is a constant multiple of a power of $|g|$ and vice versa, even though equality holds in the H&ouml;lder inequality.</p>

<hr>

<p>A very nice &ldquo;blackboard summary&rdquo; of the equality case (for finite sequences) is given in Steele's excellent book <em><a href="http://books.google.com/books?id=7GDyRMrlgDsC">The Cauchy&ndash;Schwarz Master Class</a></em>. Let $a = (a_1,\ldots,a_n) \geq 0$ and $b = (b_1, \ldots, b_n) \geq 0$ and let $\hat{a}_i = \dfrac{a_i}{\|a\|_p}$ and $\hat{b}_i = \dfrac{b_i}{\|b\|_q}$. Then your argument is subsumed by the diagram (with an unfortunate typo in the upper right corner&mdash;no $p$th and $q$th roots there):</p>

<p><img src="https://i.stack.imgur.com/OxknT.png" alt="Steele&#39;s diagram for Hölder equality"></p>

<p>Mimicking this for functions, let us write $\hat{f} = \dfrac{|f|}{\|f\|_p}$ and $\hat{g} = \dfrac{|g|}{\|g\|_q}$ (assuming of course $\|f\|_p \neq 0 \neq \|g\|_q$), so $\int \hat{f}\vphantom{f}^p = 1$ and $\int \hat{g}^q =1$ and thus your argument becomes
$$
\begin{array}{ccc}
\int |fg| = \left(\int|f|^p\right)^{1/p} \left(\int|g|^q\right)^{1/q} &amp; &amp; |f|^p = |g|^q \frac{\|f\|_{p}^p}{\|g\|_{q}^q} \text{ a.e.}\\
\Updownarrow\vphantom{\int_{a}^b} &amp; &amp; \Updownarrow \\
\int \hat{f}\,\hat{g} = 1 &amp; &amp; \hat{f}\vphantom{f}^p = \hat{g}^q \text{ a.e.} \\
\Updownarrow\vphantom{\int_{a}^b} &amp; &amp; \Updownarrow \\
\int \hat{f}\,\hat{g} = \frac{1}{p} \int \hat{f}\vphantom{f}^p + \frac{1}{q} \int \hat{g}^q &amp; \qquad \iff \qquad &amp;
\hat{f}\,\hat{g} = \frac{1}{p} \hat{f}\vphantom{f}^p + \frac{1}{q} \hat{g}^q \text{ a.e.}
\end{array}
$$</p>

<p>I suggest that you draw a similar diagram for the equality case of Minkowski's inequality.</p>

==============================
===============================
Question: <p>We are familiar with the nifty fact that given the Fibonacci series $F_n = 0, 1, 1, 2, 3, 5, 8,\dots$ then $0.0112358\dots\approx 1/89$. In fact,</p>

<p>$$\sum_{n=0}^{\infty}\frac{F_n}{10^n} = \frac{10}{89}$$</p>

<p>How do we prove that, more generally, for $p &gt; 1$ then,</p>

<p>$$\sum_{n=0}^{\infty}\frac{F_n}{p^n} = \frac{p}{p^2-p-1}$$</p>

<p>(The above simply was the case $p = 10$.)</p>

 
Answer: <p>You can use Binet's formula, $$F_n=\frac{\phi^n-(-\phi)^{-n}}{\sqrt 5}$$ along with the usual geometric series formula to prove your claim:</p>

<p>$$\begin{align*}\sum_{n=0}^{\infty}\frac{F_n}{p^n}&amp;=\frac1{\sqrt 5}\left(\frac1{1-\phi/p}-\frac1{1+(p\phi)^{-1}}\right)\\&amp;=\frac{p(\phi^2+1)/(\sqrt 5)}{(p-\phi)(p\phi +1)}\\&amp;=\frac{p\phi}{\phi p^2-(\phi^2-1)p-\phi}\\&amp;=\frac{p\phi}{\phi p^2-\phi p-\phi}\\&amp;=\frac{p}{p^2-p-1}\end{align*}$$</p>

==============================
===============================
Question: <p>I am working on a project presentation and would like to illustrate that it is often difficult or impossible to estimate how long a task would take. I’d like to make the point by presenting three math problems (proofs, probably) that on the surface look equally challenging.  But…</p>

<ul>
<li>One is simple to solve (or prove)</li>
<li>One is complex to solve (or prove) </li>
<li>And one is impossible</li>
</ul>

<p>So if a mathematician can’t simply look at a problem and say, “I can solve that in a day, or a week, or a month, how can anyone else that is truly solving a problem? The very nature of problem solving is that we don’t know where the solutions lies and therefore we don’t know how long it will take to get there.</p>

<p>Any input or suggestions would be greatly appreciated.</p>

 
Answer: <p>This isn't exactly what you're asking for, but it should serve the same purpose very nicely. </p>

<p>Hilbert gave a talk in 1920 or so in which he discussed the difficulty of various problems. </p>

<p>He said that great progress had been made in analytic number theory in recent years, and he expected to live to see a proof of the Riemann Hypothesis. </p>

<p>Fermat's Last Theorem, he said, was harder; maybe the youngest members of his audience would live to see a proof. </p>

<p>But the problem of determining whether $2^{\sqrt2}$ is transcendental was so hard that not even the children of the youngest people in the audience would live to see a solution to that one. </p>

<p>With the benefit of hindsight, we can see that Hilbert had it exactly backwards. </p>

<p>$2^{\sqrt2}$ was settled in 1929 - Hilbert lived to see it. </p>

<p>Fermat, as we know, held out until the 1990s. </p>

<p>And the Riemann Hypothesis is still unsettled. </p>

<p>The point of the story is not to make fun of Hilbert. The point of the story is that if even Hilbert, the strongest mathematician of his era, could be so wrong in judging the relative difficulty of various mathematical problems, then it must be a really hard thing to do - which, I think, is the point you are trying to make. </p>

==============================
===============================
Question: <p>Is there an exact or good approximate expression for the expectation, variance or other moments of the maximum of $n$ independent, identically distributed gaussian random variables where $n$ is large?</p>

<p>If $F$ is the cumulative distribution function for a standard gaussian and $f$ is the probability density function, then the CDF for the maximum is (from the study of order statistics) given by</p>

<p>$$F_{\rm max}(x) = F(x)^n$$</p>

<p>and the PDF is</p>

<p>$$f_{\rm max}(x) = n F(x)^{n-1} f(x)$$</p>

<p>so it's certainly possible to write down integrals which evaluate to the expectation and other moments, but it's not pretty. My intuition tells me that the expectation of the maximum would be proportional to $\log n$, although I don't see how to go about proving this.</p>

 
Answer: <p>The $\max$-central limit theorem (<a href="http://en.wikipedia.org/wiki/Fisher%E2%80%93Tippett%E2%80%93Gnedenko_theorem">Fisher-Tippet-Gnedenko theorem</a>) can be used to provide a decent approximation when $n$ is large. See <a href="http://reference.wolfram.com/mathematica/ref/ExtremeValueDistribution.html#6764486">this example</a> at reference page for extreme value distribution in <em>Mathematica</em>.</p>

<p>The $\max$-central limit theorem states that $F_\max(x) = \left(\Phi(x)\right)^n \approx F_{\text{EV}}\left(\frac{x-\mu_n}{\sigma_n}\right)$, where $F_{EV} = \exp(-\exp(-x))$ is the cumulative distribution function for the extreme value distribution, and 
$$
   \mu_n = \Phi^{-1}\left(1-\frac{1}{n} \right) \qquad \qquad
   \sigma_n = \Phi^{-1}\left(1-\frac{1}{n} \cdot \mathrm{e}^{-1}\right)- \Phi^{-1}\left(1-\frac{1}{n} \right)
$$
Here $\Phi^{-1}(q)$ denotes the inverse cdf of the standard normal distribution.</p>

<p>The mean of the maximum of the size $n$ normal sample, for large $n$, is well approximated by
$$ \begin{eqnarray}
  m_n &amp;=&amp;  \sqrt{2} \left((\gamma -1) \Phi^{-1}\left(1-\frac{1}{n}\right)-\gamma  \Phi^{-1}\left(1-\frac{1}{e n}\right)\right) \\ &amp;=&amp; \sqrt{\log \left(\frac{n^2}{2 \pi  \log \left(\frac{n^2}{2\pi} \right)}\right)} \cdot \left(1 + \frac{\gamma}{\log (n)} + \mathcal{o} \left(\frac{1}{\log (n)} \right) \right) 
\end{eqnarray}$$
where $\gamma$ is the <a href="http://en.wikipedia.org/wiki/Euler%E2%80%93Mascheroni_constant">Euler-Mascheroni constant</a>.</p>

==============================
===============================
Question: <p>Prove $x = \sqrt[100]{\sqrt{3} + \sqrt{2}} + \sqrt[100]{\sqrt{3} - \sqrt{2}}$ is irrational.</p>

<p>I can prove that $x$ is irrational by showing that it's a root of a polynomial with integer coefficients and use rational root theorem to deduce it must be either irrational or an integer and then show it's not an integer, therefore, it must be irrational.</p>

<p>I was wondering what are the other methods to prove $x$ is irrational. I'd be very interested in seeing alternative proofs.</p>

 
Answer: <p>Let $y = \sqrt[100]{\sqrt{3} + \sqrt{2}}$. Then $x = y + {1 \over y}$. Suppose $x$ were some rational number $q$. Then $y^2 - qy  + 1 = 0$. This means ${\mathbb Q}(y)$ is a field extension of ${\mathbb Q}$ of degree two, and every rational function of $y$ is in this field extension. This includes $y^{100} = \sqrt{3} + \sqrt{2}$, and $y^{-100} = \sqrt{3} - \sqrt{2}$. So their sum and difference is also in ${\mathbb Q}(y)$. Hence ${\mathbb Q}(\sqrt{2},\sqrt{3}) \subset {\mathbb Q}(y)$. But ${\mathbb Q}(\sqrt{2},\sqrt{3})$ is an extension of ${\mathbb Q}$ of degree 4, a contradiction. </p>

<p>You can make the above more elementary by showing successive powers of $y$ are always of the form $q_1y + q_2$ with $q_1$ and $q_2$ rational and eventually showing some $q_3\sqrt{2} + q_4\sqrt{3}$ must be rational, a contradiction.</p>

==============================
===============================
Question: <p>The statement is simply that the sequence $\left(1+\frac{1}{n}\right)^n$ is increasing. </p>

<p>Since the numbers $n^m$ have quite natural combinatorial interpretations, it makes me wonder if a combinatorial proof exists, but I haven't been able to find one.</p>

<p>For example, if we let $S_{n,m}$ denote the set of function $\{1, \dots, n\} \to \{1, \dots, m\}$, then a proof would follow from the construction of an injection $S_{2n+1,n+1} \hookrightarrow S_{n, n} \times S_{n+1,n+2} $, or of a surjection going the other way.</p>

 
Answer: <p>I managed to come up with a combinatorial proof of the statement in t.b.'s comment. I would guess a similar argument solves the original problem. Anyway, let $n$ be a positive integer. We will prove that
$$ n^{2n+1} &gt; (n-1)^n(n+1)^{n+1}.$$
After multiplying by through by $n$ and performing some trivial (though slightly arcane) manipulations, we see this is equivalent to proving
$$(n^2)^{n+1} &gt; (n^2-1)^{n+1} + (n+1) \cdot (n^2-1)^n.$$
Now for the combinatorics (see problem statement for notation). The LHS counts the functions in $S_{n+1,n^2}$. The RHS counts only the functions in $S_{n+1,n^2}$ which do <em>not</em> take the value $1$ (via the first term) or else take the value $1$ <em>exactly once</em> (via the second term). And, well, that's it!!</p>

<hr>

<p><strong>Added:</strong> Okay I think I figured out how to do the original problem in the same sort of way. The combinatorial step is a bit clumsier for some reason. Maybe someone else can see a better way? As before, let $n$ be a positive integer. We will prove that
$$(n-1)^{n-1}(n+1)^n &gt; n^{2n-1}.$$
Multiplying through by $n-1$, this becomes
$$(n^2 -1)^n &gt; (n^2)^n - n \cdot (n^2)^{n-1}$$
or, equivalently,
$$(n^2 -1)^n + n \cdot (n^2)^{n-1} &gt; (n^2)^n.$$
This last bound can be proven combinatorially. On the RHS we have all the functions in $S_{n,n^2}$. The first term on the LHS counts the functions in $S_{n,n^2}$ which never take the value $1$. Let $S$ be the set of functions in $S_{n,n^2}$ which <em>do</em> take the value $1$. We need to prove $S$ has less than $n \cdot (n^2)^{n-1}$ elements. We can inject $S$ into $\{1,\ldots,n\} \times S_{n-1,n^2}$ by sending $f \in S$ to the pair $(x,f_x)$ where $x$ is the smallest member of $\{1,\ldots,n\}$ with $f(x) = 1$, and $f_x$ is obtained from $f$ by "skipping" over $x$ (in order to get a function with one less element in the domain). In order to see the inequality is strict, note that (I think maybe assuming $n \geq 2$) $(n,1)$ is not in the range of this injection (here $1$ is the constant function). This completes the proof.</p>

==============================
===============================
Question: <p>Please correct any mistakes in this proof and, if you're feeling inclined, please provide a better one where "better" is defined by whatever criteria you prefer. </p>

<ol>
<li>Assume $2^{1/2}$ is irrational. </li>
<li>$2^{1/3} * 2^{x} = 2^{1/2} \Rightarrow x = 1/6$. </li>
<li>$2^{1/3} * {2^{1/2}}^{1/3} = 2^{1/2}$.</li>
<li>if $2^{1/2}$ is irrational, then ${2^{1/2}}^{1/3}$ is irrational. </li>
<li>$2^{1/3} = 2^{1/2} / {2^{1/2}}^{1/3}$. </li>
<li>$2^{1/3}$ equals an irrational number divided by an irrational number. </li>
<li>$2^{1/3}$ is an irrational number.</li>
</ol>

 
Answer: <p>Just use the <a href="http://en.wikipedia.org/wiki/Rational_root_theorem">rational root test</a> on the polynomial equation $x^3-2=0$ (note that $\sqrt[3]{2}$ is a solution to this equation).  If this equation were to have a rational root $\frac{a}{b}$ (with $a,b\in \mathbb{Z}$ and $b\not=0$), then $b\vert 1$ and $a\vert 2$.  Thus, $\frac{a}{b}\in\{\pm 1,\pm 2\}$.  However, none of $\pm 1,\pm 2$ are solutions of $x^3-2=0$.  Therefore the equation $x^3-2=0$ has no rational solutions and $\sqrt[3]{2}$ is irrational.</p>

<p>Alternatively, suppose we have $\sqrt[3]{2}=\frac{a}{b}$ for some $a,b\in \mathbb{Z}$, $b\not=0$, and $\gcd(a,b)=1$.  Then, rearranging and cubing, we have $2b^3=a^3$.  Therefore $a^3$ is even....what does that say about $a$?  What, in turn, does that say about $b$?  It's really not that different from the classic proof that $\sqrt{2}$ is irrational.</p>

==============================
===============================
Question: <p>Trying to solve</p>

<blockquote>
  <p>$f(x)$ is uniformly continuous in the range of $[0, +\infty)$ and $\int_a^\infty f(x)dx  $ converges.</p>
</blockquote>

<p>I need to prove that:
$$\lim \limits_{x \to \infty} f(x) = 0$$</p>

<p>Would appreciate your help!</p>

 
Answer: <p>If the integral converges than you have: $\lim_{M\to\infty} \int_a^M f(x) dx = c\ $ for some $c$. Assuming that f does not converge to 0 we have:
$\forall M&gt;0\  \exists p&gt;M: |f(p)|&gt;\varepsilon\ \ $ for some $\varepsilon$.</p>

<p>Without loss of generality we have $\forall M&gt;0\  \exists p&gt;M: f(p)&gt;\varepsilon\ \ $. So there exists $(p_n)_{n=1}^\infty$ s.t. $p_n \to \infty\ $.</p>

<p>Using uniform continuity we have that for $q: |p-q|&lt;\delta\ \ $ the inequality holds: $f(q)&gt;\varepsilon/2\ $. So $\int_a^{p+\delta} f(x) dx - \int_a^{p-\delta} f(x) dx &gt; \delta \cdot \epsilon \ \ $, which means that the sequence $(\int_a^{q_n}f(x)dx)_{n=1}^\infty$ (where $q_0=p_0-\delta,\ q_1=p_0+\delta,\ q_2=p_1-\delta \ldots)\ \ $ is not a Cauchy sequence so it can not converge.</p>

==============================
===============================
Question: <p>An undergraduate was telling me about a puzzle he'd found: the idea was to make $2011$ out of the numbers $1, 2, 3, 4, \ldots, n$ with the following rules/constraints: the numbers must stay in order, and you can only use $+$, $-$, $\times$, $/$, ^ and $!$. In words, "plus minus times divide, exponentiation and factorial". The game was to construct $2011$ with $n$ as small as possible.</p>

<p>To my amazement, he had managed to do $n=5$: indeed</p>

<p>$$((1+2)!)!+(3!)^4-5=2011.$$</p>

<p>He now wanted to solve the puzzle completely by proving that $n=1,2,3,4$ are impossible.</p>

<p>So there's where it gets interesting. My first thought was "computer search -- done". But it's not as easy as that, because factorial is only a unary operator. For example one has to rule out any possible amazing cancellations between very large numbers, e.g. one has to check</p>

<p>$$(1+2)!!!!!!!!!!!!!-3^{(4!!!!!!!!!!!)} \neq  2011.$$</p>

<p>This one in particular is not hard to rule out, because, for example, the left hand side is a multiple of $3$ and the right hand side isn't. In general, this approach can perhaps be used to bound the number of factorials that can occur in any presentation of $2011$ using $1, 2, 3, 4$ only -- but making this rigorous seemed a bit delicate and I wondered if I was missing something. Anyone any ideas?</p>

<p>EDIT: Ron Maimon's heroic attempt to deal with the problem by brute force has led him to the interesting case of $2011=(1+2)!!!...!!!/(3!!!...!!!/4!!!!...!!!)$, which seems to be tougher to rule out than the others: the game here is to prove that $2011$ cannot be written as $3!!!...!!!*4!!!!...!!!/3!!!!...!!!$ for any choices of numbers of factorials.</p>

<p>EDIT: Size considerations seem to deal with the above case. Ultimately it seems that the question I asked can be answered using a rather lengthy, but finite(!), procedure. Thanks Ron for your efforts.</p>

 
Answer: <p>This is simple enough to do by hand, although there are many cases. First, dispose of the case n=1, since 1 is a fixed point for factorials. The case n=2, is similarly trivial, since 2 is also a fixed point for factorials and 2011 is not a factorial.</p>

<p>I will come back to n=3 later, first I will discuss the problem of n=4.</p>

<p>Binary operations make a parse-tree, so that the binary operations you perform give a skeleton upon which you can add factorials. There are exactly five binary trees on 4 nodes, which I list below:</p>

<ul>
<li>pairing: ((12)(34))</li>
<li>forward: (((12)3)4)</li>
<li>backward: (1(2(34)))</li>
<li>center-left: ((1(23))4)</li>
<li>center-right: (1((23)4))</li>
</ul>

<p>These five parenthizations define the five ways to apply binary operations to the leaves 1,2,3,4. The factorials can come on the three leaf, producing 6,720,etc, on the four leaf, producing 24, etc, or on one of the three parenthesized intermediate quantities.</p>

<p>There can be no factorial applied to the top node, since 2011 is not a factorial. For each case, there are exactly four nodes on each tree where you can apply factorial--- on 3, on 4, and on the two intermediate nodes.</p>

<h3>Three quantities cannot do it</h3>

<p>In order to deal with n=4, one has to methodically deal with n=3. In this case, there are only 2 different parenthizations</p>

<ul>
<li>left: (1(23))</li>
<li>right: ((12)3)</li>
</ul>

<p>Factorial is only allowed on 3, and on the value of the inner parenthesis. The outer quantity can't get a factorial, since 2011 is not a factorial.</p>

<p>Now notice: the operation involving 1 is either +,-,*,/,^. The last operation produces 1, reducing the problem size to binary, the divide operation produces nonsense, and the * operator just removes the 1 node. So the only possibility is +/- (EDIT: if you expand the domain to rational numbers, so that you can make 1/(2*3!!!) in intermediate stages, there are many new cases)</p>

<p>This means that, the answer 2011 is either produced from left, in which case 2010 is written using (23), or right, in which case 2011 is written using (33). Both of these are binary and trivially impossible.</p>

<p>This disposes of n=3</p>

<h3>Four quantities mostly reduce to three</h3>

<p>Again, four quantities reduce to 3 when you consider the binary operation involving 1. If this operation is not + or -, it must kill the node (EDIT: excluding rational number operations), thereby reducing the tree to 3,2, or 1 objects.</p>

<p>The remaining possiblity is that 1 adds to a quantity. This produces the following three-quantity problems:</p>

<ul>
<li>((3 3) 4) make 2011</li>
<li>(3(3 4)) make 2011</li>
<li>(2(3 4)) make 2010 or 2011</li>
<li>((2 3) 4) make 2010 or 2011</li>
</ul>

<p>and exactly one true four-quantity problem
* ((1 + (23)) 4)</p>

<p>The true four-quantity problem has 15 possible operation combinations and 4 places to put factorials. I will first dispense with the three-quantity cases.</p>

<h3>2 3 4 or 3 3 4 don't make 2011</h3>

<p>The top node making 2011 can't be ^, because 2011 is not a power. It can't be * because 2011 is prime. This leaves +,-,/. I will call A_n the n-fold factorial iteration:</p>

<ul>
<li>(3_n + 3_m)_k + 4_l</li>
<li>(3_m - 3_n)_k + 4_l</li>
<li>(3_m * 3_n)_k + 4_l</li>
<li>(3_m / 3_n)_k + 4_l</li>
<li><p>(3_m ^ 3_n)_k + 4_l</p></li>
<li><p>(3_n + 3_m)_k - 4_l</p></li>
<li>(3_m - 3_n)_k - 4_l</li>
<li>(3_m * 3_n)_k - 4_l</li>
<li>(3_m / 3_n)_k - 4_l</li>
<li>(3_m ^ 3_n)_k - 4_l</li>
</ul>

<p>For k>0, these cannot be 2011 for parity reasons. For k=0, the products/quotients are excluded for parity reasons (since 3_m and 3_n are never different by 1, their quotient is always even or equal to 1--- 1 is excluded because 2010 is not an iterated factorial of 4, exponentiation case is excluded by divisibility by 3 for l>0 and by the fact that 2015 and 2007 are not powers for l=0). This leaves</p>

<ul>
<li>3_n + 3_m - 4_l</li>
<li>3_n - 3_m + 4_l</li>
<li>3_n - 3_m - 4_l</li>
</ul>

<p>(the all plus case is excluded by size bounds and a finite search). It is impossible for both n,m to be bigger than 1, or else the sum is even. So exactly one of n or m is 1. Then reducing modulo 6 gives 3 for l>1 n>1 and 2011 is 1 modulo 6.</p>

<p>The case where the first 3 is replaced by 2 is handled exactly the same.</p>

<ul>
<li>(3_n + 3_m)_k / 4_l</li>
<li>(3_m - 3_n)_k / 4_l</li>
<li>(3_m * 3_n)_k / 4_l</li>
<li>(3_m / 3_n)_k / 4_l</li>
<li>(3_m ^ 3_n)_k / 4_l</li>
</ul>

<p>This cannot be 2011 for k>0 for primeness reasons (2011 is not the ratio of two factorials other than 2011!/2010! and (33) does not make 8044).  This leaves the k=0 cases:</p>

<p>EDIT: I skipped these nontrivial cases too.</p>

<ul>
<li>(3_n + 3_m) = 2011 4_l</li>
<li>(3_m - 3_n) = 2011 4_l </li>
<li>(3_m * 3_n) = 2011 4_l : UNRESOLVED</li>
<li>3_m = 2011 4_l 3_l</li>
<li>(3_m ^ 3_n) = 2011 4_l</li>
</ul>

<p>The case A!= 2011 B! C! is resolved in the next section, and this takes care of 3_m = 2011 4_l 3_l. The case 3_m^3^n is resolved by noting that the right side factorial must be sufficiently bigger than the left side factorial to include a new prime. A! + B! = 2011 C! requires A>C and B>C and WLOG A>B, so that, dividing, you get C(C+1)...(C+(A-C)) + C(C+1)..(C+(B-C)) = 2011, which requires by primeness C=B or C=B-1 but 3_k and 4_m can never be exactly equal by one-oneness of factorial, and they can't differ by 1, except at m=0 k=0, because they are always both even.</p>

<p>The case 3_m * 3_n = 2011 4_l is unresolved, and is similar to the other unresolved case below.</p>

<p>next there is (3(34)). In this case, the top node again cannot be * or ^ because 2011 is not a power or a product.</p>

<h3>EDIT: MORE (3(34))</h3>

<p>So there are another 15 cases (before, I wrote them down, but didn't work them out.)</p>

<ul>
<li>3_l + (3_m + 4_n)_p :</li>
</ul>

<p>The inside of the paren is at least 7, 7! is 5040, too big, so p=0. The quantities 3_l+3_m is even unless exactly one of l or m is zero, so you have 3 +3_m + 4_n , which is a finite search to pass through 2011.</p>

<ul>
<li>3_l + (3_m - 4_n)_p</li>
</ul>

<p>The inside of the paren cannot be negative, and if it is positive, m must be at least 1, so that the second term is even. This means the first term must be odd, so l=0. This makes 3 + (3_m - 4_n)_p = 2011, and 2008 is not a factorial, so p=0. So you want the difference of 3_m and 4_n to be 2008, which is impossible if n>0 because 2008 isn't 0 mod 3. So 2004 must be 3_m, which is impossible. </p>

<ul>
<li>3_l + (3_m * 4_n)_p</li>
</ul>

<p>2011 is 1 mod 3, and this is zero mod 3.</p>

<ul>
<li>3_l + (3_m / 4_n)_p</li>
</ul>

<p>The question of how to interpret quotients arises here--- I will interpret it as the integer part. So the inner argument of the paren can be 0 or 1 (3/4 and 6/4), making 3_l 2010 or 2011, impossible. So the inner part of the paren is not 0 or 1. The ratio of two factorials which is bigger than 2 is itself an integer, so you get the sum of two factorials, which is even unless l=0 or p=0.</p>

<p>If l=0, you have a factorial which gives 2008, which, since 2008 is not factorial, gives p=0, and 2008 is a ratio of factorials which is impossible, because it doesn't factor into the product of consecutive numbers.</p>

<p>This leaves p=0, l nonzero. (3_l - 2011) * 4_n + 3_m = 0, which by signs requires that 3_l&lt;2011, so that l is 1,2,3. and this is the two cases:</p>

<ul>
<li>(6 - 2011) * 4_n + 3_m = 0</li>
<li>(720 - 2011) * 4_n + 3_m = 0</li>
</ul>

<p>Both these equations are impossible because the nontrivial coefficient, 2005 and 291, cannot be the ration of two factorials, since neither is a product of consecutive numbers.</p>

<ul>
<li>3_l + (3_m ^ 4_n)_p</li>
</ul>

<p>This is zero mod 3, and 2011 is not.</p>

<ul>
<li>3_l - (3_m + 4_n)_p</li>
</ul>

<p>This is zero mod 3 unless n=0 and p=0. 3_l - 3_m + 4 = 2011, meaning that the difference of 2 iterated factorials of 3 needs to be 2007, which is odd, so this is impossible.</p>

<ul>
<li>3_l - (3_m - 4_n)_p</li>
</ul>

<p>This is zero mod 3 unless n=0 and p=0, 3_l - 3_m - 4 = 2011 so that the difference of 2 iterated factorials of 3 needs to be 2015, which is not zero mod 3, so done.</p>

<ul>
<li>3_l - (3_m * 4_n)_p</li>
</ul>

<p>This quantity is zero mod 3, unlike 2011.</p>

<ul>
<li>3_l - (3_m / 4_n)_p</li>
</ul>

<p>These two quantities will both be even unless p=0, l=0, or the quantity in the parentheses is 1. l=0 is excluded since the result is less than 3, and if the quantity in parens is 1, then 3_l must be 2010, not possible. So this requires p=0, and this becomes the diophantine equations</p>

<ul>
<li>3_m = (3_l- 2011)4_n</li>
</ul>

<p>In this case, 3_l must be bigger than 2011, so that l>2. 3_m/4_n is a ratio of two factorials, so it becomes</p>

<p>(A!/(B!(A-B)!))*(A-B)! = (3_l - 2011)</p>

<p>The left side is even in any nontrivial case, and the right side is odd, ruling this out by parity.</p>

<ul>
<li>3_l - (3_m ^ 4^n)_p</li>
</ul>

<p>This is zero mod 3, so not 2011.</p>

<ul>
<li>3_l / (3_m + 4_n)_p </li>
<li>3_l / (3_m - 4_n)_p</li>
<li>3_l / (3_m * 4_n)_p</li>
<li>3_l / (3_m / 4_n)_p</li>
<li>3_l / (3_m ^ 4_n)_p</li>
</ul>

<p>The quotient of two nontrivial factorials is always a product of consecutive numbers, so it cannot be 2011 unless the top is 2011! and the bottom is 2010!. 3_l is never 2011. You can conclude that either l=0 or p=0. l=0 is impossible, since the result would be smaller than 3, so p=0 for all the above. This gives the following 4 diophantine equations</p>

<ul>
<li>3_l = 2011*(3_m + 4_n)</li>
<li>3_l = 2011*(3_m - 4_n)</li>
<li>3_l = 2011*(3_m * 4_n)</li>
<li>3_l = 2011*(3_m ^ 4_n)</li>
<li>3_l = 2011*(3_m / 4_n)</li>
</ul>

<p>For the first four cases, l must be bigger than 3 because 3!!!=720! which does not have a factor of 2011. So these are all big nontrivial factorials.</p>

<p>Consider a more general form of the sum equation, the first case equation above:</p>

<ul>
<li>A! = 2011 (B!+C!)</li>
</ul>

<p>Without loss of generality A>B>C, so dividing by C! gives A!/C! = 2011(B!/C!+1) where the quantities A!/C! and B!/C! are products of consecutive integers, at least one of which is even, because A is not equal to B, and both are even unless B=C+1. So B=C+1, and you get A!/C! = 2011(C+1), or A!=2011(C+1)! which is impossible because 2011 is not a product of consecutive integers. The same thing rules out the minus sign case.</p>

<ul>
<li>A! = 2011 B! C!</li>
</ul>

<p>Again, WLOG, B>C, this can be rewritten:</p>

<ul>
<li>(A!/B!(A-B)!) ( (A-B)!/C!(A-B-C)!) (A-B-C)! = 2011</li>
</ul>

<p>where everything is expressed in terms of the multiplicatively more fundamental binomial coefficients. This requires that each factor is either 1 or 2011, which requires either A=B+C or A=B+C+1, since the last factor can't equal 2011 under any circumstances. In both cases, the two combinatorial coefficients become one, and the result is that C=1 or 0 and B=2010 while A=2011, giving the two trivial solutions 2011! = 2011 * 2010! 1! and 2011! = 2011 2010! 0!, and no others (these trivial solutions don't work, they don't have C>4 for one). Done.</p>

<ul>
<li>A! = 2011 B!^C!</li>
</ul>

<p>Where C>4. Since C>4, and for B bigger than 2, (B!)^4> (2B)! (easy to prove using Stirling's formula), you can conclude that A>2B, so that there is a new prime between B and 2B which is contained in A! which is not contained on the right side, done. This also works when C is 3, so it resolves the parallel case for (33)4 above.</p>

<p>The final case to consider is the quotient of the quotient, which rearranges into</p>

<ul>
<li>3_l * 4_n = 2011 * 3_m</li>
</ul>

<p>here, either l is bigger than 3, or else n is bigger than 2, in order for one of the two objects on the left to have a factor of 2011, so these are big factorials again. The general form</p>

<ul>
<li>A! B! = 2011 C!</li>
</ul>

<p>for large A, B, and C, WLOG A

<ul>
<li>2011 ((A+B)!/A!B!) = (A+B)(A+B-1)..(A+B-y+1)</li>
</ul>

<p>In this formula, A and C are both factorial iterates of 3, while B is a factorial iterate of 4. This means that C is either equal to A (which doesn't work) or enormously bigger than A, being at least A!. To make the size of the right and left hand side equal, B must be about the same size as C.</p>

<p>The LHS is B^A/A!, while the right hand side is B^y, so to match, A and y have to be of the same order.</p>

<p>Now the right hand side is divisible by y!, while the left hand side cannot be divisible by something as big as A!. This is a property of Pascal's triangle, that ((A+B)!/A!B!) is not divisible <em>again</em> by A!. The reason is a simple prime counting:</p>

<p>The number of powers of 2 in N! is N/2 + N/4 + N/8 + N/16... + N/(2^(log_2(N))) where division means floor division. This is asymptotic to N, and this means that the number of powers of 2 just cancel between numerator and denominator when A+B=C. If you want y! to factor into the resulting element of Pascal's triangle, you need extra powers of 2 in C!, an amount about equal to 2A+B. There shouldn't be this many powers of 2 in (C!). The same holds for powers of 3, or of any other prime less than A.</p>

<p>So it should be impossible to satisfy the equation based just on prime-power counting, but this argument doesn't prove it, because B is so enormous compared to A, the error in the power of two estimate for ((A+B)!) is naively bigger than A. But there are odd entries in Pascal's triangle arbitrarily far out, especially near the left edge, so there must be better bounds on the prime powers occuring in Pascal's triangle than what I gave. I am sure that y! can't go into the Pascal triangle entry for large y, but I can't give a solid argument. So I will leave it as unresolved for now.</p>

<p>I am surprised that this case is so much more difficult than the other cases, because it is relatively obvious that purely multiplicative stuff cannot work, that you need additive stuff.</p>

<p>anyway: UNRESOLVED. But the above sketch might resolve it if made precise.</p>

<h3>EDIT (2 (3 4)) doesn't make 2011 (for completeness sake)</h3>

<p>I neglected to work out the 2(34) cases to make 2011. The top node cannot be * or ^, since 2011 is not prime or a power, and it can't be - or /, because 2011 is bigger than 2.</p>

<ul>
<li>2 + (3_m + 4_n)_p</li>
<li>2 + (3_m - 4_n)_p</li>
<li>2 + (3_m * 4_n)_p</li>
<li>2 + (3_m / 4_n)_p</li>
<li>2 + (3_m ^ 4_n)_p</li>
</ul>

<p>p>0 is excluded because 2009 is not a factorial. 3_m + 4_n, 3_m - 4_n  doesn't work for m>0 because of parity, so m=0, and so done. The power case 3_m^4_n is excluded because 2009 is not a power. (3_m *4_n) is zero mod 3, and 2009 is not, so the only case is 3_m=2009 4_m, which is of the form</p>

<ul>
<li>A! = 2009 B!</li>
</ul>

<p>or (A!/B!(A-B)!)(A-B)! = 2009 which is excluded by parity unless A=B+1, when you get the trivial solution 2009! = 2009*2008!, which doesn't match iterated factorials of 3 and 4.</p>

<p>For the sake of allowing fractions, I will consider the only reasonable division process</p>

<ul>
<li>2/(3_m/4_m) = 2*4_m/3_m = 2011</li>
</ul>

<p>this is an even integer when the numerator is bigger than the denominator, namely 2( A!/(B!(A-B)!))(A-B)!, so excluded.</p>

<h3>2 3 4 doesn't make 2010</h3>

<p>Now 2010 = 2 * 3 * 5 * 67. The decomposition into ((23)4) can only get factorials on 3 and 4.</p>

<ul>
<li>(2+3_m)_n +4_p</li>
<li>(2-3_m)_n +4_p</li>
<li>(2*3_m)_n +4_p</li>
<li>(2/3_m)_n +4_p</li>
<li><p>(2^3_m)_n +4_p</p></li>
<li><p>(2+3_m)_n -4_p</p></li>
<li>(2-3_m)_n -4_p</li>
<li>(2*3_m)_n -4_p</li>
<li>(2/3_m)_n -4_p</li>
<li>(2^3_m)_n -4_p</li>
</ul>

<p>for these cases, it is enough to note that 2010 is not divisible by 4, so that n=0 or n=1, or the argument of the factorial is 1, and a tedious enumeration exhausts these.</p>

<ul>
<li>(2+3_m)_n *4_p</li>
<li>(2-3_m)_n *4_p</li>
<li>(2*3_m)_n *4_p</li>
<li>(2/3_m)_n *4_p</li>
<li>(2^3_m)_n *4_p</li>
</ul>

<p>2010 is not divisible by 4, so these are ruled out.</p>

<ul>
<li>(2+3_m)_n /4_p</li>
<li>(2-3_m)_n /4_p</li>
<li>(2*3_m)_n /4_p</li>
<li>(2/3_m)_n /4_p</li>
<li>(2^3_m)_n /4_p</li>
</ul>

<p>These give the relation 2010 4^p = (2*3_n)_m. Looking at it modulo 7 and 67 forbids this equation from holding for any m,n.</p>

<ul>
<li>(2+3_m)_n ^4_p</li>
<li>(2-3_m)_n ^4_p</li>
<li>(2*3_m)_n ^4_p</li>
<li>(2/3_m)_n ^4_p</li>
<li>(2^3_m)_n ^4_p</li>
</ul>

<p>2010 is not a power.</p>

<h3>((1+(23))4) doesn't make 2011</h3>

<p>There are 15 cases, since the top node cannot be * by primeness, and cannot be ^ since 2011 is not a power:</p>

<ul>
<li>(1+(2+3_l)_m)_n + 4_p</li>
<li>(1+(2-3_l)_m)_n + 4_p</li>
<li>(1+(2*3_l)_m)_n + 4_p</li>
<li>(1+(2/3_l)_m)_n + 4_p</li>
<li><p>(1+(2^3_l)_m)_n + 4_p</p></li>
<li><p>(1+(2+3_l)_m)_n - 4_p</p></li>
<li>(1+(2-3_l)_m)_n - 4_p</li>
<li>(1+(2*3_l)_m)_n - 4_p</li>
<li>(1+(2/3_l)_m)_n - 4_p</li>
<li>(1+(2^3_l)_m)_n - 4_p</li>
</ul>

<p>n=0 by parity. This reduces the problem by associativity into 2,3,4 making 2010.</p>

<ul>
<li>(1+(2+3_l)_m)_n / 4_p</li>
<li>(1+(2-3_l)_m)_n / 4_p</li>
<li>(1+(2*3_l)_m)_n / 4_p</li>
<li>(1+(2/3_l)_m)_n / 4_p</li>
<li>(1+(2^3_l)_m)_n / 4_p</li>
</ul>

<p>These are the only truly new cases. In this case, you get 2011*4_p = (1 + (something))_n which is forbidden by looking modulo 2011.</p>

<p>It is very likely that your friend did a search of this sort for the case n=5 to find the special solution.</p>

==============================
===============================
Question: <p>When you're taking a mathematics class, you usually know exactly what sections of a book you need to know, and you can focus your time on these important sections.</p>

<p>However, when studying by myself, even when I'm trying to study the book as thoroughly as possible, I often feel tempted to skip sections of material (maybe a subsection of a chapter, a proof, or an exercise set). Yet at the same time, I don't want to skip it, fearing that what I want to skip might be something really important. Some reasons you might want to skip are:</p>

<ul>
<li>You might feel that you already know it well enough</li>
<li>The proof or the exercises might be too difficult or boring</li>
<li>The section might seem not very important</li>
</ul>

<p>For instance, when self-studying from Apostol's Calculus, I felt the need to skip the section on calculating errors of the taylor series for the log function because it seemed unimportant, and the 'rigorous' proof of the FTC which seemed completely unmotivated.</p>

<p>What are your strategies for studying material in a thorough, complete way? When is it best to skip -- and how should you determine if the material you're skipping is important or not?</p>

 
Answer: <p>I would recommend the following strategies:</p>

<blockquote>
  <p><strong>(1)</strong> If you are having difficulty knowing which parts of a mathematics textbook to skip and which to read, then <strong><em>try to mostly
  read "user-friendly" mathematics textbooks for the time being</em></strong>.
  Usually, there are many mathematics textbooks on a given subject which
  give <strong><em>a roadmap at the beginning of the book detailing which
  sections/chapters of the book can be skipped and which are
  important/interesting</em></strong>. I should remark, however, that sometimes these
  roadmaps are not entirely accurate and alleged optional sections are
  actually mandatory to understanding other parts of the textbook.
  Therefore, it is important to exercise caution, but be assured
  nonetheless that results used in other parts of the textbook will be
  quoted when applied and thus you can always return to the optional
  sections when necessary.</p>
  
  <p><strong>(2)</strong> If you are thinking about skipping certain theorems and proofs rather than entire sections or chapters, then <strong><em>I would recommend you to
  at least read the statements of the theorems which you skip (if you do
  not read the proof)</em></strong>. The reason is that, if the theorem happens to be
  applied later in the book, then <strong><em>you at least know the statement and
  can accept it on faith for the purposes of the application</em></strong>. If the
  theorem is sufficiently important that it is applied several times
  throughout the textbook, then you might feel guilty and go back and
  read the proof later. If not, then it was probably a good choice (in
  terms of time) that you did not read the proof. (I hasten to add,
  however, that <strong><em>some theorems may not have any applications in the
  textbook despite being important and interesting results</em></strong>.)</p>
  
  <p><strong>(3)</strong> Of course, <strong><em>you can also ask on this website whether or not a particular proof is worth reading or whether or not you can skip
  certain material</em></strong>! I believe that the totality of all mathematics
  textbooks read by users on this website is quite a broad and deep
  collection.</p>
  
  <p><strong>(4)</strong> Also, at the basic level, I think <strong><em>it is generally not a good idea to skip too much material</em></strong>. The reason is that experienced authors
  usually choose the material to include in their textbooks very
  carefully. For example, Walter Rudin is an author that comes to mind
  who very rarely includes a result in his textbooks that is not to be
  used elsewhere in the textbook (unless the result is important and
  interesting enough to be stated despite not having applications
  elsewhere in the textbook). In other words, <strong><em>most authors do not
  include arbitrary material in their textbooks and you should have
  faith and accept that whatever they do include merits inclusion</em></strong>. (In
  particular, at least for the time being, <strong><em>I would recommend you to read
  well-known books or books of well-known (and good!) authors</em></strong>.)</p>
  
  <p><strong>(5)</strong> Ultimately, mathematics is an extremely broad and deep subject. You will eventually need to become accustomed to accepting
  results on faith as there are simply too many results worth knowing
  and too little time. Therefore, you should get into the habit of
  applying results whose proof you do not know. I mentioned earlier that
  <strong><em>if you apply the result sufficiently many times, then the chances are
  that it is important and it is worth knowing the proof of the result</em></strong>.
  Of course, you should read a healthy number of proofs as well.</p>
</blockquote>

<p>I hope this helps!</p>

==============================
===============================
Question: <p>I want to understand what values can be simultaneously attained as the arithmetic (AM), geometric (GM), and harmonic (HM) means of finite sequences of positive real numbers. Precisely, for what points $(G, H) \in \mathbb R^2_{\geqslant 0}$, do there exist a $n$-tuple $a = (a_1, a_2, \ldots, a_n) \in \mathbb R^n_{\geqslant 0}$ such that
$$
\begin{align*}
\operatorname{AM}(a) &amp;= 1,
\\  \operatorname{GM}(a) &amp;= G,
\\ \operatorname{HM}(a) &amp;= H.
\end{align*}
$$
Here the constraint on AM provides an implicit normalisation on the $n$-tuple. Note that the AM-GM-HM inequality implies that such an $(G, H)$ must lie in the lower right half of the unit square given by </p>

<blockquote>
  <p>$$ \quad 1 \geqslant G \geqslant H \geqslant 0.\tag{$\ast$}$$</p>
</blockquote>

<p>I think that the problem is quite hard for a general $n$, so I will be content with $n = 4$. In fact, I will also be happy to see <em>any</em> bounds improving on $(\ast)$, either for general $n$ or for specific small values of $n$. Below I sketch the solution for $n= 2$ and $n=3$. </p>

<hr>

<p><strong>Case $n=2$.</strong> It turns out that, for any pair of numbers $(a_1, a_2)$, the three means satisfy a tight relation: $\operatorname{AM} \cdot \operatorname{HM} = \operatorname{GM}^2$. That is, all our points must lie on the parabola $H = G^2$. </p>

<hr>

<p><strong>Case $n=3$.</strong> Now the tight relationship between the means disappears; however, the situation is still rigid enough to permit an algebraic solution. It is easy to check that the three numbers are roots of the cubic equation
$$
x^3 - 3 \operatorname{AM}  x^2 + 3 \frac{\operatorname{GM}^3}{\operatorname{HM}} x - \operatorname{GM}^3 = 0,
$$
which rearranges to
$$
H x^3 - 3H x^2 + 3 G^3 x - G^3 H = 0.
$$
We want this equation to have three real, nonnegative roots. It is well-known† that this is equivalent to the condition that the discriminant of the cubic is nonnegative:
$$
\begin{array}{crl}
&amp; 27 (6 G^6 H^3+3 G^6 H^2 -4 G^9 H-G^6 H^4-4 G^3 H^4) &amp;\geqslant 0
\\ \iff &amp; 6 G^3 H^2+3 G^3 H -4 G^6- G^3 H^3-4 H^3 &amp;\geqslant 0.
\end{array}
$$</p>

<p>Here is a plot of this region for $n=3$ (with $G$ along the $x$-axis and $H$ along the $y$-axis):</p>

<p><img src="https://i.stack.imgur.com/S7cUl.png" alt="AM-GM-HM plot for n=3"></p>

<hr>

<p><strong>Question.</strong> To restate my question:</p>

<blockquote>
  <p>Can you give <em>any</em> bounds on the AM-GM-HM region for <em>any</em> $n \geqslant 4$ that beats $(\ast)$? </p>
</blockquote>

<p>In fact, the following conjecture looks plausible:</p>

<blockquote>
  <p><strong>Conjecture.</strong> For any $n$, there exists $c = c_n &gt; 0$ such that the following holds for any $n$-tuple of positive reals:
  $$
\operatorname{AM} + c \operatorname{HM} \geqslant (1+c) \operatorname{GM}.
$$
  That is, the region lies entirely to the left of the line $G = \frac{1}{1+c} + \frac{c}{1+c} H$.</p>
</blockquote>

<p>This conjecture is inspired by <a href="https://math.stackexchange.com/q/57057">an earlier post</a> that essentially claims that $c = \frac{33}{50}$ works for $n=5$.‡ <strike>The proposed answer in that thread suggests using Lagrange multipliers. But unfortunately, it seems to me that it is rather too sparse on the details; I am not entirely sure how fruitful this approach would be.</strike>* </p>

<hr>

<p>†See the <a href="http://en.wikipedia.org/wiki/Cubic_function#The_nature_of_the_roots" rel="nofollow noreferrer">Wikipedia article on solving a cubic equation</a>.</p>

<p>‡The equivalence between the stated problem and my question is explained clearly in <a href="https://math.stackexchange.com/a/57124">Zarrax's answer in that thread</a>.</p>

<p>*The answer is now deleted.</p>

<p>[Thanks to QED for the plot.]</p>

 
Answer: <p>One way to look at this problem is to look for the extremes of the geometric mean given fixed arithmetic and harmonic means.</p>

<p>The following inequalities can be verified by taking $\log$s and using Jensen:
$$
\frac{1}{\int\frac{1}{x}\;\mathrm{d}\mu}\le\exp\left(\int\log(x)\;\mathrm{d}\mu\right)\le\int x\;\mathrm{d}\mu\tag{1}
$$
That is, $HM\le GM\le AM$.</p>

<p>Scaling the data scales all three means by the same factor, so let us assume that 
$$
\int x\;\mathrm{d}\mu=1\quad\text{(arithmetic mean }=1\text{)}\tag{2}
$$
and
$$
\int\frac{\mathrm{d}\mu}{x}=\frac{1}{h}\quad\text{(harmonic mean }=h\text{)}\tag{3}
$$
and attempt to find the critical values for the $\log$ of the geometric mean:
$$
\int\log(x)\;\mathrm{d}\mu\tag{4}
$$
Taking variances of $(2)$, $(3)$, and $(4)$, we get that for all variations so that the $AM$ is stationary
$$
\int\delta x\;\mathrm{d}\mu=0\tag{5}
$$
and the reciprocal of the $HM$ is stationary,
$$
\int\frac{\delta x}{x^2}\mathrm{d}\mu=0\tag{6}
$$
we should also have that the $\log$ of the geometric mean is stationary:
$$
\int\frac{\delta x}{x}\mathrm{d}\mu=0\tag{7}
$$
Linearity considerations say that $(5)$, $(6)$, and $(7)$ imply that there are constants $a$ and $b$ so that
$$
\frac{1}{x}=a+\frac{b}{x^2}\tag{8}
$$
Multiplying $(8)$ by x and combining with $(2)$ and $(3)$ yields
$$
1=a+\frac{b}{h}\tag{9}
$$
Solving $(8)$ for $x$ and $(9)$ for $b$, we get
$$
x=\frac{1\pm\sqrt{1-4ha(1-a)}}{2a}\tag{10}
$$
To maintain $(2)$, we need a combination of the two values of $x$:
$$
\lambda\frac{1+\sqrt{1-4ha(1-a)}}{2a}+(1-\lambda)\frac{1-\sqrt{1-4ha(1-a)}}{2a}=1\tag{11}
$$
Solving $(11)$ for $\lambda$, we get
$$
\lambda=\frac{1}{2}\left(1+\frac{2a-1}{\sqrt{1-4ha(1-a)}}\right)\quad\text{and}\quad a=\frac{1}{2}\left(1+\frac{2\lambda-1}{\sqrt{1+4\frac{h}{1-h}\lambda(1-\lambda)}}\right)\tag{12}
$$
Note that $(12)$ shows that $\lim\limits_{a\to0}\frac{\lambda}{a}=\lim\limits_{a\to1}\frac{1-\lambda}{1-a}=1$.</p>

<p>For a given harmonic mean, $h$, and split between values of $x$, $\lambda$, $(10)$ and $(12)$ yield that the stationary geometric mean is
$$
\begin{align}
g(h,\lambda)
&amp;=\left(\frac{1+\sqrt{1-4ha(1-a)}}{2a}\right)^\lambda\left(\frac{1-\sqrt{1-4ha(1-a)}}{2a}\right)^{1-\lambda}\\
&amp;=\frac{\left(\sqrt{1+4\frac{h}{1-h}\lambda(1-\lambda)}+1\right)^\lambda\left(\sqrt{1+4\frac{h}{1-h}\lambda(1-\lambda)}-1\right)^{1-\lambda}}{\sqrt{1+4\frac{h}{1-h}\lambda(1-\lambda)}+2\lambda-1}\tag{13}
\end{align}
$$
For each $h\in[0,1]$, $g(h,\lambda)$ is monotonic in $\lambda$ (verified below) and
$$
\lim_{\lambda\to0}g(h,\lambda)=h\qquad\text{and}\qquad\lim_{\lambda\to1}g(h,\lambda)=1\tag{14}
$$
With a countinuous selection of $\lambda$, we can attain any value of $g(h,\lambda)$ between $h$ and $1$.  However, When dealing with $n$ numbers, $\lambda$ can only take the values $\frac{1}{n}\dots \frac{n-1}{n}$. Thus, with a harmonic mean of $h$, the geometric mean can only vary between $g(h,\frac{1}{n})$ and $g(h,\frac{n-1}{n})$.</p>

<p><strong>$\mathbf{n}$ objects with arithmetic mean $\mathbf{=1}$:</strong></p>

<p><img src="https://i.stack.imgur.com/4Dvrt.gif" alt="range of geometric means"></p>

<p><hr>
<strong>Proof that for any $\mathbf{h}$, $\mathbf{g(h,\lambda)}$ is monotonic in $\mathbf{\lambda}$:</strong></p>

<p>Fix $h$. Define
$$
\Delta=\sqrt{1+4\frac{h}{1-h}\lambda(1-\lambda)}\tag{15}
$$
Using $(13)$ and $(15)$, we get that
$$
g(h,\lambda)=\frac{(\Delta+1)^\lambda(\Delta-1)^{1-\lambda}}{\Delta+2\lambda-1}\tag{16}
$$
Equation $(15)$ also implies that
$$
(1-h)\Delta^2+h(2\lambda-1)^2=1\tag{17}
$$
In consideration of $(17)$, define $\eta$ and $\theta$ by
$$
\begin{align}
\sin(\eta)&amp;=\sqrt{h}\\
\cos(\eta)&amp;=\sqrt{1-h}
\end{align}\tag{18}
$$
and
$$
\begin{align}
\sin(\theta)&amp;=\sin(\eta)\;(2\lambda-1)\\
\cos(\theta)&amp;=\cos(\eta)\;\Delta
\end{align}\tag{19}
$$
where $0\le\lambda\le1$ and thus $-\eta\le\theta\le\eta$. Then using the identities
$$
\begin{array}{ccccc}
\cos(\eta)(\Delta+1)&amp;=&amp;\cos(\theta)+\cos(\eta)&amp;=&amp;2\cos\left(\frac{\eta+\theta}{2}\right)\cos\left(\frac{\eta-\theta}{2}\right)\\
\cos(\eta)(\Delta-1)&amp;=&amp;\cos(\theta)-\cos(\eta)&amp;=&amp;2\sin\left(\frac{\eta+\theta}{2}\right)\sin\left(\frac{\eta-\theta}{2}\right)\\
\sin(\eta)2\lambda&amp;=&amp;\sin(\eta)+\sin(\theta)&amp;=&amp;2\sin\left(\frac{\eta+\theta}{2}\right)\cos\left(\frac{\eta-\theta}{2}\right)\\
\sin(\eta)2(1-\lambda)&amp;=&amp;\sin(\eta)-\sin(\theta)&amp;=&amp;2\cos\left(\frac{\eta+\theta}{2}\right)\sin\left(\frac{\eta-\theta}{2}\right)
\end{array}\tag{20}
$$
we get that
$$
\begin{align}
&amp;\left(\frac{1}{\sin(\eta)}\frac{(\Delta+1)^\lambda(\Delta-1)^{1-\lambda}}{\Delta+2\lambda-1}\right)^{2\sin(\eta)}\\
&amp;\vphantom{\Huge{\dfrac{A}{A}}}=\frac{(\cos(\theta)+\cos(\eta))^{\sin(\eta)+\sin(\theta)}(\cos(\theta)-\cos(\eta))^{\sin(\eta)-\sin(\theta)}}{\left(\sin(\eta)\cos(\theta)+\cos(\eta)\sin(\theta)\right)^{2\sin(\eta)}}\\
&amp;\vphantom{\Huge{\dfrac{A}{A}}}=\frac{(2\cos(\frac{\eta+\theta}{2})\cos(\frac{\eta-\theta}{2}))^{\sin(\eta)+\sin(\theta)}(2\sin(\frac{\eta+\theta}{2})\sin(\frac{\eta-\theta}{2}))^{\sin(\eta)-\sin(\theta)}}{\sin(\eta+\theta)^{2\sin(\eta)}}\\
&amp;\vphantom{\Huge{\dfrac{A}{A}}}=\frac{(\sin(\eta+\theta)\sin(\eta-\theta))^{\sin(\eta)}(\cot(\frac{\eta+\theta}{2})\cot(\frac{\eta-\theta}{2}))^{\sin(\theta)}}{\sin(\eta+\theta)^{2\sin(\eta)}}\\
&amp;\vphantom{\Huge{\dfrac{A}{A}}}=\left(\frac{\sin(\eta-\theta)}{\sin(\eta+\theta)}\right)^{\sin(\eta)}\left(\frac{\cos(\theta)+\cos(\eta)}{\cos(\theta)-\cos(\eta)}\right)^{\sin(\theta)}\tag{21}
\end{align}
$$
The logarithmic derivative of $(21)$ is
$$
\begin{align}
&amp;\frac{\mathrm{d}}{\mathrm{d}\theta}\left(\sin(\eta)\log\left(\frac{\sin(\eta-\theta)}{\sin(\eta+\theta)}\right)+\sin(\theta)\log\left(\frac{\cos(\theta)+\cos(\eta)}{\cos(\theta)-\cos(\eta)}\right)\right)\\
&amp;\vphantom{\Huge{A}}=\sin(\eta)(-\cot(\eta-\theta)-\cot(\eta+\theta))\\
&amp;+\cos(\theta)\log\left(\frac{\cos(\theta)+\cos(\eta)}{\cos(\theta)-\cos(\eta)}\right)\\
&amp;+\sin(\theta)\left(\frac{-\sin(\theta)}{\cos(\theta)+\cos(\eta)}+\frac{\sin(\theta)}{\cos(\theta)-\cos(\eta)}\right)\\
&amp;\vphantom{\Huge{\dfrac{A}{A}}}=-2\cos(\eta)+\cos(\theta)\log\left(\frac{\cos(\theta)+\cos(\eta)}{\cos(\theta)-\cos(\eta)}\right)\tag{22}
\end{align}
$$
Dividing $(22)$ by $\cos(\theta)$ and setting $t=\dfrac{\cos(\eta)}{\cos(\theta)}$, yields that $(22)$ vanishes precisely when
$$
-2t+\log\left(\frac{1+t}{1-t}\right)=0\tag{23}
$$
However, $(23)$ vanishes only at $t=0$, but because $-\eta\le\theta\le\eta$, we have $t\ge\cos(\eta)=\sqrt{1-h}$. Therefore, $(22)$ doesn't vanish, and thus, $(21)$ is monotonic.</p>

==============================
===============================
Question: <p>This is Exercise 18.14 from Algebra, Isaacs.</p>

<p>$p_{1}\ ,\ p_{2}\ ,\ ... p_{n}$ are different prime numbers. How to show that $$\mathbb{Q}[\sqrt{p_{1}}, \sqrt{p_{2}}, \ldots, \sqrt{p_{n}} ] = \mathbb{Q}[\sqrt{p_{1}}+ \sqrt{p_{2}}+\cdots + \sqrt{p_{n}}] \quad ?$$  First we can note that the Galois group of the first extension over $\mathbb{Q}$ ( which I call $E$ ) is elementary abelian of order $2^{n}$, so we can prove that the orbit of $\sqrt{p_{1}}+\sqrt{p_{2}}+ ... + \sqrt{p_{n}}$ under $\operatorname{Gal}(E/\mathbb{Q})$ contains $2^{n}$ elements, but how to do so?  </p>

 
Answer: <p>OK, in view of what is written above, I will write down what I had in mind more carefully. Let us take the positive choice of $\sqrt{p_i}$ in each case, so clearly the sum (and each non-empty subsum) of the square roots is non-zero. Let $E$ be as stated in the question, the Galois group of the left-hand extension. The extension is certainly a Galois extension of $\mathbb{Q}.$ Let $\alpha$ be an element of $E$. Then $\alpha(\sqrt{p_i}) = \pm \sqrt{p_i}$ for each $i.$ Let $I$ be the subset of $\{i: 1 \leq i \leq n \}$ such that $\alpha$ fixes $\sqrt{p_i}$ for each $i \in I$, but no other $i.$
Let $s = \sum_{i=1}^{n} \sqrt{p_i}$. Then $s- \alpha(s) = 2\sum_{i \not \in I} \sqrt{p_i},$ which is strictly positive unless $\alpha$ is trivial. Since $E$ is elementary Abelian (I do not think we need to know that it has order $2^n$), we know that every intermediate extension is a Galois extension. Hence $s$ lies in no intermediate extension, and must generate the whole of the left-hand extension. </p>

==============================
===============================
Question: <p>Is it the case that for every non-negative integer $n$, iterating $n \to 2n+1$ eventually produces a prime number? (This is the same as asking whether for every positive integer $n$, there is a non-negative integer $k$ such that $2^k n  - 1$ is prime.) If this is not settled by proof, is there some heuristic argument either way?</p>

 
Answer: <p>The <a href="http://en.wikipedia.org/wiki/Riesel_number">Riesel Numbers</a> are odd numbers $k$ such that $k\cdot 2^N-1$ is never prime.  It is known that there are infinitely many Riesel numbers. It follows that there are infinitely many $n$ such that your iteration, starting at $n$,  produces <strong>no</strong> primes.    </p>

<p>The smallest known Riesel number is $509203$, but there may be smaller ones.  The Riesel numbers are the obscure cousins of the Sierpinski Numbers.  </p>

==============================
===============================
Question: <p>In the book <a href="http://www.scribd.com/doc/64346506/Titu-Andreescu-Zuming-Feng-103-Trigonometry-Problems" rel="noreferrer">101 problems in Trigonometry</a>, Prof. Titu Andreescu and Prof. Feng asks for the proof the fact that $\cos 1^\circ$ is irrational and he proves it. The proof proceeds by contradiction and using the strong induction principle. (Problem on Pg:84, 70 in typeset; solution on Pg:126, 111 in Typeset). However, for Completeness, I'll append it here:</p>

<blockquote>
  <h2>Proof of irrationality of $\cos (1^\circ)$</h2>
  
  <p>Assume for the sake of contradiction, that $\cos(1^\circ)$ is rational. Since, $$\cos(2^\circ)=2\cos^2(1^\circ)-1$$ we have that, $\cos(2^\circ)$ is also rational. Note that, we also have $$\cos(n^\circ +1 ^\circ)+\cos(n^\circ -1 ^\circ)=2\cos(1^\circ)\cdot 
\cos(n^\circ)$$ By Strong induction principle, this shows that $\cos(n^\circ)$ is rational for all integers $n \geq 1$. But, this is clearly false, as for instance, $\cos(30^\circ)=\dfrac{\sqrt{3}}{2}$ is irrational, reaching a contradiction. </p>
</blockquote>

<p>But, as my title suggests, $\sin(1^\circ)$ is irrational, (look at the following image for its value!) <img src="https://i.stack.imgur.com/Ngsdl.gif" alt="Sine 1 degree"> </p>

<p>Is there a proof as short as the above proof or can any of you help me with a proof that bypasses actual evaluation of the above value?</p>

<p>Image Courtesy:  <a href="http://www.efnet-math.org/Meta/sine1.htm" rel="noreferrer">http://www.efnet-math.org/Meta/sine1.htm</a> 
This link explains how to evaluate this value. </p>

<p>My next question is </p>

<blockquote>
  <p>Is $\tan(1^\circ)$ rational and is there a short proof that asserts or refutes its rationality?</p>
</blockquote>

<p>P.S.: This is not a homework question.</p>

 
Answer: <p>$\sin(1^\circ) = \cos(89^\circ)$, and since 89 is relatively prime to 360, the proof for $\cos 1^\circ$ works with almost no change.</p>

<p>More precisely: Assume that $\cos(89^\circ)$ is rational. Then, by the same induction as before with every $1^\circ$ replaced by $89^\circ$ we get that $\cos(89n^\circ)$ is rational for every $n\in\mathbb N$. In particular, since $150\times 89=37\times 360+30$, we get that $$\cos(150\times 89^\circ)=\cos(37\times 360^\circ+30^\circ)=\cos(30^\circ)$$ is rational, a contradiction.</p>

<p>For $\tan(1^\circ)$, a slight variant of the same proof works. Assume that $\alpha = \tan(1^\circ)$ is rational. Then $1+\alpha i$ is in $\mathbb Q[i]$, and then $\tan(n^\circ)$, being the ratio between the imaginary and real parts of $(1+\alpha i)^n$ is also rational. But $\tan(30^\circ)$ is not rational, so $\tan(1^\circ)$ cannot be either.</p>

==============================
===============================
Question: <p>Well I am quite sure it's known (I mean number theory exists thousands of years), warning beforehand, it may look like numerology, but I try not to go to mysticism.</p>

<p>So I was in a bus, and from boredom I started just adding numbers in the next way:
$$1+1=2$$
$$2+2=4$$
$$4+4=8....$$</p>

<p>etc up to $32,768$ (it was quite boring, I can tell... :-)), I didn't have calculator.</p>

<p>and notice that if I keep adding the digits until I get a number from 1 to 10, I get that for example for $8+8=16$, $1+6=7$, now seven steps after this, at $512+512=1024$, which $1+2+4=7$, and again after $7$ steps $32768+32768=65536$, and adding $6+5+5+3+6=10+12+3=25$, $2+5=7$.
So this led me to cojecture that this repetition may occur endlessly.</p>

<p>Now ofcourse I can programme some code that will check for large numbers, but I am tired, long day.
So if this indeed the case (which could be disproved, but even then I would wonder when this repetition stops) then why?</p>

<p>As I said, I am tired, it may make no sense, and I might have done mistakes in my calculations, and it may be trivial.</p>

<p>Either way, if you have some answer, I would like to hear it.</p>

 
Answer: <p>"Adding the digits until [you] get a number from $1$ to $10$" is the same as finding the remainder when dividing by $9$ (except that you would get $9$ instead of $0$ by adding digits, and there is no reason to stop with $10$: you can add the digits to get $1$).</p>

<p>It turns out, by something called <a href="http://en.wikipedia.org/wiki/Euler%27s_Theorem">Euler's Theorem</a>, that if $a$ is not divisible by $3$, then $a^6$ always leaves a remainder of $1$ when divided by $9$. In particular, $2^6$ has remainder $1$ when divided by $7$.</p>

<p>Another property of remainders is that if $a$ leaves a remainder of $r$ when divided by $9$, and $b$ leaves a remainder of $s$, then $ab$ leaves the same remainder as $rs$. </p>

<p>So, that means that if $2^n$ leaves a remainder of $r$, then $2^n\times 2^6 = 2^{n+6}$ will leave the same remainder as $r\times 1 = r$; that is, the same remainder as $2^n$. So adding the digits of $2^n$ until you get a single number between $1$ and $9$ will give you the same answer as doing it for $2^{n+6}$. This is what you observed: $8=2^3$, and $512=2^9 = 2^{3+6}$. You will get the same answer ($7$) with $2^{15}$, $2^{21}$, $2^{27}$, etc.</p>

<p>I note that you were slightly off in describing $512$ as being "seven steps after" $8$: it's really only six steps later: 
$$8\stackrel{1}{\mapsto} 16 \stackrel{2}{\mapsto}32 \stackrel{3}{\mapsto}64\stackrel{4}{\mapsto}128\stackrel{5}{\mapsto}256\stackrel{6}{\mapsto}512.$$</p>

==============================
===============================
Question: <p>I am aware that this might turn into a discussion, but I have a feeling this might have an <strong>answer</strong> (maybe something historical?) instead. I'm hoping that those with speculations keep it in the comments.</p>

<p>I have started to work on formal proof writing this quarter, and I discovered that the key to getting to some of them is to think of the problem "backwards." But, alas, when I wrote my proof starting with this, my professor said I shouldn't do it. But why not? It gives the reader a sense of what motivated this type of proof and allows for more understanding, doesn't it?</p>

<p>Mods: Feel free to close, if this turns out to be too much of a discussion. I will be in chat for those willing to discuss this.</p>

 
Answer: <p>One main problem with writing an argument backwards, especially for a student beginning to learn about proofs, is that it would be much more difficult to keep track of what is an assumption and what is a goal. In a proof that $A\implies B$, we should never along the way assume that $B$ is true, otherwise we are being circular; but if the statement of $B$ is written down on your paper already, you might get confused and think you'd already demonstrated it to be true. I'm not saying this will always happen, just that it is a greater risk.</p>

<p>While it's true that "thinking backwards" can sometimes be a useful strategy for attacking a problem, and explaining your strategy to the reader can be a good <em>addition</em> to a formal proof, it is not a substitute; one should always be able to explain the argument starting from your given information and axioms, and proceeding to the desired statement completely "forwards". It is essential to get sufficient practice with phrasing your argument this way. </p>

==============================
===============================
Question: <p>Although I know very little category theory, I really do find it a pretty branch of mathematics and consider it quite useful, especially when it comes to laying down definitions and unifying diverse concepts. Many of the tools of category theory seem quite useful to me, such as Mitchell's embedding theorem, which allows one to prove theorems in any abelian category using diagram chasing. It lets me the ability to treat lots of objects I would not otherwise feel comfortable with as if they were modules over some ring; in essence, I feel like I've gained some tools from it.</p>

<p>However, I simply cannot see where to apply the Yoneda lemma to some useful end. This is not to say that I don't think it is a very pretty lemma, which I do, or that I do not appreciate the aesthetic of being able to study an object in a category by looking at the morphisms from that object, which I also do. And I do find it useful to consider the modules over a ring rather than the ring itself when studying that ring, or to treat groups as subgroups of permutation groups, which are the two applications I've heard of the Yoneda lemma. The problem is that I already knew these things could be done. Essentially, I don't feel like I've gained any tools from the Yoneda lemma. </p>

<p>My question is this: how can the Yoneda lemma be applied to make problems more approachable, other than in cases like those I have listed above which can easily be treated without a general result like the Yoneda lemma? Basically, what <strong>new</strong> tools does it give us?</p>

 
Answer: <p>Some elaboration on Dylan Moreland's comment is in order. Consider the gadget $\text{GL}_n(-)$. What sort of gadget is this, exactly? To every commutative ring $R$, it assigns a group $\text{GL}_n(R)$ of $n \times n$ invertible matrices over $R$. But there's more: to every morphism $R \to S$ of commutative rings, it assigns a morphism $\text{GL}_n(R) \to \text{GL}_n(S)$ in the obvious way, and this assignment satisfies the obvious compatibility conditions. That is, $\text{GL}_n(-)$ defines a functor
$$\text{GL}_n(-) : \text{CRing} \to \text{Grp}.$$</p>

<p>Composing this functor with the forgetful functor $\text{Grp} \to \text{Set}$ gives a functor which turns out to be representable by the ring 
$$\mathbb{Z}[x_{ij} : 1 \le i, j \le n, y]/(y \det_{1 \le i, j \le n} x_{ij} - 1).$$</p>

<p>Now, this ring itself only defines a functor $\text{CRing} \to \text{Set}$. What extra structure do we need to recover the fact that we actually have a functor into $\text{Grp}$? Well, for every ring $R$ we have maps
$$e : 1 \to \text{GL}_n(R)$$
$$m : \text{GL}_n(R) \times \text{GL}_n(R) \to \text{GL}_n(R)$$
$$i : \text{GL}_n(R) \to \text{GL}_n(R)$$</p>

<p>satisfying various axioms coming from the ordinary group operations on $\text{GL}_n(R)$. These maps are all natural transformations of the corresponding functors, all of which are representable, so <em>by the Yoneda lemma</em> they come from morphisms in $\text{CRing}$ itself. These morphisms endow the ring above with the extra structure of a commutative <a href="http://en.wikipedia.org/wiki/Hopf_algebra">Hopf algebra</a>, which is equivalent to endowing its spectrum with the extra structure of a <a href="http://en.wikipedia.org/wiki/Group_object">group object</a> in the category of schemes, or an affine <a href="http://en.wikipedia.org/wiki/Group_scheme">group scheme</a>.</p>

<p>In other words, in a category with finite products, saying that an object $G$ has the property that $\text{Hom}(-, G)$ is endowed with a natural group structure in the ordinary set-theoretic sense is equivalent to saying that $G$ itself is endowed with a group structure in a category-theoretic sense. I discuss these ideas in some more detail, using a simpler group scheme, in <a href="http://qchu.wordpress.com/2011/01/21/structures-on-hom-sets/">this blog post</a>. </p>

==============================
===============================
Question: <p>Given: $a = qb + r$</p>

<p>Then it holds that $\gcd(a,b)=\gcd(b,r)$. That doesn't sound logical to me. Why is this so?</p>

<hr>

<p>Addendum by LePressentiment on 11/29/2013: (in the interest of <a href="http://meta.math.stackexchange.com/a/4110/53259">http://meta.math.stackexchange.com/a/4110/53259</a> and averting a duplicate)</p>

<p>What's the intuition behind this result? I only recognise the proof and examples solely due to algebraic properties and formal definitions; I'd like to apprehend the result naturally. </p>

 
Answer: <p>If $d$ is a divisor of $a$ and of $b$, then
$$
\begin{align}
a &amp; = dn, \\
b &amp; = dm.
\end{align}
$$
So $$a-b= dn-dm=d(n-m)= (d\cdot\text{something}).$$
So $d$ is a divisor of $a-b$.</p>

<p>Thus: <b>All divisors that $a$ and $b$ have in common are divisors of $a-b$.</b></p>

<p>If $d$ is a divisor of $a$ and of $a-b$, then
$$
\begin{align}
a &amp; = dn, \\
a-b &amp; = d\ell.
\end{align}
$$
So
$$
b=a-(a-b)=dn-d\ell=(d\cdot\text{something}).
$$
So $d$ is a divisor of $b$.</p>

<p>Thus: <b>All divisors that $a$ and $a-b$ have in common are divisors of $b$.</b></p>

<p>Therefore, the set of all common divisors of $a$ and $b$ is the same as the set of all common divisors of $a$ and $a-b$.</p>

<p>Subtracting one member of a pair from the other never alters the set of all common divisors; therefore it never alters the $\gcd$.</p>

==============================
===============================
Question: <p>If $(V, \langle \cdot, \cdot \rangle)$ is a finite-dimensional inner product space and $f,g : \mathbb{R} \longrightarrow V$ are differentiable functions, a straightforward calculation with components shows that </p>

<p>$$
\frac{d}{dt} \langle f, g \rangle = \langle f(t), g^{\prime}(t) \rangle + \langle f^{\prime}(t), g(t) \rangle
$$</p>

<p>This approach is not very satisfying. However, attempting to apply the definition of the derivative directly doesn't seem to work for me. Is there a slick, perhaps intrinsic way, to prove this that doesn't involve working in coordinates?</p>

 
Answer: <p>Observe that
$$
\begin{align*}
  \frac{1}{h}
  &amp; 
  \left[
    \langle f(t+h),\, g(t+h)\rangle - \langle f(t),\, g(t) \rangle
  \right] \\
  &amp; = 
  \frac{1}{h}
    \left[
      \langle f(t+h),\, g(t+h)\rangle - \langle f(t),\, g(t+h)\rangle
    \right] 
  + \frac{1}{h}
    \left[
      \langle f(t),\, g(t+h)\rangle - \langle f(t),\, g(t)\rangle
    \right] \\
  &amp;= 
  \left\langle
    \frac{1}{h}
      \left[
        f(t+h) - f(t) 
      \right],\,
        g(t+h)
  \right\rangle 
  +
  \left\langle
    f(t),\,
    \frac{1}{h}
      \left[
        g(t+h) - g(t)
      \right]
  \right\rangle.
\end{align*}
$$
As $h\to 0$ the first expression converges to
$$
\frac{d}{dt} \langle f(t), g(t) \rangle
$$ and the last expression  converges to
$$
\langle f^{\prime}(t), g(t) \rangle + \langle f(t), g^{\prime}(t) \rangle
$$
by definition of the derivative, by continuity of $g$ and by continuity of the scalar product. Hence the desired equality follows.</p>

<p>Note that this doesn't use finite-dimensionality and that the argument is the exact same as the one for the ordinary product rule from calculus.</p>

==============================
===============================
Question: <p>I've been doing some exercises from my introductory algebra text and came across a problem which I reduced to proving that:</p>

<blockquote>
  <p>The number of distinct subgroups of prime order $p$ of a finite group $G$ is either $0$ or congruent to $1\pmod{p} $. </p>
</blockquote>

<p>With my little experience I was unable to overcome this (all I was able to conclude is that these groups are disjoint short of the identity), and also did not find any solution with a search on google (except for stronger theorems which I am not interested in because of my novice level).</p>

<p>I remember that a similar result is widely known as one of Sylow Theorems. This result was proven by the use of group actions. But can my problem be proved without using the concept of group actions? Can this be proven WITH the use of that concept?</p>

<p><strong>EDIT: With help from comments I came up with this:</strong></p>

<p>The action Derek proposed is well-defined largely because in a group if $ab = e$ (the identity), then certainly $ba = e$. By Orbit-Stabilizer Theorem we can see that all orbits are either of size 1 or $p$ (here I had most problems, and found out cyclic group of order $p$ acts on the set of solutions in the same way).
The orbits of size 1 contain precisely the elements $(x,x,x....,x)$ for some element x in G. In addition, orders of all orbits add up to $|G|^{(p-1)}$ because the orbits are equivalence classes of an equivalence relation.
But certainly $(e,e,e....,e)$ is in an orbit of size 1, and that means there has to be more orbits of exactly one element, actually $p-1 + np$ more for some integer $n$. These elements form the disjoint groups I am looking for. if $p-1$ divides $(p-1 + np)$, it's easy to check the result is 1 mod p.</p>

<p>Could someone check if I understood this correctly?  </p>

 
Answer: <p>Here's another approach. Consider the solutions to the equation $x_1x_2\cdots x_p=1$ in the group $G$ of order divisible by $p$. Since there is a unique solution for any $x_1,\ldots,x_{p-1}$, the total number of solutions is $|G|^{p-1}$, which is divisible by $p$. If $x_1,x_2,\ldots,x_p$ is a solution, then so is $x_2,x_3,\ldots,x_p,x_1$, and so we have an action of the $p$-cycle $(1,2,3,\ldots,p)$ on the solution set.</p>

<p>Since $p$ is prime, the orbits of this action have size $p$ if $x_1,x_2,\ldots,x_p$ are not all equal, and size 1 if they are all equal. So the number of solutions of $x^p=1$ is a multiple of $p$. Now use Steve D's hint to complete the proof.</p>

<p>Incidentally there is a theorem of Frobenius that says that for any $n&gt;0$ and any finite group of order divisible by $n$, the number of solutions of $x^n=1$ is a multiple of $n$.  </p>

==============================
===============================
Question: <p>While reading some things about analytic functions earlier tonight it came to my attention that Fourier series are not necessarily analytic. I used to think one could prove that they <em>are</em> analytic using induction</p>

<ol>
<li>Let $P(n)$ be some statement parametrized by the natural number $n$ (in this case: the $n$th partial sum of the Fourier series is analytic)</li>
<li>Show that $P(0)$ is true</li>
<li>Show that $P(n-1)\Rightarrow P(n)$</li>
<li>(Invalid) conclusion: $P(n)$ continues to be true as we take the limit $n\to\infty$<sup>*</sup></li>
</ol>

<p>Why exactly is the conclusion not valid here? It seems very strange that even though $P(n)$ is true for any finite $n$, it ceases to be valid when I remove the explicit upper bound on $n$. Are there circumstances under which I <em>can</em> make an argument of this form?</p>

<hr>

<p><strong>Example of invalid proof:</strong> Define the truncated Fourier series $F_n(x)$ as the partial sum</p>

<p>$$F_n(x) = \sum_{k=0}^{n} A_k\sin\biggl(\frac{kx}{T}\biggr) + B_k\cos\biggl(\frac{kx}{T}\biggr)$$</p>

<p>where $A_k$ and $B_k$ are the Fourier coefficients for some arbitrary function $f$. Using the facts that $\sin(t)$ and $\cos(t)$ are analytic, and that any linear combination of analytic functions is analytic:</p>

<ol>
<li>$P(n)$ is the statement "$F_n(x)$ is analytic"</li>
<li>$F_0(x)$ is clearly analytic because it is a linear combination of sine and cosine functions</li>
<li><p>$F_n(x)$ can be written as the linear combination</p>

<p>$$F_{n}(x) = F_{n-1}(x) + A_n\sin\biggl(\frac{nx}{T}\biggr) + B_n\cos\biggl(\frac{nx}{T}\biggr)$$</p>

<p>So if $F_{n-1}(x)$ is analytic, $F_n(x)$ is analytic.</p></li>
<li>$F(x) \equiv \lim_{n\to\infty} F_n(x)$ is analytic. But $F(x)$ is the Fourier series for $f$; therefore, the Fourier series for $f$ is analytic.</li>
</ol>

<hr>

<p><sup>*</sup>I'm assuming that $P(n)$ is a statement about some sequence which is parametrized by $n$ and for which taking the limit as $n\to\infty$ is meaningful</p>

 
Answer: <p>Here is a quote from B. Russell's <em>Introduction to mathematical philosophy</em>, pages 27-28, that I think describes well this limitation of induction:</p>

<blockquote>
  <p>Mathematical induction affords, more than anything else, the essential characteristic by which the finite is distinguished from the infinite.  The principle of mathematical induction might be stated popularly in some such form as "what can be inferred from next to next can be inferred from first to last." This is true when the number of intermediate steps between first and last is finite, not otherwise.  Anyone who has ever watched a goods train beginning to move will have noticed how the impulse is communicated with a jerk from each truck to the next, until as last even the hindmost truck is in motion.  When the train is very long, it is a very long time before the last truck moves.  If the train were infinitely long, there would be an infinite succession of jerks, and the time would never come when the whole train would be in motion.  Nevertheless, if there were a series of trucks no longer than the series of inductive numbers..., every truck would begin to move sooner or later if the engine persevered, though there would always be other trucks further back which had not yet begun to move.</p>
</blockquote>

<p>There are contexts in which a statement $P(n)$ can be proved for all $n\in\mathbb N$ by induction, and has a counterpart $P(\infty)$ that is false.  In other contexts, $P(\infty)$ may be true.  But even then, induction on $\mathbb N$ does not prove the $P(\infty)$ case.  </p>

<p>Getting back to limits of functions, note for example that:</p>

<ul>
<li><p>A finite sum of continuous functions is continuous.</p></li>
<li><p>A pointwise convergent series of continuous functions need not be continuous.</p></li>
<li><p>But, a <em>uniformly</em> convergent series of continuous functions is continuous.</p></li>
</ul>

<p>So in this case, going from finite sums to infinite series requires new tools, different types of convergence, to obtain the desired properties.  As for real analytic functions, I don't know what can be said along these lines.  For complex analytic functions there are nicer results, such as the fact that a locally uniformly convergent sequence of complex analytic functions is complex analytic.  In the real case, to give a stark contrast, every continuous function on a bounded interval is a uniform limit of polynomials (as analytic as you can get), but there are continuous functions that are differentiable nowhere.  Similarly, a continuously differentiable function of period $2\pi$ is the uniform limit of its Fourier series, but continuously differentiable functions need not even be twice differentiable, let alone analytic.</p>

==============================
===============================
Question: <p>I have a problem where I have TWO NON-rotated rectangles (given as two point tuples {x1 x2 y1 y2}) and I like to calculate their intersect area. I have seen  more general <a href="https://stackoverflow.com/questions/4558835/total-area-of-intersecting-rectangles">answers</a> to this question, e.g. more rectangles or even rotated ones, and I was wondering whether there is a much simpler solution as I only have two non-rotated rectangles. </p>

<p>What I imagine should be achievable is an algorithm that only uses addition, subtraction and multiplication, possibly abs() as well. What certainly should not be used are min/max, equal, greater/smaller and so on, which would make the question obsolete.</p>

<p>Thank you!</p>

<p>EDIT 2: okay, it's become too easy using min/max or abs(). Can somebody show or disprove the case only using add/sub/mul?</p>

<p>EDIT: let's relax it a little bit, only conditional expressions (e.g. if, case) are prohibited!</p>

<p>PS: I have been thinking about it for a half hour, without success, maybe I am now too old for this :)</p>

 
Answer: <p>Uses only max and min (drag the squares to see the calculation. Forget about most of the code, the calculation is those two lines with the min and max):</p>

<p><a href="http://jsfiddle.net/Lqh3mjr5/" rel="noreferrer">http://jsfiddle.net/Lqh3mjr5/</a></p>

<p>You can also reduce min to max here (or the opposite), i.e. $min\{a,b\} = -max\{-a,-b\}$.</p>

<hr>

<p>First compute the bounding rectangles <code>rect1</code> and <code>rect2</code> with the following properties:</p>

<pre><code>rect = {
  left: x1,
  right: x1 + x2,
  top: y1,
  bottom: y1 + y2,
}
</code></pre>

<p>The overlap area can be computed as follows:</p>

<pre><code>x_overlap = Math.max(0, Math.min(rect1.right, rect2.right) - Math.max(rect1.left, rect2.left));
y_overlap = Math.max(0, Math.min(rect1.bottom, rect2.bottom) - Math.max(rect1.top, rect2.top));
overlapArea = x_overlap * y_overlap;
</code></pre>

==============================
===============================
Question: <p>Let $X$ be a compact Kähler manifold of complex dimension $\dim_{\mathbb C} = n$. Let $[\omega]$ be the cohomology class of a Kähler metric on $X$. Then powers of the class $[\omega]$ defines a linear morphism between cohomology groups</p>

<p>$$ L^k :  H^{n-k}(X,\mathbb C) \longrightarrow H^{n+k}(X,\mathbb C) $$</p>

<p>which is simply given by cup product against the class $[\omega]^k$. The hard Lefschetz theorem says that this is in fact an isomorphism of vector spaces.</p>

<p><strong>Question:</strong> Why do we call this the "hard" Lefschetz theorem?</p>

<p>Modern proofs of this theorem are not that involved; one picks a Kähler metric $\omega$ and proves the Kähler identities on $X$, and the rest then follows from the existence of primitive decompositions. Thus it seems a bit of hype to call the theorem "hard".</p>

<p>One might think this is to distinguish this from another theorem of Lefschetz, often called the "weak" Lefschetz theorem, which gives a similar result in the case where $[\omega]$ is the Chern class of an ample line bundle. But then we'd surely call this the "strong" Lefschetz theorem, right?</p>

 
Answer: <p>This question can only have a subjective answer (which is actually fun, from time to time!), so here  are a few personal remarks.  </p>

<p>1) You are a dynamic PhD student working in 2012 under the supervision of Demailly, a world leader in complex algebraic geometry.<br>
You have at your disposal a technology that didn't exist on Lefschetz' time: singular and De Rham cohomology, higher homotopy groups, Kähler manifolds, Hodge theory,...<br>
Even the abstract notion of a finite-dimensional vector space had not been axiomatized.<br>
So  when you claim that the theorem is not that hard, you should not lose sight of  the historic context in which Lefschetz "proved" his theorem in 1924.  </p>

<p>2) I wrote "proved" in quotes, since as Sabbah diplomaticallty puts it, Lefschetz' proof was "insufficient".<br>
So the theorem was not easy, even for Lefschetz. </p>

<p>3) The theorem has fascinated many Fields medalists and other giants who gave proofs of some version of the theorem: Andreotti, Frankel, Thom, Bott, Kodaira, Spencer, Artin, Grothendieck, Deligne.<br>
This is certainly an indication of the depth of the theorem...  </p>

<p>4) Like you I am enthusiastic about complex algebraic manifolds and am grateful for  the transcendental methods , like Kähler theory, which allow us to study them.<br>
However algebraic geometers also  want to consider algebraic varieties in characteristic $p$, and  there these transcendental tools  unfortunately completely break down.<br>
Hard Lefschetz for smooth varieties over finite fields was proved by Deligne only in 1980, after much preliminary work by himself and Grothendieck (cf. SGA7).<br>
 I would surmise that  the terminology "Lefschetz vache" introduced by Grothendieck is to be understood in that context.  </p>

<p>5) Finally even in the complex case, I find the proof of hard Lefschetz starting from scratch not so easy.<br>
I'll let you and the  other users judge by linking to a <a href="http://www.math.polytechnique.fr/cmat/sabbah/livres/hodge-str.pdf" rel="nofollow noreferrer">free online course of Sabbah</a> on Hodge theory and hard Lefschetz (in the Introduction  of which he writes the diplomatic remark mentioned above!)</p>

<p><strong>Edit</strong><br>
Since this is a good-humoured, non-technical  answer,  I'll  take the liberty of quoting the following picturesque metaphor by Lefschetz:    </p>

<p><em>It was my lot to plant the harpoon of algebraic topology into the body of the whale of algebraic geometry</em></p>

==============================
===============================
Question: <p>Why is the Euler characteristic of a boundary even? How can one prove this and is there an geometric way to think about it?</p>

 
Answer: <p>Let $M$ be your (compact) manifold. You can glue two copies $M_1$, $M_2$ of $M$ along their boundary, getting a closed manifold $2M$. Using the Mayer-Vietoris long exact sequence for the triad $(2M;M_1,M_2)$. It gives us the relation $\chi(2M)=2\chi(M)-\chi(\partial M)$, because $M_1$ and $M_2$ intersect along $\partial M$.</p>

<p>Now, if $\dim M$ is odd, then $\dim 2M$ is also odd and $\chi(2M)=0$, so $\chi(\partial M)=2\chi(M)$ is even. If $\dim M$ is even, then $\dim \partial M$ is odd and therefore $\chi(\partial M)=0$ is also even.</p>

==============================
===============================
Question: <p>This seems to be one of those tricky examples. I only know one proof which is quite complicated and follows by localizing $\mathbb{Z}[\sqrt[3]{2}]$ at different primes and then showing it's a DVR. Does anyone know any simple quick proof?</p>

 
Answer: <p>The short answer is no, in that you almost certainly have to perform separate checks "one prime at a time."  For that matter, there's no <em>really</em> slick of doing the quadratic case, either.  You either have to do some grunt work with mod-4 conditions on coefficients of minimal polynomials, etc., or build up the theory of the different, etc., and start hitting problems with bigger hammers.  When you get past the quadratic case, the grunt work becomes increasingly tedious (/impossible), and you're only left with hammers.  So you need technical lemmas on how to conclude that a subring of a ring of integers is really the whole thing, and I don't think it's possible to do that without considering the various primes which could possibly divide the index.  Keith Conrad's notes that Álvaro mentions give one solution (his Lemma 1) -- here's another slightly different approach.  At the very least, it avoids working explicitly with local rings, even if it doesn't avoid the fact that philosophically we're working locally anyway.</p>

<p>Let $\mathcal{O}$ be the ring of integers of $\mathbb{Q}(\sqrt[3]{2})$.  We have $\mathbb{Z}[\sqrt[3]{2}]\subset\mathcal{O}$, and we wish to show equality.  It suffices to show that for each prime $\mathfrak{p}$ of $\mathbb{Z}[\sqrt[3]{2}]$, we have $\mathcal{O}=\mathbb{Z}[\sqrt[3]{2}]+\mathfrak{p}$ (this is basically using Nakayama's Lemma to disguise a collection of local things to check with a collection of global things to check).  Since for $\alpha:=\sqrt[3]{2}$, the minimal polynomial of $\alpha$ is $f_\alpha(x)=x^3-2$, we also know that 
$$
\mathcal{O}\subset \tfrac{1}{f&#39;(\alpha)}\mathbb{Z}[\sqrt[3]{2}]=\frac{1}{3\sqrt[3]{4}}\mathbb{Z}[\sqrt[3]{2}],
$$
making it trivial to check the desired equality for everything but $p=2$ and $p=3$.  Now (this part is basically the same as in Keith Conrad's notes) we observe that it suffices to demonstrate $p$-Eisenstein polynomials $h_p(x)$ for a generator $x_p\in\mathbb{Z}[\sqrt[3]{2}]$ for $p=2$ and $p=3$.  But these are easy to come by:  For $p=2$, take $x_2=\sqrt[3]{2}$ and $h_2(x)=f_\alpha(x)$ and for $p=3$, take $x_3=\sqrt[3]{2}+1$ and $h_3(x)=f_\alpha(x-1)$.  Ta-da.</p>

==============================
===============================
Question: <p>I would like to prove that:</p>

<p>$$ \int_{0}^{\infty} \frac{\ln(t)}{\sqrt{t}}e^{-t} \mathrm dt=-\sqrt{\pi}(\gamma+\ln{4})$$</p>

<p>I tried to use the integral $$\int_{0}^{n} \frac{\ln(t)}{\sqrt{t}}\left(1-\frac{t}{n}\right)^n \mathrm dt$$</p>

<p>$$\int_{0}^{n} \frac{\ln(t)}{\sqrt{t}}\left(1-\frac{t}{n}\right)^n \mathrm dt \;{\underset{\small n\to\infty}{\longrightarrow}}\; \int_{0}^{\infty} \frac{\ln(t)}{\sqrt{t}}e^{-t} \mathrm dt$$ (dominated convergence theorem)</p>

<p>Using the substitution $t\to\frac{t}{n}$, I get:</p>

<p>$$ \int_{0}^{n} \frac{\ln(t)}{\sqrt{t}}\left(1-\frac{t}{n}\right)^n \mathrm dt=\sqrt{n}\left(\ln(n)\int_{0}^{1} \frac{(1-t)^n}{\sqrt{t}} \mathrm dt+\int_{0}^{1} \frac{\ln(t)(1-t)^n}{\sqrt{t}} \mathrm dt\right) $$</p>

<p>However I don't know if I am on the right track for these new integrals look quite tricky.</p>

 
Answer: <p>Consider integral representation for the <a href="http://en.wikipedia.org/wiki/Gamma_function">Euler $\Gamma$-function</a>:
$$
   \Gamma(s) = \int_0^\infty t^{s-1} \mathrm{e}^{-t} \mathrm{d} t
$$
Differentiate with respect to $s$:
$$
   \Gamma(s) \psi(s) = \int_0^\infty t^{s-1} \ln(t) \mathrm{e}^{-t} \mathrm{d} t
$$
where $\psi(s)$ is the <a href="http://en.wikipedia.org/wiki/Digamma_function">digamma function</a>.
Now substitute $s=\frac{1}{2}$. So
$$
    \int_0^\infty \frac{ \ln(t)}{\sqrt{t}} \mathrm{e}^{-t} \mathrm{d} t = \Gamma\left( \frac{1}{2} \right) \psi\left( \frac{1}{2} \right) 
$$
Now use duplication formula:
$$
    \Gamma(2s) = \Gamma(s) \Gamma(s+1/2) \frac{2^{2s-1}}{\sqrt{\pi}}
$$
Differentiating this with respect to $s$ gives the duplication formula for $\psi(s)$, and substitution of $s=1/2$ gives $\Gamma(1/2) = \sqrt{\pi}$. 
$$
   \psi(2s) = \frac{1}{2}\psi(s) + \frac{1}{2} \psi(s+1/2) + \log(2)
$$
Substitute $s=\frac{1}{2}$ and use $\psi(1) = -\gamma$ to arrive at the result.</p>

==============================
===============================
Question: <p>I've noticed that $\mathrm{GL}_n(\mathbb R)$ is not a connected space, because if it were $\det(\mathrm{GL}_n(\mathbb R))$ (where $\det$ is the function ascribing to each $n\times n$ matrix its determinant) would be a connected space too, since $\det$ is a continuous function. But $\det(\mathrm{GL}_n(\mathbb R))=\mathbb R\setminus\{0\},$ so not connected.</p>

<p>I started thinking if I could prove that $\det^{-1}((-\infty,0))$ and $\det^{-1}((0,\infty))$ are connected. But I don't know how to prove that. I'm reading my notes from the topology course I took last year and I see nothing about proving connectedness...</p>

 
Answer: <p>Your suspicion is correct, $GL_n$ has two components, and $\det$ may be used to show there are at least two of them. The other direction is slightly more involved and requires linear algebra rather than topology. Here is a sketch of how to do this:</p>

<p>i) If $b$ is any vector, let $R_b$ denote the reflection through the hyperplane perpendicular to $b$. These are all reflections. Any two reflections $R_a, R_b$ with $a, b$ linear independent can be joined by a path consisting of reflections, namely $R_{ta+ (1-t)b}, t\in[0,1]$.  </p>

<p>ii) Any $X\in O^+(n)$ (orthogonal matrices with positive determinant) is the product of an even number of reflections. Since matrix multiplication is continuous $O(n)\times O(n) \rightarrow O(n)$ and by i) you can join any product $R_a R_b$ with $R_a R_a = Id$ it follows that $O^+(n)$ is connected.</p>

<p>iii) $\det$ shows $O(n)$ is not connected.</p>

<p>iv) $O^-(n) = R O^+ (n)$ for any reflection $R$. Hence $O^-(n)$ is connected.</p>

<p>v) Any $ X\in GL_n$ is the product $AO$ of a positive matrix $A$ and $O \in O(n)$ (polar decomposition). Now you only need to show that the positive matrices are connected, which can be shown again using convex combination with $Id$. This proves the claim.</p>

==============================
===============================
Question: <p>If $G$ is a group, then $M(G)=2^G$ is has a monoid structure when we define $AB$ to be $\{ab|a\in A,b\in B\}$ and $1_{M(G)}=\{1\}$. How much of the structure of $G$ can be recovered by studying the structure of $M(G)?$ Is there any known example of a sensibly large class $\mathscr{C}$ of groups, for which the following implication holds?</p>

<p>For any $G,H\in \mathscr C,$ if $M(G)\cong M(H),$ then $G\cong H.$</p>

<p>Could you please give me any references concerning the monoid of subsets of a group?</p>

<p><strong>Edit:</strong> I'll write here what I came up with after I asked the quesiton. Please comment on it as well.</p>

<p>I've found a funny structure that I think is isomorphic to $M(G).$ Let $B=(\{0,1\},∨,∧).$ It's a semiring in which infinite sums (and products, actually) are well-defined. If I'm not mistaken, we can define the "group semiring" $B[G]_\infty$ just like we define group rings, but without the restriction of finite supports. It looks like the multiplicative structure of $B[G]_\infty$ is isomorphic to $M(G).$ The additive structure of $B[G]_\infty$ seems to be isomorphic to $(M(G),\cup).$ </p>

<p>If we do keep the restriction of finite supports and define $B[G]$ as we would a group ring, I believe it's equivalent to changing $2^G$ to the family of all <em>finite</em> subsets of $G$ in the definition of $M(G).$ </p>

<p>I haven't written the proofs of these things down, but I will if anyone thinks it's a good idea. </p>

<p><strong>Edit:</strong> I don't know how close I am, but for what it's worth. OK, so $M(G)$ has a structure of an additively idempotent semiring. Indeed, let's take $(M(G),\cup,\cdot,\emptyset,\{1\}).$ The additive structure is obviously that of a commutative idempotent monoid. The multiplicative structure is that of a monoid. The distributive laws hold because:</p>

<p>$
\begin{eqnarray}
\left(\forall A,B,C\in M(G)\right) \;\;\; A(B\cup C) &amp;=&amp; \{ax\,|\,a\in A\wedge x\in B\cup C\}=\{ax\,|\, a\in A\wedge (x\in B\vee x\in C)\}\\ &amp;=&amp; \{ax \,|\,(a\in A\wedge x\in B)\vee (a\in A\wedge x\in C)\} \\ &amp;=&amp; \{ax\,|\,a\in A \wedge x\in B\}\cup\{ax\,|\,a\in A \wedge x\in C\}\\ &amp;=&amp; AB\cup AC,
\end{eqnarray}
$</p>

<p>and analogously</p>

<p>$\left(\forall A,B,C\in M(G)\right) \;\;\; (B\cup C)A=BA\cup CA.$</p>

<p>Now, in this semiring there is the subset $G'=\left\{\{g\}\,|\,g\in G\right\}.$ The multiplicative structure of this subset is isomorphic to $G.$ Suppose we have the semiring $(M,+,\cdot,0,1)$ and we know that $M\cong M(G)$ for some group $G.$ (The isomorphism is between semirings, not monoids.) Then finding out the structure of $G$ is equivalent to recognizing $G'$ inside $M.$ But this is possible when we have the additive structure. $G'$ is the set of all elements $g$ such that the equation $g+x=g$ has exactly one solution, that is $0.$ </p>

<p>This, if I'm not mistaken means that the <strong>semiring</strong> structure of $M(G)$ gives the structure of $G$ unanmbiguously. So perhaps, having the <strong>monoid</strong> $M(G),$ we could try proving that there is a unique additive operation that makes this monoid into an (additively idempotent) semiring? </p>

<p><strong>Edit:</strong> This is to announce that I have asked a <a href="https://mathoverflow.net/questions/95575/is-the-class-of-inverse-semigroups-globally-determined">follow-up question</a> on MO. It is whether the class of inverse semigroups is globally determined (as defined in my answer below). Inverse semigroups can be seen as generalized groups and I'd like to know if they retain this particular property of groups.</p>

 
Answer: <p>I believe it is always true that $M(G)\cong M(H)$ implies $G\cong H$.  Because let $\phi:\ M(G)\rightarrow M(H)$ be a monoid isomorphism.  Note that the only elements  $x\in M(G)$ such that there exists $y\in M(G)$ with $xy=1$ are the one-element subsets of $G$.  That is, the invertible elements in $M(G)$ are the one-element subsets of $G$; and the monoid product in $M(G)$, restricted to these one-element subsets of $G$, is just the group product of $G$.  Thus $\phi$ restricted to these invertible elements induces an isomorphism between $G$ and $H$.</p>

==============================
===============================
Question: <p>Let $R$ be a commutative ring with identity. Show that $R$ is a field if and only if the only ideals of $R$ are $R$ itself and the zero ideal $(0)$.</p>

<p>I can't figure out where to start other that I need to prove some biconditional statement. Any help?</p>

 
Answer: <p>From some of the comments above you seem a little confused. Since you said you are not familiar with proofs I will try to write this out in a way that you can understand.</p>

<p>You are trying to prove the equivalence of the following statements:</p>

<p>$P:$ A commutative ring $R$ with $1$ is a field.</p>

<p>$Q:$ The only ideals of $R$ are $(0)$ and $(1)$.</p>

<p>Let us look at statement $Q$ closely. Well it is saying that the only ideals of $R$ are the zero ideal (which has only one element, zero) and $(1)$. What is $(1)$? Well by definition of an ideal if you multiply anything in the ideal $(1)$ by anything in $R$, you should get something back in $(1)$ again. But then $1$ is the multiplicative identity of $R$ so multiplying everything in $R$ by $1$ just gives everything in $R$ back again. This means that $(1)$ must be the whole ring $R$.</p>

<p>Now suppose we want to prove $P \implies Q$. Let $I$ be an ideal of a ring $R$. Here "ring" means "commutative ring with a unit". Now here are some things you should know: </p>

<blockquote>
  <blockquote>
    <p>(1) $I$ is non-empty</p>
    
    <p>(2) $I$ must at least contain the element $0$ (Why?)</p>
    
    <p>(3) If $I$ has more than one element this means that at least one non-zero element $a$ of the ring must be in $I$. (Why?)</p>
  </blockquote>
</blockquote>

<p>Therefore if $I$ contains only $0$, $I = (0)$. If $I$ does not only contain zero, then by (3) above it contains at least one non-zero element $a$ of $R$. Now recall that we are trying to prove $P \implies Q$. We already know $P$. Therefore this means by definition of a field that $a^{-1}$ exists in $R$.</p>

<p>But then by definition of an ideal $I$, $a^{-1} a = 1$ must be in $I$. Therefore $1 \in I$ so that $I$ must be the whole ring $R$. Hence $I = (1)$. This establishes $P \implies Q$.</p>

<p>Now for the converse:</p>

<p>To show $Q \implies P$ it suffices to show that non-zero every element $a \in R$ contains a multiplicative inverse. So let $a$ be a non-zero element of $R$. The trick now is to consider the principal ideal generated by $a$ (which we denote by $(a)$ ).</p>

<p>Now by assumption of $Q$, since the only ideals of $R$ are $(0)$ and $(1)$, this means that $(a)$ being an ideal of $R$ must be either $(0)$ or $(1)$. Now $(a)$ cannot be $(0)$ for $a \neq 0$. So $(a) = (1)$. But then this means that $1$ is a multiple of $a$, viz. there exists a non-zero $c$ such that</p>

<p>$$ac = 1.$$</p>

<p>However this is precisely saying that $a$ has a multiplicative inverse. Since $a$ was an arbitrary non-zero element of $R$, we are done. Q.E.D.</p>

<p>Does this help you? I can discuss more if you need help.</p>

==============================
===============================
Question: <p>Plato puts the following words in Socrates' mouth in the <em>Phaedo</em> dialogue:</p>

<blockquote>
  <p>I mean, for instance, the number three, and there are many other examples. Take the case of three; do you not think it may always be called by its own name and also be called odd, which is not the same as three? Yet the number three and the number five and <strong>half of numbers in general are so constituted, that each of them is odd</strong> though not identified with the idea of odd. And in the same way two and four and all the other series of numbers are even, each of them, though not identical with evenness. (<a href="http://www.perseus.tufts.edu/hopper/text?doc=Perseus:text:1999.01.0170:text=Phaedo:section=104a" rel="nofollow noreferrer">104a-b</a>)</p>
</blockquote>

<p>The <a href="https://philosophy.stackexchange.com/q/2148/73">philosophical point</a> is that there exists an Idea (or Form) called Odd and odd numbers are merely specific instances of Odd.  The are not, themselves, identical to the concept of Oddness.</p>

<p>But I bolded a throwaway phrase that prompts my question: Are half of all integers odd?</p>

<hr>

<p>Plato likely did not consider <a href="http://en.wikipedia.org/wiki/Parity_%28mathematics%29#History" rel="nofollow noreferrer">one to be odd</a> nor did he likely consider either zero or negative integers among his set of "numbers in general".  I don't see his proof (if he had or was aware of one), but I would imagine it be something along the lines that for every even number <code>N</code> there is an odd number <code>N+1</code>.  Therefore half of all numbers greater than 1 are odd.</p>

<p>I'm aware that <a href="https://math.stackexchange.com/q/15556/23504">zero is even</a>, which makes me think there is one extra even number than odd numbers.  My thinking is that if half of all positive numbers are odd and half of all negative numbers are odd, than leaving out zero, half of all integers are odd.  But when you add in the only non-positive, non-negative number, which is even, you have an extra even number.  (The programmer in me wants to add the concepts of <code>-0</code> and <code>+0</code> for symmetry.  The rest of me thinks that's nuts!)</p>

<p>However, I think my imagined platonic proof still works as long as zero is definitely even and won't work if it's either odd or neither parity.</p>

<p>Are either of these proofs valid?</p>

 
Answer: <p>While they are both countable, there is a more applicable mechanism for measuring how many natural numbers have a certain property. If $A \subset \mathbb{N}$, let $$A_n = \text{number of elements in A less or equal to n}$$ then we can define density of $A$ as $$\operatorname{density}(A) = \lim_{n\to\infty}  \frac{A_n}{n}$$Then the odd numbers have density $\frac{1}{2}$.</p>

==============================
===============================
Question: <p>I am looking for the "best" way to determine whether a function is one-to-one, either algebraically or with calculus. I know a common, yet arguably unreliable method for determining this answer would be to graph the function. However, this can prove to be a risky method for finding such an answer at it heavily depends on the precision of your graphing calculator, your zoom, etc...</p>

<p>What is the best method for finding that a function is one-to-one? In your description, could you please elaborate by showing that it can prove the following:</p>

<p>This is one-to-one: $\frac{x-3}{x+2}$</p>

<p>This is not one-to-one: $\frac{x-3}{x^3}$</p>

 
Answer: <p>To show that $f$ is 1-1, you could show that $$f(x)=f(y)\Longrightarrow x=y.$$
So, for example, for $f(x)={x-3\over x+2}$:</p>

<p>Suppose ${x-3\over x+2}= {y-3\over y+2}$. Then:
\begin{align*}
&amp;{x-3\over x+2}= {y-3\over y+2}  \\
\Longrightarrow&amp; (y+2)(x-3)= (y-3)(x+2)\\
\iff&amp; yx+2x-3y-6= yx-3x+2y-6\\
\iff&amp;2x-3y =-3x+2y\\
\iff&amp;2x+3x =2y+3y\\
\iff&amp;5x =5y\\
\iff&amp;x=y
\end{align*}
So $f(x)={x-3\over x+2}$ is 1-1.</p>

<p>I'll leave showing that $f(x)={{x-3}\over 3}$ <i>is</i> 1-1 for you.</p>

<p>Alternatively, to show that $f$ is 1-1, you could show that $$x\ne y\Longrightarrow f(x)\ne f(y).$$</p>

<p>Or, to show that a differentiable $f$ is 1-1, you could show that its derivative $f'$ is either always positive or always negative. </p>

<p><br></p>

<p>You would discover that a function $g$ is not 1-1, if, when using the first method above, you find that the equation is satisfied for some $x\ne y$. For example, take $g(x)=1-x^2$. Then</p>

<p>$$
\eqalign{
&amp;g(x)=g(y)\cr
\iff&amp;{1-x^2}= {1-y^2}  \cr
\iff&amp;-x^2= -y^2\cr
\iff&amp;x^2=y^2\cr}
$$
The above equation has $x=1$, $y=-1$ as a solution.  So, there is $x\ne y$ with $g(x)=g(y)$; thus $g(x)=1-x^2$ is not 1-1.  </p>

<p>Of course, to show $g$ is not 1-1, you need only find two distinct values of the input value  $x$ that give $g$ the same output value. </p>

<p><hr>
Although you rightfully point out that the graphical method is unreliable; it is still instructive to consider the methods used and why they work:</p>

<p>Graphically, you can use either of the following:</p>

<ol>
<li><p>Use the "Horizontal Line Test":</p>

<p>$f$ is 1-1 if and only if every horizontal line intersects the graph
        of $f$ in at most one point.  Note that this is just the graphical
        interpretation of "if $x\ne y$ then $f(x)\ne f(y)$"; since the
        intersection points of a horizontal line with the graph of $f$ give
        $x$ values for which $f(x)$ has the same value (namely the $y$-intercept of the line).</p></li>
<li><p>Use the fact that a continuous $f$ is 1-1 if and only if $f$ is either
    strictly increasing or strictly decreasing. This, of course, is
    equivalent to the derivative being always positive or always
    negative in the case where $f$ is differentiable. 
(Note this method  applies to only the green function below.) </p>

<p><img src="https://i.stack.imgur.com/P1gAl.png" alt="enter image description here"></p></li>
</ol>

==============================
===============================
Question: <p>Let's say I consider the Banach–Tarski paradox unacceptable, meaning that I would rather do all my mathematics without using the axiom of choice. As my foundation, I would presumably have to use ZF, ZF plus other axioms, or an approach in which sets were not fundamental.</p>

<p>Suppose that all I want is enough analysis to express all existing theories in physics. Is ZF enough? If not, then is there any attractive, utilitarian system of the form ZF+x, where x represents some other axiom(s), that does suffice, without allowing Banach-Tarski?</p>

<p>Wikipedia has a list of statements that are equivalent to choice: <a href="http://en.wikipedia.org/wiki/Axiom_of_choice#Equivalents">http://en.wikipedia.org/wiki/Axiom_of_choice#Equivalents</a> The only one that seems obviously relevant is Blass's result that you need choice to prove that every vector space has a basis. But if all I care about is vector spaces that would actually be used in physics (probably nothing fancier than the space of functions from $\mathbb{R}^m$ to $\mathbb{R}^n$), does this matter? I.e., are the spaces for which you need choice to prove the existence of a basis too pathological to be of interest to a physicist? In cases of physical interest, it seems like it would be trivial to construct a basis explicitly.</p>

<p>Is Solovay's theorem relevant? I'm confused about the role played by the existence of inaccessible cardinals.</p>

<p>I'm a physicist, not a mathematician, so I would appreciate answers pitched at the level of a dilettante, not that of a professional logician.</p>

<p>[EDIT] André Nicolas asks: "[...] why should Banach-Tarski be unacceptable?" Fair enough. Let me try to clarify what I had in mind. The real number system contains stuff that is physically meaningless, but (a) I have a clear idea of which of its features can't mean anything physical (e.g., the distinction between rationals and irrationals), and (b) doing math in $\mathbb{Q}$ would be much less convenient than doing math in $\mathbb{R}$. Similarly, I might prefer to think of my $dy$'s and $dx$'s as infinitesimals, and although those are unphysical, I understand what's unphysical about them, and they're convenient. But when it comes to choice, it's not obvious to me how to distinguish physically meaningful consequences from physically meaningless ones, and it's not obvious that I would lose any convenience by limiting myself to ZF.</p>

 
Answer: <p>An interesting question, that would take many pages to begin to answer!  We make  a small disjointed series of comments.   </p>

<p>In the last few years, there has been a systematic program, initiated by Friedman and usually called <a href="http://en.wikipedia.org/wiki/Reverse_mathematics">Reverse Mathematics,</a> to discover precisely how much we need to prove various theorems.  The rough answer is that for many important things, we need very much less than ZFC.  For many things, full ZF is vast overkill. Small fragments of second-order arithmetic, together with very limited versions of AC, are often enough. </p>

<p>About the Axiom of Choice, for a fair bit of basic analysis, it is pleasant to have Countable Choice, or Dependent Choice, at least for some kinds of sets.  We really want, for example, sequential continuity in the reals to be equivalent to continuity. One could do this without full DC, but DC sounds not unreasonable to many people who have some discomfort with the full AC. This was amusingly illustrated in the early $20$-th century.  A number of mathematicians who had publicly objected to AC turned out to have unwittingly used some form of AC in their published work. </p>

<p>Next, bases. For finite dimensional vector spaces, there is no problem, we do not need any form of AC (though amusingly we do to prove that the Dedekind definition of finiteness is equivalent to the usual definition.)</p>

<p>For <em>some</em> infinite dimensional vector spaces, we cannot prove the existence of a basis in ZF (I guess I have to add the usual caveat "if ZF is consistent"). However, an algebraic basis is not usually what we need in analysis.  For example, we often express nice functions as $\sum_0^\infty a_nx^n$. This is an infinite "sum." The same remark can be made about Fourier series. True, we would use an algebraic basis for $\mathbb{R}$ over $\mathbb{Q}$ to show that there are strange solutions to the functional equation $f(x+y)=f(x)+f(y)$. But are these strange solutions of any conceivable use in Physics? </p>

<p>Finally, why should the Banach-Tarski result be unacceptable to a physicist <em>as</em> physicist?  It is easy to show that the sets in the decomposition cannot be all measurable.  In mathematical models of physical situations, do non-measurable sets of points in $\mathbb{R}^3$ ever appear?   </p>

==============================
===============================
Question: <p>I was intrigued by a book I saw called <a href="http://rads.stackoverflow.com/amzn/click/0883857006" rel="noreferrer">Proofs without Words</a>. So I bought it, and discovered that the entire book doesn't have any words in it. I figured at least it would have some words explaining the pictures or something to help understand the proofs. I was wrong.</p>

<p>The book gives several picture proofs of the Pythagorean theorem. Attached is the first one. <strong>Can someone</strong> add a few words (or even just arrows and labels or anything) which would <strong>help me understand how this pic proves the theorem</strong> (which says, as I know all of you know, that $a^2+b^2=c^2$, where $a$ and $b$ are the lengths of the perpendicular sides of a right triangle, and $c$ is the length of the hypotenuse).</p>

<p>$\qquad\quad$ <img src="https://i.stack.imgur.com/JKISK.png" alt="enter image description here"></p>

 
Answer: <p>How about just three letters?</p>

<p>$\;\;$ <img src="https://i.stack.imgur.com/d6n4Z.gif" alt="pythag"></p>

<p>(Hat tip: Clipart Etc.)</p>

==============================
===============================
Question: <p>Here's the problem</p>

<blockquote>
  <p>Suppose that
  $$ a, b \in \mathbb {R^+},\qquad  0 &lt; a + b &lt; 1 $$
  Prove or disprove that
  $$ \exists n \in \mathbb{Z^+}: \left\{na\right\} + \left\{nb\right\} \ge 1$$
  where $\{x\} = x - \lfloor x \rfloor$ and $\lfloor x \rfloor = \max\left\{ n | n \in \mathbb{Z}, n \le x \right\}$.</p>
</blockquote>

<p>Postscripts:</p>

<ol>
<li><p>The original problem in magazine ( ISSN 1005-6416 ) might be (For a long time, I can't remember clearly):</p>

<blockquote>
  <p>$a, b$ are irrationals, subjects to $\forall n \in \mathbb{Z^+}: \left\{ na \right\} + \left\{ nb \right\} \le 1$, prove that $a + b \in \mathbb{Z}$.</p>
</blockquote>

<p>Because I've found that $a, b$ needn't have been irrationals, I insist that there be a general proof (I think it's algebrian). I think the steps are like this:</p>

<ul>
<li>Divides $\left\{ (x, y) | x, y \in \mathbb{R^+}, x + y &lt; 1 \right\}$ into many (infinity) pieces.</li>
<li>For each piece, we obtain a $n$.</li>
</ul></li>
<li><p>It may be easy when $a, b \in \mathbb{Q}$. Here's the proof:</p>

<p>Let $f(n) = \left\{na\right\} + \left\{nb\right\}$.
For each $x \not \in \mathbb{Z}$, we have
$\left\{x\right\} + \left\{-x\right\} = 1$</p>

<p>So if $a, b \in \mathbb{Q}$, we have
$f(1) + f(-1) = 2$</p>

<p>Note that:
$\exists T \in \mathbb{Z^+}$ subjects to $\forall n \in \mathbb{Z}: f(n + T) = f(n)$</p>

<p>So
$2 = f(1) + f(-1) = f(1) + f(2T-1) \le 2 \max\left(f(1), f(2T-1)\right)$</p>

<p>We've done.</p></li>
<li><p>I'd like a proof with algebraic construction.</p></li>
</ol>

<p>Thanks</p>

 
Answer: <p>Look at the following figure of the checkered $(x,y)$-plane with gridlines at integer $x$'s and $y$'s:</p>

<p><img src="https://i.stack.imgur.com/eCg33.png" alt="kronecker"></p>

<p>The points $z_n:=(n\ a,n\ b)$ $\ (n\in{\mathbb Z})$ are marked. We will show that at least one $z_n$ with $n&gt;0$ falls in the interior of a grey triangle, which means $\{n a\}+\{n b\}&gt;1$.</p>

<p>We distinguish the following two cases:</p>

<p>(i) $b/a$ is rational. $-$ In this case there are $p$, $q\in{\rm N}_{\geq1}$ with ${\rm gcd}(p,q)=1$ and a $\lambda&gt;0$ with $a=p\lambda$, $b=q\lambda$. All points $z_n$ are lying on the line
$$\ell:\quad t\mapsto z(t)=(pt, qt)\qquad(-\infty&lt;t&lt;\infty)\ ;$$ 
in fact $z_n=z(n\lambda)$. This line passes through the points $(j p, j q)$ $\ (j\in{\mathbb Z})$ and actually is a closed curve $\gamma$ on the torus $T$ obtained by identifying points $(x,y)$ and $(x',y')$ with $x\equiv x'$ $\ ({\rm mod}\ p)$  and $y\equiv y'$ $\ ({\rm mod}\ q)$. Let $\pi: \ {\mathbb R}^2\to T$ denote the corresponding projection. There is a finite set of segments $\sigma_k\subset\gamma=\pi(\ell)$  colored in grey, which makes up for half of the length of $\gamma$.</p>

<p>(i.i) If $\lambda$ is rational then the $z_n$ project onto only finitely many equally spaced points on $\gamma$, and some $z_n$ with $n&gt;0$ will project onto the same point as $z_{-1}$ and therefore will lie in the interior of a grey triangle. (This case has already been dealt with by the OP.)</p>

<p>(i.ii) If $\lambda$ is irrational then the  points $\pi(z_n)$ are dense on $\gamma$, and some of them will lie in the interior of one of the grey intervals of $\gamma$. It follows that the corresponding $z_n$ are lying in a grey triangle.</p>

<p>(ii)  $b/a=:m$ is irrational. $-$ Put $\delta:=1-a-b$ and consider again the line
$$\ell: \quad t \mapsto z(t):=(t, m t)\qquad(-\infty&lt;t&lt;\infty)$$
(now with a different parametrization). The $z_n$ are equally spaced on $\ell$ with  distance $d:=\sqrt{a^2+b^2}$. The line $\ell$ intersects the vertical gridlines $x=k\in{\mathbb Z}$ in the points $(k, m k)$ whose ordinates $y_k:=m k$ are irrational for $k\ne0$. Therefore the $y_k$ are dense ${\rm mod}\ 1$. There is a $k_0&gt;0$ such that $1-\{y_{k_0}\}&lt;\delta$. It is easy to see that the segment $\sigma\subset\ell$ with endpoints $(k_0-a, y_{k_0}-b)$ and $(k_0, y_{k_0})$ is lying completely in the grey triangle to the left of  $(k_0, y_{k_0})$. Since $\sigma$ has length $d$ there is at least one $z_n\in\sigma$, and this $z_n$ lies in the interior of  a grey triangle.</p>

==============================
===============================
Question: <p>Can an irrational number raised to an irrational power be rational?</p>

<p>If it can be rational, how can one prove it?</p>

 
Answer: <p>There is a classic example here. Consider $A=\sqrt{2}^\sqrt{2}$. Then A is either rational or irrational. If it is irrational, we have $A^\sqrt{2}=\sqrt{2}^2=2$. </p>

==============================
===============================
Question: <p>$\sin x^2$ does not converge as $x \to \infty$, yet its integral from $0$ to $\infty$ does.</p>

<p>I'm trying to understand why and would like some help in working towards a formal proof.</p>

 
Answer: <p>$x\mapsto \sin(x^2)$ is integrable on $[0,1]$, so we have to show that $\lim_{A\to +\infty}\int_1^A\sin(x^2)dx$ exists. Make the substitution $t=x^2$, then $x=\sqrt t$ and $dx=\frac{dt}{2\sqrt t}$. We have $$\int_1^A\sin(x^2)dx=\int_1^{A^2}\frac{\sin t}{2\sqrt t}dt=-\frac{\cos A^2}{2\sqrt A}+\frac{\cos 1}2+\frac 12\int_1^{A^2}\cos t\cdot  t^{-3/2}\frac{-1}2dt,$$
and since $\lim_{A\to +\infty}-\frac{\cos A^2}{2\sqrt A}+\frac{\cos 1}2=\frac{\cos 1}2$ and the integral $\int_1^{+\infty}t^{-3/2}dt$ exists (is finite), we conclude that $\int_1^{+\infty}\sin(x^2)dx$ and so does $\int_0^{+\infty}\sin(x^2)dx$. 
This integral is computable thanks to the residues theorem.</p>

==============================
===============================
Question: <p>Completeness is defined as if given $\Sigma\models\Phi$ then $\Sigma\vdash\Phi$.
Meaning if for every truth placement $Z$ in $\Sigma$ we would get $T$, then $\Phi$ also would get $T$. If the previous does indeed exists, then we can prove $\Phi$ using the rules in $\Sigma$.</p>

<p>Soundness is defined as: when given that $\Sigma\vdash\Phi$ then $\Sigma\models\Phi$ , which is the opposite. </p>

<p>Can you please explain the basic difference between the two of them ? </p>

<p>Thanks ,Ron</p>

 
Answer: <p>In brief:</p>

<p>Soundness means that you <em>cannot</em> prove anything that's wrong.</p>

<p>Completeness means that you <em>can</em> prove anything that's right.</p>

<p>In both cases, we are talking about a some fixed system of rules for proof (the one used to define the relation $\vdash$ ).</p>

<p>In more detail: Think of $\Sigma$ as a set of hypotheses, and $\Phi$ as a statement we are trying to prove.  When we say $\Sigma \models \Phi$, we are saying that $\Sigma$ <em>logically implies</em> $\Phi$, i.e., in every circumstance in which $\Sigma$ is true, then $\Phi$ is true.  Informally, $\Phi$ is "right" given $\Sigma$.</p>

<p>When we say $\Sigma \vdash \Phi$, on the other hand, we must have some set of rules of proof (sometimes called "inference rules") in mind.  Usually these rules have the form, "if you start with some particular statements, then you can derive these other statements".  If you can derive $\Phi$ starting from $\Sigma$, then we say that $\Sigma \vdash \Phi$, or that $\Phi$ is provable from $\Sigma$.  </p>

<p>We are thinking of a proof as something used to convince others, so it's important that the rules for $\vdash$ are mechanical enough so that another person or a computer can <em>check</em> a purported proof (this is different from saying that the other person/computer could <em>create</em> the proof, which we do <em>not</em> require).</p>

<p>Soundness states: $\Sigma \vdash \Phi$  implies $\Sigma \models \Phi$. If you can prove $\Phi$ from $\Sigma$, then $\Phi$ is true given $\Sigma$.  Put differently, if $\Phi$ is not true (given $\Sigma$), then you can't prove $\Phi$ from $\Sigma$.  Informally: "You can't prove anything that's wrong."</p>

<p>Completeness states: $\Sigma \models \Phi$ imples $\Sigma \vdash \Phi$.  If $\Phi$ is true given $\Sigma$, then you can prove $\Phi$ from $\Sigma$.  Informally: "You can prove anything that's right."</p>

<p>Ideally, a proof system is both sound and complete.</p>

==============================
===============================
Question: <p>I came across the following challenging problem in my self-study:</p>

<p>Let $f: \mathbb{R} \rightarrow \mathbb{R}$ be continuous. Then the set of points where $f$ is differentiable is a measurable set.</p>

<p>I am having trouble thinking of where to begin in proving this result, and wanted to see if anyone visiting had some suggestions on how to proceed.</p>

 
Answer: <p>Here's an attempt to salvage Matthew Pancia's solution, which unfortunately depended on an <em>uncountable</em> union over all possible derivatives.</p>

<p>Given $f$ we can define, in the obvious way, a continuous function $F:\mathbb R\times(\mathbb R\setminus 0)\to \mathbb R$ such that $f$ is differentiable at $x$ exactly when $\lim_{h\to 0} F(x,h)$ exists.
The usual formalization of this is
$$\exists y:\forall\varepsilon:\exists \delta:\forall h: |h|&lt;\delta\Rightarrow |F(x,h)-y|&lt;\varepsilon$$
Classically all of the variables here are real, but it is easy to see that we can restrict $\varepsilon$ and $\delta$ to $\mathbb Q$ without changing the meaning. We can also restrict $h$ to $\mathbb Q$ because $F$ is continuous. However, it is essential that $y$ can be an arbitrary real, because otherwise we would be looking for points where $f$ is differentiable <em>with rational derivative</em>, which is something quite different.</p>

<p>However, we can also formalize the existence of a limit like
$$\forall\varepsilon:\exists \delta:\exists Y:\forall h: |h|&lt;\delta \Rightarrow |F(x,h)-Y|&lt;\varepsilon$$
This works because $\mathbb R$ is complete; it is essentially the same as changing "has a limit" about a <em>sequence</em> to "is Cauchy". The arguments that $\varepsilon$, $\delta$ and $h$ can be restricted to the rationals work as before, but now $Y$ can also be taken to be a rational in each case.</p>

<p>For each particular choice of $\varepsilon$, $\delta$, $Y$, and $h$, the set of $x$ such that $|h|&lt;\delta\Rightarrow |F(x,h)-Y|&lt;\varepsilon$ is open and therefore Borel.</p>

<p>Now handle each of the quantifiers from the inside out: For each choice of $\varepsilon$, $\delta$, and $Y$, the set of $x$ such that
$$\forall h: |h|&lt;\delta \Rightarrow |F(x,h)-Y|&lt;\varepsilon$$
is a countable intersection of Borel sets and therefore Borel. For each choice of $\varepsilon$ and $\delta$ the set of $x$ such that
$$\exists Y:\forall h: |h|&lt;\delta \Rightarrow |F(x,h)-Y|&lt;\varepsilon$$
is a countable union of Borel sets and therefore Borel. And so forth. At the top we find that the set of points of differentiability is Borel and thus in particular measurable.</p>

==============================
===============================
Question: <p>How many pairs of positive integers $(a, b)$ such that $a!+b! = a^b$?</p>

<p>A straight forward brute-force reveals that $(2,2)$ and $(2,3)$ are solutions and this seems to be the only possible solutions, I was just wondering how could we prove this.</p>

 
Answer: <p>We first show that $a \leq b$.</p>

<p>Assume by contradiction that $a &gt;b$. Then </p>

<p>$$a^b=b!( a(a-1)...(a-b+1) +1) \,.$$</p>

<p>Thus $a(a-1)...(a-b+1) +1 | a^b$. But $gcd(a,a(a-1)...(a-b+1) +1)=1$ thus  $gcd(a^b,a(a-1)...(a-b+1) +1)=1$. This shows that $a(a-1)...(a-b+1) +1=1$ which is not possible since $a&gt;b$.</p>

<hr>

<p>We now prove that $a \leq 2$.</p>

<p>Since $a \leq b$ than $a!| a!+b!=a^b$.</p>

<p>Assume by contradiction that $a &gt; 2$. Then, by Bertrand Postulate, there exists a prime $p$ so that $p|a!$ and $p$ doesn't divide $a$. Hence $p|a!$ but $p$ doesn't divide $a^b$, contradiction.</p>

<p>We proved that $a=2$, now the rest is easy.</p>

==============================
===============================
Question: <p>I'd like your help with proving that
$$\int_0^1 \frac{\ln x }{x-1}d x=\sum_{n=1}^\infty \frac{1}{n^2}.$$
I tried to use Fourier series, or to use a power series and integrate it twice but it didn't work out for me.</p>

<p>Any suggestions?</p>

<p>Thanks!</p>

 
Answer: <p>Hint: use the substitution $u=1-x$ to obtain
$$
I:=\int_{0}^{1}\frac{\ln x}{x-1}dx=-\int_{0}^{1}\frac{\ln \left( 1-u\right) 
}{u}\,du
$$</p>

<p>and <a href="http://en.wikipedia.org/wiki/Taylor_series#List_of_Maclaurin_series_of_some_common_functions">the following Maclaurin series</a>
$$
\ln \left( 1-u\right) =-u-\frac{1}{2}u^{2}-\frac{1}{3}u^{3}-\ldots -\frac{
u^{n+1}}{n+1}-\ldots\qquad(\left\vert u\right\vert &lt;1) 
$$</p>

==============================
===============================
Question: <p>In this post, all vector spaces are assumed to be real or complex.</p>

<p>Let $(X, ||\cdot||)$ be a Banach space, $Y \subset X$ a closed subspace. $Y$ is called $\underline{\mathrm{complemented}}$, if there is a closed subspace $Z \subset X$ such that $X =Y \oplus Z$ as topological vector spaces.</p>

<p>If $H$ is a Hilbert space every closed subspace $Y$ is complemented; the orthogonal complement $Y^{\bot}$ is a closed subspace of $H$ and we have $H=Y \oplus Y^{\bot}$. A famous theorem of Lindenstrauß and Tzafriri (which can be found in their article "On the complemented subspaces problem", Isreal Journal of Mathematics, Vol. 9, No.2, pp. 263-269) asserts that the converse is true as well. More precisely, if $(X, ||\cdot||)$ is a Banach space such that every closed subspace is complemented then $||\cdot||$ is induced by a scalarproduct, i.e. $(X,||\cdot||)$ is a Hilbert space.</p>

<p>Now to my question. Can you give me an example of a Banach space $(X,||\cdot||)$, which is not a Hilbert space, and of a closed subspace $Y \subset X$ which is not complemented? It is easily seen that $Y$ must be both infinite-dimensional and infinite-codimensional, for every finite-dimensional and every (closed) finite-codimensional subspace is complemented.</p>

<p>I thought about something like $c_{0} \subset (\ell^{\infty}, ||\cdot||_{\infty})$ the closed subspace of null sequences in the Banach space of bounded sequences but couldn't produce a proof that no closed complement exists in that case. Can you help me either proving that $c_{0}$ is not complemented (if that's true at all) or by giving me a different example?</p>

 
Answer: <p>Try the following article "A Survey of the Complemented Subspace Problem":
<a href="http://m.mathnet.or.kr/mathnet/kms_tex/986009.pdf">http://m.mathnet.or.kr/mathnet/kms_tex/986009.pdf</a></p>

<p>Your suspicion about $c_0$ is correct.  A couple of other examples: The disc algebra (those functions in $C(\mathbb{T})$ which are restrictions of functions analytic in the open unit disc) is closed in $C(\mathbb{T})$ but not complemented.  Similarly, in $L^1(\mathbb{T})$, the subspace $H^1(\mathbb{T})$ consisting of functions whose negative Fourier coefficients vanish is closed but not complemented.  See Rudin's <em>Functional Analysis</em> (the proof isn't very easy).</p>

==============================
===============================
Question: <p>Is a set of convex functions closed under composition? I don't necessarily need a proof, but a reference would be greatly appreciated.</p>

 
Answer: <p>In general, the answer is negative.</p>

<p><strong>Counterexample</strong>: Let $f(x) = e^{-x}$ on $[0,\infty)$. Then $f$ is convex, but $f \circ f$ is concave. (Check derivatives.)</p>

<p>However, if we add an additional assumption, then we can get the desired result.</p>

<p><strong>Lemma</strong>: Let $f_1,\ldots,f_n$ be convex <em>nondecreasing</em> functions. Then $f_1 \circ \cdots \circ f_n$ is convex (and nondecreasing).</p>

<p><em>Proof</em>: Here is a proof for the case where each of the $f_i$ are twice-differentiable. We can show it by induction. Let $g_n = f_1 \circ \dots \circ f_n$. Suppose that $g_n$ is convex and nondecreasing. Then, $g_{n+1} = g_n \circ f_{n+1}$. But, two applications of the chain rule yield
$$
{g&#39;\!\!}_{n+1} = ({g&#39;\!\!}_n \circ f_{n+1}){f&#39;\!\!}_{n+1} \geq 0\&gt;,
$$
and,
$$
{g&#39;&#39;\!\!}_{n+1} = ({g&#39;&#39;\!\!}_n \circ f_{n+1})({f&#39;\!\!}_{n+1})^2 + ({g&#39;\!\!}_n \circ f_{n+1}){f&#39;&#39;\!\!}_{n} \geq 0 \&gt;,
$$
and so the stated result follows.</p>

==============================
===============================
Question: <p>In my solution to <a href="https://math.stackexchange.com/questions/30514/x-y-are-integers-satisfying-2x2-1-y15-show-that-5-mid-x">this MSE problem</a>, I noted that $2x^2-1=y^5$ is unlikely to have
solutions in integers with $y&gt;1$. Recently, I've tried to find a proof, without success.</p>

<p>Following Thomas Andrews's suggestion (see his solution to the same problem), we start by writing $1-2x^2=(-y)^5$. Working in the ring $\mathbb{Z}[\sqrt{2}]$ we can factorize this 
as $$(1-x\sqrt{2})(1+x\sqrt{2})=\text{ a fifth power }.$$ 
After showing  that $1-x\sqrt{2}$ and $1+x\sqrt{2}$ are relatively prime
(always working in $\mathbb{Z}[\sqrt{2}]$), the proposed equation 
would force $$1+x\sqrt{2}=u(a+b\sqrt{2})^5$$ for some integers $a,b$ and some unit $u$.</p>

<p>The group of units in $\mathbb{Z}[\sqrt{2}]$ is given by $\pm (1+\sqrt{2})^n$ for $n\in \mathbb{Z}$.
A minus sign could be absorbed into the fifth power, so we only need to show that 
$$1+x\sqrt{2}=(1+\sqrt{2})^\delta(a+b\sqrt{2})^5$$ for some integers $a,b$ and $0\leq \delta\leq 4$ forces $|x|\leq 1$. Here I am following the method 
described by Adrián Barquero <a href="https://math.stackexchange.com/questions/30457/x348-y4-does-not-have-integer-solutions">in this MSE question</a> for dealing with an infinite group of units.   </p>

<p>For $\delta=0$, it is pretty straightforward but for $\delta=1$, I'd need to show that 
$$1= a^5+20 a^3 b^2+20 a b^4+10 a^4b+40a^2b^3+8b^5$$ is not possible, excepting the 
trivial solution $a=1$ and $b=0$. I haven't made any progress with this, or the other 
similar expressions we get when $\delta=2,3,4$. I'm stuck here, and this problem seems to me to be as 
difficult as the original question.  </p>

<p><strong>Question:</strong> Can the method outlined here be pushed through to give a full solution,
or does this problem require higher level approaches? </p>

<p>I'm clearly out of my depth with algebraic number theory, so any suggestions or references that are suitable for amateurs will be greatly appreciated. </p>

<p><strong>Update (Feb. 20)</strong> I have followed Ewan's suggestion and tested all the cases $\delta=0,1,2,3,4$ with Sage and there really are no solutions with $y&gt;1$. I will wait a couple of days before rewarding the bounty in case an elementary solution is given. Otherwise, it will go to Ewan.    </p>

 
Answer: <p>The answer to your question is YES, the method can be pushed to a full solution, if you are willing to rely on some standard number theory software (see below). Of course you may still ask for a computer-free proof, that unfortunately may not exist because of the horribly complicated computations involved.</p>

<p>You asked about the equation $Q(a,b)=1$, where $Q(a,b)=a^5 + 10ba^4 + 20b^2a^3 + 40b^3a^2 + 20b^4a + 8b^5$. This is a Thue equation, which can be solved by a one-liner in GP and other software : just type</p>

<p>thue(thueinit(a^5 + 10*a^4 + 20*a^3 + 40*a^2 + 20*a + 8,1),1)</p>

<p>and, lo and behold, GP tells you that the only solution is (a=1,b=0), just as you guessed.
    You can download and install GP on your computer, or, if you are lazy, just use GP directly online at <a href="http://www.sagemath.org/">http://www.sagemath.org/</a></p>

<p>If $\zeta$ denotes the unique real root of $Q(1,t)=0$, and $\cal O$ denotes the ring of integers of the number field ${\mathbb Q}(\zeta)$, the equation $Q(a,b)=1$ reduces to the problem of finding a unit in $\cal O$ of the form $a+b\zeta$ where $a$ and $b$ are integers.</p>

==============================
===============================
Question: <blockquote>
  <p>Is there an explicit isomorphism between $L^\infty[0,1]$ and
  $\ell^\infty$?</p>
</blockquote>

<p>In some sense, this is a follow-up to my answer to <a href="https://math.stackexchange.com/q/97126/">this question</a> where the non-isomorphism between the spaces $L^r$ and $\ell^s$ for $1 \leq r,s \lt \infty$, unless $r$ and $s$ are both two was discussed (among other things).</p>

<p>There is the somewhat surprising fact that the Banach spaces $X = L^\infty[0,1]$ and $Y = \ell^\infty$ are
isomorphic. More precisely, there are mutually inverse bounded linear
maps $T:  X \to Y$ and $S: Y \to X$ (see below for a proof of
existence). </p>

<blockquote>
  <p>Is there a direct and explicit way to prove this? In other words: I'm wondering
    whether there is an explicit and natural expression for either $S$ or $T$.</p>
</blockquote>

<p>Here's the argument I know: Using Pe&#322;czy&#324;ski's decomposition technique one can prove that
$X = L^\infty$ and $Y = \ell^\infty$ are isomorphic as Banach spaces:</p>

<ol>
<li><p>Choose a countable partition $[0,1] = \bigcup_{n=0}^\infty E_n$
into disjoint sets of positive measure and send $(x_n)_{n \in
\mathbb{N}} \in \ell^\infty$ to $\sum_{n=0}^\infty x_n [E_n]$ to get
an isometric embedding $i: Y \hookrightarrow X$. Since $\ell^\infty$
is injective, its image is complemented, in particular, this yields a
decomposition $X \cong Y \oplus \widetilde{Y}$.</p></li>
<li><p>Choose a dense sequence $(f_n)_{n \in \mathbb{N}}$ of the unit sphere of $L^1[0,1]$. For
$h \in L^\infty[0,1]$ let $j(h) = \left( \int f_n \, h \right)_{n \in
\mathbb{N}} \in \ell^\infty$ to get an isometric map $j: L^\infty[0,1] \to
\ell^\infty$. Since $L^\infty[0,1]$ is injective, its image is
complemented in $\ell^\infty$, so this yields a
decomposition $Y \cong X \oplus \widetilde{X}$.</p></li>
<li><p>Observe that $X \cong X \oplus X$ since $L^\infty[0,1] =
L^\infty[0,1/2] \oplus L^\infty[1/2,1] \cong L^\infty [0,1] \oplus
L^\infty [0,1]$ and $Y \cong Y \oplus Y$ by decomposing $\mathbb{N}$
into the sets of even and odd numbers. Thus, Pe&#322;czy&#324;ski's argument yields:
$$X \cong Y \oplus \widetilde{Y} \cong (Y \oplus Y) \oplus
\widetilde{Y} \cong Y \oplus (Y \oplus \widetilde{Y}) \cong Y \oplus
X$$
and 
$$Y \cong X \oplus \widetilde{X} \cong (X \oplus X) \oplus
\widetilde{X} \cong X \oplus (X \oplus \widetilde{X}) \cong X \oplus
Y$$
so that $X \cong Y \oplus X \cong X \oplus Y \cong Y$.</p></li>
</ol>

<p>Of course, one can trace through this argument and &ldquo;construct&rdquo; an  isomorphism, but the resulting maps are rather messier than what I'm looking for. A further deficit of this argument is that the appeal to injectivity properties makes this inherently non-constructive.</p>

<p>Any simplifications of this argument or pointers to the literature would be welcome.</p>

 
Answer: <p>Suppose $T: L^\infty \to \ell^\infty$ is your isomorphism.   Looking at this coordinatewise, this corresponds to a bounded sequence $\phi_n$ of bounded linear functionals on $L^\infty$ such that</p>

<p>1) there is $\epsilon &gt; 0$ such that $\max_n |\phi_n(f)| \ge \epsilon \|f\|_\infty$ for all $f \in L^\infty$</p>

<p>2) For every bounded sequence $t_n$ of reals there is $f \in L^\infty$ such that $\phi_n(f) = t_n$.</p>

<p>As far as I know, the only really "constructible" bounded linear functionals on $L^\infty$ are of the form
$f \to \int_0^1 f(x) g(x)\ dx$ where $g \in L^1$.  If all $\phi_n$ were of this form, say
$\phi_n(f) = \int_0^1 f(x) g_n(x)\ dx$, then $T^*$ would map $\ell^1$ (as a closed subspace of $(\ell^\infty)^*$) one-to-one to a closed subspace $V$ of $L^1[0,1]$, i.e. for any 
$y \in \ell^1$ and $f \in L^\infty$, $(T^* y)(f) = y(Tf) = \sum_n y_n \phi_n(f) = \int_0^1 \left(\sum_n y_n g_n(x)\right) f(x)\ dx$ where $\sum_n y_n g_n \in L^1$.
Now $$V^\perp = \{f \in L^\infty: \int_0^1 f(x) g(x)\ dx = 0 \text{ for all } g \in V\}
= (T^*)^{-1}(\ell^1)^\perp = \{0\}$$
and then $V = L^1$.  But we know $\ell^1$ and $L^1[0,1]$ are not isomorphic, so this is impossible.  That says that any isomorphism of $L^\infty$ onto $\ell^\infty$ must involve some of the "exotic" linear functionals on $L^\infty$.  </p>

==============================
===============================
Question: <p>I've been using Spivak's book for a while now and I'd like to know what is the formal difference between a Theorem and a Lemma in mathematics, since he uses the names in his book. I'd like to know a little about the ethymology but mainly about why we choose Lemma for some findings, and Theorem for others (not personally, but mathematically, i.e. why should one classify a finding as lemma and not as theorem). It seems that Lemmas are rather minor findings that serve as a keystone to proving a Theorem, by that is as far as I can go.</p>

<p><strong>NOTE</strong>: This <a href="https://math.stackexchange.com/questions/25639/lemma-proposition-theorem-which-one-should-we-pick">question</a> doesn't address my concern, so please avoid citing it as a duplicate.</p>

 
Answer: <p>First off there is no "formal difference" between a theorem and a lemma. Formally, if you view mathematics from the perspective of set theory (<a href="http://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory">ZFC</a>), you must conclude that anything commonly called a "lemma" in the literature is by definition "a theorem of ZFC," i.e. a finite sequence of true formulas of ZFC which flow logically from one formula to the next ending on a formula representing the statement of the theorem. </p>

<p>So, lemmas are invoked with literary freedom that it be understood that they really are theorems, but somehow "little ones". But why bother?</p>

<p>A lemma comes typically in two forms: (i) a useful trick or (ii) a technical step in a proof. Let me demonstrate some examples.</p>

<p>A useful trick in real analysis is called "<a href="http://en.wikipedia.org/wiki/Fatou%27s_lemma">Fatou's Lemma</a>," which helps us interchange limit operations and integrals. Very roughly, it states that</p>

<p>"if $\displaystyle\lim_{n \rightarrow \infty} f_n(x) \rightarrow f(x)$ for all $x$, then </p>

<p>$$\int \lim f_n(x) dx = \int f(x) dx \leq \lim \displaystyle\int f_n(x) dx ,&quot;$$</p>

<p>which, it turns out, becomes "half of the work" in proving a lot of very useful and frequently used inequalities like the <a href="http://en.wikipedia.org/wiki/Monotone_convergence_theorem#Lebesgue.27s_monotone_convergence_theorem">Montone Convergence Theorem</a> and Lebesgue's <a href="http://en.wikipedia.org/wiki/Dominated_convergence_theorem">Dominated Convergence Theorem</a>. On its own, Fatou's Lemma is not so remarkable, and it quickly becomes a minor routine step in very major and fundamental theorems in real analysis -- this is why it is itself a lemma, not a theorem. </p>

<p>Another good example of a theorem of the (i) type is "<a href="http://en.wikipedia.org/wiki/Zorn%27s_lemma">Zorn's lemma</a>". Zorn's lemma is a technical statement about <a href="http://en.wikipedia.org/wiki/Partially_ordered_set">partially ordered sets</a> but it is invoked frequently in proofs studying <a href="http://en.wikipedia.org/wiki/Ideal_%28ring_theory%29">ideals</a> in ring theory (I'm sure it has many more uses but I'm unfamiliar with them). </p>

<p>The strange thing about Zorn's lemma is that it is logically equivalent to the <a href="http://en.wikipedia.org/wiki/Axiom_of_choice">Axiom of Choice</a>, i.e. from Zorn's lemma you can prove the Axiom of Choice and from the Axiom of Choice you can prove Zorn's lemma. In other words, if you studied the axioms of set theory but instead of assuming the axiom of choice you assumed Zorn's Lemma <em>as an axiom</em> (let's call this Zorn's Axiom for now), then you could eventually deduce the Axiom of Choice (perhaps Lemma of Choice?) as a consequence of Zorn's Axiom. So Zorn's lemma is a lemma ONLY BECAUSE we assume the Axiom of Choice rather than Zorn's lemma as an axiom of standard set theory: it is a lemma only because of how we choose to organize mathematics.</p>

<p>A type (ii) lemma is something highly technical that, if proven in the middle of the theorem you <em>really are trying to</em> prove, you may have difficulty getting back on track since it takes too long. This happens ALL THE TIME in mathematics. Here is an example I came across recently from the proof of Dirichlet's theorem on arithmetic progressions in Tom Apostol's "Introduction to Analytic Number Theory":</p>

<p><strong>Theorem (Dirichlet's Theorem):</strong> If $h$ and $k$ are relatively prime integers, then there are infinitely many primes in the arithmetic progression $\{hn+k \colon n = 1,2,3,\ldots\}$.</p>

<p>To prove this theorem, he proves a number of lemmas, such as</p>

<p><strong>Lemma 7.4:</strong> If $x &gt; 1$ we have</p>

<p>$$\displaystyle\sum_{p \leq x; p \equiv h (mod k)} \frac{\log p}{p} = \frac{1}{\phi(k)} \log x + \frac{1}{\phi(k)} \displaystyle\sum_{r=2}^{\phi(k)} \overline{\chi_r(h)} \displaystyle\sum_{p \leq x} \frac{\chi_r(p)\log p}{p} + \mathscr{O}(1),$$</p>

<p>and</p>

<p><strong>Lemma 7.5</strong> For $x &gt; 1$ and $\chi \neq \chi_1$, we have</p>

<p>$$\displaystyle\sum_{p \leq x} \frac{\chi(p)\log p}{p} = -L_{\chi}&#39;(1) \displaystyle\sum_{n \leq x} \frac{\mu(n)\chi(n)}{n} + \mathscr{O}(1),$$</p>

<p>and so forth. He has, in total, about 5 or 6 such lemmas which are steps in the proof of the theorem stated above. The reason these things, while complicated and substantial (far more than Fatou's lemma!), are called lemmas, is that if you began proving Dirichlet's Theorem and proved these in the middle of that proof, you would easily get lost.</p>

<p>So really, what a lemma is to you is whatever you want it to be. It is a word that exists in our vocabulary that is part of the proper <em>name</em> of a concept like Zorn's lemma or it can be simply a word to promote a more readable exposition. </p>

==============================
===============================
Question: <p><strong>EDIT:</strong> </p>

<p>No answer addresses the "bottleneck" question. It's not surprising to me because the question is vague. But I would like to know whether that is indeed the reason, or perhaps something else. The question is interesting to me and I would be grateful for <em>any</em> help with it.</p>

<p><strong>MAIN PART:</strong></p>

<p>Unfortunately, there will be a bit of vagueness in this question because of its nature and because of my limitations. I would like to ask for your understanding and help with the formulation, if they're possible.</p>

<p>I know (although without knowing the proof) that the consistency of ZF or ZFC cannot be proven within these theories, but their inconsistency can if they are inconsistent. I have read -- to my relief -- that it is considered unlikely that they are inconsistent. I would like to understand this statement better. </p>

<p>One simple argument that comes to mind is that no contradiction has been found so far, even though the theories have been extensively researched. But this alone seems a bit weak to me. The space of all provable statements in ZF or ZFC is clearly infinite. I have noticed that when mathematicians make statements about the likelihood of the truth of statements about elements of infinite classes, they usually give finer arguments than just the truth of the statement for the elements of some finite subclass. For example, many mathematicians seem to believe that Goldbach's conjecture is true, and they base their belief on theorems about the distribution of prime numbers in natural numbers. </p>

<p>Are there any arguments of this kind (unfortunately, I don't seem to be able to define what "this kind" means precisely here) for there not being a contradiction in ZF or ZFC? I've been thinking about how it could happen that there would actually <em>be</em> a contradiction in, say, ZF. I think we could define the "length" of a theorem in ZF to be the minimal number of symbols in a proof of the theorem. (Please tell me if there is something wrong with such a definition.) If we assume that ZF is inconsistent, then the proof of its inconsistency has a finite length, say $n$. For every natural number $k$ there is a finite number of theorems of length at most $k$, so we should be able to tell when we have proven all theorems of length at most $k$. The mathematical community has proven many theorems in ZF. Is it known how far we have gotten in this scale? For example, have we gotten past $k=10$? Let $m$ be the greatest natural number such that all theorems of length at most $m$ are known. Clearly, $n$ would have to be greater than $m$.</p>

<p>But I think many theorems must have been proven with length greater than $m$. Can we meaningfully talk about the chance of hitting the proof of the contradiction of ZF by making random correct reasonings of length $\geq n$? I've been trying to define an "inference bottleneck" that could cause the contradiction to be hard to hit, but I've failed. Since I haven't defined it, it may be difficult or impossible to understand what I mean by "inference bottleneck", but I hope it's not. I mean a theorem that can be proven by only a "small" number of reasonings, only I have trouble saying exactly in comparison to what it should be small.</p>

<p>I would like to ask if it actually is possible to define such "bottlenecks" and if so, would it be possible to prove that they cannot be too narrow? I'm thinking such a theorem could be a more convincing argument for there not being a contradiction in ZF.</p>

<p>And the more general question, to reiterate it, is what other arguments mathematicians (or philosophers?) give for ZF and ZFC being consistent. The belief in the consistency of those theories seems to me to be very strong among mathematicians, even though they tend to be very careful about saying things about other unproven statements. Why is that?</p>

 
Answer: <p>ZFC is meant to capture a certain notion, the <strong>cumulative hierarchy</strong> of sets. For this justification to make sense you need to think of "well ordering" or "ordinal" as a pre-existing mathematical concept, not one based on ZFC. This justification is explained at more length in Shoenfield's article in the <em>Handbook of Mathematical Logic</em> from 1977, and elsewhere. It dates back to the early 20th century. </p>

<p>Assuming that we have a collection of "ordinals" $O$, which is downward closed and has minimal element $0$, we can define a collection $V^O$ as follows. </p>

<ul>
<li><p>$V^O(0) = \emptyset$</p></li>
<li><p>If $\alpha + 1$ is in $O$ then $V^O(\alpha + 1)$ is the powerset $V^O(\alpha)$</p></li>
<li><p>If $\lambda$ is a limit ordinal in $O$ then $V^O(\lambda)$ is the powerset of $\bigcup_{\alpha &lt; \lambda} V^O(\alpha)$</p></li>
</ul>

<p>Finally, $V^O$ itself is $\bigcup_{\alpha \in O} V^O(\alpha)$. The informal way to put this is: think of the elements of $O$ as "stages". Then a set will be put into $V^O$ at stage $\alpha$ if all of its elements have already appeared at stages earlier than $\alpha$. </p>

<p>We can ask: which axioms of set theory does $V^O$ satisfy? </p>

<ul>
<li><p>$V^O$ will contain the empty set as long as $O$ has at least two elements, because the empty set appears in $V^O(1)$.</p></li>
<li><p>$V^O$ will satisfy the separation axiom. To see this, assume $z \in V^O$ and that we want to prove that $y = \{x \in z : \phi(x)\}$ is in $V^O$. Well, $z$ was formed at some stage, so all the elements of $z$ were formed at earlier stages. But this means that all the elements of $y$ were also formed at stages earlier than the one where $z$ was formed, so $y$ will be formed no later than $z$. </p></li>
<li><p>Every subset of a set $z$ is formed at the same time that $z$ is formed. Therefore, the powerset of $z$ will be formed at the stage after $z$ is formed, assuming there is a next stage. So if $O$ has no maximal element then $V^O$ satisfies the axiom of power set. </p></li>
</ul>

<p>These examples suggest that the axioms that are satisfied by $V^O$ will depend on how "long" $O$ is.  Indeed, it turns out that if we assume sufficient properties about $O$ then we can argue in a similar way that $V^O$ satisfies all the ZFC axioms. In particular, if we let $O$ contain <em>all</em> the ordinals, then $V^O$ will satisfy ZFC, and we usually just write $V$ instead of $V^O$ in this case. This $V$ based on all the ordinals will be a proper class, not a set. </p>

<p>This argument cannot be captured in ZFC itself, although various properties of the cumulative hierarchy can be captured in ZFC. But the argument does give some motivation for why ZFC should be consistent, by giving a conception of sets (as elements of $V$) which seems intuitively reasonable. Indeed, it appears that all we need to have in order to form $V$ is a well-determined collection of ordinals, the ability to take powersets, the ability to take unions, and the ability to iterate these operations along the ordinals. </p>

<p>So where could ZFC be inconsistent, even if this argument is correct? One place is the separation axiom. In the argument above we assumed that $\{x \in z : \phi(x)\}$ actually does define a subset of $z$ whenever $\phi$ is a formula of set theory. If somehow there were formulas $\phi$ which do not determine subsets of $z$, our argument for why the separation axiom holds in $V$ would not go through. There is a certain sense in which the argument above is proving the consistency of second-order ZFC rather than first-order ZFC, just as the informal proof of consistency of Peano arithmetic that says "$\mathbb{N}$ is a model" is really a consistency proof for second-order PA rather than first-order PA. </p>

==============================
===============================
Question: <p>I had some thoughts about how to prove the turing completeness of a programming language. I came to the conclusion, that if you could write a program that is able to parse a turing machine program, both should be equivalent as you could execute every turing machine program with that parser written in that language. Therefore the language must be turing complete. Am I right? What are other ways of proving turing completeness?</p>

 
Answer: <p>A programming language is Turing complete if and only if we can write every computable function in this language. So proving that we can emulate a turing machine is a good way to prove that a language is turing complete, by the way this is not the only way, another way can be to prove that your language is able to describe all the <a href="http://en.wikipedia.org/wiki/%CE%9C-recursive_function">$\mu$-recursive functions</a>. To do that you just have to prove that you can write some programs that compute some special functions (the constant zero function, the successor operation and the projection functions) and shows that you can write the operations of composition of functions and $\mu$-recursion (primitive recursion being a special case of $\mu$-recursion) in term of operations of programs.</p>

<p>Hope this helps.</p>

==============================
